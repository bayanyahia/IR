{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Function to preprocess text\n",
        "# Function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    filtered_tokens = [word for word in tokens if word.isalpha()]\n",
        "    preprocessed_text = ' '.join(tokens)\n",
        "    return preprocessed_text\n",
        "\n",
        "\n",
        "# Define directory containing documents\n",
        "docs_dir = '/content/drive/MyDrive/Colab Notebooks/data/fb'\n",
        "\n",
        "# Initialize corpus\n",
        "corpus = \"\"\n",
        "\n",
        "# Iterate over each document\n",
        "for filename in glob.glob(os.path.join(docs_dir, '*.txt')):\n",
        "    with open(filename, 'r', encoding='utf-8') as file:\n",
        "        content = file.read()\n",
        "        corpus += content\n",
        "\n",
        "# Preprocess the corpus\n",
        "preprocessed_corpus = preprocess_text(corpus)\n",
        "\n",
        "# Print the preprocessed corpus\n",
        "print(preprocessed_corpus)\n",
        "\n",
        "# Tokenize the corpus\n",
        "tokens = word_tokenize(preprocessed_corpus)\n",
        "\n",
        "# Remove non-alphabetic characters\n",
        "tokens = [word for word in tokens if word.isalpha()]\n",
        "\n",
        "# Calculate token statistics\n",
        "total_tokens = len(tokens)\n",
        "tokens_with_synsets = [word for word in tokens if wordnet.synsets(word)]\n",
        "num_tokens_with_synsets = len(tokens_with_synsets)\n",
        "\n",
        "print(\"Total number of tokens:\", total_tokens)\n",
        "\n",
        "def create_dictionary(tokens):\n",
        "    token_dict = {}\n",
        "    for token in tokens:\n",
        "        if token in token_dict:\n",
        "            token_dict[token] += 1\n",
        "        else:\n",
        "            token_dict[token] = 1\n",
        "    return token_dict\n",
        "# Call the function to create the dictionary\n",
        "token_dict = create_dictionary(tokens)\n",
        "\n",
        "# Find the length of the dictionary\n",
        "print(\"Length of token dictionary:\", len(token_dict))\n",
        "\n",
        "from collections import Counter\n",
        "import math\n",
        "import pandas as pd\n",
        "\n",
        "# Function to calculate TF\n",
        "def calculate_tf(corpus_tokens):\n",
        "    # Calculate Term Frequency (TF)\n",
        "    tf = Counter(corpus_tokens)\n",
        "    return tf\n",
        "\n",
        "# Calculate TF for the corpus tokens\n",
        "tf = calculate_tf(tokens)\n",
        "# Convert TF to DataFrame\n",
        "data = {'Token': list(tf.keys()),\n",
        "        'TF': list(tf.values())}\n",
        "df_table = pd.DataFrame(data)\n",
        "top_15_tokens = df_table.sort_values(by='TF', ascending=False).head(15)\n",
        "print(top_15_tokens)\n",
        "\n",
        "print('----------------------stemming--------------------')\n",
        "def preprocess_text1(text):\n",
        "    # Tokenize the text\n",
        "    tokens1 = word_tokenize(text)\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_tokens = [stemmer.stem(word) for word in tokens1 if word.isalpha()]\n",
        "    preprocessed_text1 = ' '.join(stemmed_tokens)\n",
        "    return preprocessed_text1\n",
        "\n",
        "\n",
        "# Preprocess the corpus\n",
        "preprocessed_corpus1 = preprocess_text1(corpus)\n",
        "\n",
        "# Tokenize the preprocessed corpus\n",
        "tokens1 = word_tokenize(preprocessed_corpus1)\n",
        "\n",
        "# Calculate token statistics after removing stop words\n",
        "total_tokens1 = len(tokens1)\n",
        "token_dict1 = create_dictionary(tokens1)\n",
        "num_different_tokens1 = len(token_dict1)\n",
        "\n",
        "# Print token statistics after stop words removal\n",
        "print(\"Total number of tokens after stemming words:\", total_tokens1)\n",
        "print(\"Length of token dictionary after  stemming:\", num_different_tokens1)\n",
        "\n",
        "# Calculate TF for the corpus tokens after stop words removal\n",
        "tf = calculate_tf(tokens1)\n",
        "\n",
        "# Convert TF to DataFrame and print top 15 frequent tokens\n",
        "data1 = {'Token': list(tf.keys()),\n",
        "        'TF': list(tf.values())}\n",
        "df_table = pd.DataFrame(data1)\n",
        "top_15_tokens = df_table.sort_values(by='TF', ascending=False).head(15)\n",
        "print(top_15_tokens)\n",
        "\n",
        "print('----------------------------stop words removal-------------------------')\n",
        "def preprocess_text2(text):\n",
        "    # Tokenize the text\n",
        "    tokens2 = word_tokenize(text)\n",
        "\n",
        "    # Remove stop words and non-alphabetic characters\n",
        "    filtered_tokens2 = [word for word in tokens2 if word.isalpha() and word.lower() not in stop_words]\n",
        "\n",
        "    # Join the filtered tokens back into text\n",
        "    preprocessed_text2 = ' '.join(filtered_tokens2)\n",
        "\n",
        "    return preprocessed_text2\n",
        "# Preprocess the corpus\n",
        "preprocessed_corpus2 = preprocess_text2(corpus)\n",
        "\n",
        "# Tokenize the preprocessed corpus\n",
        "tokens2 = word_tokenize(preprocessed_corpus2)\n",
        "\n",
        "# Calculate token statistics after removing stop words\n",
        "total_tokens2 = len(tokens2)\n",
        "token_dict2 = create_dictionary(tokens2)\n",
        "num_different_tokens2 = len(token_dict2)\n",
        "\n",
        "# Print token statistics after stop words removal\n",
        "print(\"Total number of tokens after removing stop words:\", total_tokens2)\n",
        "print(\"Length of token dictionary after removing stop words:\", num_different_tokens2)\n",
        "\n",
        "# Calculate TF for the corpus tokens after stop words removal\n",
        "tf = calculate_tf(tokens2)\n",
        "\n",
        "# Convert TF to DataFrame and print top 15 frequent tokens\n",
        "data2 = {'Token': list(tf.keys()),\n",
        "        'TF': list(tf.values())}\n",
        "df_table = pd.DataFrame(data2)\n",
        "top_15_tokens = df_table.sort_values(by='TF', ascending=False).head(15)\n",
        "print(top_15_tokens)\n",
        "\n",
        "print('----------------------------case_folding-------------------------')\n",
        "def preprocess_text3(text):\n",
        "    tokens3 = word_tokenize(text)\n",
        "    tokens3 = [word.lower() for word in tokens3 if word.isalpha()]\n",
        "    preprocessed_text3 = ' '.join(tokens3)\n",
        "    return preprocessed_text3\n",
        "\n",
        "# Preprocess the corpus\n",
        "preprocessed_corpus3 = preprocess_text3(corpus)\n",
        "\n",
        "# Tokenize the preprocessed corpus\n",
        "tokens3 = word_tokenize(preprocessed_corpus3)\n",
        "\n",
        "# Calculate token statistics after removing stop words\n",
        "total_tokens3 = len(tokens3)\n",
        "token_dict3 = create_dictionary(tokens3)\n",
        "num_different_tokens3 = len(token_dict3)\n",
        "\n",
        "# Print token statistics after stemming\n",
        "print(\"Total number of tokens after stemming:\", total_tokens3)\n",
        "print(\"Length of token dictionary after stemming:\", num_different_tokens3)\n",
        "\n",
        "# Calculate TF for the corpus tokens after stemming\n",
        "tf = calculate_tf(tokens3)\n",
        "\n",
        "# Convert TF to DataFrame and print top 15 frequent tokens\n",
        "data3 = {'Token': list(tf.keys()),\n",
        "        'TF': list(tf.values())}\n",
        "df_table = pd.DataFrame(data3)\n",
        "top_15_tokens = df_table.sort_values(by='TF', ascending=False).head(15)\n",
        "print(top_15_tokens)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCEUq7ShhYMk",
        "outputId": "029263dc-7ae0-4106-e616-cba6b711fc19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "View metadata , citation and similar papers at core.ac.uk brought to you by 2 . CORE provided by Archive Ouverte en Sciences de I'Information et de la Communication archives-ouvertes Community-based Recommendations on Twitter : Avoiding The Filter Bubble Quentin Grossetti , Cédric Du Mouza , Nicolas Travers > To cite this version : Quentin Grossetti , Cédric Du Mouza , Nicolas Travers . Community-based Recommendations on Twit- ter : Avoiding The Filter Bubble . Web Information Systems Engineering - WISE 2019 , Nov 2019 , Hong-Kong , China . 10.1007/978-3-030-34223-4_14 . hal-02465790 HAL Id : hal-02465790 https : //hal-cnam.archives-ouvertes.fr /hal-02465790 Submitted on 4 Feb 2020 HAL is a multi-disciplinary open access L ’ archive ouverte pluridisciplinaire HAL , est archive for the deposit and dissemination of sci- destinée au dépdt et a la diffusion de documents entific research documents , whether they are pub-_ scientifiques de niveau recherche , publiés ou non , lished or not . The documents may come from émanant des établissements d ’ enseignement et de teaching and research institutions in France or recherche francais ou étrangers , des laboratoires abroad , or from public or private research centers . publics ou privés . Community-based Recommendations on Twitter : Avoiding The Filter Bubble Quentin Grossetti ! , Cédric du Mouza ! , and Nicolas Travers ! ? ! CEDRIC Lab , CNAM Paris , France firstname.lastname @ cnam.fr ? Léonard de Vinci Péle Universitaire , Research Center , Paris La Défense , France nicolas.travers @ devinci.fr Abstract . Due to their success , social network platforms are consid- ered today as a major communication mean . In order to increase user engagement , they rely on recommender systems to personalize individual experience by filtering messages according to user interest and/or neigh- borhood . However some recent results exhibit that this personalization of content might increase the echo chamber effect and create filter bub- bles . These filter bubbles restrain the diversity of opinions regarding the recommended content . In this paper , we first realize a thorough study of communities on a large Twitter dataset to quantify how recommender systems affect users ’ behavior and create filter bubbles . Then we propose the Community Aware Model ( CAM ) to counter the impact of different recommender systems on information consumption . Our results show that filter bubbles concern up to 10 % of users and our model based on similarities between communities enhance recommender systems . Keywords : Twitter - Communities - Filter Bubble - Recommender System 1 Introduction Social networking has become a major way to share and discover information on the Internet . Users generally connect since they know each other in real life or share a common interest . Since received content from the flow is related to peo- ple with whom they are connected to , users may consequently find their opinions constantly echoed back which creates an echo chamber [ 8 ] , that may skew their point of view . Moreover , it has been theorized that this phenomenon is reinforced by recommender systems [ 18 ] massively used to enhance users ’ engagement by personalizing individual experience . Consequently , they tend to focus on highly relevant messages mainly based on users ’ neighborhood and/or interests . Re- cently critics argued that such systems are impoverishing user opportunities to be displayed to diversified information , so called the “ filter bubble ” . The link between Recommender Systems ( RS ) and filter bubbles is not clearly characterized in literature and we particularly target this issue in this paper . So we first extract communities with a traditional community detection algorithm 2 Q. Grossetti et al . in a real Twitter dataset . This algorithm which relies mainly on topological properties ( so not topic-centric ) will group people who are close and strongly connected in the network , because they know each other , are geographically close and/or share common interests . Then we perform analysis to detect filter bubbles by measuring how often messages leave their community of origin and we try to understand how RS focus on content originated from a reduced number of communities . To achieve this we propose to characterize users by a community profile based on their interactions with communities through messages prove- nance . Then we show that recommendations provided by RS may differ from users ’ community profile and generate a filter bubble for some users . Therefore , we advocate the fact that filter bubbles can be characterized by topology-based communities , further works on opinion mining are out of the scope of this article . Our second objective is to tackle this filter bubble effect for these users through a re-ranking of their recommendations to be more respectful of their community profile . Our proposal can be deployed on top of any RS without modifying its implementation . We show that our solution significantly improve the quality of recommendations by matching more closely users ’ community pro- file and by reducing the filter bubble effect at a limited computation cost . In a nutshell , the main contributions of the paper are : 1 . A community analysis to study how information is propagated through com- munities to characterize echo chambers , 2 . A measure and an analysis of the filter bubble effect from respectively a community and a user ’ s point of view , 3 . A novel re-ranking strategy that relies on users ’ community profile and the community network to reduce the filter bubble effect . 2 Related Work Most popular social network platforms such as Facebook , Baidu , Twitter or Insta- gram gather millions of users . To help them find relevant content , these platforms largely rely on RS . Recently , some works have shown that these platforms have to face two simultaneous effects that affect user points of view . First , the “ echo chamber ” phenomenon means that some users tend to consume only information from the same ideological alignment . This leads to biased opinions . The second effect , due to the personalization of content from recommender systems , traps users in a “ filter bubble ” as described by Eli Pariser [ 18 ] . Studies on “ echo chambers ” were initially conducted in social sciences to in- vestigate how people tend to bind with similar people , creating communities and having difficulties to access opposite view points . It has been partially described and analyzed in [ 7,16 ] . They conclude that people tend to choose news articles from sources aligned with their political opinions . [ 3 ] also shows that people tend to connect to each other on social platforms following an homophily behavior , so to bind with similar people . A large study [ 5 ] focusing on filter bubbles and echo chambers states that this phenomenon is not limited to the digital era since social media users only mimic traditional offline reading habits . In short , echo Community-based Recommendations 3 # nodes 2,2M|| # edges 325.5M|| # tweets 3,002M avg . path length ] 3.7|/avg . out-deg . 57.8||max out-deg.| 349K diameter 15|lavg . in-deg . 69.4|/max in-deg . 185K Table 1 : Main features of the Twitter dataset chambers is a natural phenomenon which has existed for a long time before Face- book and the echo chamber on social networks is due to this real-life behavior , homophily , which is only replicated on social platforms . While it is commonly admitted that echo chambers exist , there is no in- disputable evidence of the existence of “ Filter Bubbles ” . Indeed , it is unclear whether recommender system algorithms amplify the echo chamber phenomenon or not . Some studies have tried to quantify this phenomenon . [ 5 ] studied web- browsing habits of 50,000 US-located people . To our knowledge , this is the largest study on filter bubbles and echo chambers phenomena . They observed a coun- terintuitive behavior : users with the highest ideological segregation ” rely more on recommender systems to find new information but also are more exposed to opposite perspectives . Thus , people using recommendation systems ( RS ) are the ones seeing more different points of view . Another study [ 17 ] related to movie recommendations made by the GreupLens team has a similar conclusion . This work on filter bubbles asserts that RS actually lower the chances of being trapped into a filter bubble . Facebook also conducted a similar study [ 1 ] on their algorithm which is used to filter the feed of users . They conclude that it only decreases by 1 % the chances of seeing posts corresponding to opposing views . Models aiming at bursting an echo chamber to create more ” peaceful ” debates on a specific topic , such as gun control or Obamacare , have been presented in [ 6 ] . In this work the authors propose to add edges between people having opposite views in order to reduce controversy in the network . [ 12 ] proposes a model where the user gives a specific point of view in order to see how recommendation change based on this new perspective . A similar idea is developed in [ 8 ] . However , these solutions are difficult to deploy in practice because they rely on the will of the users to change their viewpoints . Our approach largely differs from existing work since it is , to the best of our knowledge , the first approach to use communities as a tool to observe echo chambers and filter bubbles effects , and to propose a re- ranking strategy of the recommendation to reduce the filter bubble phenomenon . 3 Community Analysis In order to estimate the importance of the filter bubbles and echo chambers ’ phenomena induced by recommender systems ’ usage , we first extract communi- ties from the social graph with the traditional Louvain method . Then we try to have a better understanding of the communities these algorithms produce and we study the behavior of users regarding the community they belong to . 4 Q. Grossetti et al . 3.1 Twitter dataset We present here the main characteristics of our Twitter dataset introduced in /anonymous ] . It is based on a connected component extracted from the graph made provided by Kwak et al . [ 14 ] which has been updated since 2017 thanks to the Twitter API * . We collected the incoming edges ( followers ) , out-coming edges ( followees ) and all the tweets published by the associated accounts . Observe that due to the API limit we only retrieved the last 3,200 messages for each node . Table 1 summarizes the main features of the dataset . We can notice that , with more than 2 million users and 3 billion messages , we have a mean number of 1,375 published tweets per user . We detect that around 12 % of these tweets , so on average 150 tweets per user , correspond to a retweet action . Our analysis also exhibits that 92 % of the tweets are never retweeted . It means that recommendations mainly focus on a small part of the messages . As shown in [ 11 ] users tend to have more similar profiles with users within a 2-hop distance in the graph ( called homophily [ 13 ] ) . This homophily has an impact on information propagation : people close to each other in the network tend to have a higher number of retweets in common . 3.2 Communities ’ detection To characterize the echo chamber phenomenon and the information propaga- tion between users , we identify and study communities in our dataset . Scal- able community detection algorithms are proposed in literature , like Infomap , Louvain and Label Propagation . Note that these methods only use the network topology and not topics , user profiles or exchanged content to extract commu- nities . Moreover they associate users to a single community . The Louvain al- gorithm we have adopted is tailored for directed graphs [ 15 , 4 ] . It consequently suits to the Twitter network . It maximizes the modularity of clusters inside the graph that will produce denser components ( 7.e. , maximizing the number of connection triplets ) . However note that we also performed similar work for Infomap and got very similar results . To explain the filter bubble effect , we try to understand the rationale for the formation of a community . We first label the communities according to their main feature ( s ) . Remember that a user belongs to a single * community ” according to the considered community-detection algo- rithms , and that these communities are built by considering only the topology of the underlying social graph . We focus on the 105 more representative commu- nities , z.e. , those with more than 100 users identified by the Louvain method . To determine the labels , we adopt the following three-step process : 1 ) Most followed users inside each community are selected ( most central users ) , 2 ) We find most frequent terms occurring in the tweets of these users and we check important features from their profiles like age , location , language , etc. , 3 ) Based on these two kinds of information we provide the most representative tag for each entity . 3 https : //dev.twitter.com/rest /public Community-based Recommendations 5 Some improvements may be considered like performing named-entity extrac- tion rather than only relying on term frequencies , for instance . However it turned out that our basic strategy provides good labeling since users who have strong common interests , such as ’ Sports ” for instance , are highly connected and form a community we effectively tagged as ” Sports ” . 3.3 . The community network We exploit here the detected communities to enlighten the echo chamber effect . The objective is to quantify how information spreads outside the community to which it has been attached to . We first link a tweet to a community , then we find out how many communities it reaches . This quantification could be seen as a propagation measure inside the social network . This allows us to study the presence of echo chambers at both users and communities level . Community Membership of a Message . To track messages activity ” we need to identify the way to attach messages to a community . Two options can mainly achieve this : a message belongs to the community from which it occurs first or to the community in which it obtained most likes/retweet . It appears that 90 % of retweeted messages obtain a high popularity in the community from which it comes from . The remaining 10 % belong to small com- munities and naturally become famous when they reach larger communities . In the following we decide to identify the message community membership based on the community where it was written initially in order to emphasize the influence of small communities on bigger ones . Correlation Between Popularity and Spread . Now we have commu- nities and messages , we can measure the popularity of messages and how they propagate throughout the community network . Figure 1 shows the distribution of retweeted messages with respect to the number of reached communities . We can see that 80 % of retweeted messages reach at most 2 communities , and among them , half remains internal to the community they belong to . This distribution is characterized by a Power Law : Cx ( with C = 200 , a = 2.2 and min > 1 for probabilities ) . As expected C is really high stating that the probability that a tweet remains in a community is high . According to a , this classical value ( typically between 2 and 3 ) indicates that communities have far connections between each other . This experiment confirms the fact that most of the messages are rarely retweeted while few very popular messages reach high numbers of communities . It underlines the existence of an echo-chamber effect inside communities . According to this analysis , we conclude that most of the tweets hardly ever leave their community , especially if they are not popular . 4 Filtering Bubble The objective is to analyze how recommender systems create or reinforce the echo chamber phenomenon at community and user levels . We study the filter bubble 6 Q. Grossetti et al . — — -— Messages distribution 3 0.25 e 3 EL GraphJet o _—— Power Law “ so P 4 CF a g 0.2 — @ — SimGraph g q Po 3 3 4 ° a 4 5 3 3 : % a g 3 ag a 123 4567 8 9101112 50 100 15 200 Number of reached communities ( Louvain ) Number of recommendations per day per user Fig . 1 : Msg . wrt . # reached communities Fig . 2 : Ratio of intra-community reco effect with three different recommendation systems : GraphJet [ 19 ] proposed by Twitter , Collaborative Filtering [ 2 ] ( called CF ) and SimGraph [ 11 ] . To achieve this , we consider recommendations produced for samples of 25 users randomly extracted from each community obtained by Louvain . 4.1 Community-level approach A global approach to quantify the filter bubble effect is to compute the pro- portion of intra-community recommendations . When the proportion of users ’ recommendations belongs to its own community is too high ( intra-community recommendations , opposite of the diversity ) , it implies that a filter bubble effect could lead to the reinforcement { or apparition ) of an echo chamber effect . In Figure 2 we plot the ratio of intra-community recommendations regarding the number of recommendations proposed per day ( for each user ) . We find out that GraphJet tends to propose less ’ diverse ” recommendations than CF with on average 23 % of intra-community recommendations . This could be explained by the random walk-based algorithm behind GraphJet that would give more opportunities to recommend messages in the neighborhood , which corroborates conclusions of Figure 1 . At the opposite CF computes similarities between users from the whole graph independently from the topology and tends to provide more diversified recommendations than other solutions , in terms of community provenance . SimGraph results are between CF and GraphJet since it mixes both topology and similarity ( ¢.e. , homophily ) . We also notice that independently of the number of recommendations pro- posed , the diversity is constant after 20 recommendations . Consequently , in the following we fix the recommendation number to 20 per day . As expected , in Figure 2 filter bubbles aren ’ t visible due to average values over every user . To study the filter bubble at community scale , we display in Figure 3 the ratio of intra-community recommendations per community along with their size for the CF recommendation algorithm . Community labels come from Section 3.2 . Due to space limitations , we do not display Figures for the other algorithms but they behave similarly . We observe that for all recommendation algorithms , there is a logarithmic correlation between community size and intra-cluster recommen- 5 Ratio of Intra Cluster Reco Community-based Recommendations 7 190785 | 107° F log trend line Rago ean Christian @ Difference of gini scores 103 10 * 10° 0.6 04 } 0.2 0 —0.2 —0.4 —EL GraphJet sz CF H — @ — SimGraph 0 200 400 User rank sorted by difference of Gini scores Cluster Size ( number of users ) Fig . 4 : Diff . of Gini coefficients between Fig . 3 : CF intra-Recommendations likes and recos dations . The rationale is that the bigger a community is , the higher the chances are for its users to receive a recommendation from this community . However this experiment reveals that a global approach isn ’ t sufficient to exhibit a particular community being concerned by a filter bubble . 4.2 Local approach Since we can not detect filter bubbles with a global approach at community- level , we attempt to see whether this phenomenon can be observed at user-level . Therefore , we analyze communities ’ diversity for which recommended tweets are issued from . For this , we apply for each user the Gin ? coefficient [ 9 ] on the aggre- gate number of received recommendations per community . The Gini coefficient measures the ratio of inequalities within a set of values , z.e. , its diversity . Users with high Gini scores seem to be trapped into a filter bubble . It is due to the RS which provides recommendations issued from few different communities . However after analyzing their profiles , we observe that these users have in fact a very specific usage of the platform ( e.g. , football player ’ s account only interact with sports messages ) . Therefore the RS by recommending only sports messages just follow the usage of the user maintaining the echo-chamber effect . Consequently we believe that we must consider users ’ profile in the platform to determine if they are in a bubble or not . We thus consider the difference between user ’ s interactions and RS recommendations . We propose to show this effect by computing the difference between the Gini coefficient of users ’ profile ( list of effectively ” liked ” communities ) and the one from the recommender sys- tem ( list of ” recommended ” communities ) . Results are plotted in Figure 4 . High values mean that the recommendations are too diversified compared to the real user behavior while low values lead to a bubble effect with fewer communities concerned by recommendations compared to the real user behavior . We see that 30 % of the users are faced with less diversified recommendations than their own profile . This effect is mainly due to a frequent behavior of the user who ” likes ” many messages from a particular community and less frequently from ” random ” ones . However , recommender systems focus mostly on this main community and provide recommendations mainly issued from this community . 8 Q. Grossetti et al . 5 CAM - a Community-Aware Model Thanks to this preliminary but essential study , we are now able to detect a filter- bubble effect on users ’ community profile with topology-based communities . We propose in the following our Community-Aware Model whose objective is to reduce the filter-bubble impact . It can be deployed on top of a RS and it enhances it with a new scoring function which permits re-ranking the recommendations . Observe that our approach is consequently independent of the choice of the RS and may be consequently deployed in any existing social network platform . 5.1 Community profiles So consider a user u and a social network where n communities were detected by a community detection algorithm . Let Pu be the user ’ s u community profile represented as a normalized vector : Pu = ( pc1 , pcg , ... , pCn ) where pe ; denotes the rate of messages from the community c ; among all the messages he liked . Suppose that a recommender system RS produces a list of recommenda- tions EReco , , for the user u from which only the top-k items are extracted and presented to u . The main idea is to re-rank LReco , by considering , for each message , its community of origin . The end goal consists in finding a top- & which corresponds more precisely to the user community profile Pu . Note that naive models which attempt to pick up the required number of messages from LReco , , in each community of Pu wouldn ’ t be successful . Indeed , due to too low recommendation scores or to a period where the corresponding community is less active , some communities from a profile Pu are not present ( or insufficiently present ) in LReco , . Besides , with such naive approaches , a message with a high recommendation score which is not issued from a community appearing in Pu will also be discarded , even if the community is topologically and/or thematically closed to , which contributes to the filter bubble effect . Since our community analysis reveals that some communities are themat- ically very close to , we propose that our re-ranking model takes into account this similarity and consequently modifies the scores produced by RS even for messages from communities which are not in Pu . Our model relies on the impact of items on communities called Va and the user ’ s profile Pu . It tries to minimize the distance between Ve and Pu . 5.2 Community similarity score We first need to determine a measure of similarity between communities which takes into account 1 ) topology , 2 ) semantic information and 3 ) flows of informa- tion between these communities . We propose the following similarity measure to estimate how similar two communities can be . Definition 1 . ( Community Similarity Score ) The asymmetric similarity mea- sure between a community c ; and c ; is estimated as follows : sim ( c ; , cj ) = a Links ( cq , > cj ) + B Sem ( ci , c ; ) + y Flow ( a ; > cj ) ( 1 ) Community-based Recommendations 9 where Links is the ratio of the number of links from c ; which are directed to c ; among its outgoing links , Sem represents the similarity ( see Section 6.1 ) between the main topics of c ; and c ; , and Flow corresponds to the link importance which relies on the proportion of circulating tweets ( retweets ) from c ; to c ; . a , 8 and y are constants which can be tuned according to the behavior of the underlying RS ( see Section 6.2 ) in order to target relevance and/or filter bubbles . Based on this similarity measure we can build the Community Similarities Matrix ( CSM = ( sim ) i < i , j < n ) . Observe that this matrix is not symmetric since we consider links ’ direction and information propagation ( flow ) . 5.3 . Community-aware recommendations We consider that each item J is associated to a community score vector T which captures how this item is thematically and topologically close to each community . To compute the vector J of an item J we rely on the community- similarity matrix CSM . So corresponds to the community similarities from column c ; of the CSM matrix to which community J is associated to . Our model intends to propose a set of recommendations U , selected from the recommendation list LReco , produced by RS , with a community score vector Vu which matches as much as possible the user profile Pu . The community score vector Vy of a set of recommendations U is the aggregation of different normalized community score vectors of each item in U : Vy = SO JI /|| > JI . feu feu — Finding the set of recommended items U whose community profile Vj ; matches as much as possible , the profile Pu can be modeled as a distance minimization problem between Vy and Pu : U = argmacttreco , \\Pu - Ve ( 2 ) |U ] =k However , determining the new recommendations based only on the distance with the user profile , regardless of the importance of the recommended con- tent , may lead to recommend content of lower interest for the user . So another objective for our approach consists in the following maximization problem : U =argmakttreco , Y , recom ( u , I ) rev ( 3 ) Ul|=k where recom ( u , I ) denotes the score of item J for user u provided by the RS . Consequently the objective of our re-ranking algorithm is expressed as a multi-objective optimization problem determined by both Equations 2 and 3 . 5.4 Avoiding the filter bubble A traditional strategy to determine a solution to a multi-objective optimization problem is scalarization where no solution satisfies both objectives . Scalarizing is 10 Q. Grossetti et al . Ranking Origin community Score 3-item set and their score 1 A 0.8 { 1,2,3 } 0.81 ) { 1,2,4 } 0.40 2 A 0.7 { 1,2,5 } 0.57 ) { 1,3,4 } 0.41 3 A 0.5 { 1,3,5 } 0.54 ) { 1,4,5 } 0.48 4 B 0.4 { 2,3,4 } 0.42 ) { 2,3,5 } 0.47 5 Cc 0.1 { 2,4,5 } 0.47 ) { 3,4,5 } 0.43 Table 2 : Recommendation scores for Joe Table 3 : Scores for all 3-item combinations an a priori method , which transforms the multi-objective optimization problem into a single-objective optimization problem . To achieve this transformation , we propose to integrate the recommendation score when estimating the community score vector J . Since our objective is to get a high global recommendation score , we attempt to discard first from our recommendation set , items with a low recommendation score . Thus , we adopt for our community score vector T this new definition : 7-1 __ x. ese } ( 4 ) recom ( u , I ) With this new definition , an item with a low recommendation score will significantly increase the different components of its community score vector . This item will have a high impact on Vy and increase the profile distance . Thus , this item is more likely to be replaced by another one in the final item set . Example 1 . Consider a user Joe to whom a recommender system proposes a list of recommendations Recoy e. Assume for this example that we limit the recommendations to the top-3 scores , so Joe receives the three recommendations originated from the community A . We suppose that there are only 3 communities and that there exists no similarity between them . Therefore CSM is the identity matrix . We assume that Joe interacts equally with these three communities ; therefore his profile is : Pye = ( 0.33 , 0.33 , 0.33 ) To re-rank the items by considering the user profile and the relevance of the messages , we compute the distance from Equation 2 with the community score vector computed with Equation 4 . We display in Table 3 the distance = Pros _ Vyoc| for the different 3-item combinations . For our example , we see that the score for the best combination is 0.40 and corresponds to { 1 , 2 , 4 } . We see in Table 2 that these items have a high recommendation score , and this set better matches the user profile . To determine the top-k recommendation set , we theoretically need to com- pute all the combinations of & items from U extracted from LReco , , which con- sists of N items has a complexity of ( ) . We escape the exponential complexity by adopting an interchange algorithm . So we initialize the recommendation set with the & top-rated items . Then we check for each of the N — & remaining items if we can reduce the distance with the user profile by replacing one recommen- dation by this item . This algorithm has a N ? complexity . Community-based Recommendations 11 6 Experiments We first detail the experimental protocol we adopted to measure the benefits of our re-ranking model CAM for both the relevance of recommendations and the number of users suffering from the filter bubble effect . We also study the impact of the different parameters in our model , i.e. , semantic similarities , the flow and the topological similarity , on the overall results . Our experiments reveal that our model can be tailored for different RS to provide significant gains . For all our experiments , we use the Twitter dataset described in Section 3 . 6.1 Settings To measure the filter bubble effect , we use the Gini coefficient ( see Section 4.2 ) for a sample of users from our dataset . More precisely we measure the differ- ence between the user ’ s Gini coefficient computed for his community profile and the one computed for the community distribution of the recommendations . We consider that a user is affected by a filter bubble if this difference is lower than a given threshold of —0.2 ( bottom right of Figure 4 ) . This —0.2 corresponds to the inflection point observed in Figure 4 which characterizes 10 % of the users . We select the largest communities , with at least 1,000 users , from the USA found by the Louvain clustering method . They represent 38 communities . For each of these communities , we randomly extract 16 users , leading to 608 selected users . This choice of 16 users corresponds to the maximum number of users for the smallest community that retweeted at least twice , therefore users that can be targeted by a RS to give sufficient messages to re-rank . We chose to balance all the communities by an equal number of users . Then we select messages ’ retweets which were retweeted at least twice . This constitutes a set of 132,389,409 sharing actions , timely ordered . We split the set in two : the first 90 % of actions ( the oldest retweets ) compose the training set and the last 10 % the test set . While the former set is used to train the three methods , the latter one allows checking the recommendations with real retweets . Note that the test set captures 66 days of retweets from users in our dataset . Then for each recommender system we compare CF , GraphJet and Sim- Graph , we observe the recommendations computed during the test set with and without applying our CAM algorithm . To estimate the CAM re-ranking score we determine its three components Links , Semantic and Flow as follows : — The number of directed edges between communities is used to compute the Links weight , capturing the topological proximity between communities . — In order to compute the Semantic similarity we rely on Word2Vec trained on Google News data [ 10 ] . We extract most frequent words from communities and combined them to create a vector thanks to Word2Vec . This method allows us to compute semantic distance between communities . — We measure the Flow weight from the network of communities based on the proportion of tweets that circulates between corresponding communities through retweets ( flow proximity ) . 12 Q. Grossetti et al . 6 ( Semantics ) Fig . 5 : hits and users suffering from filter bubble for GraphJet w.r.t . y and 6 4 ( Flow ) 4 ( Flow ) 02 03 04 O56 O6 7 0.4 0.7 0.8 1420 1412 1418 1423 1416 . 1402 1416 1418 1426 1412 1424 1420 1430 1417 1400 ai Shey ae 2 ) ae a 1431 1430 ¥ oe 21414 1428 1400 1400 BIcKIo ) 6 ( Semantics ) - Se & 3 3 13 3 3 oy cs Fig . 6 : hits and users suffering from filter bubble for CF model w.r.t . y and 8 We consider that a message is a Ait if it is recommended to a user based on the training set , and we detect that it leads indeed to an interaction ( retweet /like ) in the test set . This prediction task can be seen as a relevance measure . 6.2 Studying weights ’ impact The re-ranking algorithm relies on the similarities between communities ( Equa- tion 1 ) . Since similarity scores depend on a , § and y , we perform experiments to study the impact of each weight on the re-ranking quality . Each weight is bounded between 0 and 1 and we adopt a 0.1 padding for our experiments pro- viding 11 different values for every weight which leads to 11° = 1,331 different weights configurations . For space reason , we displayed only results with a set to 0.5 which showed a lower impact than § and y that are considered here . In Figure 5 we plot the results for Graph Jet from Twitter . The left table shows the number of accurate predictions ( hits ) made by the system w.r.t . 8 and y weights . The right table represents the number of users among our 608 selected users who suffer from a bubble effect ( those with a Gini difference lower than the —0.2 threshold ) . Results for respectively the collaborative system ( CF ) and for SimGraph are presented respectively in Figure 6 and 7 . We first observe a high variability of results depending on our parameters . The number of accu- rate recommendations - hits - ranges from 492 to 653 for GraphJet for instance , so a 32 % difference . We notice the same order of variability for both CF and SimGraph . The variability is even more important for the number of users fac- ing a filter bubble . For instance , we see that 6 users at a minimum are concerned by a filter bubble for the CF ’ model while in the worst configuration there are 128 users concerned . So we see that the given weights to the different dimen- sions ( semantics and messages flow ) have an important impact on the quality of Community-based Recommendations 13 4 ( Flow ) ° 6 ( Semantics ) = 1455 1460 1441 1430 1431 1423 1421 1419 ] 1452 1433 1432 1422 1404 1403 1400 1409 i il il il qi El qj i ais ih iL Fig . 7 : hits and users suffering from filter bubble for SimGraph w.r.t . y and 8 Initial Best configuration Hits Filter Bubble Hits Filter Bubble GraphJet 552 5.4 % | 630 ( 414 % ) 4.6 % ( —15 % ) CF 1,400 2.7 % |1,348 ( -3 % ) 0.9 % ( -64 % ) SimGraph 1,468 10.0 % |1,491 ( 42 % ) 7.0 % ( —23 % ) Table 4 : CAM approach benefits the recommendations and they allow us to efficiently boost the relevance of rec- ommendations or to decrease the number of users suffering from filter bubbles . Obviously , the two scores are linked : the more we narrow users ’ interests the more chances we have to make accurate recommendations but the more users are proposed the same kinds of recommendations . Overall we observe that the three RS tested show similar key trends when changing a , 8 and y . Reducing weight ( ( the semantics similarity between com- munities ) allows tweets whose topic is different from the users niche interest to be more likely recommended and therefore lowers the number of users suffering from the bubble effect . On the other hand , lowering this weight also induces that some relevant items will not be recommended to the user . The y weight ( the flow between communities ) has an opposite effect . Higher y values tend to recommend items from different communities with which the user is used to interacting but also to decrease at the same time the number of hits . Finally , we observe that a has a similar impact on the results but with a lower amplitude . Our experiments show that there does not exist a configuration where both the relevance of recommendations and the number of users in a filter bubble are optimized . So the different weights in our CAM model may be tuned according to the objectives of the recommender system . Thanks to our experiments , we can also determine for each recommender system the configurations which minimize the number of users suffering from the filter bubble effect ( see below ) . 6.3 . Gains Achieved with the CAM Approach Our next experiment aims at illustrating the gain that we achieve by deploying the CAM model on top of existing recommender systems . So for each recom- mender system , we select the best weight setting to minimize the number of users affected by filter bubbles according to our observations in Figure 5 , 6 and 7 . 14 Q. Grossetti et al . a | | | | | a | 0 Dow 0 0 medium-low 10 medium-high Ml Bhigh A 20 16 3 0 12 9 12 11 8 | ] ce ir 5 5 6 5 ] 5 5 o S 22 2 32 = LULU nm pas 2200 puna oll SimGraph SimGraph * CF CF * GraphJet GraphJet * Fig.8 : Filter bubble users w.r.t . their activity without or with * CAM We present in Table 4 the percentage of users facing a filter bubble with and without re-ranking the recommendations for the different recommender systems , along with the total number of hits we get . We observe that our re-ranking model successfully decreases the number of users affected by the filter bubble by 15 % for GraphJet , 64 % for CF and 23 % for SimGraph . Additionally , by matching more to the user ’ s profile we also improve the relevance of recommendations and boost the number of accurate predictions especially for Graphjet . Only for CF , removing 64 % of filter bubble effects on affected users slightly decreases their relevance : —3 % of hits . Our model seems to remove users more successfully from a filter bubble for the CF model . This could be explained by choice possibilities of the re-ranking step . Sometimes , GraphJet and SimGraph hardly produce recommendations far in the social network , narrowing the possibilities of reranking while CF could compute a large list of recommendations for all users [ 11 ] . 6.4 Users Activity and Filter Bubbles In Figure 8 , we investigate the link between users ’ activity , z.e. , number of mes- sages they interacted with , and the filter bubble . Users are assigned to a category ( i.e. , low , medium-low , medium-high , high ) according to the number of inter- actions they made on the platform . For each of these categories , we plot the percentage of users affected by a filter bubble . We observe that most users con- cerned by this phenomenon have a low activity . Users with low or medium-low activities correspond to more than 70 % of affected users . Due to fewer interactions , recommender systems focus on the known interest of these users . Therefore , this limits the scope of possible recommendations . Consequently , using CAM allows highlighting items that were poorly considered by the underlying recommender system , and impact those users much more . 7 Conclusion In this paper we have presented a thorough study on information flow on Twitter and we showed that the filter bubble phenomenon only concerns a minority of users . We proposed the CAM approach which relies on similarities between communities to re-rank lists of recommendations in order to weaken the filter Community-based Recommendations 15 bubble effect for these users . Moreover our approach is able to boost the accuracy of GraphJet recommendations by increasing the prediction by 14 % . For future works , we want to investigate better partitioning strategies for Twitter . Even if we showcased filter bubbles with topology-based communities , our approach can reasonably be enhanced by finding location and/or opinion- based community detection algorithms to better detect filter bubble effects . We also wish to study the evolution of the links between communities , since retweets evolve over time , it will have an impact on the similarity measure . References 1 . Bakshy , E. , Messing , S. , Adamic , L.A. : Exposure to ideologically diverse news and opinion on facebook . Science 348 ( 6239 ) , 1130-1132 ( 2015 ) 2 . Breese , J.S. , Heckerman , D. , Kadie , C. : Empirical analysis of predictive algorithms for collaborative filtering . In : UAP18 . pp . 43-52 ( 1998 ) 3 . Colleoni , E. , Rozza , A. , Arvidsson , A. : Echo chamber or public sphere ? predicting political orientation and measuring political homophily in twitter using big data . Journal of Communication 64 ( 2 ) , 317 — 332 ( 2014 ) 4 . Dugué , N. , Labatut , V. , Perez , A. : A community role approach to assess social capitalists visibility in the Twitter network . SNAM 5 ( 1 ) , 26 ( 2015 ) 5 . Flaxman , S. , Goel , S. , Rao , J.M . : Filter bubbles , echo chambers , and online news consumption . Public Opinion Quarterly 80 ( S1 ) , 298-320 ( 2016 ) 6 . Garimella , K. , De Francisci Morales , G. , Gionis , A. , Mathioudakis , M. : Reducing controversy by connecting opposing views . In : WSDM . pp . 81-90 ( 2017 ) 7 . Garrett , R.K. : Echo chambers online ? : Politically motivated selective exposure among internet news users . JCC 14 ( 2 ) , 265-285 ( 2009 ) 8 . Gillani , N. , Yuan , A. , Saveski , M. , Vosoughi , S. , Roy , D. : Me , my echo chamber , and I : introspection on social media polarization . CoRR abs/1803.01731 ( 2018 ) 9 . Gini , C. : Variabilité e mutabilita . Libreria Eredi Virgilio Veschi ( 1912 ) 10 . Google : Word2vec . https : //code . google.com/archive/p/word2vec/ ( 2013 ) 11 . Grossetti , Q. , Constantin , C. , du Mouza , C. , Travers , N. : An homophily-based approach for fast post recommendation in microblogging systems . In : Proc . Intl . Conf . on Extending Database Technology ( EDBT ) . pp . 1-12 . Austria ( 2018 ) 12 . Kamishima , T. , Akaho , 8. , Asoh , H. , Sakuma , J. : Enhancement of the neutrality in recommendation . In : Decisions @ RecSys . pp . 8-14 ( 2012 ) 13. hyung Kang , J. , Lerman , K. : Using Lists to Measure Homophily on Twitter . In : AAAT . pp . 26-32 ( 2012 ) 14 . Kwak , H. , Lee , C. , Park , H. , Moon , 8.B . : What is twitter , a social network or a news media ? In : WWW . pp . 591-600 ( 2010 ) 15 . Leicht , E.A. , Newman , M.E.J . : Community structure in directed networks . Phys . Rev . Lett . 100 , 118-122 ( Mar 2008 ) 16 . Munson , S.A. , Resnick , P. : Presenting diverse political opinions : how and how much . In : Human Factors in Computing Systems . pp . 1457-1466 . ACM ( 2010 ) 17 . Nguyen , T.T. , Hui , P. , Harper , F.M. , Terveen , L.G. , Konstan , J.A . : Exploring the filter bubble : the effect of using recommender systems on content diversity . In : WWW . pp . 677-686 ( 2014 ) 18 . Pariser , E. : Beware online ” filter bubbles ” ( 2011 ) , https : //www.ted.com/talks/ eli_pariser_beware_online_filter_bubbles , 19 . Sharma , A. , Jiang , J .. Bommannavar , P. , Larson , B. , Lin , J. : GraphJet : Real-time Content Recommendations at Twitter . PVLDB 9 ( 13 ) , 1281-1292 ( 2016 ) 1602.05642v1 [ cs.SI ] 18 Feb 2016 arXiv Adiya Abisheva , David Garcia , Frank Schweitzer : When the Filter Bubble Bursts : Collective Evaluation Dynamics in Online Communities Submitted to the 8th International ACM Web Science Conference 2016 When the Filter Bubble Bursts : Collective Evaluation Dynamics in Online Communities Adiya Abisheva , David Garcia , Frank Schweitzer Abstract We analyze online collective evaluation processes through positive and negative votes in various social media . We find two modes of collective evaluations that stem from the existence of filter bubbles . Above a threshold of collective attention , negativity grows faster with positivity , as a sign of the burst of a filter bubble when information reaches beyond the local social context of a user . We analyze how collectively evaluated content can reach large social contexts and create polarization , showing that emotions expressed through text play a key role in collective evaluation processes . Categories and Subject Descriptors : Human-centered computing , Collaborative and social comput- ing , Empirical studies in collaborative and social computing Keywords : Social filtering , emotions , collective dynamics 1 Introduction When the filter bubble bursts Rebecca Black , an amateur teenage singer , posted a music video ! on YouTube on February 10 , 2011 . The song originally circulated mostly among the Facebook friends of its 13-year old singer and was loved and positively commented . Rebecca Black ’ s song received the `` all the usual friends things '' [ 36 ] and was enough to please her , but it suddenly went viral in the wrong direction . From initial 4,000 views on YouTube her song skyrocketed to 13 Million views . This sudden popularity brought mostly negative attention , up to the point of becoming officially the most disliked YouTube video ” , and by June 15 , 2011 the song received 3.2 Million dislikes in YouTube against less than half a million likes . From local fame her song soared to the heights of global shame . The anecdotal example of Rebecca Black ’ s song is paradigmatic of some aspects of the collective dynamics of evaluations in online media . A video can become relatively popular within a small community and receive initial positive evaluations , but when larger audiences are reached , negativity rises faster than in early moments . Figure 1 shows this phenomenon through an example of the relative daily volume of likes and dislikes of a YouTube video . Initially , the video is positively evaluated , but the volume of likes decreases quickly . While initial dislikes also decrease , they start rising after the fourth day , reaching a peak at the ninth day . The early viewers of a YouTube video are prone to like it , either due to a social connection with the uploader , or given the similarity of the video with their past liked content . This is a consequence of the 'The original video was deleted and reuploaded again at : https : //www . youtube .com/watch ? v=kf Vsf0SbIYO * http : //knowyourmeme . com/memes/rebecca-black- friday 1/20 Adiya Abisheva , David Garcia , Frank Schweitzer : When the Filter Bubble Bursts : Collective Evaluation Dynamics in Online Communities Submitted to the 8th International ACM Web Science Conference 2016 @ 0.257 E 0.204 — Likes 5B 015H — Dislikes oO ISI > 0.104 2 o054 0 — oO T T 5 10 15 20 day Figure 1 : Example of evaluation dynamics in Youtube . Normalized daily volume of likes and dislikes for a video in our YouTube dataset . Likes appear soon after the video is uploaded , while dislikes tend to appear later . purpose of social filtering mechanisms and recommender systems , which is to personalize content selection such that users find content that they consider relevant and of good quality . In contrast , the video can also spread through other media towards more general users , and eventually reach a global audience with users more critical or negative towards the video . Beyond YouTube videos , this phenomenon can be seen as another aspect of the filter bubble [ 51 ] : The reinforcement of opinions caused by filtering mechanisms creates an initial pocket of positivity , but when the filter bubble bursts , collective negativity can backlash . Our study sets out to understand collective evaluation processes in various social media through likes and dislikes , as manifestations of opinions towards the evaluated content . We test the duality of collective evaluations in the local versus global behavior illustrated above , looking for the existence of a threshold of positivity after which negative evaluations rise faster and polarization emerges . Emotions in polarization Technological filters are not the only factor that shapes collective evalua- tions ; emotions influence cognitive information processing , shaping opinions and attitudes towards online content . A number of studies in social psychology show how emotions influence individual evaluations , judgements , and opinions [ 35 , 24 , 25 ] , based on the theory of core affect [ 57 ] . Within this theoretical frame- work , emotions are composed of two dimensions : i ) valence , which characterizes the feeling of pleasure or displeasure , and ii ) arousal , which encompasses a feeling of activation or deactivation , and quantifies mo- bilization and energy [ 57 ] . Additional dimensions can improve the representation of emotional experience , such as potency or surprise [ 15 ] , but their consistent inclusion in psychological research about opinions is still to be explored . Research in psychology on the role of emotions in evaluations show that arousal can lead to extreme reactions and polarized responses [ 55 ] . The theory of misattribution explains this effect [ 76 , 55 ] as a transfer of residual emotions between events that intensifies the reaction to the second event . For instance , men in a state of high emotional arousal { for example from physical exercises ) give more extreme ratings of attractiveness to women in comparison to the situation in which raters are in a calm emotional state . Similarly , valence can be misattributed and bias evaluations [ 58 ] , in particular when individuals inspecting their current feelings , which might be caused by an incidental source rather than the evaluated content . Further theoretical explanations for the role of emotions in evaluations pose the reduction of cognitive complexity induced by emotional states , which bias the formulation of evaluations towards fast rather than informed responses . The theory of affect priming explains this through the attribution of an individual ’ s 2/20 Adiya Abisheva , David Garcia , Frank Schweitzer : When the Filter Bubble Bursts : Collective Evaluation Dynamics in Online Communities Submitted to the 8th International ACM Web Science Conference 2016 mood to similarly valenced signals in memory , which helps reducing the effort of evaluation tasks [ 29 ] . Empirical evidence shows that the subjective experience of arousal motivates evaluation on the extremes [ 52 ] . For example , the ratings of famous figures by students are found to be more polarized right before taking an exam , in comparison to weeks before or after . This kind of reactions are especially salient when arousal is experienced along with negative valence ( such as the stress before an exam ) , and thus we can expect the expression of negative and aroused emotions to motivate more polarized collective evaluations in social media . The digital traces of collective evaluations allow us to analyze further the role of emotions in online evaluation processes . Contributions of this article In this work we analyze collective evaluations across different social media to reveal statistical regularities related to information filters and emotions . First , we test if the distributions of likes and dislikes of evaluated content shows signs of the existence of multiplicative growth processes of social interaction . Second , we test if the relationship between likes and dislikes is non-linear with a division in to two different modes , corresponding to local and global collective evaluations . Third , we test if the emotions expressed in the evaluated content lead to global and polarized collective responses . Our work provides insights into the properties of collective evaluations and tests established psychology theories on the role of emotions in opinion formation . 2 Background Collective dynamics In the last years , lots of research focused on the topic of online communities , ie . large groups of individuals that interact through an online medium . Collective phenomena such as dynamics of trends [ 75 , 70 ] , or viral marketing [ 38 ] can be assessed with data from online communities . Examples of studies on online user behaviour are understanding dynamics of replying activity and website engagement of users [ 56 ] , buyer activity in online shopping websites [ 37 ] and communication dynamics in forums [ 30 ] . Another example is research on social influence , which was shown to exist in YouTube [ 12 ] , in Facebook [ 50 ] , and in Twitter [ 69 ] . Furthermore , social influence on popularity of Facebook applications has been shown to arise from a mixture of local and global signals [ 50 ] . While the former notion indicates how friends and local community influence an individual ’ s behaviour , the latter suggests the effect of the aggregate popularity of products or behaviours on an individual . Additionally , previous results for popularity distributions show that the amount of votes for Digg stories [ 67 ] and tweets in trending topics [ 6 ] follow log-normal distributions that are explained by social coupling . Collective evaluations Online voting dynamics and dynamics of human appraisal were studied in a number of previous research . Studies on collective evaluations mostly interrelates and finds explanations in research on collective popularity of the online content , with the assumption that more likes lead to item ’ s popularity . Despite the differences in the ways of measuring popularity , as a number of views in YouTube [ 60 ] , or as a number of likes and dislikes in Reddit [ 44 ] , or as a number of votes in Digg [ 67| or as a time span of trending topics in Twitter [ 6 ] , these measures showed the existence of statistical regularities of content popularity , and fit to the log-normal distribution . 3/20 Adiya Abisheva , David Garcia , Frank Schweitzer : When the Filter Bubble Bursts : Collective Evaluation Dynamics in Online Communities Submitted to the 8th International ACM Web Science Conference 2016 Studies on collective dynamics of negative evaluations are scarcer , but some recent works illustrate that social influence effects are present in movie ratings from imdb.com [ 41 ] , and that controversiality expressed through movie ratings evolves with time [ 5 ] . Additionally , herding effects have been observed in random manipulations of votes in Reddit [ 73 ] , which shows that the way users vote depends on the votes of other users . Further research on Reddit [ 44 ] showed a non trivial dependency between likes and dislikes at the collective level , in line with the questions we address in this article . Online polarization The proliferation of online participatory media , such as social network sites , blogs and online fora , increases users engagement in discussions on political and societal issues , which in its turn may - under certain conditions - split individuals apart in their opinion space . Opinion polarization is characterzied by a division of the population into a small number of fractions with high internal consensus and sharp disagreement between them [ 14 ] . Agent-based models [ 40 , 42 ] and experimental studies [ 68 ] explain some aspects of opinion formation and its role in consensus and polarization . Based on data from digital traces , previous research investigated polarization from the network perspective in political blogs [ 3 ] , in follower and mention links in Twitter [ 11 ] , and in Swiss politicians profiles [ 19 ] , as well as in a non-political domains like friendship networks [ 26 ] , and cultural expression [ 22 ] . Additionally , exprerimental evidence shows that group processes like polarization function differently in computer- mediated communication than in a face-to-face interaction [ 62 ] , for example as the relative annonymity of online media dampens inhibiting effects like the spiral of silence [ 48 ] . Online emotions Emotional expression through online text has been analyzed in earlier research on data from MySpace [ 66 ] , Yahoo answers [ 34 ] , IRC channels [ 18 ] , Wikipedia [ 28 ] , BBC , Digg , YouTube and Twitter [ 64 ] . Availability of large-scale quantitative datasets allows us to understand emotions and their role in various domains . Studies in the field of subjective well-being leverage extensively on quantifying emotions through text . For instance , subjective well-being is manifested in Facebook status updates [ 71 ] , and shows a pattern of assortativity in social networks [ 54 ] in relation to feelings of loneliness [ 7 ] . This is in a close relation to the quantification of mood in Twitter which has been used to validate theories of periodic mood oscillations [ 23 ] . Twitter mood measured in terms of valence and arousal reveals aspects of the relation between mood states and online interaction and participation [ 9 ] , and the psycholinguistic analysis of emotions reveal the traces of mental health issues [ 10 ] . Furthermore , segregation patterns in geographical space [ 39 ] and gender-based patterns [ 32 , 66 ] can be partially attributed to differences in emotional expression . In online interaction , for example in real-time chat conversations [ 18 ] and product reviews [ 21 ] , emotions are not a phenomenon characteristic to just an individual , but exhibit collective properties [ 59 ] . Lastly , information-centric role of online emotions has been studied through blogs [ 45 ] , in Twitter [ 53 ] , and in Yahoo answers [ 34 ] . Emotions are the building blocks for a creation of social network structures [ 74 , 61 ] through empathy [ 31 ] that lead to correlations between emotional expression and popularity [ 33 , 63 ] . Negative emotional posts were shown to be drivers of communication among users and responsible for extension of the lifetime of online discussions in forums [ 8 ] . Furthermore , the digital traces of emotions synchronize with political outcomes [ 24 ] , which goes inline with the findings that political discussions are emotionally charged [ 27 ] , in particular during election periods [ 20 ] . 4/20 Adiya Abisheva , David Garcia , Frank Schweitzer : When the Filter Bubble Bursts : Collective Evaluation Dynamics in Online Communities Submitted to the 8th International ACM Web Science Conference 2016 3 Data and Methods 3.1 Data on collective evaluations Datasets The data used in this research is the result of our crawl of four publicly accessible online communities . YouTube ( http : //www . youtube.com/ ) is a video sharing website on which registered users can upload and view videos , as well as post comments and rate videos with likes and dislikes . Our crawl ? was launched in June 2011 to daily collect a combination of top videos in various categories and to iteratively explore the channels of general users [ 2 ] , including 6.3 Million videos by February 2015 . Reddit ( http : //www.reddit.com ) is a message board in which registered users submit posts with links and text , and vote up and down for posts to appear on a frontpage . Conversations between users appear in one of the many thematic boards , called subreddits , covering diverse topics from politics to science fiction and adult content . From 2012 to 2014 our daily Reddit crawl * collected 338,000 submissions from 1,972 subreddits . While the user interface of Reddit provides fuzzed amounts of votes , it is possible to construct the total amount of up and downvotes to a submission based on the JSON fields of reddit score and like ratio . This way , we count with the text and the final amount of up and downvotes for each submission in our dataset . Imgur ( http : //www . imgur.org/ ) is an image hosting and sharing website where registered users upload , rate , and discuss uploaded images . Image sharing traffic of Imgur has a large presence in Reddit such that every 6th successful Reddit post has a link to an image on Imgur [ 49 ] . Our daily crawl ? collected 200,000 images and their user activity statistics between December 2015 and January 2016 . Finally , Urban Dictionary ( http : //www.urbandictionary.com/ ) is an online crowdsourced platform consisting of non-standard lexicon of slang words and idioms . Registered users can submit new terms and provide definitions , and all users of the website , registered and anonymous , can vote up and down for the best definitions . Between April and May 2013 our python-based crawl collected 220,000 definitions and their votes . All platforms provide functionality for users to evaluate uploaded content positively and negatively by clicking an upvote/like or downvote/dislike button respectively . For simplicity , from now on we refer to evaluated videos , submissions , images and definitions as items and we denote as likes and dislikes to positive and negative evaluations , including up and down votes respectively . Sentiment Analysis To quantify emotional expression , we applied sentiment analysis to headers or titles of each item , leaving for a future research the analysis of longer descriptions , transcripts , and comments . We applied sentiment analysis techniques to video descriptions in YouTube , image titles in Imgur , submission headers in Reddit and term definitions in Urban Dictionary . Headers and titles area “ YouTube Data API Java wrapper ( https : //developers . google .com/youtube/v3/ ) “ PRAW ( https : //pypi . python . org/pypi/praw ) °PyImgur Python API wrapper ( https : //github.com/Damgaard/PyImgur ) . Seed images were selected from Imgur ’ s gallery sitemap ( http : //imgur.com/gallery/sitemap.xm1 ) 5/20 Adiya Abisheva , David Garcia , Frank Schweitzer : When the Filter Bubble Bursts : Collective Evaluation Dynamics in Online Communities Submitted to the 8th International ACM Web Science Conference 2016 Number of items , NV Dataset Nossa Nyc Nope Num . of likes Num . of dislikes Urban Dict . definitions 220 , 270 213,512 208 , 441 61 , 100 , 699 26 , 508 , 869 YouTube video descriptions 6,279,461 3 , 864 , 480 2 , 750 , 554 763 , 291 , 676 41 , 214,035 Reddit submissions 338 , 845 174 , 444 142 , 662 5 , 078 , 242 947,519 Imgur image titles 201,181 147 , 752 125 , 230 54 , 786 , 629 1,931,918 Table 1 : Number of items in each dataset . Nerayieq counts the number of crawled items , and Nyear > 1 the number of items in English and that existed for more than a year . NUp > 1 counts items that received at least 1 like and 1 dislike . good proxy of the emotional tone of a discussion , in line with earlier research on forum-like conversations [ 24 ] . We measured emotional content of items by applying two complementary sentiment analysis methods . First , we apply a lexicon of affective norms of valence V , arousal A and dominance D of nearly 14,000 English words [ 72 ] . In line with previous findings [ 72 ] , the scores of valence and dominance in our dataset are highly correlated , in comparison with the weaker correlation between valence and arousal as explained more in detail in the Results section . This motivates our focus to only valence and arousal as suggested by the theory of core affect . Second , we apply the SentiStrength classifier [ 65 , 64 ] a state-of-the-art lexicon-based method [ 34 , 1 ] that has been used in earlier research on the online data from MySpace [ 66 ] , Yahoo ! [ 34 ] , IRC channels [ 18 ] , BBC , Digg , YouTube [ 64 ] , Twitter [ 64 , 53 ] and Wikipedia [ 28 ] . The core of the SentiStrength method is to predict the sentiment of a text , based upon the occurrences of the words from a lexical corpora , which contains the set of terms with known sentiment of a text . The classifier incorporates various rules , which strengthen or weaken sentiments of the lexicon words detected in the short text . Among the rules are syntactic rules , e.g . exclamation marks and punctuation , language modifiers and intensifiers , such as negation and booster words , and spelling correction rules . The final sentiment score is composed of a positive P and a negative N score for each text as two discrete values in the range of [ +1 , +5 ] and [ —5 , —1 ] respectively . In our analysis , we normalize all emotions variables to [ 0 .. 1 ] mapping P from [ +1 , +5 ] to ( 0 , 1 ] and reversing and rescaling N from [ —1 , —5 ] to ( 0 , 1 ] . To ensure a valid measurement of sentiment and collective evaluations , we apply two filters to our datasets . First , since both sentiment analysis techniques are designed only for English texts , we apply language classification [ 47 ] and filter out all non-English texts . Second , we remove all items with less than a like and a dislike , and that existed for less than a year in all platforms , to ensure that positive and negative evaluations are stable . Detailed statistics on the number of posts in each dataset are shown in Table 1 , showing that they are still sufficient for large scale analyses . We will make these datasets available for research purposes . 3.2 Statistical analysis methods Distribution fits We apply a Maximum Likelihood criterion to fit the distributions of likes and dislikes [ 4 ] , to confirm early findings of the fits of the popularity distribution to the log-normal distribution 6/20 Adiya Abisheva , David Garcia , Frank Schweitzer : When the Filter Bubble Bursts : Collective Evaluation Dynamics in Online Communities Submitted to the 8th International ACM Web Science Conference 2016 |67 , 6 ] . We use the powerlaw python package to fit four statistical distributions related to complex growth phenomena [ 46 ] : power law , log-normal , truncated power law and exponential distributions . We compare the likelihood of each distribution using the log-likelihood ratio R = In ( L , /L2 ) between the two candidate distributions and its significance value p. Positive ratios indicate evidence for the first distribution , and negative ratios for the second one . Instead of testing the hypothesis of the data following a certain distribution , this comparative test answers the question of which parametric distribution provides the best fit available , following the principle of Maximum Likelihood estimation [ 4 ] . To finally assess the quality of the best fit , we measure the Kolmogorov-Smirnov distance between the best fitting distribution and the emprical data . Dual regime analysis We test the existence of a dual local versus global regime in collective evalua- tions by analyzing the non-linear properties of the relationship between the amounts of likes and dislikes for each item . We use an extension of a traditional linear modelling , multivariate adaptive regression splines ( MARS ) [ 17 , 16 ] implemented in the R programming language package earth . MARS fits a continuous piecewise regression function with knots that join locally linear pieces . In our analysis , we are interested to test a dual pattern in the relationship between the number of likes L and the number of dislikes D , therefore we set the number of knots to one and fit a model of the form D ( L ) = I+ a , * max ( 0 , L — L , ) + ag x max { 0 , L , — L ) The values of likes above LE , and the values of dislikes above D ( Z , ) correspond to observations in the global regime , after the bubble bursts , and the values in which any is below map to the local regime . To evaluate the quality of the MARS model , we compare it to the Ordinary Least Squares ( OLS ) regression using the Generalized Cross-Validation prediction error ( GCV ) defined as RSS GCV = ——_ Nea ep where N is the number of observations , RSS is the residual sum of squares , and ENP is the effective number of parameters to avoid overfitting [ 16 ] . We use the implementation provided by the package boot in R as well as the coefficient of determination R ? of both OLS and MARS fits . Emotion and polarization analysis Having identified the two regimes and their thresholds in the relationship between the number of dislikes and the number of likes , we can mark items either in the global or the local regime as a binary class . We test how emotions influence the chances of items reaching the global regime through two logistic regression models , one for each sentiment analysis technique . Similarly , we combine the values of likes and dislikes through their geometric mean to measure polarization , as manifested by simultaneous large amounts of positive and negative evaluations . We regress this measure of polarization through two linear models depending on the emotions expressed on the items . Prior to modelling , we examine the normalized emotional dimensions for multicollinearity by computing the Spearman ’ s rank correlation coefficients , to avoid singularities . We assess the quality of fits in com- parison to null models , by measuring the x ? statistic of model likelihood ratio tests implemented in the imtest R package . 7/20 Adiya Abisheva , David Garcia , Frank Schweitzer : When the Filter Bubble Bursts : Collective Evaluation Dynamics in Online Communities Submitted to the 8th International ACM Web Science Conference 2016 4 Results 4.1 Stylized facts of evaluation distributions Figure 2 shows the probability density functions of the distributions of the amount of likes and dislikes for items in each of the four datasets . To understand the process that generates these distributions , we fit a set of parametric distributions that provide insights into how likes and dislikes are given to items . Following the categorization of [ 46 ] , generative mechanisms produce stylized size distributions that can be traced back to the properties of growth processes . If the appearance of likes and dislikes follows an uncorrelated process and new evaluations are independent of previous ones , likes and dislikes should follow exponential distributions . On the other hand , the presence of likes and dislikes can motivate further evaluations through social effects , creating multiplicative growth { also known as preferential attachment in the context of networks ) . In the presence of multiplicative growth , if items have similar lifespans , likes and dislikes follow log-normai distributions . On the other hand if multiplicative growth is combined with heterogeneous lifespans , likes and dislikes follow a power law distribution . This power law can be corrected by adding an exponential cutoff if finite size effects limit the growth of likes and dislikes , a case in which the distributions would be better fitted by a truncated power law . Urban Dictionary YouTube Reddit Imgur 107 a 4 . _ _ yn a g wn © io g x Z a 5 107 a a a a a a 10 % “ 10 \\ 10 \\ 1 10° 10° 10° 1088108107 Likes Likes 107 _ 197 ! a a io ? a £ x 10 '' & Z 103 a a Dips B = 2 107 a ” Bio = ao = — o Dig 10° ie \\ 10 ! 10° 10 ) 108 10°10 ” 118 wm 18 Dislikes Dislikes Dislikes Dislikes Figure 2 : Probability density function of collective evaluations . Probability density function of the number of likes ( top ) and the number of dislikes ( bottom ) with exponential binning and fits to log-normal distribution InN ( j1 , 0 ) ( red dashed lines ) . For all datasets , the results of the log-likelihood pairwise comparisons of the four distributions ( see text ) identified the log-normal distribution as the best fit . For all datasets , the results of pairwise comparisons of the four proposed distributions identified the log-normal distribution as the best fit , with significant and positive log-likelihood ratios as shown in Table 2 along with the best fitting parameter estimates . The dashed lines in Figure 2 show the fitted distributions , revealing the quality of the fit . The cases of YouTube and Urban Dictionary provide very 8/20 Adiya Abisheva , David Garcia , Frank Schweitzer : When the Filter Bubble Bursts : Collective Evaluation Dynamics in Online Communities Submitted to the 8th International ACM Web Science Conference 2016 Urban Dictionary YouTube Reddit Imgur P ( Likes ) P ( Dislikes ) P ( Likes ) P ( Dislikes ) P ( Likes ) P ( Dislikes ) P ( Likes ) P ( Dislikes ) be 4.092 3.657 5.492 1.405 2.197 0.492 4.668 1.821 o 1.705 1.435 2,28 2,528 1.332 1.35 2.46 1.447 D 0.008 0.008 0.009 0.002 0.029 0.01 0.098 0.031 in ( 2 ) 123115.6° * =129462.1 * * * 174835.6 '' '' = 42309.5 '' * * = 45355.3 * * * 13898.9 * * * 65314.8 * * * 34103.6 * * * In ( - ) 55538.6° * 61135.1° * * 252646.1° * * = 42592.3° = 17182.5 * * 10084 * * * =20108.5 * * * 3662.4 * * * PL in ( x ) 260098.8 * * * — 126865 * * * 953075 '' = 1270237.6 * * 149405 * * * =70261.5° * =75817.7 * = 26681.4 * * * Table 2 : Log-normal fit parameters of collective evaluations and comparison to other distributions . Estimated parameters of the fitted log-normal distribution InN ’ ( u , o ) and Kolmogorov-Smirnov distances D. The bottom row shows the log-likelihood ratios of pairwise comparison between the log-normal distribution fit ( numerator ) and the other three distribu- tions : power law , truncated power law and exponential . All three ratios are positive , large and significant ( p < 0.05 ) which confirms that among the four candidate distributions the log-normal distribution is the best fit . good fits with extremely low Kolmogorov-Smirnov D statistics . The fits are not so good at the tails of Reddit and Imgur , but the the Kolmogorov-Smirnov D statistic provide good values below 0.05 and the log-normal distribution clearly outperforms all others . The worst fit is for the number of likes in Imgur , for which Figure 2 suggests a bimodal pattern . Identifying the possible mechanisms that can produce such bimodality goes beyond the scope of this research . We can conclude that the amounts of likes and dislikes display a general heavy tailed behavior of log-normal distributions , lending evidence for the production of evaluations following socially coupled growth processes with homogeneous life spans . 4.2 The dual pattern of collective evaluations We explore the existence of a dual relationship between likes and dislikes through non-linear MARS fits , testing if the relationship can be divided in a local and a global regime . We restrict the number of model terms to have a single knot , measuring if a dual model outperforms a linear pattern . Figure 3 shows the results of MARS fits between the logarithms of likes and dislikes . Vertical and horizontal lines mark the likes cutoff value LE , and its corresponding value of dislikes in the fit D ( Z , . ) . These cutoff values divide the system in a local versus a global regime , with the fitted functions of the form D « L * and D « LY respectively . In all datasets , the exponent of the global regime is larger than exponent of the local one , for example in YouTube y = 0.93 > A = 0.29 . While both exponents are below 1 and indicate sublinear scaling , the much higher value of the second one shows that , beyond a threshold value of likes , the dislikes given to items grow faster than below the threshold as a sign of the burst of a filter bubble . The presence of scaling in Reddit votes was previously reported in a smaller data subsample [ 44 ] , concluding the existence of superlinear scaling of dislikes with likes . Our analysis shows that the relationship between likes and dislikes in Reddit is better approximated by a dual regime model , in line with the results of the other three datasets . 9/20 Adiya Abisheva , David Garcia , Frank Schweitzer : When the Filter Bubble Bursts : Collective Evaluation Dynamics in Online Communities Submitted to the 8th International ACM Web Science Conference 2016 Tae y 5 . Urban Dictionary aw YouTube ax Reddit 10 ae _ ‘ Imgur 5. ag 5s ) Dox L™ D « L ” De L™ 10°97 DeL 10 09 0.42 -0.37 De [ 28 De « L™ jo74 } Dx L™ De L™ 3 3 3 & ip x , x , x x 10 = 10 = 10 3 3 wn wn wn wn a a a a count + count 1 count count 3 1000 1000 10 ~~ 104 2 1000 ae wy i ! 0 is 1 » 1 1 1 7 ] 10 ! 10° 10° 10 ! 10° 10° 10 ! 10° 10 ! 10° 10° Likes Likes Likes Likes Figure 3 : Relationship between the number of dislikes and likes . Two-dimensional joint distributions with 50 bins , bin colors indicate the count of observations within the bin . Pur- ple and red lines show the local and global regimes of the non-linear relationship between the number of dislikes and the number of likes . Threshold estimates are located at L , , estimated as L , = 155 in Urban Dictionary ; L , = 131 in YouTube ; L , = 7 in Reddit ; and L , = 27 in Imgur . We evaluate the goodness of the dual model against a single regime model in Table 3 . The dual model outperforms in R ? and GCV to the single regime model , lending strong evidence to the existence of two regimes . We further tested if additional knots could improve the fits , and found that a dual regime is the optimal model for Urban Dictionary , YouTube , and Reddit , and only a 4 knot model could improve the Imgur fit by a marginal GCV of less than 0.01. model Urban Dict . YouTube Reddit Imgur R ? ( 1m ) 0.646 0.634 0.727 0.505 R ? ( MARS ) 0.654 0.683 0.741 0.597 GCV ( 1m ) 0.785 1.283 0.301 0.804 GCV ( MARS ) 0.767 1.111 0.286 0.654 Table 3 : The goodness of the dual and the linear model . Comparison of the linear and the MARS models of the relationship between the number of dislikes and the number of likes . Top row shows the coefficient of determination R ? ( higher is better ) . Bottom row shows the generalized 10-fold cross-validation prediction error ( GCV ) ( lower is better ) . The dual model outperforms in R ? and in GCV compared to the linear model . 4.3 . Emotions in the global regime Figure 4 illustrates the rank correlations between emotional dimensions . In all datasets valence and dominance are highly correlated with p > 0.7° * * , and therefore we discard the dominance variable from regression analysis as it is difficult to distinguish from valence . Valence and positivity P have a minor pos- itive significant correlation p € [ 0.2,0.3 ] , and valence and negativity N have a slightly negative correlation p = —0.3 , illustrating the relation of emotion variables accross both valence/arousal and positive/negative models . 10/20 Adiya Abisheva , David Garcia , Frank Schweitzer : When the Filter Bubble Bursts : Collective Evaluation Dynamics in Online Communities Submitted to the 8th International ACM Web Science Conference 2016 A D P N A D P N A D P N A D P N_| , V |-0.01 0.33 V | 0.12 02 V |-0.05 0.29 V |0.26 0.31 G 33 Ga V |012| GF 02 GV 005 GP 029 ] V 620 GF 030/93 ] A |-0.08 ] 0.11 | 0.16 A | 0.02 | 0.06 | 0.16 A |-0.12 ] 8 | 0.19 A | 0.15 | 0.17 | ( 0.23 0 D0 . Dio . Do . D |025 025 027 0.18 038 027 024 025 os P| o.14 P 024 P | o.16 P |-0.05 -l Figure 4 : Correlations of emotions . Spearman ’ s correlation matrix of emotional dimensions , in an order from left to right : A ) Urban Dictionary , B ) YouTube , C ) Reddit , D ) Imgur . Significance level p < 0.05 . Insignificant correlations are crossed out . Predictors are normalized to [ 0 .. 1 ] . Dominance is highly correlated with valence , and therefore the dominance variable is discarded from the further analysis . We fit two regression models in which the probability of the event of an item reaching the global regime G depends on the emotions expressed in the evaluated item . The first model uses V and A as explana- tory variables , and focuses on the role of emotions as quantified through their pleasant /unpleasant and active/calm dimensions . The second model takes P and N as predictors , and measures significance of positive and negative sentiments in bringing an item to global regime . Table 4 reports the results of logistic regression of the form logit ( G ) ~ V + A and logit ( G ) ~ P + N respectively . The role of arousal is heterogeneous , having a significant positive effect in Urban Dictionary and Imgur , but a weak nega- tive effect in YouTube and a non-significant one in Reddit . The effect of valence is also mixed , in Urban Dictionary and YouTube the chances of reaching the global regime grow with valence , while in Reddit and Imgur is the opposite case . The second model sheds more light to this : the pattern is the same for positive sentiment , but negative sentiment increases the chance of reaching the global regime in all datasets but Reddit , where the effect is not significant . Urban Dict . YouTube Reddit Imgur Intercept —2.071 * * * —0.305 * * * —0.111 * * * 0.228 * * * V 0.976 * * * 0.618 '' * * —0.262 * * * —0.209 * * * A 0.584° * * —0.049 '' * = —0.006 ( n ) 0.300 * * * x ? 547.3 '' 2791.4 * * 44.1 * * * 35.7° '' * Urban Dict . YouTube Reddit Imgur Intercept —1.369 '' * * —0.115 * * * —0.259 * * * 0.261 * * * P 1.019 * * * 0.581 * * * —0.166 * * * —0.296 * * * N 0.170 * * * 0.218 '' * * = —0.006 ( n ) 0.191 * * * x ? 2552.6 '' 17150.9 * * 41.9 * * * 120.3° * “ p < 0.001 , * * p < 0.01 , * p < 0.05 , ( m ) not significant . Table 4 : The role of emotions in the global regime . Logistic regression models , logit ( G ) ~ V + A and logit ( G ) ~ P+ N , results for probability of an item to be in a global regime . The effect of arousal and valence is heterogeneous , and depends on the dataset . 11/20 Adiya Abisheva , David Garcia , Frank Schweitzer : When the Filter Bubble Bursts : Collective Evaluation Dynamics in Online Communities Submitted to the 8th International ACM Web Science Conference 2016 4.4 Analysis of emotions in polarization Since the distributions of likes and dislikes are approximately log-normal , we can treat the logarithms of likes In ( L ) and dislikes In ( D ) as centrally distributed around their means ( [ n ( D ) ) and ( In ( L ) ) . We standardize the logarithmic counts In ( D ) and In ( L ) as : _ _ In ( D ) = ( in ( D ) ) 4u = sd ( In ( L ) ) 4p = sd ( In ( D ) ) where sd ( In ( L ) ) and sd { in ( D ) ) are the standard deviations . Then , we compute a measure of polariza- tion as the geometric mean of both values : Pol = \\/Z , * Zp . This measure captures the principle that polarization is high under simultaneous large amounts of positive and negative evaluations , and that polarization is low when only one of the values is dominant . To understand which kind of emotional content creates polarization , we fit two regression models as in the previous section , one of polarization as a function of valence and arousal in the evaluated item , and another as a function of positive and negative sentiment scores . The results of the fits are shown in Table 5 . In line with the theory that links arousal to more extreme opinions , we find a general pattern in three datasets where arousal leads to higher levels of polarization . While there is no significant effect in Reddit , all the other datasets show that items that contain words that transmit higher arousal also create a stronger polarized response . Urban Dict . YouTube Reddit Imgur Int . 2.0508 * * * 1.4543 '' = 1.3511 '' 1.7623 * * * V 0.3132 '' 0.2980 * * * —0.1954 '' '' * —0.1908 * * A 0.2662 * * * 0.1005 * * * —0.0327 ( n ) 0.2399 * * * x ? 480.64 '' 3420.4 '' 97.315° * —88.669 '' '' * Urban Dict . YouTube Reddit Imgur Int . 2.2744 * * * 1.5896 * * = 1.2220 * * * —-1.7625 * * * P 0.4889 '' 0.3059 '' * —0.1107 '' * —0.1484 * '' * N 0.1194 * * * 0.1698 * * * 0.0077 ( n ) 0.1672 * * * x ? 3271.2 * * 19830.0 * * * 63.073 '' 170.81° * * % * n < 0.001 , * * p < 0.01 , * p < 0.05 , ( m ) not significant Table 5 : The role of emotions in the polarization . Linear regression models , Pol ~ V + A and Pol ~ P+N , results for polarization of the evaluation of an item as a function of emotions expressed on its text . Arousal and negativity drive polarization in all datasets except Reddit . The effect of valence and positivity is dataset-dependent . This also manifests in the model using positive and negative scores , where negative content predicts higher polarization in the same three cases as for arousal . The results of these two metrics are consistent with the hypothesis that the expression of activating and negative feelings , such as anger or outrage , 12/20 Adiya Abisheva , David Garcia , Frank Schweitzer : When the Filter Bubble Bursts : Collective Evaluation Dynamics in Online Communities Submitted to the 8th International ACM Web Science Conference 2016 tend to create more polarized responses , in line with the theoretical argument that poses emotions as mechanisms to speed up evaluation processes at the expense of more extreme reactions . Valence in evaluated items creates different responses . Two communities , Imgur and Reddit , show a negative relation of polarization with valence and positive sentiment . The other two , Urban Dictionary and YouTube , show the opposite , where polarization increases with valence . This suggests a context dependent interpretation of positive expression , which does not necessarily motivate positive empathy but can also fuel polarized responses . The positive and negative scores model works better than the valence and arousal model in all cases but Reddit , where the valence and arousal model was more explanatory for polarization , as evidenced by x ? tests comparing both models . 5 Discussion Our study of emotions focuses on understanding the role of emotions expressed in the text of items with relation to the chances that the items reach the global regime and produce polarized evaluations . While we used two established and validated sentiment analysis methods based on metrics from psychology , future advanced techniques can reveal new patterns and potentially falsify the conclusions of our analysis with current techniques . Furthermore , deeper analyses on individual data can correlate the expression of individual emotions in the comments of a user and the evaluations given by the user , bridging closer this way the measurement of emotional states and evaluations and providing a better understanding of interpersonal emotions . Following an observational approach to collective evaluations has the advantage of having high ecological validity , but lacks the level of control that can be induced in experimental scenarios . We can deduce insights on the factual properties of collective evaluations , such as the dual regime between likes and dislikes , but testing the conditions that produce them requires a controlled set up . Our motivation and explanation for the dual regime stems from the phenomenon of filter bubbles [ 51 ] , but to fully understand how these filters affect our behavior we need to experiment on how individual evaluations respond to filtering mechanisms . While these experiments can be carried out it in typical psychological settings and surveys , large platforms like Facebook can also experiment with the behavior of their users in this respect ( under the appropriate ethical considerations ) . A complete understanding of online evaluations can only be achieved when our results are complemented by experimental approaches . The use of observational data has the advantage of taking a natural exposure approach : we analyze the evaluations of what people actually see , rather than the forced exposure to content in experiments [ 43 ] . In contrast , using digital traces of evaluations contains a selection bias by which some users might be responsible for much larger amounts of likes and dislikes than other users . While this selection bias is natural at the collective level , inferring conclusions about the behavior of individuals needs to consider corrections and use richer datasets [ 13 ] , or apply agent-based modelling approaches to connect the micro and macro levels [ 59 ] . We explain the dual pattern between likes and dislikes as the result of filter bubbles , but other possible explanations might also be plausible . Some unkown deleting mechanism might downsample videos with a lot of dislikes in the local regime , or some external factor like audience size might explain the values of the thresholds . The results of our statistical analyses of distributions of likes and dislikes fit to hypothetical 13/20 Adiya Abisheva , David Garcia , Frank Schweitzer : When the Filter Bubble Bursts : Collective Evaluation Dynamics in Online Communities Submitted to the 8th International ACM Web Science Conference 2016 mechanisms of multiplicative growth , in line with previous findings on popularity metrics rather than evaluations [ 67 , 6 ] . Our in depth statistics also provide a clear view on the limits of our results , for exam- ple in the worse fits of log-normal distributions in Imgur . Future research can conjecture on the possible alternative explanations of our findings , in particular with respect to which filtering mechanisms are in place . Our results do not allow us to distinguish social filtering , based on friends and follower links , from recommender systems , which are based on previous evaluations of a user . Further research with informa- tion on individual behavior can shed light on these different processes , for example measuring evaluation tendencies to content produced by friends versus strangers , or across assortative and disassortative links with respect to opinions . Our analysis of the relation between likes and dislikes is based on the amounts given to items after a long time has passed . This way , we evaluate items after they do not attract lots of attention and their counts are stable . In a figurative way , we study the fossils of broken filter bubbles , but we do not study them in a live setting . To fully understand the dynamics of collective evaluations , we need data with temporal resolution on the counts of likes and dislikes . In general , such data is not publicly available on the sites , which requires a much more powerful crawling approach to monitor items on a frequent basis , or access to proprietary data . 6 Conclusions Our analysis of collective evaluations across various online media shows statistical regularities in the distributions of evaluations and their relationships . Our contribution is threefold : First we report that the distributions of the amounts of likes and dislikes per item are well fitted by log-normal distributions , a result that gives insights into the properties of the process that creates evaluations . Second , we test the existence of a dual pattern in the relation between likes and dislikes , finding robust evidence of the existence of a local and a global regime that is consistent with our hypotheses about the burst of filter bubbles . Third , we found evidence for the role of emotions in the creation of polarization and the access to the global regime , lending support for psychology theories about the role of affect , in particular arousal , in the polarization of opinions . Our results have implications for the design of online platforms and filtering mechanisms . Recommender systems and filtering mechanisms allow users to discover content of relevance and quality , but can have unintended consequences in the large scale . Our results suggest that the increasing polarization levels of discussions might be created by these filtering mechanisms , and that users are at risk of receiving a negative backlash to their content when it goes beyond their local social context . Such abrupt behavior with respect to negative evaluations can have important consequences to user motivation and engagement , which might only be visible on the long run . Our findings shed light on fundamental polarization processes , in particular with respect to the role of emotions . Increasing levels of polarization pose a risk of social conflict and hinder collaboration and common goods , but a healthy society needs certain level of disagreement to be able to deliberate , discuss , and take decisions about important topics . Calibrating the design of web and social media offers this way the chance to find a balance between stagnation and polarization , leading to productive interaction in our current online society . 14/20 Adiya Abisheva , David Garcia , Frank Schweitzer : When the Filter Bubble Bursts : Collective Evaluation Dynamics in Online Communities Submitted to the 8th International ACM Web Science Conference 2016 7 Acknowledgments : This research was funded by the Swiss National Science Foundation ( CR2111_146499/1 ) . References [ 1 ] [ 2 ] [ 3 ] [ 4 ] [ 5 ] [ 6 ] [ 7 [ 8 ] [ 9 ] [ 10 ] [ 11 ] ABBASI , A. , Hassan , A. , AND Duar , M. Benchmarking twitter sentiment analysis tools . In Pro- ceedings of the Ninth International Conference on Language Resources and Evaluation ( LREC ’ 14 ) ( Reykjavik , Iceland , may 2014 ) , European Language Resources Association ( ELRA ) . ABISHEVA , A. , GARIMELLA , V. R. K. , GARcIA , D. , AND WEBER , I . Who watches ( and shares ) what on youtube ? and when ? using twitter to understand youtube viewership . In In Proceedings of the 7th ACM international conference on Web search and data mining , pages : 593-602 ( February 2014 ) . ADAMIC , L. A. , AND GLANCE , N. The political blogosphere and the 2004 us election : divided they blog . In Proceedings of the 3rd international workshop on Link discovery ( 2005 ) , ACM , pp . 36-43 . ALSTOTT , J. , BULLMORE , E. , AND PLENZ , D. powerlaw : A python package for analysis of heavy- tailed distributions . PLoS ONE 9 , 1 ( 01 2014 ) , e85777 . AMENDOLA , L. , MARRA , V. , AND QuARTIN , M. The evolving perception of controversial movies . Palgrave Communications 1 ( 2015 ) . Asur , S. , HUBERMAN , B . A. , $ zaBo , G. , AND WaNG , C. Trends in social media : Persistence and decay . Available at SSRN 1755748 ( 2011 ) . Burke , M. , MARLow , C. , AND LENTO , T. Social network activity and social well-being . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems ( 2010 ) , ACM , pp . 1909-1912 . CHMIEL , A. , SOBKOWICZ , P. , SIENKIEWICZ , J. , PALTOGLOU , G. , BUCKLEY , K. , THELWALL , M. , AND Hotyst , J . A . Negative emotions boost user activity at { BBC } forum . Physica A : Statistical Mechanics and its Applications 390 , 16 ( 2011 ) , 2936 — 2944 . CuHoupuurRY , M. D. , Counts , $ . , AND GAMON , M. Not all moods are created equal ! exploring human emotional states in social media . In ICWSM ( 2012 ) , J. G. Breslin , N. B. Ellison , J. G. Shanahan , and Z. Tufekci , Eds. , The AAAI Press . CuHoupuHury , M. D. , AND DE , S. Mental health discourse on reddit : Self-disclosure , social sup- port , and anonymity . In Proceedings of the Eighth International Conference on Weblogs and Social Media , ICWSM 2014 , Ann Arbor , Michigan , USA , June 1-4 , 2014 . ( 2014 ) . Conover , M. , RATKIEWICz , J. , FRANcIsco , M. R. , GONGALVES , B. , MENCZER , F. , AND FLAMMINI , A . Political polarization on twitter . JCWSM 133 ( 2011 ) , 89-96 . 15/20 Adiya Abisheva , David Garcia , Frank Schweitzer : When the Filter Bubble Bursts : Collective Evaluation Dynamics in Online Communities Submitted to the 8th International ACM Web Science Conference 2016 [ 12 ] [ 13 ] [ 14 ] [ 15 ] [ 16 ] [ 17 ] [ 18 ] [ 19 ] [ 20 ] [ 21 ] [ 22 ] [ 23 ] [ 24 ] [ 25 ] [ 26 ] [ 27| CRANE , R. , AND SORNETTE , D. Robust dynamic classes revealed by measuring the response function of a social system . Proceedings of the National Academy of Sciences 105 , 41 ( 2008 ) , 15649-15653 . CUDDEBACK , G. , WILSON , E. , ORME , J. G. , AND COMBS-ORME , T. Detecting and statistically correcting sample selection bias . Journal of Social Service Research 30 , 3 ( 2004 ) , 19-33 . FLAcHE , A. , AND Macy , M. W. Small worlds and cultural polarization . The Journal of Mathe- matical Sociology 35 , 1-3 ( 2011 ) , 146-176 . FONTAINE , J. R. , SCHERER , K. R. , ROESCH , E. B. , AND ELLSwWorRTH , P. C. The world of emotions is not two-dimensional . Psychological science 18 , 12 ( 2007 ) , 1050-1057 . FOR COMPUTATIONAL STATISTICS , S. U. L. , AND FRIEDMAN , J. H. Fast MARS . 1993 . FRIEDMAN , J. H. Multivariate adaptive regression splines . The annals of statistics ( 1991 ) , 1-67 . Garas , A. , Garcia , D. , Skowron , M. , AND SCHWEITZER , F. Emotional persistence in online chatting communities . Scientific Reports 2 , arXiv:1205.2466 ( May 2012 ) , 402 . 34 p. Comments : 34 pages , 4 main and 12 supplementary figures . Garcia , D. , ABISHEVA , A. , SCHWEIGHOFER , S. , SERDULT , U. , AND SCHWEITZER , F. Ideo- logical and temporal components of network polarization in online political participatory media . Policy & Internet 7 , 1 ( 2015 ) , 46-79 . Garcia , D. , MENDEZ , F. , SERDULT , U. , AND SCHWEITZER , F. Political polarization and pop- ularity in online participatory media : An integrated approach . In Proceedings of the first edition workshop on Politics , elections and data - PLEAD ’ 12 ( 2012 ) , pp . 3-10 . Garcia , D. , AND SCHWEITZER , F. Emotions in product reviews AAS empirics and models . Pro- ceedings of 2011 IEEE International Conference on Privacy , Security , Risk , and Trust , and IEEE International Conference on Social Computing , PASSAT/SocialCom ( 2011 ) , 483- 488 . Garcia , D. , AND TANASE , D. Measuring cultural dynamics through the eurovision song contest . Advances in Complex Systems 16 , 08 ( 2013 ) , 1350037 . GOLDER , S. A. , AND Macy , M. W. Diurnal and seasonal mood vary with work , sleep , and daylength across diverse cultures . Science 333 , 6051 ( 2011 ) , 1878-1881 . GONZALEZ-BAILON , S. , BANCHS , R. E. , AND KALTENBRUNNER , A . Emotional reactions and the pulse of public opinion : Measuring the impact of political events on the sentiment of online discussions . CoRR abs/1009.4019 ( 2010 ) . Gorn , G. , PHAM , M. T. , AND SIN , L. Y . When arousal influences ad evaluation and valence does not ( and vice versa ) . Journal of consumer Psychology 11 , 1 ( 2001 ) , 43-55 . GueErRRA , P. H. C. , MEIRA JR , W. , CARDIE , C. , AND KLEINBERG , R. A measure of polariza- tion on social media networks based on community boundaries . In JCWSM ( 2013 ) . Hoana , T.-A. , CoHEN , W. W. , LIM , E.-P. , PrERcE , D. , AND REDLAWSK , D. P. Politics , shar- ing and emotion in microblogs . In Proceedings of the 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining ( 2013 ) , ACM , pp . 282-289 . 16/20 Adiya Abisheva , David Garcia , Frank Schweitzer : When the Filter Bubble Bursts : Collective Evaluation Dynamics in Online Communities Submitted to the 8th International ACM Web Science Conference 2016 [ 28 ] [ 29 ] [ 30 ] [ 31 ] [ 32 ] [ 33 ] [ 34 ] [ 35 ] [ 36 ] [ 37 ] [ 38 ] [ 39 ] [ 40 ] [ 41 ] [ 42| Iosus , D. , LAntapo , D. , CASTILLO , C. , FUSTER MORELL , M. , AND KALTENBRUNNER , A . Emotions under discussion : Gender , status and communication in online collaboration . PLoS ONE 9 , 8 ( 2014 ) , e104880 . Isen , A. M. , SHALKER , T. E. , CLARK , M. , AND Karp , L. Affect , accessibility of material in memory , and behavior : A cognitive loop ? Journal of personality and social psychology 36 , 1 ( 1978 ) , 1 . Kan , A. , CHAN , J. , HAYES , C. , AND HoGan , B . Studying forum dynamics from a user engage- ment perspective . kim , S. , Bak , J. , AND OH , A. H. Do you feel what i feel ? social aspects of emotions in twitter conversations . In JCWSM ( 2012 ) . KIVRAN-SWAINE , F. , BRopy , S. , DIAKOPOULOS , N. , AND NAAMAN , M. Of joy and gender : Emotional expression in online social networks . In Proceedings of the ACM 2012 Conference on Computer Supported Cooperative Work Companion ( 2012 ) , CSCW °12 , pp . 139-142 . KIVRAN-SWAINE , F. , AND NAAMAN , M. Network properties and social sharing of emotions in social awareness streams . In Proceedings of the ACM 2011 conference on Computer supported cooperative work ( 2011 ) , ACM , pp . 379-382 . KucukTuNcC , O. , CAMBAZOGLU , B . B. , WEBER , I. , AND FERHATOSMANOGLU , H. A large-scale sentiment analysis for yahoo ! answers . In Proceedings of the Fifth ACM International Conference on Web Search and Data Mining ( New York , NY , USA , 2012 ) , WSDM 712 , ACM , pp . 633-642 . KUune , R. , ET AL . Political news , emotions , and opinion formation : Toward a model of emo- tional framing effects . In Annual Conference of the International Communication Association ( ICA ) , Phoenix , AZ ( 2012 ) . LARSEN , P. O.c. ’ s rebecca black talks about ‘ friday ’ . http : //www.ocregister.com/articles/ -292662 -- .html . Accessed : 2016-02-02 . Leg , M. , Ha , T. , HAN , J. , AND Rua , J.-Y . Online footsteps to purchase : Exploring consumer behaviors on online shopping sites . LEesKoveEc , J. , ADAMIc , L. A. , AND HUBERMAN , B . A . The dynamics of viral marketing . ACM Transactions on the Web ( TWEB ) 1 , 1 ( 2007 ) , 5 . Lin , Y.-R. Assessing sentiment segregation in urban communities . In Proceedings of the 2014 International Conference on Social Computing ( 2014 ) , pp . 9:1-9:8 . LORENZ , J . Continuous opinion dynamics under bounded confidence : A survey . International Journal of Modern Physics C 18 , 12 ( 2007 ) , 1819-1838 . LORENZ , J. Universality in movie rating distributions . The European Physical Journal B 71 , 2 ( 2009 ) , 251-258 . MAs , M. , AND FLacHE , A. Differentiation without distancing . explaining bi-polarization of opin- ions without negative influence . PloS one 8 , 11 ( 2013 ) , e74516 . 17/20 Adiya Abisheva , David Garcia , Frank Schweitzer : When the Filter Bubble Bursts : Collective Evaluation Dynamics in Online Communities Submitted to the 8th International ACM Web Science Conference 2016 [ 13 ] [ 44 ] [ 45 ] [ 46 ] [ 47| [ 48 ] [ 49 ] [ 59 ] [ 51 ] [ 52| [ 53 ] [ 54 ] [ 55 ] [ 56 ] [ 57| [ 58 ] [ 59 ] McPHEE , W.N . Formal theories of mass behavior . ‘ The Free Press of Glencoe , Collier- Macmillian , London , 1963 . MIEGHEM , P. V. Human psychology of common appraisal : The reddit score . [ EEE Transactions on Multimedia 13 , 6 ( 2011 ) , 1404-1406 . MILLER , M. , SATHI , C. , WIESENTHAL , D. , LESKOVEC , J. , AND POTTS , C. Sentiment flow through hyperlink networks . In ICWSM ( 2011 ) . MITZENMACHER , M. A brief history of generative models for power law and lognormal distribu- tions . Internet mathematics 1 , 2 ( 2004 ) , 226-251 . NAKATANI , S. Language detection library for java . https : //github.com/shuyo/ language-detection/blob/wiki/ProjectHome.md , 2010-current . NOELLE-NEUMANN , E. , AND NOELLE-NEUMANN , E. The spiral of silence : Public opinion , our social skin . University of Chicago Press Chicago , 1993 . OLson , R. A data-driven guide to creating successful reddit posts , redux . Accessed : 2016-02-02 . ONNELA , J.-P. , AND REED-TsocHas , F. Spontaneous emergence of social influence in online systems . Proceedings of the National Academy of Sciences 107 , 43 ( 2010 ) , 18375-18380 . PARISER , E. The filter bubble : What the Internet is hiding from you . Penguin UK , 2011 . PAULHUS , D. L. , AND Lim , D. T. Arousal and evaluative extremity in social judgments : A dy- namic complexity model . European Journal of Social Psychology 24 , 1 ( 1994 ) , 89-99 . PFITZNER , R. , GARAS , A. , AND SCHWEITZER , F. Emotional divergence influences informa- tion spreading in twitter . In ICWSM ( 2012 ) , J. G. Breslin , N. B. Ellison , J. G. Shanahan , and Z. Tufekci , Eds. , The AAAI Press . QuerciA , D. , CAPRA , L. , AND CROWCROFT , J . The social world of twitter : Topics , geography , and emotions . In ICWSM ( 2012 ) , J. G. Breslin , N. B. Ellison , J. G. Shanahan , and Z. Tufekci , Eds. , The AAAI Press . REISENZEIN , R. The schachter theory of emotion : two decades later . Psychological bulletin 94 , 2 ( 1983 ) , 239 . Rowe , M. , anp ALANI , H. Mining and comparing engagement dynamics across multiple so- cial media platforms . In Proceedings of the 2014 ACM conference on Web science ( 2014 ) , ACM , pp . 229-238 . RUSSELL , J . A. , AND BARRETT , L. F. Core affect , prototypical emotional episodes , and other things called emotion : Dissecting the elephant . Journal of Personality and Social Psychology 76,5 ( 1999 ) , 805-819 . SCHWARZ , N. , AND CLORE , G. How doi feel about it ? the informative function of affective states . Affect , cognition , and social behavior ( 1988 ) , 44-62 . SCHWEITZER , F. , AND GaARcIA , D. An agent-based model of collective emotions in online com- munities . The European Physical Journal B 77 , 4 ( 2010 ) , 533- 545 . 18/20 Adiya Abisheva , David Garcia , Frank Schweitzer : When the Filter Bubble Bursts : Collective Evaluation Dynamics in Online Communities Submitted to the 8th International ACM Web Science Conference 2016 [ 60 ] [ 61 ] [ 62| [ 63 ] [ 64 ] [ 65 ] [ 66 ] [ 67| [ 68 ] [ 69 ] [ 70 ] [ 71 ] [ 72| [ 73 ] [ 74 ] SZABO , G. , AND HUBERMAN , B . A . Predicting the popularity of online content . Communications of the ACM 53 , 8 ( 2010 ) , 80-88 . Tan , C. , LEE , L. , Tanc , J. , JIANG , L. , ZHou , M. , AND LI , P. User-level sentiment analysis incorporating social networks . In Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining ( 2011 ) , KDD 711 , pp . 1397-1405 . TAYLOR , J. , AND MACDONALD , J . The effects of asynchronous computer-mediated group interac- tion on group processes . Social Science Computer Review 20 , 3 ( 2002 ) , 260-274 . TcHoxnI , S. , O SEAGHDHA , D. , AND QuErRcIA , D. Emoticons and phrases : Status symbols in social media . In Proceedings of the 8th International AAAI Conference on Weblogs and Social Media ( ICWSM 2014 ) ( Ann Arbor , MI , 2014 ) . THELWALL , M. , BUCKLEY , K. , AND PALTOGLOU , G. Sentiment strength detection for the social web . J . Am . Soc . Inf . Sci . Technol . 63 , 1 ( Jan. 2012 ) , 163-173 . THELWALL , M. , BUCKLEY , K. , PALTOGLOU , G. , Cal , D. , AND Kappas , A . Sentiment in short strength detection informal text . J . Am . Soc . Inf . Sci . Technol . 61 , 12 ( Dec. 2010 ) , 2544-2558 . THELWALL , M. , WILKINSON , D. , AND UPPAL , S. Data mining emotion in social network commu- nication : Gender differences in myspace . Journal of the American Society for Information Science and Technology 61 , 1 ( 2010 ) , 190-199 . VAN MIEGHEM , P. , BLENN , N. , AND DOERR , C. Lognormal distribution in the digg online social network . The European Physical Journal B 83 , 2 ( 2011 ) , 251-261 . VAN Swot , L. M. Extreme members and group polarization . Social Influence 4 , 3 ( 2009 ) , 185- 199 . VAROL , O. , FERRARA , E. , OGAN , C. L. , MENCZER , F. , AND FLAMMINI , A. Evolution of on- line user behavior during a social upheaval . In Proceedings of the 2014 ACM conference on Web science ( 2014 ) , ACM , pp . 81-90 . WANG , C. , AND HUBERMAN , B . A . Long trend dynamics in social media . EPJ Data Science 1 , 1 ( 2012 ) , 1-8 . Wanc , N. , KosINsk1 , M. , STILLWELL , D. , AND Rust , J . Can well-being be measured using facebook status updates ? validation of facebookaAZs gross national happiness index . Social Indi- cators Research 115 , 1 ( 2014 ) , 483-491 . WaRRINER , A. , KUPERMAN , V. , AND BRYSBAERT , M. Norms of valence , arousal , and dominance for 13,915 english lemmas . Behavior Research Methods 45 , 4 ( 2013 ) , 1191-1207 . WENINGER , T. , JOHNSTON , T. J. , AND GLENSKI , M. Random voting effects in social-digital spaces : A case study of reddit post submissions . In Proceedings of the 26th ACM Conference on Hypertext & Social Media ( 2015 ) , ACM , pp . 293-297 . WEsT , R. , Paskov , H. , LESKOVEc , J. , AND PoTTs , C. Exploiting social network structure for person-to-person sentiment analysis . Transactions of the Association for Computational Linguis- tics 2 ( 2014 ) , 297-310 . 19/20 Adiya Abisheva , David Garcia , Frank Schweitzer : When the Filter Bubble Bursts : Collective Evaluation Dynamics in Online Communities Submitted to the 8th International ACM Web Science Conference 2016 [ 75 ] Wu , F. , AND HUBERMAN , B . A . Novelty and collective attention . Proceedings of the National Academy of Sciences 104 , 45 ( 2007 ) , 17599-17601 . [ 76 ] ZILLMANN , D. Excitation transfer in communication-mediated aggressive behavior . Journal of experimental social psychology 7 , 4 ( 1971 ) , 419-434 . 20/20 QUT Queensland University of Technology Brisbane Australia This may be the author ’ s version of a work that was submitted/accepted for publication in the following source : Graham , Timothy & Ackland , Robert ( 2017 ) Do socialbots dream of popping the filter bubble ? The role of socialbots in promoting deliberative democracy in social media . In Gehl , R W & Bakardjieva , M ( Eds . ) Socialbots and their friends : Digital media and the automation of sociality . Routledge , United States of America , pp . 187-206 . This file was downloaded from : https : //eprints.qut.edu.au/127909/ © Consult author ( s ) regarding copyright matters This work is covered by copyright . Unless the document is being made available under a Creative Commons Licence , you must assume that re-use is limited to personal use and that permission from the copyright owner must be obtained for all other uses . If the docu- ment is available under a Creative Commons License ( or other specified license ) then refer to the Licence for details of permitted re-use . It is a condition of access that users recog- nise and abide by the legal requirements associated with these rights . If you believe that this work infringes copyright please provide details by email to qut.copyright @ qut.edu.au Notice : Please note that this document may not be the Version of Record ( i.e . published version ) of the work , Author manuscript versions ( as Sub- mitted for peer review or as Accepted for publication after peer review ) can be identified by an absence of publisher branding and/or typeset appear- ance . If there is any doubt , please refer to the published source . https : //doi.org/10.4324/978 1315637228 This is a PRE-PRINT version of the following book chapter : Graham , T. , & Ackland , R. ( 2017 ) . Do Socialbots Dream of Popping the Filter Bubble ? The role of socialbots in promoting participatory democracy in social media . In M. Bakardjieva & R. Gehl , ( Eds . ) , Socialbots and their friend : Digital media and the automation of sociality ( Chapter 10 ) . New York : Routledge . Do Socialbots Dream of Popping the Filter Bubble ? The role of socialbots in promoting deliberative democracy in social media Timothy Graham and Robert Ackland Australian National University , Canberra , Australia Timothy.Graham @ anu.edu.au Robert.Ackland @ anu.edu.au The electric things have their lives , too . Paltry as those lives are . —Rick Deckard , in Do Androids Dream of Electric Sheep ? What counts is that we are at the beginning of something . —Deleuze ( 1992 , p. 7 ) Introduction Philip K. Dick ’ s seminal novel , Do Androids Dream of Electric Sheep ? ( adapted into the film Blade Runner ) , poses multiple questions about the relations between humans and non- humans . One such question concerns whether we might one day reach a future in which robotic humanoids ( i.e . the titular ‘ androids ’ ) and humans are no longer easily distinguishable . In the age of social media , it is now evident that the question Dick initiated over half a century ago has found particular relevance in the figure of the ‘ socialbot ’ . As Gehl This is a PRE-PRINT version of the following book chapter : Graham , T. , & Ackland , R. ( 2017 ) . Do Socialbots Dream of Popping the Filter Bubble ? The role of socialbots in promoting participatory democracy in social media . In M. Bakardjieva & R. Gehl , ( Eds . ) , Socialbots and their friend : Digital media and the automation of sociality ( Chapter 10 ) . New York : Routledge . contends : “ The last tweet you got may have been from a robot ” ( Gehl , 2014 , p. 21 ) . Yet ‘ bots ’ , loosely defined as software applications involved in the automation of tasks over the internet , have existed since at least the mid-1990s . For example , web crawlers ( bots that assist in the collection and indexing of web content ) and ‘ spambots ’ ( bots that send massive volumes of unsolicited ‘ spam ’ email ) are so mundane as to appear almost invisible nowadays . Similarly , chatbots or ‘ chatterbots ’ ( bots that engage in conversation in online spaces ) have existed since the early years of the web ( Mauldin , 1994 ) , and have developed into the research area of ‘ conversational agents ’ ( Gaglio & Lo Re , 2014 , pp . 285-299 ; see also Chapter Six ) . Scholars have also recently explored the role of bots in automated high-frequency trading within global financial markets , drawing to attention the world-shaking events that can emerge as a result of their complex interactions ( Steiner , 2012 ) . Given the broader context , one might ask what is unique or interesting about socialbots . Hwang et al offer the following : What distinguishes these “ social ” bots from their historical predecessors is a focus on creating substantive relationships among human users—as opposed to financial resources—and shaping the aggregate social behaviour and patterns of relationships between groups of users online . ( 2012 , p. 40 , emphasis added ) In recent years a growing body of literature has explored the proliferation of socialbots in social media sites such as Twitter and Facebook . Indeed , various studies have now demonstrated that socialbots are able to infiltrate social media , remain undetected and even function ‘ successfully ’ as social actors ( Boshmaf et al , 2011 ; Freitas et al , 2014 ) . Like the conversional agent ‘ Max ’ in Muhle ’ s study , their status as human or non-human is not always settled , although their capacity to be ‘ social ’ actors in a ‘ human-like ’ way is disputed ( Chapter Six ) . Nevertheless , there is no doubt that socialbots are able to act successfully in generating attention and attracting followers . In an experiment to infiltrate Twitter using socialbots , Freitas et al ( 2014 ) found that “ over the duration of the experiment , the 120 socialbots created by us received in total 4,999 follows from 1,952 distinct users , and 2,128 message- This is a PRE-PRINT version of the following book chapter : Graham , T. , & Ackland , R. ( 2017 ) . Do Socialbots Dream of Popping the Filter Bubble ? The role of socialbots in promoting participatory democracy in social media . In M. Bakardjieva & R. Gehl , ( Eds . ) , Socialbots and their friend : Digital media and the automation of sociality ( Chapter 10 ) . New York : Routledge . based interactions from 1,187 distinct users ... a significant fraction of the socialbots acquire relatively high popularity and influence scores ” ( Freitas et al , 2014 , p. 7 ) . In a similar study , Hwang et al ( 2011 ) discovered that socialbots were not only able to infiltrate target sub- networks on Twitter , but also “ succeed in reshaping the social graph of the 500 targets , drawing responses and interactions from users that were previously not directly connected ” ( Hwang et al , 2011 , p. 41 ) . Indeed , in making sense of this phenomenon , Gehl ( 2014 ) argues that socialbots are becoming enrolled in processes of noopower ( a term drawing on Lazzarato ) , broadly defined as “ the action before action that works to shape , modulate , and attenuate the attention and memory of subjects ” ( Gehl , 2014 , p. 23 ) . Emerging theoretical perspectives on socialbots suggests a subtle and complex role for social robotics in the context of social media . The ability for socialbots to appear human-like and also shape social relations calls to mind the rogue Nexus-6 androids of Dick ’ s novel , which , in the eyes of the state , constituted a serious danger to individuals and society . Indeed , discourse in recent literature tends to construct socialbots as a kind of ‘ danger ’ or hazard to society . For example , we learn that socialbots are deployed to ‘ infiltrate ’ and ‘ exploit ’ social network sites ( SNS ) in order to extract or expose private information about individuals and their workplaces ( see for example : Elyashar et al , 2013 ; Paradise et al , 2014 ) . We are informed that ‘ botnets ’ , coordinated armies of socialbots mimicking human users , are able to circumvent existing security mechanisms in order to wreak systemic havoc by spreading propaganda or misinformation ( Boshmaf et al , 2011 ) . Other studies , such as Mitter et al ( 2014a ) have taken the dangers of socialbots into the ‘ meta ’ realm , by developing a categorisation schema to understand and counter-act the various categories of socialbot ‘ attacks ’ on SNS . There is certainly much validity to such narratives , and the negative aspects of socialbots constitute a complex , open research problem . However , there is another side to socialbots that has not attracted much scholarly inquiry , as Hwang et al argue : “ While much has been made about the dark side of social robotics , several positive applications interactions of this technology are emerging ” ( Hwang et al , 2012 , p. 40 ) . This is a PRE-PRINT version of the following book chapter : Graham , T. , & Ackland , R. ( 2017 ) . Do Socialbots Dream of Popping the Filter Bubble ? The role of socialbots in promoting participatory democracy in social media . In M. Bakardjieva & R. Gehl , ( Eds . ) , Socialbots and their friend : Digital media and the automation of sociality ( Chapter 10 ) . New York : Routledge . It is therefore evident that much research tends to highlight the dangers or risks associated with socialbots—what might be considered as the ‘ social bad ’ perspective . In this chapter we seek to evaluate the obverse of this perspective in order to explore some beneficial capacities of socialbots ( in their capacity to ‘ exploit ’ and shape online social networks ) . In this way , in this chapter we tackle an idea previously raised by Hwang et al : “ Swarms of bots could be used to heal broken connections between infighting social groups and bridge existing social gaps . Socialbots could be deployed to leverage peer effects to promote more civic engagement and participation in elections ” ( 2012 , p. 40 ) . More specifically , we explore how socialbots on social media could exploit network structure to mitigate the effect of political filter bubbles and political segregation , thus promoting the Habermasian ideal of deliberative democracy - a public sphere ( e.g . Habermas , 1996 ) where individuals can discuss matters of mutual interest and hopefully reach a common understanding or solution , or at the least can “ hear the other side ” ( Mutz , 2006 ) . For simplicity , we focus much of our presentation on the microblog Twitter but our ideas are applicable to any social media where people congregate to discuss and engage with political issues ( e.g . web forums , fan pages and group pages in Facebook ) . The remainder of this chapter is structured as follows . In the next section we define and problematise deliberative democracy in the context of the web , highlighting key theoretical perspectives and empirical research . The third section introduces and discusses the role of socialbots in promoting deliberative democracy in social media networks . In doing so , we set forth three ‘ principles ’ for socialbots that introduce key concepts and technical methods for socialbots in this role . In section four , we develop these concepts and methods further by introducing the notion of ‘ popperbots ’ and ‘ bridgerbots ’ , providing a two-fold ‘ schematic ’ for programming socialbots to promote deliberative democracy in social media . Finally , we conclude with a reflection on the meaning and implications of social robotics within the entangled trajectories of politics , social media , and contemporary modes of power . Filter bubbles and deliberative democracy on the web : network topologies , algorithmic sorting , and political homophily This is a PRE-PRINT version of the following book chapter : Graham , T. , & Ackland , R. ( 2017 ) . Do Socialbots Dream of Popping the Filter Bubble ? The role of socialbots in promoting participatory democracy in social media . In M. Bakardjieva & R. Gehl , ( Eds . ) , Socialbots and their friend : Digital media and the automation of sociality ( Chapter 10 ) . New York : Routledge . He experienced them , the others , incorporated the babble of their thoughts , heard in his own brain the noise of their many individual existences. ! On the web , politics unfolds through topologically variant networks , and actors both shape— and are shaped by—the hybrid socio-technological environments they co-habit . In the context of political discussion online , one might be tempted to regard the internet as an equal or neutral playing field , whereby people of all backgrounds converge to learn , debate , and participate in political discourse . This was the basis of early Utopian predictions of the impact of the web on politics ( e.g . Castells , 1996 ) : that the web would foster a new era of broad-based participation in the direction and operation of the political system . In contrast , Putnam ( 2000 ) and Sunstein ( 2001 ) predicted a loss of acommon political discourse resulting from a fragmenting of the online population into narrowly focused groups of individuals who are only exposed to information that confirms their previously held opinions - later referred to as ‘ cyberbalkanisation ' ( Van Alstyne and Brynjolfsson , 2005 ) . These concerns about the potential impact of the web on democracy have continued into the present era of social media . In his book , ‘ The Filter Bubble ’ , Eli Pariser argues that web users are increasingly entrapped within personal ‘ filter bubbles ’ that reflect back to them their already-held opinions or beliefs , and expose them to subjects they are already interested in ( Pariser , 2011 ) . The ‘ filter bubble ’ , also referred to as the ‘ echo chamber ’ , can be understood as emerging from two phenomena : algorithmic sorting ( whereby external forces or ‘ opportunity structures ’ influence the types of political information and people that individuals are likely to encounter ) and individual preferences ( whereby web technologies enable individuals to efficiently select who they want to connect with and what types of information they want to be exposed to ) . Algorithmic sorting occurs at both the aggregate- and individual-level . Concerns about the political implications of aggregate-level sorting first emerged in Web 1.0 research which considered the fact that the web , like many large-scale networks , has been found to exhibit a ‘ power law ' in the distribution of in-links ( meaning a very unequal distribution , with a small This is a PRE-PRINT version of the following book chapter : Graham , T. , & Ackland , R. ( 2017 ) . Do Socialbots Dream of Popping the Filter Bubble ? The role of socialbots in promoting participatory democracy in social media . In M. Bakardjieva & R. Gehl , ( Eds . ) , Socialbots and their friend : Digital media and the automation of sociality ( Chapter 10 ) . New York : Routledge . number of websites enjoying many in-links and the vast major of websites only have few or no in-links ) . Hindman et al ( 2003 ) argued that power laws on the web could imply vast inequalities in the distribution of attention to different political viewpoints , since people usually find new websites either by following links ( web surfing ) or by using search engines such as Google , and in both cases a website is more likely to be discovered the greater the number of in-links from other relevant sites . Aggregate-level algorithmic sorting occurs in social media in the form of “ trending topics ” in Twitter , for example , and forces of cumulative advantage ( the ‘ rich get richer ’ ) can help a topic to take off . A concern is that social media companies can exert a degree of curatorial control over trending topics . An oft-cited example is the fact that , during the Occupy Wall Street movement , participants and supporters used Twitter extensively for communication and debate ( garnering massive media attention ) , yet the # OccupyWallStreet hashtag failed to become a “ trending topic ” on the Twitter homepage ( Gillespie , 2012 ) . Individual-level algorithmic sorting is undertaken by the social media providers whereby web content is ‘ individualised ’ based on user demographics ( e.g . voluntarily contributed profile data or trace artefact data such as browser cookies ) and/or user activity ( e.g . what types of web content users statistically tend to be interested in ) . In the case of Twitter , each user has a “ home timeline ” that not only displays content they have elected to view , but also content that is suggested or curated by Twitter ’ s algorithms . As the official Twitter FAQ states : “ Your home timeline displays a stream of Tweets from accounts you have chosen to follow on Twitter . New users may see suggested content powered by a variety of signals ” . The Twitter FAQ continues : “ Additionally , when we identify a Tweet , an account to follow , or other content that 's popular or relevant , we may add it to your timeline . This means you will sometimes see Tweets from accounts you do n't follow ... Our goal is to make your home timeline even more relevant and interesting ” ( Twitter , 2015 , emphasis added ) . Dormehl ( 2014 ) argues that this ‘ algorithmic culture ’ has a dual nature . On the one hand , it is useful because it filters out the endless babble , or unnecessary ‘ noise ’ , that would otherwise overwhelm users and software platforms ( e.g . social media sites , search engines ) . But on the This is a PRE-PRINT version of the following book chapter : Graham , T. , & Ackland , R. ( 2017 ) . Do Socialbots Dream of Popping the Filter Bubble ? The role of socialbots in promoting participatory democracy in social media . In M. Bakardjieva & R. Gehl , ( Eds . ) , Socialbots and their friend : Digital media and the automation of sociality ( Chapter 10 ) . New York : Routledge . other hand , it is also problematic because users are not presented with “ ideologically untampered ” content , but rather the opposite—content that “ flatter our personal mythologies be reinforcing what we already ‘ know ’ about particular issues ” ( Dormehl , 2014 , p. 47 ) . Recent studies suggest that social media such as Facebook and Twitter are implicated in the advent of political filter bubbles . Whilst the extent and nature of this phenomenon is debated ( Bozdag et al , 2014 ) , the algorithmic modulation of incoming and outgoing flows of socially generated data suggests far-ranging consequences for individuals and collectives . While individuals are to some extent guided by algorithmic sorting , the role of individual preferences in the creation of political filter bubbles is perhaps even more important . Earlier research also considered the impact for politics of the ‘ narrowcasting ’ nature of the web , whereby users could use newly-invented RSS feed technology to efficiently select content from online newspapers or blogs that matched their existing political outlook . The emergence of social media has provided even more opportunity for politically-motivated social selectivity , as individuals can make conscious decisions as to who to friend in SNSs such as Facebook and who to follow , retweet or mention in Twitter . Such behaviour can lead to online networks that are highly divided along ideological or political lines , a phenomenon known as political homophily . It is an empirical question as to whether algorithmic ‘ filtering ’ of content in social media ( both at the scale of population-based ‘ trends ’ and the scale of individual user ‘ timelines ’ ) and computer-mediated social selection ( friending , following , mentioning etc . ) contribute to worsening already existing political divides across its network . The ‘ filter bubble ’ phenomenon warrants careful and serious consideration because of its possible implication in engendering creating social rifts that centre upon ideological or political lines . As Conover et al point out , “ a deliberative democracy relies on a broadly informed public and a healthy ecosystem of competing ideas ” ( Conover et al , 2011b , p. 89 ) . Some Principles of Socialbots for promoting deliberative democracy This is a PRE-PRINT version of the following book chapter : Graham , T. , & Ackland , R. ( 2017 ) . Do Socialbots Dream of Popping the Filter Bubble ? The role of socialbots in promoting participatory democracy in social media . In M. Bakardjieva & R. Gehl , ( Eds . ) , Socialbots and their friend : Digital media and the automation of sociality ( Chapter 10 ) . New York : Routledge . “ We selected her as your first subject . She may be an android . We 're hoping you can tell . `` 2 In this section , we identify three ‘ principles ’ of socialbots for promoting deliberative democracy on social media . Drawing on Muhle ( Chapter Six ) , these principles in a sense define the characteristics ( membership categories ) and respective activities ( category-bound activities ) of socialbots as ‘ good citizens ’ . Before enunciating our principles , it is necessary to first briefly define deliberative democracy and outline how it may be measured and quantified using network analysis . As noted above , our definition of deliberative democracy involves the Habermasian concept of the public sphere ( e.g . Habermas , 1996 ) , an informal discursive space where where individuals and groups can reach common understanding about issues of mutual interest , thus influencing public opinion and potentially leading to political action . Our definition of deliberative democracy thus does not cover more formal deliberation that occurs at different levels within the political system ( for example , see Dryzek , 2010 for a discussion on deliberative democracy ) . A network is a set of nodes ( vertices or entities ) and a set of ties ( edges or links ) indicating connections or relations between the nodes . While there are several types of networks that can be extracted from Twitter ( as noted above , the discussion focuses on Twitter for simplicity , but these ideas extend to other types of social media ) , we focus here on the network comprising Twitter users , where ties are created from users following each other , and retweeting , mentioning and replying to one another ( we refer to this as the ‘ user network ’ ) . So how can we measure the extent or degree of deliberative democracy using the Twitter user network ? A starting point is to construct the network of users participating in Twitter conversations on political issues , for example by only collecting tweets that feature the # auspol ( Australian politics ) hashtag . So the user network might consist of all Twitter users This is a PRE-PRINT version of the following book chapter : Graham , T. , & Ackland , R. ( 2017 ) . Do Socialbots Dream of Popping the Filter Bubble ? The role of socialbots in promoting participatory democracy in social media . In M. Bakardjieva & R. Gehl , ( Eds . ) , Socialbots and their friend : Digital media and the automation of sociality ( Chapter 10 ) . New York : Routledge . who authored at least one tweet containing # auspol , during a particular time period . A first quantitative measure of deliberative democracy is the network modularity score ( e.g . Newman , 2006 ) , which assesses the strength of the division of a network into “ communities ” ( or clusters , or modules ) . Modularity ranges between 0 and 1 , with a score closer to 0 indicating that more linking is occurring between clusters than within clusters ( i.e . less balkanisation ) . While it is difficult to interpret a given modularity score as an absolute measure of deliberative democracy , modularity may be useful when one is comparing across networks ( e.g . networks created for different political hashtags or the same hashtag , but constructed for different periods of time ) . So if we found that modularity score for the # auspol user network was decreasing over time then this would indicate that the Twitter conversation is becoming less clustered , thus indicating an increase in deliberative democracy . However , underlying our use of clustering in the Twitter user network as a measure of deliberative democracy is a very strong assumption regarding the nature of interactions that are taking place in political spaces on Twitter . Specifically , our approach involves the use of large-scale unobtrusively collected digital trace data : mention , reply , retweet and follower ties . Thus , we assume that if a Twitter user creates a tie to another user ( via a reply , retweet , mention or follow ) then this tie either reflects a shared political outlook ( political homophily ) or at the very least , is indicative of a desire to engage in a considered exchange of ideas . Deliberative democracy therefore involves a qualitative dimension , that would not be accounted for in the approach we describe above . Using SNA terminology , our modularity clustering measure of deliberative democracy assumes that ties in Twitter only reflect positive affect . If members of opposing political groups started engaging in name calling or abusive behaviour on Twitter ( that is , creating negative affect ties ) then this would lead toa network that is less clustered , but this surely would not indicate increasing deliberative democracy . There is a second reason why we should be careful in interpreting modularity clustering in the Twitter user network as a measure of deliberative democracy . Even if there were only This is a PRE-PRINT version of the following book chapter : Graham , T. , & Ackland , R. ( 2017 ) . Do Socialbots Dream of Popping the Filter Bubble ? The role of socialbots in promoting participatory democracy in social media . In M. Bakardjieva & R. Gehl , ( Eds . ) , Socialbots and their friend : Digital media and the automation of sociality ( Chapter 10 ) . New York : Routledge . positive affect ties in the network , there could still be a significant change in network modularity between two time periods without any underlying change in deliberative democracy . For example , if in the # auspol conversation on Twitter there was an increase in reciprocity ( I 'll retweet you because you retweeted me ) or triadic closure ( I follow person A and person A follows person B , therefore I 'm going to follow person B too ) , then this could result in the # auspol network becoming more clustered ( modularity score increasing ) without any underlying change in political homophily . Hence we recognise that modularity is a blunt measure of deliberative democracy , but propose it as an initial way of operationalising the principles of socialbots . Our principles of socialbots for promoting deliberative democracy are presented in the style of Asimov 's famous “ Three Laws of Robotics ’ ( see : Asimov , 1950 ) , however their scope and application is much less epochal or universal . The principles relate specifically to the survival and effective functioning of socialbots on social media . In the remainder of this section we expound upon these principles in more detail , before progressing to the specific roles that we envisage for socialbots ( discussed in the next section ) . Some Principles of Socialbots : 1 . Socialbots must do no harm to human beings ( measured in political and non-political terms ) ; 2 . Socialbots must protect their own existence , except where doing so would conflict with the First Principle ; 3 . Socialbots must make a significant improvement to deliberative democracy , obtaining non-trivial , quantifiable effects in the target sub-network ( s ) , except where doing so would conflict with the First and Second Principles . The First Principle of Socialbots This is a PRE-PRINT version of the following book chapter : Graham , T. , & Ackland , R. ( 2017 ) . Do Socialbots Dream of Popping the Filter Bubble ? The role of socialbots in promoting participatory democracy in social media . In M. Bakardjieva & R. Gehl , ( Eds . ) , Socialbots and their friend : Digital media and the automation of sociality ( Chapter 10 ) . New York : Routledge . 1 . Socialbots must do no harm to human beings ( measured in political and non-political terms ) ; Isaac Asimov ushered into the world an enduring problem in robotics—namely , that the notion of a robot causing ‘ harm ’ is very difficult to define precisely . In the context of this paper , the First Principle of Socialbots seeks to operationalise ‘ harm ’ broadly in two ways : political and non-political . We will briefly deal with both of these problems in this section and suggest several approaches to address them . Again , they are very specific to the research problem in this chapter , although we feel there may be broader applicability to socialbots vis- a-vis social media . First , for a socialbot , what would it mean to cause political harm ? Although this is a complex and multifaceted problem , at the most abstract level we argue that if a socialbot is positioned at a political extreme ( e.g . far-right or far-left ) , then it is held to cause political harm and therefore contravene the First Principle . While measuring whether a socialbot is ‘ politically extreme ’ is non-trivial , we argue that this problem is not insurmountable , in light of recent developments in the literature and key concepts within social network analysis ( SNA ) and graph theory . We will now briefly elaborate upon two possible paths towards measuring whether , and how , socialbots could cause ‘ political harm ’ in social media networks . First , socialbots could be programmed to endeavor to occupy a position within the target subnetwork ( s ) that approximates regular equivalence with ideologically or politically ‘ moderate ’ users . This argument centres on the graph theoretic notion of ‘ regular equivalence ’ whereby “ two nodes in a social network are regularly equivalent if they fulfil the same role ” ( van Steen , 2010 , p. 259 ) . What we are suggesting here is that socialbots could be programmed to occupy a similar ‘ social role ’ , or in Muhle ’ s terms ‘ membership category ’ ( Chapter Six ) , in the network to users who are moderate in their ideological or political views . Roughly speaking , socialbots would attempt to ‘ blend in ’ by analysing the network structure of moderate users and then attempt to replicate it , aiming to maximise an approximate regular equivalence with such users , within the constraints of the Twitter API and This is a PRE-PRINT version of the following book chapter : Graham , T. , & Ackland , R. ( 2017 ) . Do Socialbots Dream of Popping the Filter Bubble ? The role of socialbots in promoting participatory democracy in social media . In M. Bakardjieva & R. Gehl , ( Eds . ) , Socialbots and their friend : Digital media and the automation of sociality ( Chapter 10 ) . New York : Routledge . computational resources of the researchers . In this way , ‘ politically moderate ’ provides a kind of membership category that defines the identity of a given user , which is calculated by analysing the user ’ s network structure . In order to identify which Twitter users are ‘ moderate ’ and should therefore be targeted , the methods outlined in Conover et al ( 2011a ) or Boutyline & Willer ( 2014 , working paper ) , appear especially suited to the task . Conover et al ( 2011a ) find that the best way to predict political affiliation in Twitter networks is by analysing the ‘ community ’ structure of retweet networks ( i.e . where nodes represent users , and links between nodes represent whether , and how many times , user i has retweeted user j , and vice versa ) . In their study , Conover et al ( 2011 ) manually code 1,000 randomly selected users into three political affiliation categories : ‘ left ’ , ‘ right ’ , or ‘ ambiguous ’ . In addition to other methods , they perform community detection on the retweet network of 23,766 users , resulting in two ‘ clusters ’ emerging . They classify users by political affiliation using the cluster each user is assigned to , and find that this yields a 95 % accuracy when evaluated against the manually coded users . Figure 1 ( below ) is adapted from Conover et al ( 2011a , p. 197 ) , which visualises the partisan division of the retweet network into ‘ left ’ ( blue nodes ) and ‘ right ’ ( red nodes ) clusters . We have superimposed a yellow-coloured oval where the two clusters intersect , providing a visual indication of where socialbots could look to target politically ‘ moderate ’ users , who bridge together the two divided clusters . The network structure of these target users would then provide a statistically calculable ‘ social role ’ that socialbots can emulate , by attempting to establish and maintain regular equivalence . This is a PRE-PRINT version of the following book chapter : Graham , T. , & Ackland , R. ( 2017 ) . Do Socialbots Dream of Popping the Filter Bubble ? The role of socialbots in promoting participatory democracy in social media . In M. Bakardjieva & R. Gehl , ( Eds . ) , Socialbots and their friend : Digital media and the automation of sociality ( Chapter 10 ) . New York : Routledge . Figure 1 . The political retweet network , laid out using a force directed algorithm . Adapted from Predicting the Political Alignment of Twitter Users ( p. 197 ) , by Conover et al , 2011 , IEEE Third International Conference on Social Computing ( SocialCom ) . Copyright 2011 by PASSAT . Adapted with permission . Second , socialbots could be programmed to endeavor to occupy a position within the target subnetwork ( s ) that is maximally neutral in respect to quantified measures of political affiliation and/or ideological segregation . In other words , what we are suggesting is that socialbots should not find themselves in a situation where they appear to have clearly ‘ taken a side ’ or become , in a word , partisan . Again , it is possible to assess this , at least crudely , using the SNA methods . In order to measure whether this has occurred would necessitate programming socialbots to periodically assess the structure of their social network and their network activity . To achieve this , the techniques and methodology as developed in Conover et al ( 2011a ) , Halberstam & Knight ( 2014 ) , or Golbeck ( 2014 ) would provide a suitable This is a PRE-PRINT version of the following book chapter : Graham , T. , & Ackland , R. ( 2017 ) . Do Socialbots Dream of Popping the Filter Bubble ? The role of socialbots in promoting participatory democracy in social media . In M. Bakardjieva & R. Gehl , ( Eds . ) , Socialbots and their friend : Digital media and the automation of sociality ( Chapter 10 ) . New York : Routledge . reference point . For example , a socialbot may calculate that its structural position within the political retweet network expresses a ‘ left ’ political identity , as formulated by Conover et al ( 2011a ) . In this case , the socialbot would seek to remedy this bias by retweeting from users who are calculated to have a ‘ right ’ political identity . Similarly , following Conover et al , socialbots may seek to ensure that their position in the network results in a classification as ‘ ambiguous ’ , for example , by strategically ‘ mentioning ’ users from both clusters of the political divide ( 2011 , p. 197 ) . These ideas are expanded upon further in the next section , where we focus on two specific roles for socialbots for promoting deliberative democracy in social media networks . Attention now turns to the second definition of ‘ harm ’ as defined in the First Principle— namely , what would it mean for a socialbot to cause non-political harm ? Here we are concerned with a more general understanding of ‘ harm ’ , which evokes Asimov 's enduring problematic of how to define and understand the notion of robots causing harm in a ‘ social ’ context . Accordingly , what we offer here is a rudimentary or preliminary path forward . We would like to focus upon one problem in particular , which has longstanding relevance to bots on the web—namely , that socialbots should never become ‘ spambots ’ . Thus , a socialbot is said to cause harm if , through the frequency of its activity , it inconveniences other users or those managing the service . In some respects , this harkens to the ‘ bad name ’ or negative attention that socialbots inherit from their predecessors . Socialbot creators could take at least one of two approaches to ensure socialbots do not ‘ spam ’ networks and thus contravene the First Principle . The first approach could be to set fixed parameters based on evidence from the literature—for example , sending a maximum of N tweets per hour within a fixed set of times ( e.g . 8am to 9pm weekdays ; 1pm to 11pm weekends ) . Another approach would be to program socialbots to define their own parameters for ‘ non-spammy ’ update frequencies by calculating it based on other users in the network . For example , a socialbot could ( periodically ) query a random sample of 1000 users , calculate the average tweets per hour as a function of the total number of status updates and the timestamp of when the user was created , and then take the median value of this set of averages as a socially ‘ appropriate ’ hourly rate for sending out status updates . However , we again wish to point out that this is only one aspect of socialbots This is a PRE-PRINT version of the following book chapter : Graham , T. , & Ackland , R. ( 2017 ) . Do Socialbots Dream of Popping the Filter Bubble ? The role of socialbots in promoting participatory democracy in social media . In M. Bakardjieva & R. Gehl , ( Eds . ) , Socialbots and their friend : Digital media and the automation of sociality ( Chapter 10 ) . New York : Routledge . causing ‘ harm ’ , for which space precludes detailed discussion in this paper . For example , determining whether the textual content of a given status update is ‘ harmful ’ ( e.g . using offensive terms or spreading ‘ hate speech ’ ) . Techniques to deal with such problems may centre upon using dictionaries of terms ( for offensive words ) or using machine learning to build models to predict whether a tweet has a high degree of hate speech ( and therefore not ‘ retweet ’ it , for example ) . Future research may seek to further explore such lines of inquiry . The Second Principle of Socialbots 2 . Socialbots must protect their own existence , except where doing so would conflict with the First Principle ; Perhaps the most fundamental facet of the Second Principle is that socialbots must not be detected as non-human ( providing this does not conflict with the First Principle ) . However , we are not arguing that the Second Principle necessitates creating socialbots that could , for example , pass the Turing Test or instigate the kinds of existential problems presented by the Nexus-6 androids in Philip K. Dick ’ s novel . Far from such lofty aspirations , the Second Principle simply specifies that socialbots should present and conduct themselves in a manner that , ata minimum , ensures they survive long enough for the Third Principle to come into operation ( and not contravene the First Principle ) . This is perhaps somewhat self-evident . Yet the scope and nature of this task is less straightforward than it might first appear , as the literature previously cited in this chapter suggests . Socialbots must not only contend with Twitter ’ s security mechanisms ( that deploy sophisticated algorithms to find and remove fake user accounts and spambots ) , but also avoid ‘ citizen policing ’ —users , organisations , or perhaps even other bots , that detect and report social robots to Twitter . And as the Third Principle serves to address , merely ‘ surviving ’ is only the first step for socialbots—the next problem concerns the ability to ‘ thrive ’ . It could be argued that socialbots programmed using these Principles would simply do nothing , thereby satisfying the First and Second Principles . For example , a socialbot that does not send out any status updates ( e.g . tweets ) is arguably following an optimal strategy to avoid detection and do no harm . However , the Third Principle This is a PRE-PRINT version of the following book chapter : Graham , T. , & Ackland , R. ( 2017 ) . Do Socialbots Dream of Popping the Filter Bubble ? The role of socialbots in promoting participatory democracy in social media . In M. Bakardjieva & R. Gehl , ( Eds . ) , Socialbots and their friend : Digital media and the automation of sociality ( Chapter 10 ) . New York : Routledge . ( below ) ensures that this situation can not occur , or , in the case that it does , there is logical reason for such inaction . Furthermore , to achieve the Second Principle ( and arguably the Third Principle ) , socialbots must present and conduct themselves in a manner that makes them appear sufficiently ‘ human ’ to , for example , attract new followers and retweets ( again , without contravening the First Principle ) . Although previous studies have achieved success with the ‘ detection avoidance ’ problem , the problem of how to exploit social networks for optimal effect proves trickier . For example , some studies suggest that female socialbots with ‘ attractive ’ or ‘ good- looking ’ profile photos are more successful for social engineering on SNS ( Boshmaf et al. , 2011 ) . Others find that the ‘ gender ’ of socialbots has no correlation with success or popularity ( Freitas et al. , 2014 ) . Still others , such as Wald et al ( 2013 ) , take a different tack by looking at which types of human users socialbots should target for interaction . Wald et al found that the highest predictors of whether a user is likely to interact with socialbots comes down to how popular or influential a user is ( i.e . their ‘ Klout ’ score and number of friends ) , and the amount of sexual language and terminology they tend to use ( Wald et al , 2013 , p. 10 ) . The implication is that users who are more likely to interact with socialbots ( e.g . retweeting or ‘ liking ’ their tweets ) are those that are well-connected or have more followers , and those that use a greater amount of sexual language and terminology . Clearly , in terms of SNA methods , ensuring that socialbots function effectively in social media networks involves both ‘ art ’ and ‘ science ’ . At the same time , it reinforces the importance of the First and Second Principles as one way to approach socialbot ethics . The Third Principle of Socialbots 3 . Socialbots must make a significant improvement to deliberative democracy , obtaining non-trivial , quantifiable effects in the target sub-network ( s ) , except where doing so would conflict with the First and Second Principles . This is a PRE-PRINT version of the following book chapter : Graham , T. , & Ackland , R. ( 2017 ) . Do Socialbots Dream of Popping the Filter Bubble ? The role of socialbots in promoting participatory democracy in social media . In M. Bakardjieva & R. Gehl , ( Eds . ) , Socialbots and their friend : Digital media and the automation of sociality ( Chapter 10 ) . New York : Routledge . At an abstract level , the Third Principle seeks to ensure that socialbots are actually achieving something ( providing it does not contravene the First and Second Principles ) . In this way , socialbot activity must be quantifiable ( accounted for statistically ) and must also be non- trivial ( having a magnitude of effect that is not negligible ) . It is therefore evident that analysis of the impact or effects of socialbots must pay attention to network structure and network dynamics over time . Any studies that investigate whether socialbots could , for example , heal social rifts , promote deliberative democracy , bridge segregated subnetworks , or ‘ pop ’ filter bubbles , must be able to formalise socialbot activity as a concrete , statistically calculable phenomenon . A growing body of literature demonstrates that the methods and formalisms of SNA provide such tools . More specifically , SNA methods to quantify and analyse political segregation and ideological clustering on Twitter have emerged in recent years ( see : Conover et al , 2011a ; Halberstam & Knight , 2014 ; Golbeck , 2014 ) . In particular , Mitter et al ( 2014b ) provide a detailed methodology for assessing the impact of socialbots ‘ attacks ’ on Twitter in terms of shaping or influencing the social graph of a subset of users . Any combination of these methods would be suited to advancing the Third Principle of socialbots , and such methods are expanded upon later in this section . Furthermore , to achieve the Third Principle , socialbots must present and conduct themselves in a manner that makes them appear sufficiently ‘ human ’ to , for example , attract new followers and retweets . This is consistent with the Second Principle , and again , must not be in contravention of the First Principle . We can further operationalise the Third Principle by making the following argument : the presence of socialbots in target sub-networks should , over time , correlate with a decreased modularity score ( thus implying decreased political homophily in the target sub-network , although noting our caveat about equating changes in modularity with changes in homophily ) . This brings us deeper into the realm of socialbot ethics and further reveals the raison d ’ étre of socialbots in promoting deliberative democracy . In this way , we can begin to explicate the ‘ life goals ’ or telos of socialbots in the context of this paper—broadly speaking , to build bridges between separate , ideologically homogeneous subnetworks ; to expose tightly knit clusters of users to alternative viewpoints ; or to bring about measurable shifts towards deliberative democracy in online discourse . In this way , the Third Principle draws stark attention to the This is a PRE-PRINT version of the following book chapter : Graham , T. , & Ackland , R. ( 2017 ) . Do Socialbots Dream of Popping the Filter Bubble ? The role of socialbots in promoting participatory democracy in social media . In M. Bakardjieva & R. Gehl , ( Eds . ) , Socialbots and their friend : Digital media and the automation of sociality ( Chapter 10 ) . New York : Routledge . normative political rationalities that socialbots in this role embody—which could be conceived as a kind of social robotic ‘ hacktivism ’ . As Howard ( 2003 ) writes , hacktivism is understood broadly as using the tools and strategies of hackers for political ends : “ hacktivists believe that they have a responsibility to expose abuses of power and to redistribute informational resources ” ( Howard , 2003 , p. 216 , emphasis added ) . Positioning socialbots as ersatz ‘ hacktivists ’ facilitates a rethinking of their agential capacities—in this case , to propagate deliberative democracy on social media via the strategic exploitation of network structure . Popperbots and bridgerbots : a schematic for programming hacktivist socialbots on Twitter In .45 of asecond an android equipped with such a brain structure could assume any one of fourteen basic reaction-postures. ? Programming bots to perform social roles in social media environments represents a moving target . Over time , the tasks to be performed by socialbots become suboptimal or even impossible in environments whereby the entities involved—users , protocols , algorithms , data , hardware specifications , and so forth—are constantly in flux . However , the aim in this section is not to provide a comprehensive or codified tutorial for programming socialbots , but rather to set forth a general ‘ schematic ’ for how socialbots might be programmed to promote or ‘ propagate ’ deliberative democracy on Twitter . We wish to focus on issues of methodology and the conceptual , network-oriented space in which such methods would be applied , which are broadly located at the intersection of politics , the dynamics of social media networks , and social robotics . We want to examine some possibilities and sketch out possible approaches moving forward . The over-arching question asks whether it is possible to program socialbots to mitigate or break down political filter bubbles and ideological segregation on Twitter , hence promoting deliberative democracy in online discourse . In this section we provide a possible answer to this question by elucidating two distinct roles and respective category- bound activities for socialbots . This is a PRE-PRINT version of the following book chapter : Graham , T. , & Ackland , R. ( 2017 ) . Do Socialbots Dream of Popping the Filter Bubble ? The role of socialbots in promoting participatory democracy in social media . In M. Bakardjieva & R. Gehl , ( Eds . ) , Socialbots and their friend : Digital media and the automation of sociality ( Chapter 10 ) . New York : Routledge . 1 . ‘ Popperbots ’ We conceive the ‘ popperbot ’ as a type of socialbot tasked with the role of ‘ infiltrating ’ subnetworks of Twitter users that exhibit high or extreme levels of homophily . Once the popperbot has established itself in the subnetwork , it would then begin to ‘ inject ’ information reflecting more moderate or even contrasting ideological standpoints . As the name suggests , the idea is that this type of socialbot will reduce , or in a sense ‘ pop ’ the ideological bubble that users within a given subnetwork are situated within , by exposing these users to alternate points of view that appear to come from a member of their own cohort . The telos of the popperbot is to produce measurable increases in heterophily in the subnetworks in which they have infiltrated . Similarly , as argued previously in relation to the Third Principle , popperbots could attempt to decrease ‘ balkanisation ’ by striving to reduce the modularity score of their target subnetwork . For example , a popperbot could be programmed to occasionally ( say , with probability P ) retweet or reply to users from a different subnetwork ( s ) that represent alternate positions on some issue . Figure 2 ( below ) shows a popperbot infiltrating a homophilous subnetwork of Twitter users who are calculated to be ‘ right ’ ( i.e . conservative ) in their political orientation , which , as mentioned in the previous section , could be derived using the methods outlined in Conover et al ( 20114 ) . This is a PRE-PRINT version of the following book chapter : Graham , T. , & Ackland , R. ( 2017 ) . Do Socialbots Dream of Popping the Filter Bubble ? The role of socialbots in promoting participatory democracy in social media . In M. Bakardjieva & R. Gehl , ( Eds . ) , Socialbots and their friend : Digital media and the automation of sociality ( Chapter 10 ) . New York : Routledge . Figure 2 : a ‘ popperbot infiltrating a homophilous subnetwork ( of politically conservative Twitter users ) If it is not yet apparent , a fundamental problem for the development of popperbots is that these socialbots must , by definition , violate the First Principle in order to do their job . In this way , a popperbot would have to act in an ‘ extreme ’ manner ( as discussed previously ) in order to infiltrate a homophilous subnetwork , even if its ultimate goal was to ‘ pop ’ the political bubble in that subnetwork . For example , a popperbot could ( 1 ) detect an extremely homophilous subnetwork of individuals and then ( 2 ) attempt to infiltrate the network by adapting its profile and ‘ social ’ activity to correspond with the target subnetwork . This popperbot could be ( 3 ) programmed to ‘ defect ’ after some time duration T or acquiring a pre- defined number of followers or friends N. Defection , of course , would occur in the form of injecting more moderate or perhaps even contrasting information into the subnetwork , as discussed previously . However , a popperbot would never infiltrate a network by pretending to be , for example , a radical Communist because doing so would definitely ( and as we have previously argued , quantifiably ) violate the First Principle . Thus , Asimov 's enduring problem remains and we inherit another complex , or perhaps ‘ wicked ’ , problem to address . Yet , despite these obstacles , we argue that there are possibilities for moving forward , which could This is a PRE-PRINT version of the following book chapter : Graham , T. , & Ackland , R. ( 2017 ) . Do Socialbots Dream of Popping the Filter Bubble ? The role of socialbots in promoting participatory democracy in social media . In M. Bakardjieva & R. Gehl , ( Eds . ) , Socialbots and their friend : Digital media and the automation of sociality ( Chapter 10 ) . New York : Routledge . be programmed into popperbots . For example , future research could explore lines of inquiry centering on time-limited infiltration and defection routines , which could allow socialbots to violate Principles within certain parameters or ‘ thresholds ’ of violation , although space precludes further discussion in this chapter . 2 . ‘ Bridgerbots ’ ‘ Bridgerbots ’ are conceptualised as socialbots tasked with the role of re-routing or ‘ bridging ’ informational flows between otherwise ideologically segregated sub-networks . They could perform actions such as tweeting/retweeting and following users from both ‘ sides ’ of a given political or ideological debate . Bridgerbots would seek to expose users from one homophilous subnetwork to politically diverse types and flows of information from one or more other homophilous subnetworks . In this way , the network role of bridgerbots might be thought about in a variety of ways . One possibility is in terms of what Mark Granovetter described as weak ties . Weak ties are understood as connections between different tightly knit groups that are vital to information dissemination and therefore social opportunities . As Granovetter wrote , “ It is remarkable that people receive crucial information from individuals whose very existence they have forgotten ” ( Granovetter , 1973 , p. 1372 ) . Bridgerbots could be programmed to endeavor to occupy a position within the target subnetwork ( s ) that maximizes their own betweenness centrality score . Betweenness centrality , or simply ‘ betweenness ’ , is a key concept in SNA and graph theory more broadly . In a formal sense , the “ betweenness sigma ( M ) of a vertex m is the total number of shortest paths between all possible pairs of vertices that pass through this vertex ” ( Dorogovtsev & Mendes , 2003 , p. 18 , emphasis original ) ! . We can think about betweenness in terms of how important a node ( a.k.a . vertex ) is in providing a path that connects isolated nodes or isolated clusters of nodes . Thus , informally , nodes with high betweenness could be loosely conceived as ‘ brokers ’ 1 In graph theory , a ‘ path ’ is an unbroken sequence of connections between two or more vertices . This is a PRE-PRINT version of the following book chapter : Graham , T. , & Ackland , R. ( 2017 ) . Do Socialbots Dream of Popping the Filter Bubble ? The role of socialbots in promoting participatory democracy in social media . In M. Bakardjieva & R. Gehl , ( Eds . ) , Socialbots and their friend : Digital media and the automation of sociality ( Chapter 10 ) . New York : Routledge . or ‘ exchange terminals ’ of information between densely connected ( or ‘ homophilous ’ ) , but otherwise poorly connected clusters of individuals . The application of this concept to bridgerbots is straightforward—they would seek to act as ‘ bridges ’ between politically segregated clusters of users . Figure 3 ( below ) visualises this idea by representing it within a graph . ® Conservative oO Liberal O Bridgerbot Figure 3 : a ‘ bridgerbot ’ connecting two ‘ segregated ’ subnetworks ( of politically conservative Twitter users ) Combining several arguments presented thus far , the role and effects of bridgerbots in respect to the target sub-network ( s ) could be tied to their success in increasing their own betweenness score or decreasing the modularity score of the subnetwork that they target . That is to say , bridgerbots with high betweenness scores are ‘ bridging ’ political rifts more effectively than those with a low score , and bridgerbots who successfully decrease the modularity score of a target subnetwork ( s ) are successfully ‘ bridging ’ political divides . For example , we could imagine that a Twitter user receives a notification that a new user has ‘ followed ’ them—and they might even return the gesture by ‘ following back ’ . Unbeknownst to This is a PRE-PRINT version of the following book chapter : Graham , T. , & Ackland , R. ( 2017 ) . Do Socialbots Dream of Popping the Filter Bubble ? The role of socialbots in promoting participatory democracy in social media . In M. Bakardjieva & R. Gehl , ( Eds . ) , Socialbots and their friend : Digital media and the automation of sociality ( Chapter 10 ) . New York : Routledge . the user , they are now following a bridgerbot who has ‘ targeted ’ them because their social network is extremely homophilous . Later , having possibly completely forgotten about this new social connection ( to the bridgerbot ) , the user might notice a tweet in their news feed that reflects a more moderate , or perhaps even competing , position to their already held beliefs on some issue . In this way , the bridgerbot has acted as a weak link , bridging heterogeneous flows of information ( e.g . two or more different sides of a debate ) to the actors involved in such communication networks . Over time , if the bridgerbot ’ s betweenness score increases , or the network structure becomes less modular , then the bridgerbot can be regarded as doing a ‘ good job ’ . Conclusion “ Your position , Mr. Deckard , is extremely bad morally . Ours is n't . `` 4 In this chapter we have introduced and examined a role for socialbots that positions them not as dangers or annoyances , but rather as socially beneficent actors , capable perhaps of ‘ building a better world ’ . We did not seek to examine whether socialbots in this context are valid social actors with human-like agency ( see Chapter Six ) , but rather to investigate their role in constructing and ( re ) assembling the social ( Latour , 2005 ) . In this way , we focussed upon a normative role for socialbots in creating and propagating deliberative democracy on Twitter . This , in one sense , can be thought about as socialbots ‘ popping the political filter bubble ’ —e.g . building bridges between separate , ideologically homogeneous subnetworks , exposing tightly knit clusters of users to alternative viewpoints , or bringing about measurable shifts towards deliberative democracy in online discourse . Yet , if socialbots ‘ dream ’ of popping filter bubbles , perhaps we can perceive within their dreams the spectre of our own political rationalities and ethical assumptions . As Paul Henman writes , “ new and emerging technologies will continue to initiate old questions in new circumstances of what these technologies mean ” ( Henman , 2013 , p. 300 ) . It is clear that socialbots of the kind we conceive in this chapter might also dream in other ways , ways that might otherwise seem unethical or politically abhorrent . This is a PRE-PRINT version of the following book chapter : Graham , T. , & Ackland , R. ( 2017 ) . Do Socialbots Dream of Popping the Filter Bubble ? The role of socialbots in promoting participatory democracy in social media . In M. Bakardjieva & R. Gehl , ( Eds . ) , Socialbots and their friend : Digital media and the automation of sociality ( Chapter 10 ) . New York : Routledge . In developing this chapter , we consciously adopted a normative position for socialbots in relation to a particular social issue ( deliberative democracy ) . In doing so , this provided a space in which to demonstrate and examine how socialbots might be used to ‘ exploit ’ network structure in order to achieve ‘ social good ’ . Yet what is defined as ethical , politically rational , socially beneficent , etc. , arguably depends upon one ’ s point of view . Hence , we can see how socialbots could be deployed to achieve different or even opposite outcomes for deliberative democracy , by simply adapting or perhaps ‘ inverting ’ various aspects of the ideas and methods established in this chapter . As Hwang et al would have it : “ The same bots that can be used to surgically bring together communities of users can also be used to shatter those social ties . The same socialbot algorithms that might improve the quality and fidelity of information circulated in social networks can be used to spread misinformation ” ( Hwang et al , 2012 , p. 40 ) . A particularly noteworthy focus is governments seeking to monitor and sway political discourse online . For example , the 50 Cent Party are “ Party-paid internet commentators and opinion guiders ” ( Sullivan , 2012 ) hired by the Chinese government and other parties to attempt to steer online opinion and conversation towards particular directions . Yet one can easily imagine the 50 Cent Party deploying socialbots alongside , or even in lieu of , human commentators and opinion guiders . Indeed , as Gehl writes , government agencies such as the U.S. Air Force have already begun to contract out software development companies to “ gather intelligence , build consensus , and influence opinions twenty-four hours a day via a network of socialbots ” ( Gehl , 2014 , p. 39 ) . In this way , current concerns regarding the uses and abuses of socialbots within a political context are not unfounded . However , it is also clear that we are only in the very early stages of this phenomenon . Hence , what we are now witnessing is an increasing sophistication of socialbot technologies and a diversification of their roles and relations of power in hybrid techno-social environments ( see Gehl , 2014 ) . Gilles Deleuze once wrote : “ What counts is that we are at the beginning of something ” ( Deleuze , 1992 , p. 7 ) . The question is how it will unfold . This is a PRE-PRINT version of the following book chapter : Graham , T. , & Ackland , R. ( 2017 ) . Do Socialbots Dream of Popping the Filter Bubble ? The role of socialbots in promoting participatory democracy in social media . In M. Bakardjieva & R. Gehl , ( Eds . ) , Socialbots and their friend : Digital media and the automation of sociality ( Chapter 10 ) . New York : Routledge . This is a PRE-PRINT version of the following book chapter : Graham , T. , & Ackland , R. ( 2017 ) . Do Socialbots Dream of Popping the Filter Bubble ? The role of socialbots in promoting participatory democracy in social media . In M. Bakardjieva & R. Gehl , ( Eds . ) , Socialbots and their friend : Digital media and the automation of sociality ( Chapter 10 ) . New York : Routledge . Acknowledgements We gratefully acknowledge the helpful feedback provided by Paul Henman on an earlier draft of this chapter . Notes The quotations commencing each section are taken from Philip K Dick ’ s novel Do Androids Dream of Electric Sheep ? The corresponding page numbers are : 1 Page 11 ; 2 Page 22 ; 3 Page 25 ( spoken by the character Eldon Rosen ) ; and 4 Page 14 . References Asimov , I . ( 1950 ) . I , Robot . New York : Doubleday & Company . Boshmaf , Y. , Muslukhov , I. , Beznosov , K. , & Ripeanu , M. ( 2011 ) . The socialbot network : When bots socialize for fame and money . Paper presented at the 93-102 . Boutyline , A . & Willer , R. ( 2014 , working paper ) . ‘ The Social Structure of Political Echo Chambers : Ideology and Political Homophily in Online Communication Networks ’ . Retrieved 28 March , 2015 , from https : //www.ocf.berkeley.edu/~andrei/downloads/echo.pdf . Bozdag , E. , Gao , Q. , Houben , G. , & Warnier , M. ( 2014 ) . Does offline political segregation affect the filter bubble ? An empirical analysis of information diversity for Dutch and Turkish twitter users . Computers in Human Behavior , 41 , 405-415 . Butts , C. T. ( 2007 ) . Social network analysis with sna . Journal of Statistical Software , 24 ( 6 ) . Castells , M. ( 1996 ) . The rise of the network society . The information age : Economy , society and culture Vol . I. Blackwell , London . Conover , M.D. , Goncalves , B. , Ratkiewicz , J. , Flammini , A. , Menczer , F. ( 20114 ) . ‘ Predicting the Political Alignment of Twitter Users ’ , Privacy , Security , Risk and Trust ( PASSAT ) and 2011 JEEE Third International Conference on Social Computing ( SocialCom ) , pp . 192- 199 , This is a PRE-PRINT version of the following book chapter : Graham , T. , & Ackland , R. ( 2017 ) . Do Socialbots Dream of Popping the Filter Bubble ? The role of socialbots in promoting participatory democracy in social media . In M. Bakardjieva & R. Gehl , ( Eds . ) , Socialbots and their friend : Digital media and the automation of sociality ( Chapter 10 ) . New York : Routledge . Conover , M.D. , Goncalves , B. , Ratkiewicz , J. , Flammini , A. , Menczer , F. ( 2011a ) . ‘ Political polarization on twitter ’ , Proceedings of the 5th International Conference on Weblogs and Social Media . Deleuze , G. ( 1992 ) . ‘ Postscript on the Societies of Control ’ , October , Vol . 59 , ( Winter 1992 ) , MIT Press , Cambridge , MA , pp . 3-7 . Dick , P. K. ( 1999 ) [ 1968 ] . Do androids dream of electric sheep ? . London : Millennium . Dormehl , L. ( 2014 ) . The Formula : How algorithms solve all our problems ... and create more . Penguin Publishing Group . Dorogovisey , S. N. , & Mendes , J. F. F. ( 2003 ) . ‘ Evolution of networks : From biological nets to the internet and WWW ’ . Oxford ; New York : Oxford University Press . Dryzek , J. S. ( 2010 ) . Foundations and Frontiers of Deliberative Governance . Oxford : Oxford University Press . Elyashar , A. , Fire , M. , Kagan , D. , & Elovici , Y . ( 2013 ) . Homing socialbots : Intrusion on a specific organization 's employee using socialbots . Paper presented at the 1358-1365 . Freitas , C. A. , Benevenuto , F. , Ghosh , S. , & Veloso , A . ( 2014 ) . Reverse engineering socialbot infiltration strategies in twitter . arXiv preprint arXiv , 1405.4927 . Gehl , R. W. ( 2014 ) . Reverse engineering social media : Software , culture , and political economy in new media capitalism . Philadelphia , Pennsylvania : Temple University Press . Gillespie , T. ( 2012 ) . Can an algorithm be wrong ? Retrieved 22 March , 2015 , from http : //limn.it/can-an-algorithm-be-wrong/ Golbeck , J. , & Hansen , D. ( 2014 ) . A method for computing political preference among twitter followers . Social Networks , 36 , 177 . Granovetter , M. ( 1973 ) . The strength of weak ties . American Journal of Sociology , 78 ( 6 ) , pp . 1360-1380 . Habermas , J . ( 1996 ) . Between Facts and Norms : Contributions to a Discourse Theory of Law and Democracy . MA : MIT Press . Henman , P. ( 2013 ) Government and the internet : evolving technologies , enduring research themes , pp . 283 - 306 in Dutton , W. H . ( ed . ) The Oxford Handbook of Internet Studies . Oxford University Press . This is a PRE-PRINT version of the following book chapter : Graham , T. , & Ackland , R. ( 2017 ) . Do Socialbots Dream of Popping the Filter Bubble ? The role of socialbots in promoting participatory democracy in social media . In M. Bakardjieva & R. Gehl , ( Eds . ) , Socialbots and their friend : Digital media and the automation of sociality ( Chapter 10 ) . New York : Routledge . Hindman , M. , Tsioutsiouliklis , K. , and Johnson , J . ( 2003 ) . ‘ Googlearchy ’ : How a few heavily- linked sites dominate politics on the Web . Mimeograph , Princeton University , 2003 . Howard , P. ( 2003 ) . Hacktivism . In Jones , S . ( Ed . ) , Encyclopedia of new media . ( pp . 216-217 ) . Thousand Oaks , CA : SAGE Publications , Inc. Hwang , T. Pearce , I. , and Nanis , M. ( 2012 ) . Socialbots : voices from the fronts . Interactions 19 , 2 ( March 2012 ) , 38-45 . Retrieved 5 March , 2015 , from http : //doi.acm.org/10.1145/2090150.2090161 . Latour , B . ( 2005 ) . Reassembling the social ; An introduction to actor-network-theory . Oxford ; New York : Oxford University Press . Mauldin , M. L. ( 1994 ) . Chatterbots , TinyMUDs and the Turing Test : Entering the Loebner Prize Competition . Proc . AAAI-94 . URL accessible via : http : //aaaipress.org/Papers/AAAI/1994/AAAI94-003.pdf Mitter , S. , Wagner , C. , & Strohmaier , M. ( 2014a ) . A categorization scheme for socialbot attacks in online social networks . Mitter , S. , Wagner , C. , & Strohmaier , M. ( 2014b ) . Understanding the impact of socialbot attacks in online social networks . Mutz , D. ( 2006 ) . Hearing the Other Side : Deliberative Versus Participatory Democracy . New York : Cambridge University Press . Newman , M. E. J . ( 2006 ) . Modularity and community structure in networks . Proceedings of the National Academy of Sciences of the United States of America , 103 ( 23 ) , 8577-8582 . Paradise , A. , Puzis , R. , & Shabtai , A . ( 2014 ) . Anti-reconnaissance tools : Detecting targeted socialbots . IEEE Internet Computing , 18 ( 5 ) , 11-19 . Pariser , E. ( 2011 ) . The filter bubble : What the internet is hiding from you . New York : Penguin Press . Putnam , R. D. ( 2000 ) . Bowling Alone . Simon & Schuster , New York . Steiner , C. ( 2012 ) . Automate this : How algorithms came to rule our world . New York : Portfolio/Penguin . Sullivan , J . ( 2012 ) . A tale of two microblogs in china . Media , Culture & Society , 34 ( 6 ) , 773-783 . Sunstein , C. ( 2001 ) . Republic.com . Princeton University Press , Princeton . This is a PRE-PRINT version of the following book chapter : Graham , T. , & Ackland , R. ( 2017 ) . Do Socialbots Dream of Popping the Filter Bubble ? The role of socialbots in promoting participatory democracy in social media . In M. Bakardjieva & R. Gehl , ( Eds . ) , Socialbots and their friend : Digital media and the automation of sociality ( Chapter 10 ) . New York : Routledge . Twitter , Inc. ( 2015 ) . What ’ s a Twitter timeline ? . Retrieved 1 April , 2015 , from https : //support.twitter.com/articles/164083-what-s-a-twitter-timeline Van Alstyne , M. and Brynjolfsson , E. ( 2005 ) . Global village or cyber-balkans ? Modeling and measuring the integration of electronic communities . Management Science , 51 ( 6 ) :851- 868 . Wald , R. , Khoshgoftaar , T. M. , Napolitano , A. , & Sumner , C. ( 2013 ) . Predicting susceptibility to social bots on twitter . Paper presented at the 6-13 . The Journal of Social Media in Society Spring 2020 , Vol . 9 , No . 1 , Page 22-38 thejsms.org Underneath the Filter Bubble : The Role of Weak Ties and Network Cultural Diversity in Cross-Cutting Exposure to Disagreements on Social Media Seong Jae Min ” and Donghee Yvette Wohn : 1Department of Communication Studies , Pace University , New York , NY , 10038 2Department of Informatics , New Jersey Institute of Technology , Newark , NJ , 07102 * Corresponding Author : smin @ pace.edu , 212-346-1867 While the idea of the filter bubble , in which people are sheltered from challenging and disagreeable information online , is a valid concern for democracy , it requires much theoretical sophistication and empirical support . This paper explores the extent and scope of the filter bubble , employing the concept of “ cross-cutting exposure , ” or exposure to disagreeable viewpoints , on social media . A survey analysis of 271 Facebook users shows that they do get exposed to cross-cutting information frequently , and that cross-cutting information was more likely to come from weak ties , or acquaintances and strangers in their network , as opposed to strong ties of friends and families . Furthermore , those who have ethnically and _ religiously more diverse networks were more likely to be exposed to cross- cutting information . Taken together , it is argued that individuals ’ network characteristics , such as network compositions and cultural diversity , can influence the degree of the filter bubble . Keywords : filter bubble , cross-cutting exposure , weak ties , diversity , network ost news consumption these days migrated to the online sphere , especially social media . Research indicates that 81 % of Americans get at least some of their news through websites , apps , or social media ( Mitchell et al. , 2016 ) , and the majority of American users of Facebook , Twitter , and Reddit say they get news from those platforms ( Gottfried & Shearer , 2016 ) . Amid such transitions in the media environment , news is becoming increasingly “ algorithmically driven ” such that computerized algorithms determine what news contents users are exposed to . This results in a grave societal concern , because the Page 22 Min & Wohn public may become trapped in the so-called “ filter bubble , ” in which they are protected from new , challenging , and stimulating viewpoints . The filter bubble or echo chamber effects ( Sunstein , 2003 ; 2017 ) threaten a healthy functioning of democracy , because , the argument goes , the personalized Internet and social media make it difficult for users to see the other side of arguments : When people are stuck in an ideological silo of like- minded people , it provides a fertile ground where disinformation and extreme political polarization can easily occur . While it is a valid threat to democracy and the public sphere , the concept of the filter bubble or echo chambers requires more theoretical sophistication and empirical support . In particular , popular claims publicizing the negative effects mostly remain at anecdotal case studies ( e.g. , Pariser , 2011 ) . This means that there is a need to investigate those phenomena more systemically . This study probes the degree to which social media users are exposed to disagreeable viewpoints by employing the idea of cross-cutting exposure ( Mutz , 2006 ) . The overall argument and findings of the study are that while we need to acknowledge some of the potential problems of filter bubbles , we need to critically evaluate their extent and effects , because the digital public today , with their multiple and overlapping identities and diverse networks , are keenly aware of different viewpoints surrounding them , and that their media diet tend to include at least some disagreements and challenging perspectives . Following the crystallization framework ( Wohn & Bowe , 2014 ) , which states that people ’ s online social network will act as agenda setters , this study conceptualizes social media as not just a platform of news delivery but socially embedded experience that has influence on individuals ’ understanding of the world . While the idea of the filter bubble focuses on the power of computer algorithms , this study emphasizes the importance of people in their social media networks . That is , the degree to which people are confined to like-minded opinions is dependent on many factors including the makeup of one ’ s social media network . For example , those who have many weak ties in their network — strangers and acquaintances — are less likely to be trapped in the silo of like-minded viewpoints . Thus , while the filter bubble may still exist , the power of the computer algorithms is countered by the networks that individuals choose to connect with online . The Journal of Social Media in Society , Vol . 9 , No . 1 Underneath the Filter Bubble LITERATURE REVIEW Exposure to Disagreement in the Algorithmic Age It has been well known in social science research that people tend to selectively expose themselves to the information and viewpoints they agree with . While selective exposure or homophily has been around as long as humans have existed , it is the supposedly unprecedented degree in the age of the Internet and social media that worries many . Pariser ( 2011 ) , who coined the term filter bubble , argues that today ’ s massive filtering algorithms present threat to our information diet . He shows an example in which the same search term “ BP ” prioritizes investment information of the firm to a certain user and the oil spill disaster information to another . Pariser argues that this filtering closes users off to new ideas and counter viewpoints . The filter bubble may eventually undermine civic discourse and make people vulnerable to propaganda and manipulation by advertisers and politicians , according to Pariser . In a similar vein , Sunstein ’ s ( 2003 ; 2017 ) echo chamber thesis suggests users in today ’ s Internet are trapped in a chamber in which they listen to only similar voices and this is driving political fragmentation , polarization , and extremism . In his latest book , Sunstein ( 2017 ) especially focuses on the negative role of social media in people ’ s news diet , saying its extreme customization creates `` cybercascades , ” and `` polarization entrepreneurism , '' which endangers the shared conversations , understandings , and experiences . It is in this context that some media outlets suggested the proliferation of the filter bubble and fake news even swayed the 2016 U.S. presidential election in favor of Donald Trump ( Parkinson , 2016 ; Read , 2016 ) . While it is no doubt that the filter bubble or echo chambers are a valid concern that may threaten healthy civic discourse , the ideas are conceptually not clear and their empirical support is rather limited . In fact , latest academic research documents the opposite , showing that people are more likely to be outside the bubble or echo chambers using the Internet or social media than offline , because of the diverse online social structure and personal relationships ( See for examples , Bakshy et al. , 2015 ; Barnidge , 2017 ; Gentzkow & Shapiro , 2011 ) . Theoretically , it would also stand to reason to think that the digital media universe today is actually helpful in breaking the bubble , when compared to the offline world : We are less likely to encounter discussion partners who have different viewpoints from ours in offline , because such face-to-face encounter is very 24 | Spring 2020 Min & Wohn uncomfortable . But in online , especially in social media , there exists norms of self- expression , and with the help of more anonymity and less social presence , differing viewpoints can be further facilitated ( Barnidge , 2017 ) . There is evidence that the existence of social endorsement on social media , such as peer recommendations , mitigates partisan selective exposure , because social endorsements shift attention away from partisan source cues ( Messing & Westwood , 2014 ) . Furthermore , many people online select information not necessarily on purpose perusing partisan cues , but on whims while browsing . Doing so , they get exposed to disagreeing viewpoints while they seek news that is interesting , fun , and socially relevant . In other words , there is a higher chance of “ incidental exposure ” to disagreeable viewpoints on social media than offline ( Kim , Chen , & de Zuniga , 2013 ; Tewksbury et al. , 2001 ) . That 's why a well-known large-scale study of Facebook found that exposure to disagreement is not uncommon : Bakshy and colleagues ( 2015 ) showed that for every four Facebook friends that share same political ideology , users have at least one friend with contrasting views . Other recent studies that looked at news personalization found no discernable effects of the filter bubble or echo chambers ( Flaxman et al. , 2016 ; Haim et al. , 2018 ) . Some studies further suggest that social media use is actually helpful in breaking the filter bubble : A study by Beam and colleagues ( Beam , Child , Hutchens , & Hmielowski , 2018 ) found that on the social media , “ context collapse ” occurs as users have to imagine and negotiate interacting with a large and diverse audience , and that this context collapse leads to more sharing and discussing news with people of diverse backgrounds in the users ’ lives . Another study by the authors ( Beam , Hutchens , & Hmielowski , 2018 ) found that Facebook news use in the long run leads to depolarization of partisan attitudes among the users . At the very minimum , it can be argued that online media users , while seeking information that conforms to their pre-existing perspectives , do not necessarily actively avoid counter-attitudinal information , as suggested by Garrett 's ( 2009 ) research . That is , people use the control afforded by online information sources to increase their exposure to like-minded opinions , without sacrificing contact with other opinions . The ideas of the filter bubble and echo chambers posited by the popular narratives of Pariser and Sunstein are rather simplistic in that they assume a passive media user The Journal of Social Media in Society , Vol . 9 , No . 1 Underneath the Filter Bubble trapped by a loop of similar informational flow : The audience here are considered to be incapable of navigating the diverse world , because they are trapped in their own ideological silo . But in today ’ s digital world , a person usually has multiple and overlapping identities and belongs to fragmented , yet multiple publics . You are a veteran , gay , father , and consumer activist at the same time , for example . This idea is also supported by empirical research . Graellis-Garrido and colleagues ( 2014 ) suggest that among people of opposing views , there exists common interests , which may work as an intermediary topic that connect them , thereby increasing diversity in exposure . The Power of Network Compositions and Diversity As suggested so far , the concern about the filter bubble or echo chambers is rather overblown . But this does not mean that they do not exist , nor are they a healthy phenomenon . Exposure to diverse viewpoints and civil discussions around them are certainly an important democratic value , and , we should strive to remove any potential roadblocks against such a noble cause . However , much like the fuss surrounding the filter bubble , many attempts to break it seem to be problematic as well . Pariser ( 2011 ) , for example , suggests Google or Facebook place a slider bar running from “ only stuff I like ” to “ stuff other people like that I will probably hate ” at the top of search results and the newsfeed to fight the filter bubble . Others developed the so-called “ serendipity ” web browsers that encourage users to see disagreeable news and counter viewpoints . Such efforts are noble . However , they are artificial and forced efforts and their effectiveness is questionable . Many of those initiatives are thus short-lived . This paper argues what matters more in breaking the filter bubble is a diverse network of people in the digital universe that is naturally occurring . Many classical studies in communication and psychology ( e.g. , Katz & Lazarsfeld , 1955 ) suggest that it is personal influence rather than media that is far more influential . More recent research documents the positive impact of heterogeneous social networks that include increased news use , political discussion , and democratic citizenship ( Kim , Hsu , & de Zuniga , 2013 ; Scheufele et al. , 2006 ) . In particular , weak ties , or a loose coalition of acquaintances , strangers , and distant friends may play a crucial role in encouraging exposure to diverse viewpoints . In the so-called “ strength of weak ties , ” Granovetter ( 1973 ) showed that weak ties are critical for the exposure to novel information and political mobilization . While 26 | Spring 2020 Min & Wohn communication occurring among strong ties usually employ “ restricted codes , ” or an implicit mode of talk that shares a same culture or background , communication among weak ties often requires much more explicit elaboration to achieve more meaningful exchange . That elaboration and openness are often beneficial to new ideas and innovations . This theory of weak ties fits the bill very well in today ’ s connected digital media world where people get informed and mobilized based on specific issues to form an “ issue public ” or become a “ monitorial citizen ” ( Schudson , 1998 ; Shirky , 2008 ) . The social media platforms allow individuals to maintain a vast array of online relationship composed of both strong and weak ties ( Hampton et al. , 2009 ) , which includes workplace relationships , a fertile ground for cross-cutting exposure ( Mutz & Mondak , 2006 ) . An enlarged network of people , after all , increases the possibility of exposure to diverse viewpoints in a natural manner . If we want to address the filter bubble and political polarization , we should care about connecting people , not forcefully providing more counter information . This network effect , rather than a medium effect , is the essence of the crystallization framework ( Wohn & Bowe , 2014 ; 2016 ) . In this framework , the term crystallization is used to describe how people ’ s perception of reality is formed in the age of social media . It is most likely the people in the network , rather than mass media , will act as both first and second-level agenda setters , determining what information users are exposed to and even influence how people will interpret this information . Since most social media contents are created , curated , and engaged by users , the contents that individuals see in their feeds come from the contents that their networks post . The contents they see are not “ news on social media , ” but “ news from one ’ s social network via social media ” ( Wohn et al. , 2017 ) . This way , the crystallization framework emphasizes the importance of people ’ s networks , which is absent in the current discussion of filter bubble or echo chamber effects . Since people have different network compositions , the uniform sense of reality that may have existed in past mass media times may not be present in an era where most news comes through social media . The empirical research from the crystallization framework found the importance of network compositions in social media . For example , having a diverse cultural network in terms of ethnicity and religion influences the users ’ exposure The Journal of Social Media in Society , Vol . 9 , No . 1 Underneath the Filter Bubble and attitudes toward such key social issues as # BlackLivesMatter ( Wohn et al. , 2017 ) ; In another study , it was found that those who had primarily U.S. networks or U.S. military networks , as opposed to non-US networks , were exposed to much cheering and triumph over the news of the death of Osama bin Laden on their social media ( Wohn & Bowe , 2014 ) . Research Questions and Hypotheses The above section highlights how important network diversity can be , but the concept of network diversity itself is multifaceted and complex . The concept of the filter bubble or echo chambers is also rather vague and difficult to operationalize . The filter bubble and echo chambers , at their root , share the basic idea of selective exposure . But Pariser ’ s filter bubble mostly focuses on algorithmic and technological filters that limit perspectives to like-minded information , whereas Sunstein ’ s echo chambers focus more on the ideological segregation resulting from being surrounded by like-minded contacts and ideas . In terms of operationalizating the ideas of filter bubbles or echo chambers , we employ the “ cross-cutting exposure , ’ the degree to which individuals are exposed to socially and politically disagreeable information . This construct is one the most well- known and robust measures to gauge the degree of one ’ s exposure to counter-attitudinal information . Cross-cutting exposure has been widely used and studied in the social sciences ( e.g. , Min & Wohn , 2018 ; Mutz 2006 ; Mutz & Mondak , 2006 ) . In this study , we first attempt to see to what degree social media users are exposed to cross-cutting information . Therefore , RQ1 . What is the overall extent of cross-cutting exposure to politically and socially disagreeable news on social media ? In particular , we hypothesize that cross-cutting exposure will more likely come from weak ties on social media . Weak ties are a loose connection of acquaintances and strangers , and they can be a better facilitator of new information than strong ties such as family members and close friends , as previous research suggested ( Granovetter , 1973 ; Shirky , 2008 ) . Therefore , H1 . Cross-cutting exposure to politically and socially disagreeable news will more likely come from weak ties than from strong ties . 28 | Spring 2020 Min & Wohn The more weak ties an individual has , the more diverse his or her network will be . Diversity is critical in facilitating cross-cutting exposure to disagreement . Homogeneous networks of similar cultural backgrounds usually result in the sharing of similar thoughts and discussions , whereas heterogenous networks will likely increase the possibility of encountering differing viewpoints . Based on this rationale , the following hypotheses are presented : H2 . Network cultural diversity will be positively associated with cross-cutting exposure to politically and socially disagreeable information . METHODS Procedure and Sample This study employed a nationwide survey of U.S. Facebook users to understand their exposure to disagreeable information . Between October 6 and 10 , 2016 , a Qualtrics web panel of 585 individuals took part in the survey and 271 finished it , yielding the completion rate of 46.3 % . Although it was a quota sample , not a random sample , it was close to the general U.S. population in terms of various demographic measurements . While there are concerns for using online opt-in panels , it is increasingly an accepted practice in an era where random digit dialing to collect probability samples has become very difficult and expensive . Indeed , evidence suggests that use of online opt-in panels makes little difference in quality ( Ansolabehere & Schaffner , 2014 ) . We limited the sample to Facebook users , because of the social media giant's dominance in news distribution . We also created quotas for political orientation to resemble the U.S. population demographics—thus Republicans and Democrats were even , each making 40 % of the sample , while 20 % identified as Independents . The sample ’ s average age was 40 years old and it was about 58 % female . The racial makeup was about 76 % White Caucasian , 11 % Asian , 9 % Black , and 7 % Latino/a . The average network size , or the number of friends , was 423 , ranging from 0 to 5,000 GSD = 799 ) . Variables and Analysis Cross-cutting exposure measured the degree to which respondents encountered politically and socially disagreeable news on Facebook . It employed a two-step measurement such that cross-cutting exposure was differentiated based on the sources of The Journal of Social Media in Society , Vol . 9 , No . 1 Underneath the Filter Bubble exposure . The overall cross-cutting exposure from all different sources ( /= 17.02 , SD= 4.34 ) were then divided into two groups : Strong and weak ties . Strong ties included romantic partners , friends , families , and relatives , whereas weak ties included strangers , classmates and co-workers , and public figures . This distinction of strong vs. weak ties was supported by factor analysis : A principal component analysis with varimax rotation yielded two factors eigenvalues over 1 . Romantic partners , family , and friends all produced loadings of at least .64 onto the first factor ( and no significant loadings onto the second factor ) and were subsequently labeled “ strong ties. ” Together , they explained 41.5 % of the variance . The second factor derived was labeled “ weak ties , ” onto which public figures and strangers produced loadings of over .80 , and together they explained 22.2 % of the variance . Initially , coworkers/classmates presented an issue because it loaded onto both the strong ties ( 55 ) and weak ties ( 54 ) to substantial degrees . Theoretically , it makes also sense that coworkers and classmates can belong to both strong and weak ties simultaneously because these relationships usually can be intersectional , encompassing one ’ s public and private lives . For a clear empirical and theoretical distinction , we decided to drop the coworkers/classmates from analysis . Dropping classmates/coworkers also improved the amount of variance explained in each of the two factors ( See Table 1 ) . Table 1 Factor Loadings on Strong and Weak Ties Spouse/ Family/ Friends Classmates/ Strangers Public Kigenvalue Partners Relatives Coworkers * Figures Strong 64 19 19 55 “ 01 16 2.49 Weak 17 14 -,07 504 85 84 1.30 * dropped from analysis . The key independent variable was network cultural diversity , which is a composite index of ethnic and religious diversities . Ethnic diversity and religious diversities were measured by the popular Herfindahl-Hirschman Index , a widely accepted measure of diversity used by ecologists , linguists , economists , sociologists , and demographers ( Pew Research Center , 2014 ) . Also known as the Simpson ’ s D , the Herfindahl-Hirschman index 30 | Spring 2020 thejsms.org Min & Wohn has been utilized in communication research as well ( e.g. , Eveland & Hively , 2009 ; McDonald & Dimmick , 2003 ; Vitak , 2012 ) . To generate the index , each survey respondent was asked to estimate the proportions of their friends ’ ethnicities and religions in his or her Facebook network . The proportions were then squared and summed , which made the index range from zero to one . One meant complete homogeneity , meaning , for example , someone 's Facebook friends consisting of completely one ethnicity only . In this research , the inverse of the index was used to make a number close to one denote higher diversity and a number close to zero denote homogeneity . In mathematical terms , the diversity index ( DP ) was calculated as the following : Tm D= 1 ) pi ? i=1 where p/is the proportion of friends within each ethnic/religious category . The ethnic diversity and religious diversity indexes were calculated separately . However , they were highly correlated ( r= .64 ) and these two were summed up and their average was taken to create the network cultural diversity variable ( /= .45 , SD = .22 ) . Other variables included in the regression analysis as controls were political ideology ( /= 3.87 , SD= 1.72 ) on a 7-point scale , with 1 being extremely liberal and 7 being extremely conservative , political interest ( A/= 3.07 , SD= .83 on a 4-point scale ) , network size , which is the number of Facebook friends ( A/= 423 , SD= 799 ) . News media use measured the frequency of radio , television , newspaper , website , and social media news use ( M= 17.20 , SD= 3.61 ) . Political knowledge was constructed based on 4-items probing the respondents ’ knowledge of current and political affairs ( A7= 1.99 , SD = .82 ) . Finally , for demographics , White Caucasians and males were coded as 1 , respectively , and all others as 0 . Educational level ( /edian = some college ) and income level ( Median = $ 50,000 to $ 59,999 ) were used as ordinal variables . RESULTS First of all , it was found that the vast majority ( 87.1 % ) of the respondents answered they get exposed to disagreement to a good degree ( RQ1 ) . In descriptive statistics , more than half ( 53.5 % ) said they get politically or socially disagreeable information “ sometimes , ” and 33.6 % said they get exposed “ often ” to such information . Only 12.9 % said The Journal of Social Media in Society , Vol . 9 , No . 1 Underneath the Filter Bubble they “ never ” ( 1.8 % ) or “ rarely ” ( 11.1 % ) get exposed to disagreement on social media . At least in the respondents ’ subjective perceptions , cross-cutting exposure was prevalent . Hypothesis 1 predicted that cross cutting exposure to disagreeable information will more likely come from weak ties . A paired sample ¢-test showed that the cross-cutting exposure score ( //= 2.67 ) from weak ties was statistically significantly higher than the one coming from strong ties ( 7= 2.38 ) ( ¢= 4.61 , df= 270 , p < .001 ) . Hypothesis 1 was supported . Hypothesis 2 predicted that higher network diversity will be associated with higher cross-cutting exposure . This hypothesis was supported . As seen in Table 2 , when the dependent variable of cross-cutting exposure was regressed upon the independent variables , the coefficient for network cultural diversity ( b = 4.80 , p < .001 ) , along with those for network size and news media use , statistically significantly predicted higher cross-cutting exposure , meaning that the more diverse and the larger one ’ s network is , and the more people use news media , the more likely they are exposed to disagreement . Table 2 Cross-cutting Exposure on Social Media Regressed upon Independent Variables Cross-cutting Exposure B S.E . Political Interest 43 33 Political Ideology 02 14 Political Knowledge -.49+ 29 News Media Use Oo Qeee 07 Age 00 O1 Gender ( Female ) 27 50 Race ( Non-White ) -.58 59 Education .05 27 Income 12 08 Network Size .01 * * .00 Network Cultural Diversity 4.80 * * * 1.13 Model Fit ( R2 ) 29 Note . N= 271 ; + * p < .10 ; * p < .05 ; * * p < .01 ; * * * p < .001 32 | Spring 2020 Min & Wohn DISCUSSION When the idea of the filter bubble was first introduced , there was a heightened sense of concern that the personalized Internet and social media harm democratic discourse and governance . This rather dystopian view that the new media trap us in the silo of selective exposure is being increasingly disputed by latest research ( for examples , see , Bakshy et al. , 2015 ; Flaxman et al. , 2016 ; Haim et al. , 2018 ; Newman et al. , 2017 ) . The present study adds to this growing body of evidence that the extent of the filter bubble is not as great as imagined in the popular narrative . This study also contributes to a more nuanced understanding of the filter bubble , probing what exist beneath it : It was found that one ’ s network characteristics may influence the degree of cross-cutting exposure to disagreement . Individuals still have agency in terms of deciding whom to be connected with on social media , which directly relates to the type of content they will see and ultimately engage with . Algorithms do not choose whom one connects to online—this is a human choice . Thus , blaming technology may be an oversight of the underlying problem . The findings do not dismiss , however , the power of algorithms . Algorithms certainly play a part in the news one sees on social media , because many social media systems use algorithms to curate the content users are exposed to . Thus , there is of course the chance that even if one chooses to connect online with a very diverse group of people , the algorithm could potentially filter out all the information coming from those diverse networks . Consistent with previous research ( Granovetter , 1973 ; Shirky , 2008 ) , weak ties are found to play an important role in facilitating exposure to diverse information . With weak ties that come without strong personal or emotional attachments , social media users may experience more emotionally detached , casual , and incidental social interactions , which creates opportunities for them to gather information , taste , and try out disagreement ( Min & Wohn , 2018 ) . The importance of weak ties found in this research needs a cautious interpretation , however . It should be noted that our study is among the few that probed the role of weak ties in acquiring “ political information. ” Much of the original work on information and weak ties was related to information about new jobs—the rationale was that people who are similar have access to similar information , and thus weak ties were more likely to be ones with information about jobs that close ties do not . However , when it The Journal of Social Media in Society , Vol . 9 , No . 1 Underneath the Filter Bubble comes to news and politics , the information is much more complex . For example , a strong tie is equally likely as a weak tie to have thoughts that are both agreeable and disagreeable to an individual . Say , among close friends Steve and Alex , it could be the case that Alex posts news about political views that Steve disagrees with , but they are still close friends because of their shared interest in science fiction . This means that there is a need to further investigate complex personal relationships present in social media interactions . Future research should tease out these intricacies . Another issue with this study is that the factor analysis found coworkers/classmates , often regarded as an example of weak ties where frequent cross- cutting exposure takes place ( Mutz & Mondak 2006 ) , belonged to both strong and weak ties . Why this happened is unclear . But we speculate that while Mutz and Mondak imagined the workplace as an archetypical place of a weak tie and cross-cutting exposure in the offline world only , the colleagues and classmates in our study represented relationships taking place both in the offline and social media world . As suggested earlier , the private/public relationship can be easily blurred on social media and that is perhaps why coworkers/classmates loaded onto both the strong ties and weak ties factors . Future research should focus on the changing nature of coworker/classmate relationships in the age of social media . As typical in survey research , the cross-cutting exposure and the cultural network diversity indexes used in this study were self-perception measures , which suggest they may not accurately reflect the actual amount of cross-cutting exposure or actual diversity in individuals ’ social networks . However , many studies probing network characteristics routinely use self-report measures ( e.g. , Choi & Lee , 2015 ; Lee et al. , 2014 ; Scheufele et al . 2004 ; 2006 ) . Furthermore , it can be argued that self-perception of disagreement is deemed a better measurement of cross-cutting exposure than a third-party ’ s judgment of incongruence , because , after all , if individuals do not perceive that disagreement has occurred , it will have less of an effect on their attitudes and behavior ( Barnidge , 2017 ) . For diversity , it was shown that a subjective measure of diversity is correlated with an objective diversity measure , rendering some support to the use of a self-report measure ( Mislevy , 2009 ) . 34 | Spring 2020 Min & Wohn Cross-cutting exposure to disagreement is normatively a very important concept . Being exposed to diverse viewpoints and experiencing challenging opinions is a bedrock of modern democracy . That ’ s why scholars are concerned about the filter bubble or echo chambers : The more filter bubble or echo chambers we have , the less healthy our democratic discourse will be . That basic premise is a valid idea . But we need more thorough investigation of their concepts and operation . We need better understanding of what exist underneath the filter bubble and what the specific dimensions of echo chambers are , before jumping to the conclusion that they are hurting the public sphere and democracy . We don ’ t know the true extent of the filter bubble , and , even if we acknowledge its existence , we know very little about how people behave within that bubble . There are many different ways people read , process , and engage with information , and thus it ’ s difficult to conclude that the existence of the bubble will automatically leads to negative outcomes . As an effort to have a more contexualized understanding of the phenomenon , our research found that there exist important roles of network characteristics — composition of people in the social media network — that facilitates the exposure to disagreement , which may mitigate the concerns of filter bubble effects . Therefore , in light of current research , we argue that the best way to fight the filter bubble — if it exists — is naturally occurring networks of diverse connections , especially weak ties . As argued before , users have the agency to decide whom they connect with , and their conscious awareness to broaden their network is an important asset required in the social media age . References Alleott , H. & Gentzkow , M. ( 2017 ) . Social media and fake news in the 2016 election . Journal of Economic Perspective , 31 ( 2 ) , 211-236. doi : 10.12574ep.31.2.211 Ansolabehere , S. & Schaffner B. F. ( 2014 ) . Does survey mode still matter ? Findings from a 2010 multi-mode comparison . Political Analysis , 2X3 ) , 285-303 . Bakshy , E. , Messing , S. , & Adamic , L. ( 2015 ) . Exposure to ideologically diverse news and opinions on Facebook . Science , 348 , 1130-1132. doi : 10.1126/science.aaa1160 Barnidge , M. ( 2017 ) . Exposure to political disagreement in social media versus face-to-face and anonymous online settings . Political Communication , 34 , 302-321. doi : 10 . 1080/10584609 . 2016 . 1235639 The Journal of Social Media in Society , Vol . 9 , No . 1 Underneath the Filter Bubble Beam , M. A. , Child , J. T. , Hutchens , M. J. , & Hmielowski , J. D. ( 2018 ) . Context collapse and privacy management : Diversity in Facebook friends increases online news reading and sharing . New media & Society , 207 ) , 2296-2314. doi : 10.1177/1461444817714790 Beam , M. A. , Hutchens , M. J. , & Hmielowski , J. D. ( 2018 ) . Facebook news and ( de ) polarization : Reinforcing spirals in the 2016 US election . /nformation , Communication & Society , 217 ) , 940-958. doi : 10.1080/1369118X.2018 . 1444783 Choi , J. , & Lee , J. K. ( 2015 ) . Investigating the effects of news sharing and political interest on social media network heterogeneity . Computers in Human Behavior , 44 , 258- 266. doi : 10.1016/.chb.2014.11.029 Eveland , W. P. , & Hively , M. H. ( 2009 ) . Political discussion frequency , network size , and “ heterogeneity ” of discussion as predictors of political knowledge and participation . Journal of Communication , 5 % 2 ) , 205-224. doi : 10.11114.1460- 2466.2009.01412.x Flaxman , S. , Goel , S. , & Rao , J . ( 2016 ) . Filter bubbles , echo chambers , and online news consumption . Public Opinion Quarterly , 80 ( S1 ) , 298-320. doi : 10.1093/poq/nfw006 Garrett , R. K. ( 2009 ) . Politically motivated reinforcement seeking : Reframing the selective exposure debate . Journal of Communication , 6KA ) , 676-699. doi:10.1111/.14602466.2009.01452.x Gentzkow , M. , & Shapiro , J . ( 2011 ) . Ideological separation online and offline . The Quarterly Journal of Economics , 126 ( 4 ) , 1799-1839. doi : 10.1093/qje/qjr044 Gottfried , J. , & Shearer , E. ( 2016 ) . News use across social media platforms 2016 . Pew Research Center . Retrieved May 22 , 2017 from http : //www.journalism.org/2016/05/26/news-use-across-social-media-platforms- 2016/ . Graellis-Gardo , E. , Lalmas , M. , & Quericia , D. ( 2014 ) . People of opposing views can share same interests . Proceedings of the 23rd International Conference on World Wide Web , 281-282 . Granovetter , M. ( 1973 ) . The strength of weak ties . The American Journal of Sociology , 7K6 ) , 1360-1380. doi : 10.1086/225469 Haim , M. , Graefe , A. , & Brosius , H. ( 2018 ) . Burst of the filter bubble ? Effects of personalization on the diversity of Google News . Digital Journalism , 6 ( 3 ) , 330-343. doi : 10.1080/21670811.2017.13838145 Hampton , K. , Goulet , L. , Her , E. J. , & Rainie , L. ( 2009 ) . Social isolation and new technology . Pew Research Center . Retrieved from http : //pewinternet.org/Reports/2009/18 -- Social-Isolation-and-New-Technology.aspx Katz , E. , & Lazarsfeld , P. ( 1955 ) . Personal influence : The part played by people in the flow of mass communications . New York : The Free Press . Kim , Y. , Chen , H.-T. , & de Zuniga , H.G . ( 2013 ) . Stumbling upon news on the Internet : Effects of incidental news exposure and relative entertainment use on political engagement . Computers in Human Behavior , 2X6 ) , 2607-2614. doi : 10.1016/ ) .chb.2013.06.005 Kim Y. , Hsu , S. H. , & de Zuniga , H.G . ( 2013 ) . Influence of social media use on discussion network heterogeneity and civic engagement : the moderating role of personality traits . Journal of Communication , 63 , 498-516. doi : 10.11114com . 12034 36 | Spring 2020 Min & Wohn Lee , J. K. , Choi , J. , Kim , C. , & Kim , Y . ( 2014 ) . Social media , network heterogeneity , and opinion polarization . Journal of Communication , 644 ) , 702-722. doi : 10.1111/4com . 12077 McDonald , D. G. , & Dimmick , J . ( 2003 ) . The conceptualization and measurement of diversity . Communication Research , 301 ) , 60-79. doi : 10.1177/0093650202239026 Messing , S. , & Westwood , S. J . ( 2014 ) . Selective exposure in the age of social media : Endorsements trump partisan source affiliation when selecting news online . Communication Research , 41 ( 8 ) , 1042-1063. doi:10.1177/00936502 12466406 Min , S. J. , & Wohn , D. Y . ( 2018 ) . All the news that you don ’ t like : Cross-cutting exposure and political participation in the age of social media . Computers in Human Behavior , 83 , 24-31. doi : 10.1016/.chb.2018.01.015 Mislevy , J . ( 2009 ) . Objective and subjective measures of diversity : How they relate to one another and climate perceptions . Institutional Research , Planning & Assessment . Paper presented at the A/dAIR Conference at the University of Maryland . Mitchell , A. , Gottfried , J. , Barthel , M. & Shearer , E. ( 2016 ) . The modern news consumer . Pew Research Center Journalism Project . July 7 , 2016 . Retrieved May 3 , 2017 from http : //www journalism.org/2016/07/07/the-modern-news-consumer ’ . Mutz , D. ( 2006 ) . Hearing the other side : Deliberative versus participatory democracy . New York : Cambridge University Press . Mutz , D. , & Mondak . J.J. ( 2006 ) . The workplace as a context for cross-cutting political discourse . Journal of Politics , 681 ) ,140-155. doi:10.11114.1468-2508.2006.00376.x Newman , N. , Fletcher , R. , & Kalogeropoulos , A. , Levy , D. , & Nielsen , R.K. ( 2017 ) . Reuters Institute digital news reports 2017 . Oxford , UK : Reuters Institute . Pariser , E. ( 2011 ) . The filter bubble : How the new personalized web is changing what we read and how we think . New York , NY : Penguin Books . Parkinson , H. ( 2016 , November 14 ) . Click and elect : How fake news helped Donald Trump win a real election . The Guardian . Retrieved May 3 , 2017 , from https//www.theguardian.com . Pew Research Center ( 2014 ) . Global religious diversity . Retrieved January 4 , 2017 , from http : ‘ /AWwww.pewforum.org/2014/04/04/global-religious-diversity/ Read , M. ( 2016 , November 9 ) . Donald Trump won because of Facebook . New York Magazine , Retrieved May 8 , 2017 , from http : //www.nymag.com . Scheufele , D. A. , Nisbet , M. C. , Brossard , D. , & Nisbet , E. C. ( 2004 ) . Social structure and citizenship : Examining the impacts of social setting , network heterogeneity , and formational variables on political participation . Political Communication , 2113 ) , 315-338. doi : 10.1080/10584600490481389 Scheufele , D. A. , Hardy , B. W. , Brossard , D. , Waismel-Manor , I. S. , & Nisbet , E. ( 2006 ) . Democracy based on difference : Examining the links between structural heterogeneity , heterogeneity of discussion networks , and democratic citizenship . Journal of Communication , 56 ( 4 ) , 728-753. doi : 10.11114.1460-2466.2006.00317.x Schudson , M. ( 1998 ) . The good citizen : A history of American civic life . Cambridge , MA : Harvard University Press . Shirky , C. ( 2008 ) . Here comes everybody : The power of organizing without organizations . New York : Penguin Books . Sunstein , C. ( 2003 ) . Why societies need dissent . Cambridge , MA : Harvard University Press . The Journal of Social Media in Society , Vol . 9 , No . 1 Underneath the Filter Bubble Sunstein , C. ( 2017 ) . # Republic : Divided democracy in the age of social media . Princeton , NJ : Princeton University Press . Tewksbury , D. , Weaver , A. , & Maddex , B . ( 2001 ) . Accidentally informed : Incidental news exposure on the World Wide Web . Journalism & Mass Communication Quarterly , 7K3 ) , 533-554. doi : 10.1177/107769900107800309 Vitak , J . ( 2012 ) . The impact of context collapse and privacy on social network site disclosures . Journal of Broadcasting & Electronic Media , & 6\\4 ) , 451-470. doi : 10 . 1080/08838151.2012.732140 Wohn , D. Y. , & Bowe , B. J . ( 2014 ) . How social media facilitates social construction of reality . In Proceedings of companion publication of CSCW 2014 , 261-264 . New York , NY : Association for Computer Machinery ( ACM ) . doi : 10.1145/2556420.2556509 Wohn , D. Y. , & Bowe , B. J . ( 2016 ) . Micro agenda setters : The effect of social media on young adults ’ exposure to and attitude toward News . Social Media + Society , 1 ) . doi : 10.1177/2056305 115626750 Wohn , D. Y. , Min , S. J. , Bowe , B. J. , & Patel , S. ( 2017 ) . Ethnic network diversity , and familiarity and engagement with race-related news on Facebook . Paper presented at the 2017 AXJMC conference , Chicago , Aug.11 . Funding and Acknowledgements The authors declare no funding sources or conflicts of interest . 38 | Spring 2020 Filter Bubble effect in the multistate voter model Giulio lannelli , t ; 2 Giordano De Marzo * , ! 3:4 and Claudio Castellano 5,1 D Centro Ricerche Enrico Fermi , Piazza del Viminale , 1 , I-00184 Rome , Italy . > ) Dipartimento di Fisica , Universita di Roma “ Tor Vergata ” , 00133 Roma , Italy . 3 ) Dipartimento di Fisica Universita “ Sapienza ” , P.le A. Moro , 2 , I-00185 Rome , Ttaly . 4 ) Sapienza School for Advanced Studies , “ Sapienza ” , P.le A. Moro , 2 , I-00185 Rome , Ttaly . 5 ) Istituto dei Sistemi Complessi ( ISC-CNR ) , Via dei Taurini , 19 , I-00185 Rome , Ttaly ( * Electronic mail : giordano.demarzoQcref.it ) ( Dated : February 3 , 2022 ) Social media influence online activity by recommending to users content strongly correlated with what they have preferred in the past . In this way they constrain users within filter bubbles that strongly limit their exposure recommendation algorithms . Information is nowadays mainly diffused via dig- | ital channels as people increasingly use online plat- 2 forms instead of newspapers or television to access news . If , on the one hand , this makes information ° easily available to all , on the other hand it allows ¢ ) extremely detailed personalization . Most web sites '' HA use recommendation algorithms to provide users with content in line with their taste and way of _ & thinking . Examples are the personalized page rank ©_of Google , “ suggested for you ” posts by Facebook —or the recommendations of Amazon and Netflix . — This leads to the formation of the so-called “ filter > bubbles ” , in which users are exposed almost ex- [ ™ clusively only to content they have already shown © to be interested to . In this manuscript we model —— this phenomenon by a modification of a very simple = model for opinion dynamics ( the multi-state voter Oo model ) where individuals are influenced not only AN by their peers but also by an external “ field ” which encodes information about the opinions the indi- N vidual held in the past . This field , if large enough , - « leads to a polarized steady state in which users > opinions are crystallized and consensus is no more Sd possible . — S I . INTRODUCTION ph ] 2 Feb 2022 S.SO The concept of “ filter bubble ” has crossed the bound- aries of the academic world reaching public discourse and mainstream media . This reflects the realization that on- line social media ( OSM ) have a tremendous impact on how people share information and form their opinions . For this reason they may constitute not only a great oppor- tunity for the diffusion of knowledge , but also a great threat for the stability of social fabric and the function- to new or alternative content . We investigate this type of dynamics by considering a multistate voter model where , with a given probability A , a user interacts with a “ personalized information ” suggesting the opinion most frequently held in the past . By means of theoretical arguments and numerical simulations , we show the existence of a nontrivial transition between a region ( for small A ) where consensus is reached and a region { above a threshold A . ) where the system gets polarized and clusters of users with different opinions persist indefinitely . The threshold always vanishes for large system size N , showing that consensus becomes impossible for a large number of users . This finding opens new questions about the side effects of the widespread use of personalized ing of democracy . A filter bubble occurs when a user is selectively exposed predominantly to content that tends to reinforce his/her current opinion/belief/state , while sup- pressing other alternatives ! ? . In OSM this typically hap- pens because of personalized recommender systems , which leverage information on past user activity to provide sug- gestions which , aiming at maximizing user satisfaction , tend to be very similar to what the user has already shown to prefer ‘ * . Together with the “ echo chamber ” effect ’ , filter bubbles are thought to be at the heart of the overall increase of polarization and radicalization that is observed in many social contexts ! - ! ? . A great deal of activity has been devoted in the last years to the goal of understanding what are the basic micro- scopic mechanisms underlying the rise of polarization and how phenomena observed at population scale are linked to them ! 3- ? ! These efforts follow the line of research aimed at understanding how basic mechanisms underlying the inter- action of individuals give rise to collective consensus phe- nomena ? * ? 3_ The voter model ? * ? ° played an important role in this activity , because of its extremely simple nature amenable to exact analytical treatment . Its dynamics de- scribes the evolution of a population of agents which have to choose between two perfectly equivalent alternatives and do it by selecting at random a peer and copying their se- lection . Starting from a disordered state , clusters of indi- viduals sharing the same opinion form and grow over time . For any structure of the interaction pattern among indi- viduals , consensus ( i.e . all agents having the same opin- ion ) is invariably reached . A very natural generalization is the Multistate Voter Model ( MVM ) , where the number of available equivalent options is a fixed value M > 227-29 , In mean-field , MVM reaches consensus for any value of M , and the average time required for it depends on M only weakly . In this paper we investigate the behavior of MVM in the presence of an additional interaction mecha- nism which biases the opinion of an agent toward the state the agent has chosen most frequently in the past . This interaction mimics the filter bubble effect of personalized recommenders in OSM , which present to users suggestions based on their previous behavior . The effect of personalized information on binary voter model dynamics has been investigated in a previous pub- lication®°® . In a homogeneous mean-field framework it was shown that for sufficiently strong coupling with the agents ’ past , consensus is no longer reached and the system re- mains stuck in a polarized state with coexistence of both opinions . Here we generalize the work in Ref . * ° by studying both analytically and numerically the effect of personalized information in the context of the MVM . The goal is to un- derstand whether , depending on the number of agents N , the number of possible opinions M and the strength of the personalized information ( A , to be defined below ) consen- sus is reached or not . Depending on the scaling of M with respect to N we identify three different regimes and in each of them we compute the threshold A , separating consensus from polarized states . Numerical simulations are in good agreement with theory in all cases expect for Mf = N and they also show that the transition from consensus to po- larization is continuous and characterized by a power law distribution of opinions numerosity at the threshold . Re- markably , for N — co the threshold goes to zero in all three regimes and this implies that in large systems even a very small form of personalized information always breaks consensus , leading to opinion polarization . Il . MULTISTATE VOTER MODEL WITH PERSONALIZED INFORMATION A . Definition of the model Many real life situations are characterized by the pres- ence of more than two possible opinions or factions , as in the case of political elections or football clubs , and so the voter model with binary opinions is not suitable for schematizing the dynamics of such systems . However this difficulty can be easily bypassed by considering the usual voter dynamics and allowing the states of the N agents to vary among M distinct opinions instead of only two , so to obtain the so called multistate voter model . De- noting by o ; ( t ) the opinion of agent i at time £ we have oi { t ) =1 ... M and the update rule reads oi { t + dt ) = 0 ; ( £ ) with prob . Ass ( 1 ) yj Aig Here Aj ; is the binary adjacency matrix of the undirected network over which the dynamics take place , while 6t = 1/N . In the following we focus on the mean field case , meaning that the underlying network is a complete graph and it holds A ; ; = 1 for i # j ; in this case the update rule Eq . ( 1 ) can be written as oi { t + 6t ) = k with prob . wu ( 2 ) where N ; , ( £ ) is the number of agents with opinion k at time t. In order to endow this system with personalized infor- mation ( PI ) we consider also N PI fields e ; , each coupled with the corresponding standard voter agent o ; . The state of PI fields is a random variable ranging from 1 to M and which assumes the value & with probability Ple ; ( t ) = k ] . This probability varies from agent to agent and over time , depending on the history of the corresponding voter : the more a voter has chosen a given opinion in the past , the higher the probability that its corresponding PI field sug- gests that opinion . In order to quantify this reinforcement process we generalize the expression for Ple ; ( { t ) = k ] pro- posed in®® to the case of M distinct opinions , more pre- cisely ( k ) ne t Plei ( t ) =k ] = Pini ( t ) | = ot ) ( 3 ) jai ¢ © ( t ) where ni ) ( 4 ) is the number of times agent i has chosen ( or also confirmed ) opinion k up to time ¢ ; in the following we ¢ will often write ni ) , keeping the time dependence implicit . The state of the system is thus described by N ( M-+1 ) vari- ables , namely { ( 0 ; , ni ) , and the dynamics takes place as in the voter model with personalized information®® . Ini- tially each opinion o ; is set equal to a random value ; at each time step a given agent 7 is selected uniformly at ran- dom and with probability 1 — A it follows the usual voter dynamics , while with probability A the agent copies the state e ; ( t ) of the corresponding PI field . More explicitly e ; ( £ ) with prob . » 4 k with prob . ( 1 — A ) 4 ( 4 ) oi { t + 6t ) = As in®° , the parameter sets the strength of the personal- ized information with respect to the interaction with other individuals , while c determines how fast personalized in- formation adapts to the preferences of agents . B. Phenomenology of the multistate voter model with personalized information Let us illustrate the overall qualitative phenomenlogy of the model , common for generic values of M , N and c. A crucial observable is the number of surviving opinions M , { t ) as function of time , which plays the role of the order parameter of the system . In the absence of personalized information ( that is for A = 0 ) , for a homogeneous initial condition with M , ( 0 ) = M states , the average value of M , ( t ) satisfies for t < N ? '' M ( t ) = , ( 5 ) For times of the order of N , M , reaches the value M , = 1 , implying an ordered configuration ( consensus ) in which all agents share the same opinion , as also shown in Fig . la . Notice also that there is an intrinsic timescale tj = N/M in Eq . ( 5 ) such that M , remains constant and equal to M , ( 0 ) for times up to tp . As A increases deviations from Figure 1 : Evolution of the number of surviving opinions for 100 realizations of the dynamical process with various values of A . ( a ) Very small \\ = 0.001 ; ( b ) Slightly subcritical A = 0.04 ; ( c ) Critical A = 0.05 ; ( d ) Supercritical A = 0.08 . In all panels N = M = 10000 , c = co. For convenience we plot { + 1 along the horizontal axis . Eq . ( 5 ) start to appear , but the system keeps reaching the ordered state after a sufficiently large amount of time , see Fig . 1b . The behavior changes as A approaches the threshold A , ; in this case consensus can still be reached , but in some realizations the system remains trapped in a stable disordered state ( also denoted as polarized state ) characterized by the presence of more than one opinion ( Fig . lc ) . Finally , for A substantially larger than A ; . , the system never reaches consensus and the asymptotic state is always the disordered one ( Fig . 1d ) . This qualitative phenomenology is observed independently of the value of c ( provided that ¢ > 1 ) . This parameter only determines the possible presence of an initial transient dominated by the randomness of personalized information in the first time steps , as shown Fig . 2 . Indeed for c= 1+6 with 6 < 1 the probability of PI fields , Eq . ( 3 ) , can be approximated as asa 1 nls wate M+ dn ? P [ ni ] = Exploiting the fact that it ni ) is nothing but the num- ber of times agent 7 has been updated and that going from t to t+ 1 each agent is on average updated once we have yt ni ? ) = t so that « & ) @ ) ttnd 1 bf aw t Pn ss eat My ( * ) Since 0 < n ; '' ’ < 1 this implies 1 i ( i ) 1 i 1 7 pe < P ] < p +8 ( 0-H ) : As a consequence P [ ni ] = 3 + O ( 6t ) and so for 6 small the dynamics is initially equal to that of a multistate voter model with external random field . This produces the ob- served transient . A detailed analysis of the multistate voter model in presence of random external information is be- yond the scope of this work , the interested reader can find further details in ? ! . In order to determine an upper bound of the c¢ ; ; , above which no transient is observed , let us con- sider the first update of agent 2 and let us suppose that opinion m is selected . As a consequence the probability of — A=0.05 — A=0.15 — A=0.30 — A=0.35 10°E z = | 10°E 400 = F 300 | 10°= Ll ol ? p1iitiul roti Loon 3 10° 10° 10° 10° 10° t Figure 2 : Temporal evolution of the number of surviving opinions for N = 1000 , M = 1000 , c = 1.2 and various values of A . The inset shows the same plot for \\ = 0.35 and various values of c. the corresponding PI field for the successive update is c ——— fork=m re=n =f ——— fork . lopwsi hem If the probability of the PI to be in state m is larger than the probability of being in any other state , a reinforcing loop gets established and the PI gets more and more po- larized along opinion m. This implies that a sufficient con- dition for observing a polarized PI already after the first step is Ple ; ( 6t ) =m ] > S© Plei ( st ) = ki , kém which implies c M-1 e+M-1° > c+M-1 yielding a threshold value Cin = M—-1 . ( 6 ) Fig . 2 shows that this estimate is an upper bound of the real c ; ; , . The duration of the transient governed by a random external field gets shorter as c is increased and it is completely absent for c © cy , = 999 . Since c plays only a marginal role , in the rest of the paper we focus on the case C > Cp so as to remove the initial transient . Finally , we illustrate the nature of the transition ob- served as 4 is varied . As evident from Fig . 1 , around the transition different realizations of the process lead to differ- ent outcomes : either consensus or a stationary state . The transition is characterized by the variation , as a function of A , of the fraction P , of runs reaching a stationary state ( Fig . 3a , inset ) . As it is possible to see , the larger is N , the sharper the transition becomes . Moreover , since for large N the critical threshold , goes to zero ( see Subsec . IITC and figures therein ) and the transition gets very sharp , this implies that in large systems even an infinitesimal amount of personalized information is sufficient to make the reach- ing of consensus impossible . The main panel of Fig . 3a displays how the fraction of surviving opinions in the sta- tionary state M , ( t > o0 ) /M = M & /M , averaged only over surviving runs , varies as a function of A . The quan- tity MS°/M grows in a continuous fashion , starting from a finite value decreasing with N. This suggests that in the large N limit the transition is continuous , as also confirmed by inspecting the distribution of S ; ( t + oo ) = SP , the number of agents polarized along opinion k in the station- ary state . When c > c : , the number of polarized agents S , along opinion k is given by the number of agents such that n\\ * ) > ni ? for any 7 # k , since , in this case , the personalized information suggest the most chosen opinion . Indeed , by looking at Fig . 3b it is clear that such a distri- bution decays as a power-law for A = A , , with a nontrivial exponent approximately equal to 2.8 ( for N = M ) . Ill. ANALYTICAL APPROACH As shown above , the phenomenology of the model is only marginally influenced by the parameter c. Therefore con- sider the case c > > cp , which can be more easily handled analytically . Indeed in such a situation the probability of the PI field e ; is strongly peaked on the opinion more fre- quently held by agent i and Eq . ( 3 ) reduces to Ple ; = k ] = dem , ( 7 ) where m is the opinion which satisfies ) . m = argmax [ ns k In other words the PI suggests only the favorite opinion in the past . Our goal is to derive , under the assumption of large c , analytical estimates of the critical value 4 , for generic large values of N and M. A . Stability of polarized states Let us consider an agent 7 in state o ; and let us as- sume that its PI is polarized along opinion m. Combining Eqs . ( 4 ) and ( 7 ) we can write the transition probability of this agent ? ? as J gpsa-n54| fork=m 1 Nr Uy Vay For the overall stability of the polarized state , the PI field e ; should remain polarized on opinion m so as to keep the agent we are considering fixed ( on average ) on this same opinion . This requires the transition probability to opinion m to be larger than the transition probability to any other Wlo , > k ) = ( 8 ) fork Am . 0.25 ) . y = 1 1 T T TT Tiny T TOTTI T TTTiTiiiy Qe = 4 4 cole N31 2 10 — N=10 0.207 ge ete 7 10 — N=3-104 3S ~ @ - N=3-10 — N=7-104 > 0.15— ae N=7-10 % | 107 % © we oe i ? — * int —e 108 nD , * es plo 107 2 0.10F he * 2 “ ra ae Bos- 10 % 0.05 8 ‘ 4 “ 6 S 0.0m 10 ° 0.8 10 ASA 0.00 l l I I 107 '' l 11 tiidil | pot oiiitl 0.00 0.05 0.10 0.15 0.20 0.25 10° 10 107 108 A Sr ( a ) ( b ) Figure 3 : a ) Main : Stationary value of the fraction M , of opinions , for Mf = N , averaged only over surviving runs . Inset : Probability that consensus is reached as a function of \\ for N = 107 , 10 * , 10° and M = 20 . As N increases the transition between consensus and polarization becomes sharper and sharper . b ) Probability distribution of the number of agents 5S ; polarized along opinion k at criticality for N = M. This has been obtained by letting the system evolve toward the stationary state and then performing a binning over the 5 ; so to obtain their histogram . Note that such an histogram corresponds to a single realization of the system . 104 Z 10° z 10° z FO Npex— N/M 4 104e 4 : - Nm ) 5 10° ! L L I L q 0 1000 2000 3000 4000 5000 t ( a ) 10 % z 10° z 10° 4 Fp NEX— N/M 3 IL a 10E - Nm¢ ( A ) : 10° ! ! ! ! 4 0 1000 2000 3000 4000 5000 t ( b ) Figure 4 : Temporal evolution of Ninax — N/M , compared with the critical value Nm , ( A ) for N = 10+ , M = 200 : a ) A = 0.07 ; b ) A = 0.08 . Different colors correspond to different simulations . opinion / , otherwise n would grow faster than ni ) and the PI would eventually depolarize and then polarize along opinion / . As a consequence , in order for the polarized state to be stable it must be Wo , > m ) > W ( o ; > I ) ViAm , which yields , using Eq . ( 8 ) N , , —N ; d mT my ) , a A = m2 ) ( 9 ) Here , in analogy with®° , we defined the critical magnetiza- tion m_ { A ) as ( 10 ) We can then repeat this same reasoning but considering an agent 7 whose PI field e ; is polarized along opinion ! . This leads to Nim — Ni ; N Combining this expression with Eq . ( 9 ) we obtain the fol- lowing necessary condition for a polarized state to be stable < m- { A ) . < m { A ) V { l , m ) . Nn —N ; By introducing the partial magnetization m , along opin- ion k , we can also rewrite this constraint as Ne — Vive Ne 2N ; , — N ny = ox —_ = — N N In this way Eq . ( 11 ) becomes “ - < Me . ( 12 ) = _ c t=50 4 10° : t=1005 E £=150 4 104 t= 200 % —_~ E t= 250 J ® .. 108 # = 300 % S & F t= 450 4 Ooh ¢=600 J E £=750 4 10°F ( a0 | 10° 3 0 50 100 150 200 Figure 5 : Temporal evolution of the Qin ” ) distribution as a function of time . Data are for c = 400 , N = 10° , M = 20 , X =0.07 . The component with high mean value represents agents polarized along opinion k ; the component with low mean value represents agents unpolarized or polarized along other opinions . The conclusion if the difference between any two magneti- zations is smaller than the threshold m , then the polarized state is stable . Note , however , that this condition is very strict and a polarized state can be stable on average even if there are some opinions held by a small number of agents not fulfilling it . Indeed in such a situation these opinions will be absorbed by the others , but still consensus will not be reached . As a consequence what really matters is that ( 11 ) is fulfilled when considering the most common opin- ion whose size is Niaz and the average opinion size given by N/M . The condition ensuring the system not to reach consensus is thus N Ninae ~ < = < Nme ( A ) . ( 13 ) M Fig . 4 checks and confirms the validity of this argument in numerical simulations . Note that m , is larger than 1 for A > 1/2 and so , as in the voter model with personalized information , above A = 1/2 an opinion can survive even with only a single agent supporting it . B. Polarization time In deriving Eq . ( 12 ) we assumed all PI fields to be po- larized on a certain opinion , meaning that for any i there is only one & such that n\\ * ) ni ) = 0 for all pairs ( i , k ) and the randomness of voter updates implies the occurrence of several ties between the various ni ) , The assumption that PI fields are polarized starts to be valid only after a polarization time t * > 0 . In order to compute this time we write down the master is maximum . However initially equation for the distribution of the ni ) values , a ( n ) , that reads dQ ( n\\ '' ) = NR ( u Jalal ? —2 ) -NA ( o ) a ( u ) 14 where we introduced the single transition probability NR ( n\\ ” ) = ( 1- a + AP ( e ; =k ) 1 ew ( 1 — A ) Wt ) +AP ( e ; =k ) . ( 15 ) Here we assumed that all surviving opinions share approx- imately the same number of agents and so we can make the approximation N ; , /N = 1/M , ( t ) . Now , considering opinion k , only a fraction $ ; /N of the agents is polarized along this opinion and thus we assume that the distribu- tion Q ( n ) is formed by two normalized components @ 1 and @ 2 corresponding to the two types of agents : those po- larized on opinion & ( component @ 2 ) and those polarized on any other opinion or not polarized at all ( component Q , ) . We can then write Q as a bimodal distribution O ( n ) = ( 1 ar ( n® ) + St00 ( n ) , Both components evolve according to the same general master equation Eq . ( 14 ) , but the transition rates are dif ferent . For what concerns the polarized component @ 2 we have NR ( n\\ ” ) = ( 1- NanH + and using this expression and Eq . ( 14 ) we can compute both the mean value nz and the variance of of the distri- bution Qe for polarized agents , finding 2 ‘ t 1-4 ma=o3= J dt may ? , ( 16 ) Analogously , the transition rate of the component @ 1 , cor- responding to agents not polarized on opinion & , is 1 MO NR ( n\\ ” ) = ( 1—2 ) and so the mean value n , and the variance o ? are nm =ot= [ a ( 573 ) : ( 17 ) Detailed computations are reported in Appendix A . Looking at Eqs . ( 16 ) and ( 17 ) it is clear that initially the two components are indistinguishable since they both have null mean and variance . However , having different velocities they tend to separate over time . This behavior is shown in Fig . 5 . Until Qi and Q2 are superposed there is no real distinction between polarized and unpolarized agents , as all agents can change their preferred opinion in one or few voter updates . Consequently we identify the polarization time ¢ * introduced above as the time when the two components split for the first time . This can be readily determined by imposing the distance between the two peaks to be equal to their widths , that is no ( t * ) — my ( t * ) =2| one ) + yoate ) ) . where the factor 2 is somewhat arbitrary and does not in- fluence the scaling of ¢ * . Substituting Eqs . ( 16 ) and ( 17 ) into this last expression we come up with an implicit inte- gral expression for the polarization time ¢ * sat ( 18 ) SL Baal C. The transition point Once the polarization time has been obtained we can turn to the determination of the critical parameter A , . The idea is the following : In the initial stage of the dynamics , the numbers of agents holding the different opinions , N ; , tend to fluctuate and their differences tend to grow over time . If this growth is slow enough , at the polarization time t * the condition for the stability of polarized states , Eq . ( 13 ) is satisfied . In such a case the disordered state with multiple coexisting opinions is stable and persists for- ever . Conversely , if at ¢ * Eq . ( 13 ) is violated , the system will eventually evolve toward the consensus state . The con- dition for A , thus reads Lmax ( t * ) = Nyax ( t * ) — x = Nz a ( 19 ) By means of numerical simulations and a simple scaling argument ( see Appendix B ) we determine that for M « < N 2max { t ) scales as Ni/2 Bnax ( t ) ~ wart ” 2 , ( 20 ) where y * 1/4 is a numerical constant . We also derived an equation for the time growth of N ; , —N/M and we checked that the temporal scaling of tmax ( £ ) is consistent with this expression , see Appendix C. Replacing this last expression into Eq . ( 19 ) we obtain an equation for A , pet ane , implying yA Oe ) ? N+ ( SO ) Eq . ( 21 ) , together with Eq . ( 18 ) for the polarization time , provide a closed system of equations in A , and ¢ SE bee fae } a ( # * ) 3/2 de = ( 21 ) ey NSE c In order to solve this system we need an explicit ex- pression for the number M ( t ) of surviving opinions . We consider two possible assumptions , which are expected to be fairly accurate for different values of Mf and N. Here we limit ourselves to report the main results , the interested reader can find detailed calculations in Appendix D. DD M < N If the number of opinions in much smaller than the num- ber of agents , each opinion is initially shared by a large number of individuals . As a consequence during a first time interval no opinion disappears and it is reasonable to make the approximation M ( t ) = M In this way Eq . ( 22 ) can be rewritten as 2 ~ a4 fey . fee ~ 2 M © M ( 23 ) V/s iy A ( ey ? \\e = —— N+ 7X ( 3 ? Depending on how large M/ is with respect to N , the solu- tions of this system scale in different ways . eM < « N * ¥/ ta 4 ( MN ) M4 de 2 ( MaN ) MS. ( 24 ) oNF < cM < EN eee 28/5 ( N M2 ) 1° ee 92/5 ( wM2 ) M5 , ( 25 ) E. M=N If M = N each agent has initially a different opinion . Hence , even during the first time steps , some opinions dis- appear by chance . In this case we can approximate the surviving opinions M , ( £ ) with the expression valid for the simple multistate voter model , Eq . ( 5 ) , that is for M = N , N M , ( t ) = . ( 26 ) Substituting this expression in Eq . ( 22 ) and imposing M = N > 1 , A . < 1 we obtain the following system 32NV/2 4 8 ) \\.N 2 ( 2.N — 16 ) NMP ) ? N + N-Y2 [ e ( A0 ) ] 9/ ? ° ra ( 27 ) whose solution scales as be x 94/3 N2/3 Ae x AN V2 ( 28 ) IV . NUMERICAL SIMULATIONS We now compare theoretical predictions with numerical simulations . We iterate MVM dynamics for various values of M and N up to ¢ = 2000 and we determine the fraction of times P , ( ) the system has reached consensus . We take as numerical estimate of A , the values such that P , ( A . ) = 1/2 . For fixed value of M and increasing size N , the analytical results predict initially a scaling regime given by Eq . ( 25 ) as long as N is much larger than Af but much smaller than M3 , followed by a scaling given by Eq . ( 24 ) . For M = 20 , the first regime spans a short interval of N values . In Fig . 6a we see only a hint of the associated scaling , while for larger values of N the agreement between theory and numerics is very good . For M = 200 instead ( see Fig . 6b ) , the first regime extends to much larger values of N , so that feasible values of N lie only in this regime . In this case A , nicely scales as N~/5 , as predicted by Eq . ( 25 ) , although the prefactor is not predicted exactly . For the case Mf = N instead , Figure 6c show that the theory is not able to catch the correct scaling . This mis- match has various potential origins . Indeed using Eq . ( 26 ) for the temporal dependence of M , ( t ) is a quite rough ap- proximation , as the number of different opinions actually decays much more slowly over time . But also the use of Eq . ( 19 ) for tmax ( £ ) is not warranted for M = N. A deeper understanding of the phenomenology of the case M = N remains an interesting open question . Vv . CONCLUSIONS In this paper we have introduced and analyzed a mul- tistate voter model where the coupling with an exter- nal history-dependent individual field mimics the effect of personalized recommendation algorithms in online so- cial media . A population of agents , initially having dif- ferent opinions , reaches consensus on a single opinion or remains polarized on multiple different opinions , depend- ing on the strength of personalized information . The phe- nomenology is governed by the competition between the fluctuations induced by voter dynamics and the tendency , due to personalized information , to bind agents to the opinion they adopted most frequently in the past . By means of arguments based on this physical picture , we estimated analytically the critical threshold between the two regimes , obtaining a reasonable agreement with sim- ulations for M < N. Conversely , the dynamics when the initial number of opinions is comparable with the number of agents seems to elude our approach . From a more general point of view , our study indicates how difficult reaching consensus is , in the presence of per- sonalized recommendations . For any number M of initial opinions the threshold , tends to vanish when the num- ber of agents N diverge . This means that no matter how weak is the coupling with the personalized information , if the system is large enough polarization unavoidably arises . In this respect , note that voter dynamics is extremely fa- vorable to the establishment of consensus : for any inter- action pattern , consensus is necessarily reached for any fi- nite number of interacting individuals . The addition of a personalized recommendation completely changes this pic- ture , at least for large systems . For a finite number of interacting agents instead consensus is still reached if the strength of personalized information is small enough . The transition between the two regimes exhibits nontrivial fea- tures that may be the focus of future activity along with generalizations to include nontrivial interaction patterns or a different functional dependence between the proba- bility distribution of the personalized information and the number of times an opinion has been selected in the past . A natural extension of this work would be to analyze more realistic recommendation algorithms . With respect to this , a promising possibility is to consider collabora- tive filtering algorithms®® , which are based on similarities among the history of different users or opinions instead of considering only the history of the user itself . This typol- ogy of algorithm is used in real life applications * * * ° , but still it is sufficiently simple to try an analytical study of its effects on opinion dynamics models . REFERENCES IR . Pariser , The filter bubble : What the Internet is hiding from you ( Penguin UK , 2011 ) . 2T.R . Dillahunt , C. A. Brooks , and S. Gulati , “ Detecting and visu- alizing filter bubbles in google and bing , ” in Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems , CHI EA 715 ( Association for Computing Machinery , New York , NY , USA , 2015 ) p. 1851-1856 . S. Nagulendra and J. Vassileva , “ Understanding and controlling the filter bubble through interactive visualization : A user study , ” in Proceedings of the 25th ACM Conference on Hypertext and Social Media , HT ’ 14 ( Association for Computing Machinery , New York , NY , USA , 2014 ) p. 107-115 . 47 . T. Nguyen , P.-M. Hui , F. M. Harper , L. Terveen , and J . A. Konstan , “ Exploring the filter bubble : The effect of using recom- mender systems on content diversity , ” in Proceedings of the 23rd International Conference on World Wide Web , WWW ’ 14 ( Asso- ciation for Computing Machinery , New York , NY , USA , 2014 ) p. 677-686 . 5L . V. Bryant , “ The youtube algorithm and the alt-right filter bub- ble , ” Open Information Science 4 , 85-90 ( 2020 ) . ®D . O ’ Callaghan , D. Greene , M. Conway , J. Carthy , and P. Cun- ningham , “ The extreme right filter bubble , ” arXiv preprint arXiv:1308.6149 ( 2013 ) . M. Cinelli , G. De Francisci Morales , A. Galeazzi , W. Quat- trociocchi , and M. Starnini , “ The echo chamber ef- fect on social media , ” Proceedings of the National Academy of Sciences 118 ( 2021 ) , 10.1073/pnas.2023301118 , https : //www.pnas.org/content /118/9/e2023301118.full.pdf . SW. Cota , S. C. Ferreira , R. Pastor-Satorras , and M. Starnini , “ Quantifying echo chamber effects in information spreading over political communication networks , ” EPJ Data Science 8 , 35 ( 2019 ) . °P . Barbera , J. T. Jost , J. Nagler , J . A. Tucker , and R. Bonneau , “ Tweeting from left to right : Is online po- litical communication more than an echo chamber ? ” Psy- chological Science 26 , 1531-1542 ( 2015 ) , pMID : 26297377 , https : //doi.org/10.1177/0956797615594620 . w ( a ) M=20€N . ~ < » — aMsnye 2/5 M2N ) -VS -- Simulations data 4H : 10 ! 10 ? 10° 104 10° 10° 107 108 10° 108 N ( b ) M =200 « .N . N — AMPN ) 8 25 MeN ) HS - @ - Simulations data N — 4n-12 L —® -- Simulations data 10° 10° Figure 6 : Comparison of analytical predictions for the threshold A , and numerical estimates of it 10 “ The partisan divide on political values grows even wider , ” https : // www.pewresearch.org/politics/2017/10/05/the-partisan- divide-on-political-values-grows-even-wider/ ( 2017 ) , accessed : 2021-10-04 . 11 , Chitra and C. Musco , “ Analyzing the impact of filter bubbles on social network polarization , ” in Proceedings of the 13th Inter- national Conference on Web Search and Data Mining , WSDM ’ 20 ( Association for Computing Machinery , New York , NY , USA , 2020 ) p. 115-123 . 12M . Maes and L. Bischofberger , “ Will the personalization of online social networks foster opinion polarization ? ” Available at SSRN 2553436 ( 2015 ) . 138 . Galam , “ Rational group decision making : A random field ising model at t= 0 , ” Physica A : Statistical Mechanics and its Applica- tions 238 , 66-80 ( 1997 ) . 14N . Crokidakis , “ Role of noise and agents ’ convictions on opinion spreading in a three-state voter-like model , ” Journal of Statistical Mechanics : Theory and Experiment 2013 , P07008 ( 2013 ) . 15G , L. Ciampaglia , A. Nematzadeh , F. Menczer , and A. Flammini , “ How algorithmic popularity bias hinders or promotes quality , ” Scientific Reports 8 , 15951 ( 2018 ) . 16N , Perra and L. E. Rocha , “ Modelling opinion dynamics in the age of algorithmic personalisation , ” Scientific reports 9 , 7261 ( 2019 ) . ITA . Sirbu , D. Pedreschi , F. Giannotti , and J. Kertesz , “ Algorithmic bias amplifies opinion fragmentation and polarization : A bounded confidence model , ” PLOS ONE 14 , 1-20 ( 2019 ) . 18P , Freitas , A. R. Vieira , and C. Anteneodo , “ Imperfect bifurcations in opinion dynamics under external fields , ” Journal of Statistical Mechanics : Theory and Experiment 2020 , 024002 ( 2020 ) . 19F , Baumann , P. Lorenz-Spreen , I. M. Sokolov , and M. Starnini , “ Modeling echo chambers and polarization dynamics in social net- works , ” Phys . Rev . Lett . 124 , 048301 ( 2020 ) . 290A . F. Peralta , M. Neri , J. Kertész , and G. Ifiiguez , “ Effect of algorithmic bias and network structure on coexistence , consensus , and polarization of opinions , ” Phys . Rev . E 104 , 044312 ( 2021 ) . 217 , W. Baron , “ Consensus , polarization , and coexistence in a con- tinuous opinion dynamics model with quenched disorder , ” Phys . Rev . E 104 , 044309 ( 2021 ) . 22 . Castellano , 8 . Fortunato , and V. Loreto , “ Statistical physics of social dynamics , ” Rev . Mod . Phys . 81 , 591-646 ( 2009 ) . 23P . Sen and B. K. Chakrabarti , Sociophysics : an introduction ( Ox- ford University Press , 2014 ) . 24P . Clifford and A. Sudbury , “ A model for spatial conflict , ” Biometrika 60 , 581-588 ( 1973 ) . 251 . Frachebourg and P. L. Krapivsky , “ Exact results for kinetics of catalytic reactions , ” Phys . Rev . E 53 , R3009-R3012 ( 1996 ) . 26P . L. Krapivsky , S. Redner , and E. Ben-Naim , A kinetic view of statistical physics ( Cambridge University Press , 2010 } . 27M . Starnini , A. Baronchelli , and R. Pastor-Satorras , “ Ordering dynamics of the multi-state voter model , ” Journal of Statistical Mechanics : Theory and Experiment 2012 , P10027 ( 2012 ) . 28W . Pickering and C. Lim , “ Solution of the multistate voter model and application to strong neutrals in the naming game , ” Phys . Rev . E 93 , 032318 ( 2016 ) . 29 . F , Peralta , N. Khalil , and R. Toral , “ Ordering dynamics in the voter model with aging , ” Physica A : Statistical Mechanics and its Applications 552 , 122475 ( 2020 ) , tributes of Non-equilibrium Statistical Physics . 39G . De Marzo , A. Zaccaria , and C. Castellano , “ Emergence of po- larization in a voter model with personalized information , ” Phys . Rev . Research 2 , 043117 ( 2020 ) . 31 , Herrerias-Azcué and T. Galla , “ Consensus and diversity in mul- tistate noisy voter models , ” Phys . Rev . E 100 , 022304 ( 2019 ) . 32.Note that these transition probabilities do not depend on the state 10 o ; of the agent . 33 ] , B. Schafer , D. Frankowski , J. Herlocker , and S. Sen , “ Col- laborative filtering recommender systems , ” in The adaptive web ( Springer , 2007 ) pp . 291-324 . 34G . Linden , B. Smith , and J. York , “ Amazon.com recommenda- tions : item-to-item collaborative filtering , ” IEEE Internet Com- puting 7 , 76-80 ( 2003 ) . 35B , Smith and G. Linden , “ Two decades of recommender systems at amazon.com , ” IEEE Internet Computing 21 , 12-18 ( 2017 ) . 36Only two because the scaling \\ < N~ ! / ? corresponds to negative times . Appendix A : Moments of the distribution of ni '' ) Let us consider the distribution Q ( n\\ '' ,1 ) , where ni ) is defined as the number of times agent 7 has chosen or confirmed opinion & in the past . The evolution of this distribution is given by Q ( n\\ ? .1 + ot ) = R ( n\\ ” _ 1 Q ( n\\ ” _ 1 , t ) + + A - R ( n\\ ) |Q ( n\\,2 ) . Expanding the left hand side for small 6t = 1/N we obtain which yields Eq . ( 14 ) Co ) 100 ) _ ( at a ) ola —NR ( ni Ja ( ni ” ) . ( AL ) Now we consider the two components Qi ( n\\ '' , t ) and Qo ( ni® ; t ) introduced in ITT B and we compute their mean value and variance . We recall that Q2 corresponds to agents whose PI are polarized along k , while Q , to the remaining agents , and that both components evolve ac- cording to the same master equation Eq . ( 14 ) , but with different transition rates . The general equation for the drift of the distribution ( also called average drift in the following ) is a ( n ) - oy €2 ( ni '' ) —-Srn® LL dt ° dt a nk a and using Eq . ( Al ) we obtain _ i ) ( ke ) ( % ) 4 ) v= a NR ( n\\ 1Q ( n\\ 1 ) ~ wR ( a® ) a ( o '' ) ] = Eom ( nolo ) Analogously the evolution of the second moment is d ni ) ° , ni o ) scum “ ot ) nk a that using Eq . ( Al ) becomes NOOD ( ey jobe wr ( n ) a ( ni® ) ) = = Yo ( n ” + 1 ) wR ( ni ) a ( n ” ) _ - ( oPYen ( a ole ) _ p ( n ) oln®™ =7 42 nl n ( ni ” ) Q ( n\\ '' ) , n a ( A3 ) where we used Eq . { A2 ) . Let us firstly consider agents polarized along & and so Qo , the transition rate is +A . NR » ( n\\ '' ) = ( 1- ) M , ( t ) and putting this expression into Eqs . ( A2 ) and ( A3 ) we get m= N5pqy th Mery ) , _ 1 dt ( 1 ) M , ( 2 ) ( Ad ) +afaa +2nz ) , where we defined nz = ( ni ) . Analogously for the com- 2 ponent Q , it holds NRi ( n\\ ) = ( 1- > ) , M ( t ) and so m1 = ( - NaH ny ) ( A5 ) a ( ( : } an d ) ! ( 1 + nz ) dt M , ( t ) Finally , considering that t n= [ | y- dt ’ Oo 2 72 ( ( ni® ) ” ) — ( ai ? ) dot KO ) ) gon sot ? ) dt dt dt we can write the expressions for the mean value and vari- ance of both components o3 ( t ) = [ a ( a * \\ ) ( A6 ) o2 ( t ) a t 1 dt ’ far These are Eqs . ( 16 ) and ( 17 ) . n2 ( t ) = ( t ) = ny 11 10 % z 10 '' e 3 10° 3 10 % 4 LOE 3 10° 10 ! 10 ” 10° t ( a ) T T T TTT T T TUTTI ] T T | 108 10 '' 5 a 10 % 10 '' z | E c a z F = E q eH 1L = T 7 i : Ae 3 & c E 7 oL L 4 107 ! [ y 10 * e1 bop pil a on | 10° 10 ! 10° 108 10° 10 ! 10° 108 t t ( b ) ( c ) Figure 7 : ( a ) Temporal evolution of 2max ( t ) , Ymax ( t ) and their difference for N = 10 ’ , M = 20 , \\ * , . ( b ) Collapse plot to check the scaling ( 20 ) with respect to N ; M = 20 and \\ & A . { c ) Collapse plot to check the scaling ( 20 ) with respect to M ; N= 10 '' and A & Ag . Appendix B : Scaling of tmax ( t ) As discussed in the main text , near the transition point the quantity tmax ( t ) = Nmax ( t ) — N/M satisfies Eq . ( 20 ) , that is Ni/2 3/2 2max ( t ) = WF le , This is shown in Fig . 7 , where we test both the evolution in time and the scaling with respect to M and N. The latter can be also explained by considering the dynamics during the first steps . Initially all ni ) are null and all opinions are equally common , so each agent , when updated , chooses an opinion with uniform probability . This regime lasts up to t < # , where f is defined as the time when the n ‘ * ) becomes statistically different from zero and so the PI stops to be completely random . This implies that for fixed i and up to tthe M variables ni ) are distributed according to a multi- nomial distribution with uniform probability 1/44 . The ) multinomial regime ends when the maximum max , [ ns ( k ) y exceeds the average ( n ; ° ’ ) ; by one , since when this occurs the external information stops to suggest random opinions . The mean value after ¢ extractions satisfies in ) , =t/M , while by drawing from a multinomial we numerically deter- mined that max ; [ ny | — ( nk * ) ) , , ww t/2M—-/4 , see Fig . 8 . 4 10° F —— M=10 —— M=80 s Cc —— M=20 — M=160 q F —— M=40 -- -- 24/2 4 ma 10 [ max ( rx ) — ( rax ) ] - M4 poy yout 10 10° 10° 104 number of extractions ¢ Figure 8 : Growth of the maximum of a multinomial distribution with M equally probable classes as a function of the number of extractions ¢ for different values of Mf . We denote by n , the number of counts in the kth classe . We plotted the quantity { max [ ng ] — ( nz ) } M14 to highlight the scaling with respect to Mf and we averaged over 25 different realizations of the process . We can then obtain the time # as PP M-M4—1 3 f=MY ? , ( Bl ) Now we consider the evolution of the number of agents Ny , in opinion k in the simple multistate voter model . The transition rates are WN : > Net l= 1N- Na Ne Ne a ONOUN ( B2 ) 1 N— ( Ng+1 ) Np4+1 Neel N ) —————_ W ( Ni # 1 Ne ) = $ y N where dt =1/N . The master equation for N ; is thus P ( N ; t+6t ) = P ( N : + 1 , t ) W ( N ; , +135 Ne ) + + [ 1—W ( N ; , > Ni , — 1 ) Expanding for 6¢ small we get dP ( Nz , t ) aL -6t =W ( N ; , +1 Ny ) P ( N ; + 1,0 ) +W ( N ; -1l > Ni ) P ( N « — 1 , é ) + — ( W ( N ; , +15 Nz ) +W ( N ; -1l > Nx ) |PCN « , t ) - ( B3 ) Starting from this master equation we can compute the average drift and the variance of N ; . The average drift satisfies “ ENE PiNet oP Net ) “ ay DAW ( Ns + Ne +1 ) — WN ; > Ne — 1 ) ) PCNg , t ) = “ eG 2 ( Nest ) = So ve ( Na ) Piet ) , ( BA ) Ne _— WN : > Ne+ 1 ) |P ( Ng , t ) . where we also introduced the drift ~ , ( N , ) = [ W ( N , > Np+1 ) —W ( N ; — Ni —1 ) ] /6t . Note that while the average drift v , determines how the mean value of the distribution P ( N ; , ) moves in time , the drift v ; , ( N ; , ) allows to compute ( neglecting diffusion ) how a specific value of N ; evolves . Using Eqs . ( B2 ) we get Nni ( 0 ) = 2. y , =0 > ( Nz ( t ) ) = Mw ( B5 ) Analogously the evolution of the variance is doz _ d ( Ng ) dt — dt a ( Nx ) _ d ( Nz ) — 9 ( N , ) Se ) = Tite Ved Gg dt ” where the last equality follows from Eq . ( B5 ) . Exploiting Eq . ( B3 ) we then obtain d ( N2 29 , 9 AD — yo yp PPE — ( iy — E002 ) , whose solution is N2 N * \\ _,4 N ? ( Ng ) ( ) = GR - ar ) oN + The variance is thus ( Ni ) `` ( t ) = ( + - a ) ( 1.2 ) , ( B6 ) As also shown in Fig . 1 , for small times and small values of > our model with personalized information behaves as the usual voter model . This is due to the fact that for t < # the external information is completely random and so , being all opinions equally numerous at the beginning , a voter model-like update or a personalized information update are equivalent . This implies that we can use Eqs . ( B5 ) and ( B6 ) to determine how Nmax and thus 2max evolve for small times even in the presence of personalized information Nynax ( £ ) = ( NA ) - ( Ng ( t ) ) + on ( t ) 2 tmax ( t ) & op ( t ) . By expanding Eq . ( B6 ) for small times we thus obtain gt Nv af Xa § t < t . — ( — —- —~ ] x —+t for N\\M M ? M 7° where again we assumed M > 1 . Finally , we know from empirical evidence that for large times it holds tmax ( t ) ~ t°/2 . this implies that the functional form of 2max { t ) must be iN max ( { t ) = Be ? 2 4h ? The prefactor a can now be determined imposing the # °/2 scaling to become dominant when the binomial scaling t ! /2 ends , so fort =t = VM . This gives af/ ? = [ Spr Tmax ( t ) xs and so Ni/2 a= : This shows that for sufficiently large t it holds N1/2 Tmax ( t ) ~ —— # ” ? , Appendix C : Evolution of N , — N/M The transition rate for N ; , in the presence of personalized information is W ( Ne > Ne +1 ) =~ ) NONE yy Poy on , N WN where the first term is the usual voter contribution , while the second one is due to PI . Denoting as S , = Ns , the number of agents whose PI is polarized along opinion k , we can write the latter as N Ne — Vien Sk 1 N M , ( t ) Let us explain this expression . Among all the N agents , those already with opinion k do not contribute to the tran- sition rate to opinion k , while those whose PI is polarized along 7 # k can make a transition toward k only by a voter update . As a consequence only N — Nz — ek Sk should be considered in computing the transition proba- bility . Moreover the PI of such agents will be unpolarized and so we can assume that it suggests a random opinion , giving the factor 1/M , ( ¢ ) . Analogously N— WN ; Ne WN , + > Nz -— 1 ) = a _ Hr + APpr ko Peron = with P _ Ne — Sk Ms { t ) —1 PLR = — “ MA Inserting these transition rates in Eq . ( B4 ) we can write the drift of Nz as Xr N—S—M , ( Nz — Sx ) , = ( Ni ~ Sx ) where we introduced the total number of polarized agents as S = 5° , Sx . The time evolution of N ; , neglecting diffu- sive fluctuations , is thus t= ( 4 ) ( 2 ) For N > > M and short times we can make the approxima- tion M , ~ M and so defining y ; , = S ; , — S/M we arrive at an expression for the time evolution of x , = N ; , — N/M vp ( Ng ) = a = Ayr — x ] + diffusive terms . ( C1 ) This expression provides additional support to our analyti- cal approach . Indeed , as shown in Fig . 7 , it holds ymaz ( t ) — 2mae ( t ) ~ t'/ ? and so Eq . ( C1 ) predicts amax ( t ) ~ 1/2 , as actually observed in Fig . 7 . Note that by ymaz we denote max , [ Ye ] . 13 Appendix D : Scaling regimes of the critical threshold 1 . M < « N For M < N during the first steps no opinion disappears and so we can make the approximation M , ( t ) = M. In- serting this into Eq . ( 22 ) yields Eq . ( 23 ) , that is 2 [ 4 fl-x fT—r , ~ 2 M ° M 1/2 ay Le ya ( t 3/2 Cc 1/2 . N +754 ) ? ( D1 ) From the expression for the polarization time ¢ * we see that there are two possible regimes . A ) 5x « A The first equation in Eq . ( D1 ) becomes r= 4 = > and replacing this expression into the second equa- tion we obtain yNU2f-1 ( + ) dQ = ee N21 3/2 , ° 1/2 , g-1 ( 4 3/2 ‘ N+ NVM ( 4 ) This gives de = 22/5 ( N M2 ) , so that AM = PEN MMA , Our initial assumption A , > 1 is then verified pro- vided that MPs NV 5 Ue NYE , Recalling that we are assuming M @ « < N we then have -1/5 Ae = 27/5 ( NM ? ) for NYS < M KN . Putting together the expressions for ¢ * and A » , we finally obtain Eq . ( 25 ) e * = 28/5 ( N M2 ) '' de = 22/8 ( M2 ) 1° B ) 4 > A In this case the polarization time becomes * 16 = — M22 and again , by putting this expression into the expres- sion for A. we obtain yN1V/2 M128 8/2 3 — eee te ot yp -8/2 1/2 ) -3 re N + yN1V2M-126 3/273 Mee Ns 14 This gives do = 2 ( MeN ) and so Md , & INNS A , Consequently the two hypotheses M « N and MX < 1 are both satisfied if M « < Ni ’ e and the expressions for ¢ * and A , are t * =~ 4 ( MN ) ‘ /4 de 2 ( MaN ) 1/8 For M = N one can no longer make the assumption M , { t ) = M , ( 0 ) = M , since some of the opinions disappear even during the first steps . In this case we can approxi- mated the decrease of M , ( t ) exploiting Eq . ( 5 ) , which is exact for a simple multistate voter model with M = N. The general expression is and putting it into Eq . ( 22 ) we get v= +y/ ( 164¥ — SAN — 1645 ) ” — 64N ( A2N + 16d — 16 ) — 84 % + SAN + 16 202N + 16\\ — 16 ) ’ which , for M/ = N , becomes +\\/ ( 16A —8\\N — 16 ) ” — 64N ( \\2N + 16 — 16 ) — 16 + 8AN + 16 In the limit of large N and small 4 this expression can be approximated as _ +£32N1/ ? + 8\\N n= 2 ( 2N — 16 ) ( m2 ) and , as it is possible to see , there are two distinct solutions . Requiring the denominator to vanish gives - < 4 2 _ =— Note that while the solution with the plus , t % . , diverges in this limit , the one with the minus , t * is finite and positive , indeed —32N1/2 4 8\\N \\aN-1/2 202N — 16 ) ANV2 — 4 =gnv2 4 ; a \\san-1/2 2 ( .\\NT/2 +4 ) ( ANT ? — 4 ) Ni/2 == > . Moreover , while for \\ < ¢ * is positive , the other one is negative , meaning that t1 is meaningful only in the region A > XA since a time must be a positive quantity . For the solution with the minus we can then take the limit A > 0 , which should give back the behavior of the multistate voter model —32N1/2 + 8\\N _ NYV2 . 02 — 16 ) lim t= = lim A+0 A+0 202N + 16\\ — 16 ) ’ This result suggest that the solution ¢ * is non physical , since if A = 0 it holds n , = nz ( see Eqs . ( 17 ) and ( 16 ) ) and so the two peaks should never split meaning that ¢ * = oo . In conclusion the expression for the splitting time is the one with the plus and it is not defined for any value of A , more precisely * _ 32N1/2 4 8AN — a with A > A= I02N—16 ) > 4 ye ( D3 ) In the limit A — 0 and N — co we have two possible scaling regimes ? ® A ) AN > NV ? 5 \\ > NV ? In this case we can approximate ¢ * as em — NL 5 re O2N— 16 ) X i and substituting this expression into Eq . ( 21 ) we get 4\\¥5 ~ —3/5 do » ( 5 ) ~N where we also exploited the fact that M = N. Note , however , that this result is in contrast with the initial assumption A > N~ ‘ / ? and so this scaling regime is impossible . B ) \\~ N72 In this case we can set \\7N = 16+ and Eq . ( D3 ) becomes 32N1/2 4 eS Moreover , using Eq . ( 21 ) , we obtain dex yN~3/2 ( ¢8 ) 3/ ? — 9138/2 yy—-3/4 , -3/2 15 and setting A , = 6 = QH/3 V6 . This is consistent with ¢€ being a small correction ( that is our initial assumption ) and moreover we see that it is the smaller the larger is N. In conclusion we have ti wy 24/3 N2/3 ~ 4 Xe ~ Ni/2 > that is Eq . ( 28 ) . ResearchGate See discussions , stats , and author profiles for this publication at : https : //www.researchgate.net/pu blication/325887180 Trapped in the Filter Bubble ? Exploring the Influence of Google Search on the Creative Process Article in Journal of Interactive Advertising - June 2018 DOL : 10.1080/15252019.2018.1487810 CITATIONS READS 6 206 1 author : Richie Barker Deakin University 10 PUBLICATIONS 27 CITATIONS SEE PROFILE All content following this page was uploaded by Richie Barker on 09 October 2020 . The user has requested enhancement of the downloaded file . mee . ~ = } Routledge | nte ra cti ve 8 Taylor & Francis Group Advertising Journal of Interactive Advertising ( tl pobcaton ofthe Amarcan Rade of Avert os . a Rese ISSN : ( Print ) 1525-2019 ( Online ) Journal homepage : http : //www.tandfonline.com/loi/ujia20 Trapped in the Filter Bubble ? Exploring the Influence of Google Search on the Creative Process Richie Barker To cite this article : Richie Barker ( 2018 ) : Trapped in the Filter Bubble ? Exploring the Influence of Google Search on the Creative Process , Journal of Interactive Advertising , DOI : 10.1080/15252019.2018.1487810 To link to this article : https : //doi.org/10.1080/15252019.2018.1487810 i Accepted author version posted online : 20 Jun 2018 . Published online : 25 Sep 2018. o ( sg Submit your article to this journal @ lil Article views : 52 ® View Crossmark data CrossMark Full Terms & Conditions of access and use can be found at http : //www.tandfonline.com/action/journallnformation ? journalCode=ujia20 JOURNAL OF INTERACTIVE ADVERTISING https : //doi.org/10.1080/15252019.2018.1487810 : Routledge Taylor & Francis Group ® Check for updates . Trapped in the Filter Bubble ? Exploring the Influence of Google Search on the Creative Process Richie Barker ® Deakin University , Burwood , Australia ABSTRACT This article explores the use of Google search by art directors and copywriters when devel- oping creative advertisements . It aims to reveal the influence of the widely applied search engine on creative process actions , including information gathering and ideation . In-depth interviews with practitioners are analyzed with reference to literature on advertising creativ- KEYWORDS Advertising creativity ; algorithmic gatekeeping ; creative process ; personalization ity and search engine personalization . This exploratory study argues that while serving as a convenient means of accessing digital media content , the personalization capabilities of Google search limit exposure to the qualitatively diverse information needed to trigger new ideas . As such , this article provides valuable insight into the complexities of producing advertisements in the digital media era and highlights avenues for further research into the information-gathering strategies of creative practitioners . A significant shift has emerged within the creative process of advertising professionals . Where once advertising art directors and copywriters relied on mass media forms of communication to build the repository of knowledge and inspiration required to develop advertisements that express attention-grabbing novelty , these specialist communicators now have access to an abundance of informational raw materi- als . This transformation through digital networks offers the benefit of immediate access to the cultural symbols and audience insights that support the pro- duction of creative advertising . A limited number of studies have considered the use of digital media in the creative process ( Wagler 2013 ; Barker 2018 ) . However , the way in which creative practitioners “ search ” the online realm while completing research and ideation tasks has yet to be explored . This article fills this research gap by presenting a valuable and original contribution to understanding how using a particular digital media technology influences the formation of creative advertisements . It does not seek to suggest that Google search is the only means with which external knowledge and inspiration is drawn into the creative process but instead argues that the search engine influences the everyday work practices of art directors and copywriters in a series of distinctive and largely obscured ways . As specialist communication professionals , advertis- ing art directors and copywriters—commonly referred to as “ creatives ” —use digital platforms to draw inspir- ation from existing media content , check facts , and collect insights into consumer behavior . A companion study ( Barker 2018 ) to the one discussed in this article reveals that practitioners access a range of online sources when building knowledge or seeking inspir- ation . These include blogs , forums , social media , news websites , and video-sharing sites . But how is informa- tion discovered or recalled when the source of a par- ticular form of information is not immediately known ? As is the case with the majority of Internet users , Google search emerges as a “ go to ” resource for information discovery and recovery tasks . The world ’ s most visited search engine has become a fixture of everyday life in most personal and professional con- texts due in part to the perception that it can “ read our minds ” ( Vaidhyanathan 2011 , p. 52 ) . However , concerns have been raised about the algorithmic filter- ing deployed by Google to preempt users ’ needs and personalize their search results . An established body of literature argues that the search engine can limit CONTACT Richie Barker @ richie.barker @ deakin.edu.au @ Deakin University , School of Communication and Creative Arts , Faculty of Arts and Education , 221 Burwood Highway , Burwood , VIC 3125 , Australia . Richie Barker ( PhD , Monash University ) is a lecturer in communication in the School of Communication and Creative Arts , Faculty of Arts and Education , Deakin University . © 2018 American Academy of Advertising 2 @ ) R BARKER knowledge building and creative thinking by delimit- ing access to unfamiliar or challenging digital media content ( Hillis , Petit , and Jarrett 2013 ; Bozdag 2013 ; Vaidhyanathan 2011 ; Pariser 2011 ) . The existence and implications of this “ filter bubble ” phenomenon , as Pariser ( 2011 ) has described it , have yet to be explored with regard to the creative process actions of advertising art directors and copywriters—professional communicators who are required to work across vari- ous cultural domains and develop surprising rather than conventional “ big advertisements . Using an inductive approach , this article explores perceptions of the role and influence of Google search in the creative process by drawing on in-depth inter- views with 18 Australian art directors and copywriters . A qualitative method has been employed in this exploratory study to interrogate the subjective and complex phenomenon of information gathering dur- ing the creative process . A review of literature on advertising creativity and algorithmic filtering is fol- lowed by an explanation of the research method . Findings based on participant perceptions of the search engine ’ s role , influence , and functioning are then presented . The study reveals largely ambivalent views of Google search ’ s impact on the creative pro- cess . While a series of benefits were noted , concerns about the restrictive nature of search engine use were commonly articulated . In addition , the majority of participants communicated limited awareness of the way in which Google filters its search results . The implications of using Google search in the creative process are explored in the article ’ s Discussion sec- tion , which argues for greater creative practitioner understanding of the algorithmic processes that shape a key information-gathering strategy . Limitations of the study and avenues for further research are also stated . The study provides insight into changes to cre- ative process actions at a time when the production of creative advertising that is capable of engaging increasingly elusive and sophisticated audiences has never been more important . ideas ” for creative Literature Review Information Gathering during the Creative Process Advertising creativity thrives on information . Those specifically responsible for developing creative con- cepts for advertisements—art directors and copy- writers—are expected to be aware of the contextual factors that surround a creative brief in addition to the existing media texts that form the starting point for a novel variation . Previous empirical studies have identified the sociocultural contours of advertising creativity , including the influence of information drawn from cultural domains , on the ideation tasks of art directors and copywriters ( Vanden Bergh and Stuhlfaut 2006 ; Stuhlfaut 2011 ; Barker 2018 ) . Collectively , these studies contribute to a view of advertising creativity that moves beyond the examin- ation of individual actions yet does not sufficiently attend to the influence of specific digital media tech- nologies used by creative professionals . While there are a number of ways of delineating advertising cre- ativity , stage-based models provide a_ practicable means of identifying actions within the creative pro- cess . The stage-based approach developed by mid- 20th-century advertising practitioner James Webb Young , which has much in common with Wallas ’ s classic model ( Lubart 2001 ) , identifies five creative process phases : e Immersion—A research stage that includes taking an interest in a broad spectrum of sources and the gathering of informational “ raw materials ” e Digestion—The act of looking for relationships between collected materials e Incubation—Turning the relaxed mind e Illumination—When _ the “ eureka ” moment happens e Verification—Making the idea fit its purpose and submitting it for criticism ( Young [ 1940 ] 2003 ; see Figure 1 ) . problem over to a idea arrives or the Bengtson ( 1982 ) has described Young ’ s model as having “ a profound effect on how advertising practi- tioners , educators , and students conceptualize idea generation and its attendant processes ” ( p. 4 ) , while Belch et al . ( 2014 ) describe the model as one of the most “ popular approaches to getting ideas ” ( p. 321 ) . While influential and broadly indicative of creative process actions , the approach has its limitations . Young envisaged his model as an assembly line means of developing creative outcomes , when in practice these phases often occur out of sequence or concur- rently ( Bengtson 1982 ) . For example , contemporary practitioners can complete research tasks—positioned Immersion B Digestion E > Incubation » Illumination » Figure 1 . Young 's ( 1940/2003 ) five-stage model of the cre- ative process . by Young ( [ 1940 ] 2003 ) in the immersion phase—at any time during the creative process due to the ubi- quity and convenience of accessing information via digital media platforms . Despite its limitations , a stage-based approach to identifying creative process actions provides an appro- priate framework for investigating the role of search engines in advertising production as it highlights the role of research—the act of drawing on knowledge from external sources during what Young ( [ 1940 ] 2003 ) would consider to be the immersion phase . In this article , the term research refers to informal infor- mation-gathering actions undertaken by creatives , as opposed to market research findings . These actions may be task specific—for example , the search for information that responds directly to a current project ( or “ brief , ” to use industry parlance ) —or part of an ongoing process of collecting and storing sources of knowledge or inspiration that can be applied to future creative tasks . In the past , broadcast and print media served as knowledge-building and inspiration-collect- ing resources ; in the contemporary era , networked digital media exhibit the capacity to introduce a tor- rent of information into the creative process . Search engine use also emerges as an influence on the cre- ative process stages of digestion and incubation . It is during these stages that new associations among exist- ing ideas are commonly formed , based on the crea- tive ’ s lived experience and exposure to external stimuli , until a suitably novel and appropriate creative solution is identified . Empirical research on practi- tioner perceptions of creative process efficacy is also relevant to this study . Importantly , existing literature has linked creative risk-taking behavior to the devel- opment of novel advertisements ( El-Murad and West 2004 ; Nyilasy , Canniford , and Kreshel 2013 ) . While networked digital media open up abundant opportuni- ties for building knowledge and triggering inspiration , the rule-based structuring of this information has the potential to limit exposure to media content that may be perceived by the search engine ’ s algorithmic proc- esses to conflict with its profile of the user ; in other words , to limit the user to a filter bubble that reinfor- ces conformity rather than disruption . Personalization and Algorithmic Gatekeeping In response to the growing amount of media content produced for and by the Web , algorithms—procedures or sets of rules that solve well-defined computational problems ( Cormen et al . 2009 ) —are used by digital platforms to filter information on behalf of users . JOURNAL OF INTERACTIVE ADVERTISING © 3 Prime among these is Google search , which has achieved widespread use through its application of algorithms that make judgments about the relevance of Internet pages . Google emerged as a widely deployed search engine in the early 21st century due to its PageRank algorithm ( Franceschet 2011 ) , which sought to place pages with the most high-ranking inbound links toward the top of search result listings . While this algorithm established a benchmark for the concept of relevance , filtering based on what is essen- tially a voting system produced search results that were largely generic in nature . Since 2007 , this condi- tion has been addressed with the introduction of per- sonalization algorithms , filtering processes designed to tailor information to the user ’ s search intention based on Google ’ s knowledge of previous online behaviors ( Pariser 2011 ) . For instance , a Google search for the term “ jaguar ” may deliver results on the Central and South American cat for a Google user who has been profiled as a travel enthusiast , while someone consid- ered to be a car lover may receive results that relate to the English automobile . A range of factors or “ signals ” are applied by personalization algorithms to achieve this form of preemption , including informa- tion about the device used to access the Web , the Internet Protocol ( IP ) address of the user , and search history ( Google n.d. ) . While Google has not publicly explained the spe- cific ways in which a user ’ s profile shapes his or her search results , it is clear that this form of filtering rep- resents a significant technological transformation for professional communicators . Both PageRank and per- sonalization algorithms order the abundant content provided by networked digital media platforms and , in doing so , function as algorithmic gatekeepers ( Bozdag 2013 ) . Importantly , this determination of access to online content presents distinctive forms of media bias . Key among these is a bias toward media content the user favors or is familiar with . When applied by technologies such as Google search , per- sonalization provides a convenient means for art directors and copywriters to access facts , ideas , and cultural representations that can be reworked into new advertisements . An obvious example is the tailor- ing of search results that reflect the user ’ s geographic location . However , Eli Pariser ( 2011 , p. 9 ) states that personalization algorithms place Web users in a filter bubble in which digital media technologies provide information that reinforces the status quo : Personalization is about building an environment that consists entirely of the adjacent unknown—the sports trivia or political punctuation marks that don ’ t really 4 @ ) ® BARKER shake our schemata but feel like new information . The personalized environment is very good at answering the questions we have but not at suggesting questions or problems that are out of our sight altogether . Under these conditions , opportunities for “ radical encounters ” with new information , as Vaidhyanathan ( 2011 , p. 182 ) puts it , are diminished , because users are limited to ideas with which they are already con- sciously or unconsciously familiar . In the context of advertising creativity , the question arises of whether the creative professional ’ s access to unfamiliar or unexpected media content is diminished and thus the imperative of being “ fully immersed in the widest pos- sible set of cultural currents ” ( Nixon 2003 , p. 80 ) — both when looking for sources of knowledge and inspiration on either a task-specific or ongoing basis—is reduced . Method A qualitative research method was selected to investi- gate the role and influence of Google search on adver- tising creativity through discourse analysis of practitioners ’ insider accounts . The creative process is , in part , a subjective phenomenon that lends itself to analysis based on detailed descriptions of perceptions and experiences . Semistructured one-on-one inter- views were selected as the research instrument , a style commonly used to collect individual experiences from study participants on a specific topic . In-depth inter- views allowed a rapport to build between the researcher and each participant , and for discussion to flow naturally . An interview schedule ( see Appendix 1 ) was used to guide open-ended questions about the role , influence , and functioning of Google search . The semistructured format enabled questions to be varied to suit different participants and their cir- cumstances while still covering the same conceptual ground , thus allowing comparisons to be made among participants ’ perceptions and experiences ( Hennink , Hutter , and Bailey 2011 ) . Interviews were conducted with a purposive sample of 18 advertising art directors and copywriters in the Australian cities of Sydney , Melbourne , and Brisbane ( see Appendix 2 ) . These cities were selected because they generate the majority ( 85 % ) of Australia ’ s adver- tising revenue ( Allday 2014 , p. 19 ) . Practitioners whose contact details were publicly available on adver- tising industry websites and social media sites were e- mailed an invitation to take part in the study . Participants were no longer recruited when sufficient data were gathered to represent the breadth and depth of the phenomenon being investigated and previously collected data could be confirmed and understood ( Trainor and Graue 2013 ) . Study participants ranged in age from 18 to 54 . Twelve art directors and six copywriters were interviewed . On average , participants had worked in advertising for 15.3 years , which indi- cates extensive industry experience , as well as likely exposure to changes in creative practice over time as a result of digital technologies . To ensure a consistent approach in the analysis of participant discourse , examination of interview tran- scripts followed a three-stage process of data reduc- tion , data display , and conclusion drawing and verification ( Miles and Huberman 1994 ) . As part of the data-reduction stage , information from the tran- scripts was categorized according to perceptions of Google use , perceptions of the influence of Google search on the creative process , and awareness of the search engine ’ s filtering processes . Summarized ver- sions of participants ’ perspectives and experiences were then organized within these categories . From this point , codes were developed from within the data using analytical induction ( Bertrand and Hughes 2005 ) . The data-display stage saw the development of a matrix that presented coded data within analytical categories in addition to a summary of the inferences drawn from this analysis . The conclusion and verifica- tion stage involved extrapolating meanings and impli- cations from the emergent findings . The findings were then confirmed by returning to the interview tran- scripts to review the coding analysis and cross-check the conclusions drawn . A_ social constructionist approach to discourse analysis in which “ emphasis is on the role of the narrative in making sense of experi- ence and constructing the self ” was adopted to inter- pret participant perceptions of their lived experience ( Wood and Kroger 2000 , p. 104 ) . The development of the study ’ s findings acknowledged the discursive status of the data as analytical objects ; that is , findings were constructed with an awareness that differences may exist between how respondents act in practice and how they talk about their actions ( Bertrand and Hughes 2005 ) . Findings Analysis of transcripts revealed three main findings regarding participant perceptions of Google search . The first reveals that Google search is used as a means of accessing digital media content during research tasks and , to a lesser extent , to consciously trigger ideation . A second and seemingly paradoxical finding reveals that Google search was commonly perceived to hinder aspects of the creative process . The third finding indicates that participants possessed largely incomplete understandings of the ways in which the search engine filters information on their behalf . A Window onto the World The widespread use of Google was established with all respondents saying they use the search engine at some point in the creative process . Responses to questions about which search engines were used included “ just Google , ” “ exclusively Google , ” and “ Google , like everyone else. ” One respondent placed considerable value on the efficacy of Google , as opposed to other search engines , saying , “ You almost don ’ t want to risk it with anything else. ” These statements suggest the term “ search engine ” is predominantly associated with Google , despite the availability of alternatives such as Bing , Yahoo ! , and DuckDuckGo . When discussing the benefits of search engine use , participants commonly said that Google enabled them to find research materials , including visual sources of inspiration , social media content , and information on a client ’ s product or service . For instance : You 'll get to find out about little fashion houses in Denmark who are doing amazing stuff , and you can take inspiration from that ... . [ Google has ] become a portal to the rest of the world , which is pretty amazing , whereas previously you would get Italian Vogue to have a look at that [ content ] . ( AD8 ) I ’ m always looking for new sources [ of inspiration ] ; generally , Google is the first port of call . ( AD2 ) Google search was also discussed as a means of finding images that were capable of triggering new associations : [ Google ] just becomes [ the creative process ] , because I have the thought and then I just go to Google and Google Image it . So I put the keywords in and Google Image it and up comes random stuff around those keywords . ( CW5 ) I ’ ve just been recently working on a beer label , so I just simply Google images , just googling “ cool beer labels , ” so that ’ s probably a recent example . Just getting yourself into that headspace . ( AD4 ) Other participants described Google search as use- ful when they lacked knowledge of a particular subject or were unable to develop new ideas on the basis of personal experience . The following observations exem- plify this perspective : JOURNAL OF INTERACTIVE ADVERTISING © 5 I might be thinking of an idea for [ a cola company ] , and ... we know the demographic really likes NASCAR racing . I don ’ t know a lot about NASCAR racing , so ’ 'd type “ NASCAR racing ” into Google and look at the images just in case there was , “ Oh wow , they use really interesting lights on the cars , don ’ t they , ” there is an idea in that with the [ product ’ s ] cans ... just seeing if there is something I can grasp onto . ( AD3 ) If I get stuck , I definitely do a simple Google word search . When I see pictures , sometimes they are still images , but I can still see them move , [ they ] come to life . ( CW6 ) Google search was also described as a means of sol- idifying an embryonic one copywriter : idea . In the words of I 'm doing this [ campaign ] for [ a global car manufacturer ] , which is an idea for their hydrogen cell car that they 've got , and the only emission is water . So I had this idea about making bottled water that ’ s come from the exhaust pipe of the car . I got online and researched if anyone had ever drunk it out of the fuel pipe , and you can ... . I can ’ t really imagine doing that idea without Google . ( CW4 ) The majority of participants discussed Google solely in terms of its ability to access unknown infor- mation : the act of discovery . However , there were exceptions , with a small number of participants dis- cussing Google ’ s ability to recall known information : I just Google anything to the point that—nowadays , I don ’ t even know if intelligence is now even having knowledge or knowing where to find it quickly , so it ’ s sometimes in between , because you often find yourself , when you don ’ t come up with the answer or something in a couple of seconds , I will go back to googling it rather than thinking it for about five to ten minutes . ( AD9 ) Google search was also identified as a means of checking the originality of a creative concept , an action that falls into the verification stage of Young ’ s ( [ 1940 ] 2003 ) model of creative process . This action , which was specifically identified by three participants as the “ Google check , ” was described as occurring when search terms that reflected the main idea of an in-development creative concept are typed into the search query box . This occurred prior to presentation to the client to determine if an idea had already been applied in an existing execution . The existence of this action highlights the value placed on originality when seeking to produce creative advertisements and reveals an unanticipated use of search engines in the cre- ative process . While it is unsurprising that Google search plays a prominent role in information gathering given its 6 @ ) R BARKER position as the most commonly visited website in Europe , North America , and Oceania ( Information Geographies 2014 ) , this finding evinces the nature of its various uses in a specialist area of creative practice . Importantly , this finding reveals the application of Google search in Young ’ s ( [ 1940 ] 2003 ) immersion stage when informational raw materials are gathered , as well as during digestion and incubation stages when new associations are formed . The use of Google to check the originality of a creative concept , while only mentioned on a few occasions , reveals another way search has been adopted into the creative process that is unique to the digital media era . Vanden Bergh and Stuhlfaut ( 2006 ) have discussed the transmission of information from cultural domains into the lived experience of creative practitioners during the creative process . For pre-digital era creative practitioners , this external knowledge and inspiration was drawn from legacy media , such as books on award-winning adver- tisements or even library-based reference material . For contemporary practitioners , this information is avail- able immediately online and accessible via search , an information-gathering platform with distinctive affor- dances and influences . A Hindrance to Creativity The majority of participants said search engine use was capable of hindering creativity , with a variety of justifications offered to support this perception . One of these was the belief that search engines were an inefficient way to use the time allocated for the cre- ative process . For instance , one participant stated : Often it doesn ’ t yield much . It ’ s amazing . You imagine Google to be this omnipotent thing , but it ’ s pretty blunt often . ( CW1 ) This senior copywriter went on to discuss his pref- erence for “ surfing ” the Internet by accessing web pages via links on websites he trusts as opposed to using the “ blank canvas of Google. ” This participant and a small number of other creatives who took part in the study discussed a preference for using and referring back to their own repository of research materials , such as note-taking programs or the more traditional notebook . What I have used in the past ... are big books which I just fill with imagery . Over my career I have ripped different things out and pasted them in . It ’ s random stuff , like spaghetti or giant tongues from a collection of books over time . And if I get stuck on an idea , I'll sit there and flick through and look at those images and it will get me out of a rut . ( AD1 ) In this instance , cultural symbols are inflected with the participant 's own decision-making processes rather than those presented immediately by Google . This description of practice reflects Burtenshaw , Mahon , and Barfoot ’ s ( 2011 ) observation that “ [ c ] reative teams have often been compared to magpies , continually collecting ideas , pictures , cuttings from magazines and anything else that they feel is worth storing away , providing cre- ative inspiration that can then be drawn upon at a later date ” ( p. 91 ) . Interestingly , these descriptions refer to analog modes of information gathering and storage that emerge as anomalies in the digital media era . The major- ity of creative practitioners may still be “ magpies ” ; how- ever , their access to sources of inspiration are more likely to revolve around digital media platforms and search engines that enable instantaneous discovery or recall . Other participants said search engine use narrowed their experience by connecting them to ideas that already exist rather than novel forms of inspiration . The following reflections illustrate this perspective : I wouldn ’ t take keywords from the brief and put them into Google ... . ’ 'm careful ; I don ’ t want to be derivative , because the Internet is full of stuff that already exists . ( AD6 ) [ When using Google search ] you 're out there looking for someone else ’ s idea or looking for an idea that you can co-opt , as opposed to analyzing what the actual solution should be within your own mind . To me , it ’ s not about approaching it logically ; it ’ s about a random process . ( AD1 ) Another participant described a specific detrimental effect of search engine use in the creative process : If [ m doing research [ using Google ] and someone from a competitor brand is doing the same thing , potentially we could get our ideas from the same source . ( CW6 ) These observations collectively reveal a desire to develop original ideas and the belief that search engine use may prioritize cultural representations that are widely known or likely to also be used by other creative teams when producing advertisements . The limitation of access to qualitatively diverse media content was observed as another detrimental effect of Google search use . As one interviewee noted : It sort of feels like it ’ s trying to keep me in a bubble of what it thinks I want , and that ’ s not very applicable in the creative industries . ( AD8 ) Another art director described the feeling of being taken on a predetermined pathway : [ Google ] can remove your own training from the process of coming up with an idea . You can actually end up going down an incorrect pathway purely based on the style or inappropriate style ; it might be something that you are attracted to , but it might not be appropriate . ( AD5 ) These statements echo the concerns raised by Pariser ( 2011 ) and Vaidhyanathan ( 2011 ) about the influence of search engines with personalization capa- bilities on knowledge building . They point to a tacit understanding that Google use imposes perimeters around tasks undertaken within an area of practice that has been described as prospering when “ rules ” are not followed ( Nyilasy and Reid 2009 ) . Other participants noted that while the use of search engines may have some detrimental effects , the engine ’ s benefits ultimately outweigh its limitations : search [ Google is ] just such a great source of inspiration ... . Rather than going to the library , you can just read [ online ] . I know [ the information Google provides ] is limited , but no , I don ’ t think [ it limits my creativity ] . ( CW4 ) In this instance , a detrimental effect is noted ; how- ever , this limitation is seen as an acceptable trade-off in return for convenient access to information . In summary , participants who expressed negative perceptions of the search engine said it limited their ability to focus on a creative project , exposed them to existing rather than new ideas , and narrowed their exposure to qualitatively diverse information . These limitations did not stop participants from using the search engine , as all stated that it was commonly used during the creative process . This ambivalence could be explained in a number of ways . It is possible that participants felt search was just one method of draw- ing information into the creative process and thus yielded limited influence . Alternatively , the belief that the benefits of Google search ultimately outweigh its limitations—which was articulated by a small number of participants—may be more broadly accepted . Another possibility is that the largely obscured ways that Google search filters information has the effect of limiting awareness of the extent of its influence . An Incomplete Understanding Analysis of participant perceptions ’ of how Google structures access to information provides a means of understanding whether they link their concerns about the search engine ’ s influence to its filtering mecha- nisms . Interestingly , participants descriptions of how Google filters its search results . Only two practitioners , both of whom specialized in varied in their JOURNAL OF INTERACTIVE ADVERTISING © 7 digital advertising , discussed both PageRank and per- sonalization algorithms , which are generally accepted as Google ’ s most influential filtering mechanisms ( Halavais 2009 ; Vaidhyanathan 2011 ; Hillis , Petit , and Jarrett 2013 ) . A group of participants alluded to the concept of personalization when discussing the search engine ’ s referral to previously collected data about the user in its formation of results . As one partici- pant stated : From what I am able to understand , it ’ s able to build a profile on a search user . ( AD2 ) Recognition that Google search had the capacity to apply information drawn from the parent company ’ s other platforms was the focus of another participant ’ s description : If you type in “ cars ” or whatever , and my girlfriend types in cars , it could come up with different results . I do know that they have that technology now ... . I 've got a Gmail account ; they might scan my subject lines or e-mails . ( CW6 ) This copywriter was the only participant to reveal an understanding that Google has the capacity to deploy information from its other online platforms to anticipate the user ’ s search queries ( Google 2012 ) . A small number of participants linked search engine functionality to specific creative process bar- riers . One art director stated that there was a danger in personalization as it “ narrows ” his “ field of vision ” when seeking to discover novel forms of information . Other participants said the “ popularity ” of Web con- tent or “ something to do with popularity ” determined search engine filtering . According to one copywriter : The more people that click on something , the more it affects the rank , and it goes up . So in a way , it is a popularity thing , isn ’ t it , that you are going to get something that many other people have gone to . ( CW2 ) While this form of popularity may have some impact on search engine rankings , it is of less influ- ence than PageRank algorithm parameters that focus on inbound links to the establish “ importance ” ( Diaz 2008 , p. 15 ) or “ authority ” ( Halavais 2009 , p. 18 ) of online content . Participants spoke broadly about the concept of “ relevance ” on a few occasions or stated that Google predominantly matches keywords con- tained in online content to search terms written in the query field—the predominant filtering mechanism for search engines prior to the development of PageRank ( Battelle 2005 ; Halavais 2009 ) . Others appeared to conflate Google ’ s organic searches with paid or spon- sored listings . 8 @ ) R BARKER Analysis of participant descriptions indicated that a limited understanding of the filtering mechanisms of digital media technology is commonly used to draw information and inspiration into the creative process . It is interesting to note that two participants linked their concerns about search engine use—specifically , its narrowing of their access to diverse sources of information—to Google ’ s algorithmic filtering proc- esses . However , it can be concluded that , for most , a link between their concerns about search engine use and Google ’ s filtering mechanisms was not read- ily apparent . Discussion Advertising practitioners have acknowledged that the online environment provides unprecedented access to an immense repository of information that can be used to inspire new ideas and resolve gaps in their knowledge ( Barker 2018 ) . This ease of access to infor- mational raw materials during the creative process offers clear benefits . Yet , at the same time , the filters needed to manage information abundance have resulted in new forms of media bias being introduced into the creative process . Rather than facilitating access to all parts of the Web , the search results pre- sented by Google are prioritized according to the company ’ s notion of relevance . Google ’ s PageRank algorithm determines relevance by placing web pages with the most inbound links at the top of its listing of search results . In effect , a quantitative measure of popularity is used to preempt relevance to the searcher . This is indeed useful to creatives when they are consciously attempting to understand what is con- sidered to be popular to an audience , in other words , to understand mainstream culture . However , Google ’ s bias toward the popular also serves to limit users ’ exposure to unconventional or nonmainstream sour- ces of inspiration . Google ’ s personalization algorithms arguably seek to counterbalance PageRank ’ s prioritization of the most popular search results , as it tailors search results according to data collected about the individual user ’ s interests , social relationships , and location . A com- monsense understanding of personalization would suggest there is a relationship between the amount of data collected by the search engine about the user and the level of personalization inherent in search results . However , while the search engine is in a position to build sizable user profiles , it is not possible for Google to establish a complete picture of a user ’ s intentions , preferences , and desires that would be necessary to develop truly individual predictions . Accordingly , per- sonalization algorithms are confined to making an approximation of the searcher ’ s intent ( Hillis , Petit , and Jarrett 2013 ) . This contention is supported by an empirical study of Google search personalization by Feuz , Fuller , and Stalder ( 2011 ) , which found user information is compiled into a profile that is then associated with particular groups : “ Rather than seeing what is of most interest to the user as an individual , we are presented with a preselected image of the world based on what kind of group the search engine associates us with ” ( para . 60 ) . It is this allocation of group characteristics to individual users that allows the search engine to fill any gaps in its knowledge of the individual searcher when making predictions . Hillis , Petit , and Jarrett ( 2013 , p. 64 ) describe this approximation of user intent as “ generic individu- alization , ” a push-pull between the collective and the personal that has the tendency to homogenize search outcomes among groups of individuals who present similar characteristics . Feuz , Fuller , and Stalder ( 2011 ) argue that an adherence to a set of prestated preferen- ces results in a self-fulfilling prophecy . Access to con- tent that has been tailored to a specific group means the user is unlikely to be exposed to information beyond the predetermined vision established for them . In the case of advertising creatives , this condition is capable of contributing to an “ echo chamber ” effect inherent in the industry ( Barker 2018 ) , with search users being directed back to advertising industry-re- lated content . The prioritization of access to advertising indus- try-related content is just one potential outcome of search engine use . Siva Vaidhyanathan ( 2011 ) argues that the delivery of results based on a profile erodes the serendipity—the chance encounters and helpful mistakes—that often evokes knowledge and creativity . Writing about “ algorithmic culture , ” Hallinan and Striphas ( 2014 , p. 119 ) have warned of a cultural con- formity that emerges when “ the use of computation processes to sort , classify , and hierarchize people , pla- ces , objects , and ideas [ shapes ] the habits of thought , conduct , and expression that arise in rela- tionship to those processes. ” This aspect of algorith- mic culture conflicts with descriptions of creative process best practice that suggest creative practitioners maintain an interest in “ everything under the sun ” ( Young [ 1940 ] 2003 , p. 40 ) and be “ aware of a wide variety of information in your environment ” ( Sawyer 2012 , p. 96 ) . There was some recognition among study participants of Google search ’ s limitation of access to diverse forms of information . In particular , this emerged in discussion of the “ pathway ” that Google search constructs for the user to follow , its logical rather than “ random ” structuring of informa- tion , and the platform ’ s propensity to place searchers in a “ bubble. ” However , an apparent lack of alterna- tives for online searching and convenient access to information negated these concerns for most . Previous empirical studies of advertising production highlight practitioners ’ desire to break rather than follow the rules ( Nyilasy and Reid 2009 ) . With its adherence to a largely obscured set of filtering rules , it can be argued that Google search introduces nascent forms of con- formity to research and ideation tasks , a condition with the capacity to intensify as personalization mech- anisms become more sophisticated . It can be argued the search engine introduces emergent complexities to creative process actions . Participant descriptions indicated the search engine is used for information-discovery and recovery purposes ; however , Google ’ s current preemp- tive capabilities do not distinguish between these two modes . Hillis , Petit , and Jarrett ( 2013 ) point out that the application of personalization algorithms to pre- empt the searcher ’ s intention lends itself to informa- tion recovery rather than information discovery because the search engine refers back to the user ’ s previous behaviors to make predictions . But do users know they are going “ back to the future ” under this model of search , even when they are attempting to discover rather than recover information- information ? Pariser ( 2011 , p. 91 ) argues that search engine personalization can result in exposure to the “ adjacent unknown , ” information that feels new but is not . Rather than broadening experience and knowledge , the adjacent unknown keeps searchers trapped within their own sphere of experience and precludes what could be described as the “ distant unknown. ” A small number of participants in this study revealed awareness of this limitation in their everyday work practices by suggest- ing that Google predominantly connected them to “ jdeas that already exist ” rather than unexpected or diverse forms of information . However , as is the case with the other limitations of Google use in the cre- ative process , these concerns are both seen and unseen due to a limited awareness of search engine function- ality . For the majority of participants in this study , Google search functions largely as a black box that has been habitualized into practice with limited con- sideration of its inner workings . This is not a surpris- ing outcome . As Kover ( 2016 ) points out , many aspects of advertising creativity , including the contexts in which it is produced , remain unquestioned . A less JOURNAL OF INTERACTIVE ADVERTISING © 9 expected outcome of this study was the extent of con- cerns raised about the search engine despite its com- mon use in research and ideation tasks . When asked to describe the search engine ’ s filtering mechanisms it became clear that most participants had not made an explicit link between effect ( frustration that search provides access to predictable or known information ) and its cause ( algorithmic processes that prioritize the familiar and mainstream ) . As such , it can be argued that greater awareness of what sits inside the black box of Google—even at a conceptual level—is needed to allow creative practitioners to reflexively undertake research , ideation , and evaluation tasks . It is in the best interests of both advertising agencies and educa- tors to broach the subject of digital literacy , as opposed to assuming that the ability to use a digital media platform equates to an awareness of its biases . This article has argued that Google search both assists and limits creative process actions , a finding evinced by participants ’ often ambiguous perceptions of the role and influence of the search engine on the creative process . The extent to which the benefits of “ search ” as means of drawing information into cre- ative process outweigh its negatives is an area for future study . Importantly , the algorithmic gatekeeping applied by Google search represents a tendency toward a simultaneous expansion and contraction of access to digital media content that is largely obscured to the user and thus has an influence on the creative process in ways that legacy media did not . The limita- tions of this study include the lack of transparency surrounding the functioning of Google search and the evolving algorithmic processes that scholars have identified as contributing to the filter bubble phenom- enon . This area of inquiry would benefit by being broadened to involve practitioners other than Australian-based participants . Future studies that employ quantitative and qualitative research approaches would serve to expand the scope of this initial investigation . It is worth noting that algorithmic gatekeeping and personalization techniques are also deployed in other digital media technologies , includ- ing video-sharing and social media platforms . Exploration of how these technologies are used to feed information into the creative process would pro- vide further understanding of how big ideas come to life in the digital media era . Indeed , Google search is just one means of drawing facts , ideas , and inspiration into the lived experience of art directors and copy- writers . Yet , as an information-gathering strategy that has quietly been normalized in practice , the nature 10 @ ) R. BARKER and extent of its transformative role in the production of creative advertising should not go unquestioned . Acknowledgments The author would like to thank the anonymous reviewers for their insightful feedback during the review process . ORCID Richie Barker @ http : //orcid.org/0000-0001-5908-8973 References Allday , A . ( 2014 ) , IBIS World Industry Report M6941 : Advertising Agencies in Australia , Melbourne : IBISWorld . Barker , R. ( 2018 ) , “ Creatives Talk Technology : Exploring the Role and Influence of Digital Media in the Creative Process of Advertising Art Directors and Copywriters , ” Media Practice and Education , doi:10.1080/ 25741136.2018.1464741 Battelle , J . ( 2005 ) , The Search : How Google and Its Rivals Rewrote the Rules of Business and Transformed Our Culture , Boston , MA : Nicholas Brealey . Belch , G.E. , M.A . Belch , G. Kerr , and I. Powell ( 2014 ) , Advertising : An Integrated Marketing Communication Perspective , 3rd ed. , Sydney , Australia : McGraw-Hill Education . Bengtson , T. ( 1982 ) , “ Creativity ’ s Paradoxical Character : A Postscript to James Webb Young ’ s Technique for Producing Ideas , ” Journal of Advertising , 11 ( 1 ) , 3-9 . Bertrand , IL , and P. Hughes ( 2005 ) , Media Research Methods : Audiences , Institutions , Texts , New York : Palgrave Macmillan . Bozdag , E. ( 2013 ) , “ Bias in Algorithmic Filtering and Personalization , ” Ethics in Information Technology , 15 ( 3 ) , 209-27 . Burtenshaw , K. , N. Mahon , and C. Barfoot ( 2011 ) , The Fundamentals of Creative Advertising , Lausanne , Switzerland : AVA . Cormen , T.C. , C.E . Leiserson , R. Rivest , and C. Stein ( 2009 ) , Introduction of Algorithms , 3rd ed. , Cambridge , MA : MIT Press . Diaz , A . ( 2008 ) , “ Through the Google Goggles : Sociopolitical Bias in Search Engine Design , ” in Web Search : Multidisciplinary Perspectives , A. Spink and M. Zimmer , eds. , Berlin : Springer , 11-34 . El-Murad , J. , and D.C. West ( 2004 ) , “ The Definition and Measurement of Creativity : What Do We Know , ” Journal of Advertising Research , 44 ( 2 ) , 188-201 . Feuz , M. , M. Fuller , and F. Stalder ( 2011 ) , “ Personal Web Searching in the Age of Semantic Capitalism : Diagnosing the Mechanisms of Personalization , ” First Monday , 16 ( 2 ) , http : //firstmonday.org/article/view/3344/2766 . Franceschet , M. ( 2011 ) , “ PageRank : Standing on the Shoulders of Giants , ” Communications of the ACM , 54 ( 6 ) , 92-101 . Google ( n.d. ) , “ How Search Works : Algorithms , ” Inside Google Search , http : //www.google.com/search/about/insi- desearch/howsearchworks/algorithms.html . ——— ( 2012 ) , “ Updating Our Privacy Policies and Terms of Service , ” Google Official Blog , January 24 , http : //www . googleblog.blogspot.com.au/2012/01/updating-our-priv- acy-policies-and-terms.html . Halavais , A . ( 2009 ) , Search Engine Society , Cambridge , United Kingdom : Polity Press . Hallinan , B. , and R. Striphas ( 2014 ) , “ Recommended for You : The Netflix Prize and the Production of Algorithmic Culture , ” New Media and Society , 18 ( 1 ) , 117-37 . Hennink , M. , I. Hutter , and A. Bailey ( 2011 ) , Qualitative Research Methods , London : Sage . Hillis , K. , M. Petit , and K. Jarrett ( 2013 ) , Google and the Culture of Search , New York , NY : Routledge . Information Geographies ( 2014 ) , “ Age of Internet Empires , ” http : //geography.oii.ox.ac.uk/ ? page=age-of-internet-empires . Kover , AJ . ( 2016 ) , “ Advertising Creativity : Some Open Questions , ” Journal of Advertising Research , 56 ( 3 ) , 235-37 . Lubart , T. ( 2001 ) , “ Models of Creative Process : Past , Present , and Future , ” Creativity Research Journal , 13 ( A ) , 295-308 . Miles , M.B. , and M.A . Huberman ( 1994 ) , Qualitative Data Analysis : An Expanded Sourcebook , Thousand Oaks , CA : Sage . Nixon , S. ( 2003 ) , Advertising Cultures : Gender , Commerce , Creativity , London : Sage . Nyilasy , G. , and L.N . Reid ( 2009 ) , “ Agency Practitioners ’ Meta-Theories of Advertising , ” International Journal of Advertising , 28 ( 4 ) , 639-68 . ——— , R. Canniford , and PJ . Kreshel ( 2013 ) , “ Ad Agency Professionals ’ Mental Models of Advertising Creativity , ” European Journal of Marketing , 47 ( 10 ) , 1691-1710 . Pariser , E. ( 2011 ) , The Filter Bubble : What the Internet Is Hiding from You , New York , NY : Penguin Press . Sawyer , R. ( 2012 ) , Explaining Creativity : The Science of Human Innovation , 2nd ed. , New York , NY : Oxford University Press . Stuhlfaut , M.W . ( 2011 ) , “ The Creative Code : An Organizational Influence on the Creative Process in Advertising , ” International Journal of Advertising , 30 ( 2 ) , 283-304 . Trainor AA , and E. Graue ( 2013 ) , Reviewing Qualitative Research in the Social Sciences , New York , NY : Routledge . Vaidhyanathan , S. ( 2011 ) , The Googlization of Everything ( And Why We Should Worry ) , Berkeley : University of California Press . Vanden Bergh , B. , and M. Stuhlfaut ( 2006 ) , “ Is Advertising Creativity Primarily an Individual or Social Process ? , ” Mass Communication and Society , 9 ( 4 ) , 373-97 . Wagler , A . ( 2013 ) , “ Embracing Change : Exploring How Creative Professionals Use Interactive Media in Advertising Campaigns , ” Journal of Interactive Advertising , 13 ( 2 ) , 118-27 . Wood , L.A. and R.O . Kroger ( 2000 ) , Doing Discourse Analysis : Methods for Studying Action in Talk and Text , Thousand Oaks , CA : Sage . Young , J.W . ( [ 1940 ] 2003 ) , A Technique for Producing Ideas , New York , NY : McGraw-Hill Professional . Appendix 1 . Semistructured Interview Schedule 1 . Which search engines , if any , are used in your cre- ative process ? Describe how search engines are used in your cre- ative process . At what points in the creative process are search engines used ? Do search engines benefit your creative process ? If so , how ? Do search engines limit your creative process in any way ? If so , how ? How does the search engine you use the most filter its search results ? JOURNAL OF INTERACTIVE ADVERTISING © 11 Appendix 2 . Overview of Participants Agency —_ Experience Alias Age Gender size ( Staff no . ) ( Years ) Position ( s ) Location ( s ) AD1 35-44 M 50-99 13 Digital MEL art director AD2 35-44 M 1-19 17 Digital MEL art director AD3 18-24 F N/A 4 Midweight MEL art director AD4 35-44 M 1-19 17 Senior BNE art director AD5 35-44 M 1-19 15 Creative and MEL art director AD6 35-44 M 50-99 13 Senior SYD art director AD7 45-54 F 100+ 26 Senior MEL art director AD8 35-44 M 1-19 27 Senior MEL art director AD9 35-44 M 50-99 9 Senior SYD art director AD10 35-44 F N/A 15 Senior MEL/SYD art director AD11 35-44 M 50-99 15 Digital BNE art director AD12 35-44 M 50-99 21 Senior BNE art director CW1 25-34 M N/A 9 Senior copywriter MEL/SYD CW2 25-34 M 50-99 5 Midweight SYD copywriter CW3 45-54 M 1-19 30 Creative BNE and copywriter CW4 35-44 ~F 20-49 12 Senior copywriter = MEL CW5 35-44 M N/A 24 Creative BNE and copywriter CW6 25-34 M 50-99 4 Midweight SYD copywriter Note . BNE : Brisbane ; MEL : Melbourne ; SYD : Sydney . 1907.01591v1 [ cs.IR ] 2 Jul 2019 arXiv Combating the Filter Bubble : Designing for Serendipity in a University Course Recommendation System Zachary A. Pardos University of California , Berkeley pardos @ berkeley.edu ABSTRACT Collaborative filtering based algorithms , including Recurrent Neu- ral Networks ( RNN ) , tend towards predicting a perpetuation of past observed behavior . In a recommendation context , this can lead to an overly narrow set of suggestions lacking in serendipity and inadvertently placing the user in what is known as a “ filter bubble ” In this paper , we grapple with the issue of the filter bubble in the context of a course recommendation system in production at a public university . Most universities in the United States encourage students to explore developing interests while simultaneously ad- vising them to adhere to course taking norms which progress them towards graduation . These competing objectives , and the stakes involved for students , make this context a particularly meaningful one for investigating real-world recommendation strategies . We introduce a novel modification to the skip-gram model applied to nine years of historic course enrollment sequences to learn course vector representations used to diversify recommendations based on similarity to a student ’ s specified favorite course . This model , which we call multifactor2vec , is intended to improve the seman- tics of the primary token embedding by also learning embeddings of potentially conflated factors of the token ( e.g. , instructor ) . Our offline testing found this model improved accuracy and recall on our course similarity and analogy validation sets over a standard skip-gram . Incorporating course catalog description text resulted in further improvements . We compare the performance of these models to the system ’ s existing RNN-based recommendations with a user study of undergraduates ( N = 70 ) rating six characteristics of their course recommendations . Results of the user study show a dramatic lack of novelty in RNN recommendations , a consequence of the filter bubble , and depict the characteristic trade-offs that make serendipity difficult to achieve . 1 INTRODUCTION Among the institutional values of a liberal arts university is to expose students to a variety of perspectives expressed in courses across its various physical and intellectual schools of thought . Col- laborative filtering based sequence prediction methods , in this envi- ronment , can provide personalized course recommendations based on temporal models of normative behavior [ 22 ] but are not well suited for surfacing courses a student may find interesting but Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . Copyrights for components of this work owned by others than ACM must be honored . Abstracting with credit is permitted . To copy otherwise , or republish , to post on servers or to redistribute to lists , requires prior specific permission and/or a fee . Request permissions from permissions @ acm.org . © 2019 Association for Computing Machinery . ACM ISBN 978-x-xxxx-xxxx-x/YY/MM . .. $ 15.00 Weijie Jiang University of California , Berkeley & Tsinghua University jiangwj @ berkeley.edu which have been relatively unexplored by those with similar course selections to them in the past . Therefore , a more diversity oriented model can serve as an appropriate compliment to recommendations made from collaborative based methods . This problem of training on the past without necessarily repeating it is an open problem in many collaborative filtering based recommendation contexts , particularly social networks , where , in the degenerate cases , users can get caught in “ filter bubbles , '' or model-based user stereotypes , leading to a narrowing of item recommendation variety [ 13 , 19 , 30 ] . We introduce a novel skip-gram model variant into a production recommender system at a public university designed to surface serendipitous course suggestions . We use the definition of serendip- ity as user perceived unexpectedness of result combined with suc- cessfulness [ 26 ] , which we define as a course recommendation the student expresses interest in enrolling in . At many universities , con- ceptually similar courses exist across departments but use widely differing disciplinary vernacular in their catalog descriptions , mak- ing them difficult for learners to search for and to realize their commonality . We propose that by tuning a vector representation of courses learned from nine years of enrollment sequences , we can capture enough implicit semantics of the courses to more abstractly , and accurately construe similarity . To encourage the embedding to learn features that may generalize across departments , our skip- gram variants simultaneously learns department ( and instructor ) embeddings . While more advanced attention-based text generation architectures exist [ 28 ] , we demonstrate that properties of the linear vector space produced by `` shallow '' networks are of utility to this recommendation task . Our recommendations are made with only a single explicit course preference given by the user , as opposed to the entire course selection history needed by session-based Recurrent Neural Network approaches [ 11 ] . Single example , also known as “ one-shot , generalization is borrowed from the vision community , which has pioneered approaches to extrapolating a category from a single labeled example [ 9 , 29 ] . Other related work applying skip-grams to non-linguistic data include node embeddings learned from sequences of random walks of graphs [ 25 ] and product embeddings learned from ecommerce clickstream [ 5 ] . Our work , methodologically , adds rigor to this ap- proach by tuning the model against validation sets created from institutional knowledge and curated by the university . We conduct a user study ( N = 70 ) of undergraduates at the university to evalu- ate their personalized course recommendations made by models designed for serendipity and by the RNN-based recommendations , which previously existed in the system . The findings underscore the tension between unexpectedness and successfulness and show the superiority of the skip-gram based method , as well as a bag- of-words baseline , for producing serendipitous results . From the open-response feedback received from students , we determined that the RNN-based recommendations still had a role to play , not in course exploration , but as a normative sorting of the order in which similar students had satisfied course requirements . 2 RELATED WORK In Natural Language Processing , a classical representation of words is as a vector of the contexts they appear in , equivalent to a word2vec model Mikolov et al . [ 18 ] without its hidden layer . Such vector representations are called explicit , as each dimension directly cor- responds to a particular context [ 15 ] . These explicit vector-space representations have been extensively studied in the NLP literature [ 3 , 27 ] , and are known to exhibit a large amount of attributional similarity [ 14 , 16 , 24 ] . Although Baroni et al . [ 2 ] show that the neu- ral embeddings obtain a substantial improvement against explicit representations on a wide range of lexical semantics tasks , Levy and Goldberg [ 15 ] argue that under certain conditions traditional word similarities induced by explicit representations can perform just as well on lexical relationship validation sets . Their debates encourage us to utilize course descriptions to generate explicit bag-of-words representations for courses and compare them to our neural embedding models . Nguyen et al . [ 19 ] measured the `` filter bubble '' effect in terms of content diversity at the individual level and found that collaborative filtering-based recommender systems expose users to a slightly nar- rowing set of items over time . McNee et al . [ 17 ] also proposed that the recommender community should move beyond conventional accuracy metrics and their associated experimental methodologies . To counter the `` filter bubble '' , Zhang et al . [ 30 ] used a collection of novel LDA-based algorithms inspired by principles of “ serendip- itous discovery '' and injected serendipity , novelty , and diversity to music recommendations whilst limiting the impact on accu- racy . Different serendipitous metrics that measure the uncertainty and relevance of user ’ s attitude towards items in order to mitigate the over-specialization problem with surprising suggestions are combined with traditional collaborative filtering recommendation [ 20 ] and content-based recommendation [ 1 ] . Kawamae et al . [ 12 ] presented the Personal Innovator Degree ( PID ) which focused on the dynamics and precedence of user preference to recommend items that match the latest preference of the target user to achieve serendipity . Recommender systems in higher education contexts have re- cently focused on prediction of which courses a student will take or the grade they will receive if enrolled . At Stanford , a system called `` CARTA '' allows students to see grade distributions , course evaluations , and the most common courses taken before a course of interest [ 4 ] . At UC Berkeley , our AskOski ! recommender , named after the school ’ s mascot , serves students next-semester course considerations based on their personal course enrollment history [ 22 ] . Earlier systems included a focus on requirement satisfaction [ 21 ] and career-based relevancy recommendation [ 8 ] . No system has yet focused on serendipitous or novel course discovery . 3 MODELS AND METHODOLOGY This section introduces three competing models used to gener- ate our representations . The first model uses the skip-gram model , ‘ https : //askoskiberkeley.edu Pardos and Jiang which we refer to as course2vec in this context , to learn course repre- sentations from enrollment sequences . Our second model is a novel variant on the skip-gram , introduced in this paper , which learns representations of explicitly defined features of a course ( such as the instructor or department ) in addition to the course representation . The intuition behind this approach is that the course representation could have , conflated in it , the influence of the multiple-instructors that have taught the course over the years . In order to separate out the department material of the course from the instructor , we allow for an instructor representation to be learned at the same time , but separate from the course representation . We contend that this may increase the fidelity of the course representation and serve as a more accurate representation of the essence of the course . The last representation model is a standard bag-of-words , constructed from course descriptions . In the last subsection , we describe the algorithm used to surface serendipitous recommendations using these course representations . 3.1 Course2vec The course2vec model involves learning distributed representations of courses from students ’ enrollment records throughout semesters by using a notion of a enrollment sequence as a `` sentence '' and courses within the sequence as “ words '' , borrowing terminology from the linguistic domain . For each student s , his/her chronological course enrollment sequence is produced by first sorting by semester then randomly serializing within-semester course order . Then , each course enrollment sequence is trained on like a sentence in the Skip- gram model . The formulation of the course2vec model is presented in our supplement ( section 10.1 ) . In language models , two word vectors will be cosine similar if they share similar sentence contexts . Likewise , in the university domain , courses that share similar co-enrollments , and similar pre- vious and next semester enrollments , will likely be close to one another in the vector space . Course2vec learns course representa- tions using a skip-gram model [ 18 ] by maximizing the objective function over all the students ’ course enrollment sequences . 3.2 Multi-factor Course2vec The training objective of the skip-gram model is to find word repre- sentations that are useful for predicting the surrounding words in a sentence or a document . Each word in the corpus is used as an input to a log-linear classifier with continuous projection layer , to predict words within a certain range before and after the current word . Therefore , the skip-gram model can be also deemed as a classifier with input as a target course and output as a context course . In this section , we consider adding more features of courses to the input to enhance the classifier and its representations , as shown in Figure 1 . Each course is taught by one or several instructors over the years and is associated with an academic department . The multi-factor course2vec model learns both course and feature representations by maximizing the objective function over all the students ’ enrollment sequences and the features of courses , defined as follows . yy SES CES —w < j < w , jt0 logp ( cisjlei , fir » fia » fin ) ( 1 ) Designing for Serendipity in a University Course Recommendation System Input ( multi hot ) Projection i-th course c ( / ) feature 1 feature 2 feature h Figure 1 : multi-factor course2vec model Probability p ( ci+ ; |ci , fit , fiz . -- . fin ) of observing a neighboring course cj4 ; given the current course c ; and its features fi1 , fiz ... fih can also be defined via the softmax function , T exp ( a ; v ; + ; ) n Ty ? Dar & XP ( G ; @ , ) plcisjlei ) = ( 2 ) h aj = vj + SS ) Wajxe fis ( 3 ) j=l where a¢ is the vector sum of input course vector representation v- and all the features vector representations of that course , fj ; is the multi-hot input of the j-th feature of course i , and Wrjxo is the weight matrix for feature j . So by multiplying Wn , xv and fij , it gets the sum of feature vector representations of the i-th course . Here we keep the vector dimensions the same for both courses and features so that they are learned and mapped to the same vector space . 3.3 Bag-of-Words A simple but indelible approach to item representation has been to create a vector , the length of the number of unique words across all items , with a non-zero value if the word in the vocabulary appears in it . Only unigram words are used to create this unordered vector list of words used to represent the document [ 6 ] . The basic methodology based on bag-of words proposed by IR researchers for text corpora - a methodology successfully deployed in modern Internet search engines - reduces each document in the corpus to a vector of real numbers , each of which represents a term weight . The term weight might be : e aterm frequency value indicating how many times the term occurred in the document . e abinary value with 1 indicating that the term occurred in the document , and 0 indicating that it did not . e tf-idf scheme [ 7 ] , the product of term frequency and inverse document frequency , which increases proportionally to the number of times a word appears in the document and is offset by the frequency of the word in the corpus and helps to adjust for the fact that some words appear more frequently in general . We evaluate all three variants in our quantitative validation testing . 3.4 Surfacing Serendipitous Recommendations from Course Representations We surface recommendations intended to be interesting but unex- pected by finding an objective course cj which is most similar to a student ’ s favorite course c ; but diversifying the results by allowing only one result per department d ; : cj = arg max cos ( c , cj ) ( 4 ) c , d ( c ) =d ; where d ( c ) means the the department of course c. Then all the counterpart courses Gj in all the other departments will be ranked according to costc ; , ci ) , where j = 1 , 2 ... , k. We can apply both neu- ral representations and bag-of-words representations of courses in this method to generate the most similar courses in each depart- ment . 4 EXPERIMENTAL ENVIRONMENTS 4.1 Off-line Dataset We used a dataset containing anonymous student course enroll- ments at UC Berkeley from Fall 2008 through Fall 2017 . The dataset consists of per-semester course enrollment records for 164,196 stu- dents ( both undergraduates and graduates ) with a total of 4.8 million enrollments . A course enrollment record means that the student was still enrolled in the course at the end of the semester . Students at this university are allowed to drop courses up until close to the end of the semester without penalty . The median course load dur- ing students ’ active semesters was four . There were 9,478 unique lecture courses from 214 departments ” hosted in 17 different Di- visions of 6 different Colleges . Course meta-information contains course number , department name , total enrollment and max capac- ity . In this paper , we only consider lecture courses with at least 20 enrollments total over the 9-year period , leaving 7,487 courses . Although courses can be categorized as undergraduate courses and graduate courses , all the students are allowed to enroll in many of the graduate courses no matter their status . Enrollment data were sourced from the campus enterprise data warehouse with course descriptions sourced from the official campus course catalog API . We pre-processed the course description data in the following steps : ( 1 ) removing generic , often-seen , sentences across descriptions ( 2 ) removing stop words ( 3 ) removing punctuation ( 4 ) word lemma- tization and stemming , and finally tokenizing the bag-of-words in each course description . We then compile the term frequency vector , binary value vector , and tf-idf vector for each course . 4.1.1 Semantic Validation Sets . In order to quantitatively evaluate how accurate the vector models are , a source of ground truth on the relationships between courses needed to brought to bear to see the degree to which the vector representations encoded this information . We used two such sources of ground truth to serve as ? At UC Berkeley , the smallest academic unit is called a `` subject . '' For the purpose of communicability , we instead refer to subjects as departments in this paper . validation sets , one providing information on similarity , the other on a variety of semantic relationships . Pardos and Jiang To evaluate course vectors on the course equivalency validation set , we fixed the first course in each pair and rank all the other e Equivalency validation set : A set of 1,351 course credit-equivalency Courses according to their cosine similarity to the first course in pairs maintained by the Office of the Registrar were used for similarity based ground truth . A course is paired with an- other course in this set if a student can only receive credit for taking one of the courses . For example , an honors and non- honors version of a course will be appear as a pair because faculty have deemed that there is too much overlapping ma- terial between the two for a student to receive credit for both . Analogy validation set : The standard method for validating learned word vector has been to use analogy to test the de- gree to which the embedding structure contains semantic and syntactic relationships constructed from prior knowl- edge . In the domain of university courses , we use course relationship pairs constructed from prior work using first- hand knowledge of the courses [ 23 ] . The 77 relationship pairs were in five categories ; online , honors , mathematical rigor , 2-department topics , and 3-department topics . An ex- ample of an “ online ” course pair would be Engineering 7 and its online counterpart , Engineering W7 or Education 161 and W161 . An analogy involving these two paris could be calculated as ; Engineering 7W - Engineering 7 + Education 161 = Education W161 . 4.2 Online Environment ( System Overview ) The production recommender system at UC Berkeley uses a stu- dent data pipeline with the enterprise data warehouse to keep up-to-date enrollment histories of students . Upon CAS login , these histories are associated with the student and passed through an RNN model , which cross-references the output recommendations with the courses offered in the target semester . Class availability information is retrieved during the previous semester from a cam- pus API once the registrar has released the schedule . The system is written with an AngulasJS front-end and python back-end service which loads the machine learned models written in pyTorch . These models are version controlled on github and refreshed three times per semester after student enrollment status refreshes from the pipeline . The system receives traffic of around 20 % of the under- graduate student body from the UC Berkeley Registrar ’ s website . 5 VECTOR MODEL REFINEMENT EXPERIMENTS In this section , we first introduce our experiment parameters and the ways we validated the representations quantitatively . Then , we describe various ways we refined the models and the results of these refinement . 5.1 . Model Evaluations We trained the models described in Section 3 on the students en- rollment records data set . Specifically , we added the instructor ( s ) who teach the course and the course department as two features of courses in the multi-factor course2vec model . To ensure repro- ducibility , we put our model experiment settings to our supplement ( section 10.2 ) . descending order . We then noted the rank of the expected second course in the pair and describe the performance of each model on all validation pairs in terms of of mean rank , median rank and recall @ 10 . For evaluation of the course analogy validation set , we followed the paradigm of analogy : course2 — coursel + course3 ~ coursed . Courses were ranked by their cosine similarity to cour se2—course1+ course3 . An analogy completion is considered accurate ( a hit ) if the first ranked course is the expected course4 ( excluding the other three from the list ) . We calculated the average accuracy ( recall @ 1 ) and the recall @ 10 over all the analogies in the analogy validation set . 5.2 Course2vec vs. Multi-factor Course2vec In this section , we first compared the pure course2vec model with the course representations from the multi-factor course2vec model using instructor , department , and both as factors . To further explore improvements to performance , we concatenated the primary course representational layer ( Wp , in Figure 1 ) with the output represen- tation layer ( W/ , . , , in Figure 1 ) , as demonstrated to be effective in the language domain [ 10 ] . Results of evaluation on the equivalency validation are shown in Table 1 with analogy validation results shown in Table 2 . Models using the output representation concatenation are labeled with '' ( tout ) '' next to their names in both tables . The multi-factor model outperformed the pure course2vec model in terms of recall @ 10 in both validation sets , with the combined instructor and department factor model performing the best . The same result held for the metrics of mean and median rank in equivalency , but multi-factor models were not always the best in terms of analogy recall @ 1 ( Accuracy ) . Output layer concatenation did not improve any of the models on the equivalency validation but , interesting , improved all but the instructor model ( recall @ 10 ) in the analogy validation set . The best recall achieved in analogies was by the instructor and department multi-factor model , successfully completing 85.57 % of course analogies when considering the top 10 candidates of each analogy completion . For results in the following sections , we will use the non output concatenation versions of course2vec for equivalency validation comparisons and the concatenation versions for analogies valida- tion comparison . 5.3 Bag-of-words vs. Multi-factor Course2vec Among the three bag-of-words models , tf-idf performs the best in all equivalency set metrics , as seen in Table 1 . The median rank ( best=4 ) and recall @ 10 ( best=0.5647 ) for the bag-of-words models were also substantially better than the best course2vec models , which had a best median rank of 15 with best recall @ 10 of 0.4485 for the instructor and department model . All course2vec models ; however , showed better mean rank performance ( best=224 ) compared with bag-of-words ( best=566 ) . This suggests that there are many outliers where literal semantic similarity ( bag-of-words ) is very poor at identifying equivalent pairs , whereas course2vec has much fewer Designing for Serendipity in a University Course Recommendation System Table 1 : Equivalency validation of all the models Model Mean / Median Recall Rank @ 10 course2vec 244/21 0.3839 course2vec ( +out ) 270 / 26 0.3430 ins-course2vec 302 / 16 0.4406 ins-course2vec ( +out ) 400 / 32 0.3478 dept-course2vec 261/17 0.4005 dept-course2vec ( +out ) 306 / 19 0.3721 ins-dept-course2vec 224/15 0.4485 ins-dept-course2vec ( +out ) 201/ 16 0.4312 tf 589/5 0.5451 binary 612/6 0.5308 tfidf 566/4 0.5647 tf+insdept-course2vec 168 / 6 0.5691 tf+insdept-course2vec ( norm ) 132 /3 0.6371 bin.+insdept-course2vec 178 /7 0.5404 bin.+insdept-course2vec ( norm ) 129 /3 0.6251 tfidf+insdept-course2vec 213/14 0.4428 tfidf+insdept-course2vec ( norm ) 132/3 0.6435 Table 2 : Analogy validation of all the models Model Accuracy Recall @ 10 course2vec 0.4739 0.7539 course2vec ( +out ) 0.5011 0.7685 ins-course2vec 0.5025 0.8094 ins-course2vec ( +out ) 0.5138 0.7853 dept-course2vec 0.3504 0.8257 dept-course2vec ( +out ) 0.3581 0.8284 ins-dept-course2vec 0.4784 0.8434 ins-dept-course2vec ( +out ) 0.4961 0.8557 tf 0.3037 0.537 binary 0.3159 0.581 tf-idf 0.3227 0.542 tf+insdept-course2vec 0.5066 0.8438 tf+insdept-course2vec ( norm ) 0.448 0.6872 bin.+insdept-course2vec 0.5193 0.8788 bin.+insdept-course2vec ( norm ) 0.4603 0.7449 tfidf+insdept-course2vec 0.5138 0.8584 tfidf+insdept-course2vec ( norm ) 0.4503 0.7059 near worst-case examples . This result is consistent with prior work comparing pure course2vec models to binary bag-of-words [ 22 ] . When considering performance on the analogy validation ( Table 2 ) , the roles are reversed , with all course2vec models performing bet- ter than the bag-of-words models in both accuracy and recall @ 10 . The difference in recall of bag-of-words compared to course2vec when it comes to analogies is substantially greater ( 0.581 vs 0.8557 ) , than the superiority difference of bag-of-words over course2vec in the equivalency validation ( 0.5647 vs 0.4485 ) . These analyses es- tablish that bag-of-words models are supreme in capturing course similarity , but are substantially inferior to our skip-gram based models in the more complex task of analogy completion . The comparison of course2vec related models and bag-of-words models on equivalency validation and analogy validation is to some extent counter to Levy and Goldberg [ 15 ] ’ s argument that Mikolov et al . [ 18 ] ’ s word analogy exploring method of first adding and sub- tracting word vectors , and then searching for a word similar to the result , is equivalent to searching for a word that maximizes a linear combination of three pairwise word similarities , instead of vec- tor offsets encoding relational semantics . Otherwise , bag-of-words representations should also performs better on course analogies if the calculation on finding analogies is also based on cosine simi- larities . On top of that , all the neural embeddings perform better than bag-of-words representations on both accuracy and recall @ 10 , which surfaces the signal that there is also relational semantics conveyed from course enrollment behaviors but not encoded in course semantic descriptions . 5.4 Combining Bag-of-words and Course2vec Representations In light of the strong analogy performance of course2vec and strong equivalency performance bag-of-words in the previous section , we use the neural embeddings learned by mult-factor course2vec which incorporates both instructor and department to concatenate with bag-of-words representations . To counterbalance the different mag- nitudes of neural embeddings and bag-of-words representations , we create a normalized version of each vector set for comparison to non-normalized sets . We find that the normalized concatenation performs substan- tially better on the equivalency test than the previous best model in terms of recall @ 10 ( 0.6435 vs. 0.5647 ) as seen in Table 1 . While the median rank of the concatenated model only improved one rank , from 4 to 3 , the mean rank improved dramatically ( from 566 to 132 ) , and is the best of all models tested in terms of mean rank . Non- normalized vectors did not show improvements over bag-of-words alone in median rank and recall @ 10 . Improvements in the analogy test ( Table 2 ) were much more mild , with a recall @ 10 of 0.8788 of the best concatenated model vs. 0.8557 of the best course2vec only model . Normalization in the case of analogies , hurt all model performance , the opposite of what was observed in the equivalency test . This suggests that normalization improves local similarity but acts to degrade the more global structure of the vector space . 6 USER STUDY Auser study was conducted to evaluate differences in recommenda- tions among our developed representation based recommendation algorithms along five dimensions of quality . Students were asked to rate course recommendations in terms of their ( 1 ) unexpectedness ( 2 ) successfulness - or interest in taking the course ( 3 ) novelty ( 4 ) diversity of the results ( 5 ) and identifiable commonality among the results . Shani and Gunawardana [ 26 ] define serendipity as the com- bination of “ unexpectedness '' and `` success . '' In the case of a song recommender , for example , success would be defined as the user listening to the recommendation . In our case , we use a student ’ s expression of interest in taking the course as a proxy for success . The mean of their unexpectedness and successfulness rating will comprise our measure of serendipity . We evaluated three of our de- veloped models , all of which displayed 10 results , only showing one course per department in order to increase diversity ( and unexpect- edness ) . The models were ( 1 ) the best BOW model ( tf-idf ) , ( 2 ) the best Analogy validation model ( bin.+insdept-course2vec ) , ( 3 ) and the best Equivalency validation model ( tfidf+insdept-course2vec norm ) . To measure the impact our department diversification filter would have on serendipity , we added a version of the best Equiva- lency model that did not impose this filter , allowing multiple courses to be displayed from the same department if they were the most cosine similar to the user ’ s specified favorite course . Our fifth com- parison recommendation algorithm was a collaborative-filtering based Recurrent Neural Network ( RNN ) that recommends courses based on a prediction of what the student is likely to take next given their personal course history and what other students with a similar history have taken in the past [ 22 ] . We put a brief summary of the collaborative-filtering based Recurrent Neural Network ( RNN ) rec- ommendation algorithm to our supplement ( section 10.3 ) . All five algorithms were integrated into a real-time recommender system for the purpose of this study and evaluated by 70 undergraduates at the university . 6.1 Study Design Undergraduates were recruited from popular university associated Facebook groups and asked to sign-up for a one hour evaluation session . Since they would need to specify a favorite course they had taken , we restricted participants to those who had been at the university at least one full semester and were currently enrolled . The study was run at the beginning of the Fall semester , while courses could still be added and dropped and some students were still shopping for courses . We used a within-departments design whereby each volunteer rated ten course recommendations made by each of the five algorithms . Because of the considerable number of ratings expected ( [ 3°10+2 ] * 5 = 160 ) and the importance for stu- dents to carefully consider each recommended course , in-person sessions were decided on over asynchronous remote in order to better encourage on-task behavior throughout the session . Student evaluators were compensated with a $ 40 gift card to attend one of four sessions offered across three days with a maximum occupancy of 25 each session . A total of 70° students participated . We began the session by introducing the evaluation motivation as a means for students to help inform the choice of algorithm that we will use for a future campus-wide deployment of a course ex- ploration tool . Students started the evaluation by visiting a survey URL that asked them to specify a favorite course they had taken at the university . This favorite course was used by the first four algorithms to produce 10 course recommendations each , which included the course ’ s department , course number , title , and full catalog description . There was a survey page for each algorithm in which students were asked to read the course descriptions care- fully and then rate each of the ten courses individually for their five point Likert scale agreement with the following statements : ( 1 ) This course was unexpected ( 2 ) I am interested in taking this course ( 3 ) I did not know about this course before . These ratings respectively measured unexpectedness , successfulness , and novelty . After rating the individual courses , students were asked to rate their agreement 3Due to an authentication bug during the fourth session , all twenty participating stu- dents were not able to access the collaborative recommendations of the fifth algorithm . RNN results in the subsequent section are therefore based on the 50 students from the first three sessions . When paired t-tests are conducted between RNN and the ratings of other algorithms , the tests are between ratings among these 50 students . Pardos and Jiang Course # 1 Course # 2 Course # 3 | Course # 4 Course # 5 Course # 6 | Course # 7 | Course # 8 Course # 9 Course # 10 0 % 10 % 20 % 30 % 40 % 50 % 60 % 70 % 80 % 90 % 100 % mmm 5 ( Strongly agree ) mmm 4 3 2 | 1 { Strongly disagree ) Figure 2 : Novelty rating proportions for BOW ( div ) with the following statements pertaining to the results as a whole : ( 1 ) Overall , the course results were diverse ( 2 ) The course results shared something in common with my favorite course . These rat- ings measured dimensions of diversity and commonality . Lastly , students were asked to provide an optional follow-up open text response to the question , “ If you identified something in common with your favorite course , please explain it here . '' On the last page of the survey , students were asked to specify their major , year , and to give optional open response feedback on their experience . Graduate courses were not included in the recommendations and the recommendations were not limited to courses available in the current semester . 6.2 Results Results of average student ratings of the five algorithms across the six measurement categories are shown in Table 3 . The diver- sity based algorithms , denoted by “ ( div ) , '' all scored higher than the non-diversity ( non-div ) algorithms in unexpectedness , novelty , diversity , and the primary measure of serendipity . The two non- diversity based algorithms ; however , both scored higher than the other three algorithms in successfulness and commonality . All pair- wise differences between diversity and non-diversity algorithms were statistically significant , using the p < 0.001 level after applying a Bonferoni correction for multiple ( 60 ) tests . Within the diversity algorithms , there were no statistically significant differences except for BOW scoring higher than Equivalency ( div ) on unexpectedness and scoring higher than both Equivalency ( div ) and Analogy ( div ) on novelty . Among the two non-diversity algorithms , there were no statistically significant differences except for the RNN scoring higher on diversity and Equivalency ( non-div ) recommendations scoring higher on novelty . With respect to measures of serendipity , the div and non-div algorithms had similar scores among their re- spective strengths ( 3.473-3.619 ) ; however , the non-div algorithms scored substantially lower in their weak category of unexpectedness ( 2.091 & 2.184 ) than did the div algorithms in their weak category of successfulness ( 2.851-2.999 ) , resulting in statistically significantly higher serendipity scores for the div algorithms . The most dramatic difference can be seen in the measure of novelty , where BOW ( div ) scored 3.896 and RNN ( non-div ) scored 1.824 , the lowest rating in the results matrix . The proportion of each rating level given to the two algorithms on this question is shown in Figures 2 and 3 . Hypothetically , an algorithm that recommended Designing for Serendipity in a University Course Recommendation System Table 3 : Average student ratings of recommendations from the five algorithms across the six measurement categories . algorithm unexpectedness successfulness serendipity novelty diversity commonality BOW ( div ) 3.550 2.904 3.227 3.896 4.229 3.229 Analogy ( div ) 3.473 2.851 3.162 3.310 4.286 2.986 Equivalency ( div ) 3.297 2.999 3.148 3.323 4.214 3.257 Equivalency ( non-div ) 2.091 3.619 2.855 2.559 2.457 4.500 RNN ( non-div ) 2.184 3.566 2.875 1.824 3.160 4.140 Successfulness 5.0 Course # 1 , Course # 2 Course # 3 Course # 4 Course # 5 Course # 6 Course # 7 | Course # 8 | Course # 9 | Course # 10- 0 % 10 % 20 % © 30 % += 40 % +©=— 50 % © 60 % += 70 % +©=— « 80 % © 90 % +— « 100 % mmm 5 ( Strongly agree ) mmm 4 3 Mm 2 © 1 ( Strongly disagree ) Figure 3 : Novelty rating proportions for RNN ( non-div ) randomly selected courses would score high in both novelty and unexpectedness , and thus it is critical to also weigh their ability to recommend courses that are also of interest to students . Figure 4 shows successfulness ratings for each of the algorithms aggregated by rank of the course result . The non-div algorithms , shown with dotted lines , always perform as well or better than the non-div al- gorithms at every rank . The more steeply declining slope of the div algorithms depicts the increasing difficulty of finding courses of in- terest across different departments . The tension between the ability to recommend courses of interest that are also unexpected is shown in Figure 5 , where BOW ( div ) is able to recommend courses of in- terest but low unexpectedness in the top few results . These values quickly swap places the lower the result ranks go . The non-diversity algorithms , on the other hand , maintain high successfulness but also low unexpectedness throughout the 10 result ranks . Are more senior students less likely to rate courses as novel or unexpected , given they have been at the university longer and been exposed to more courses ? Among our sophomore ( 27 ) , junior ( 22 ) , and senior ( 21 ) level students , there were no statistically significant trends among the six measures , except for a marginally significant trend ( p = 0.007 , shy of the p < 0.003 threshold given the Bonferroni correction ) of more senior students rating recommendations as less unexpected ( avg = 2.921 ) than juniors ( avg = 3.024 ) , whose ratings were not statistically separable from sophomores ( avg = 3.073 ) . 6.3 Qualitative Characterization of Algorithms In this section , we attempt to synthesize qualitative characteriza- tions of the different algorithms by looking at the open responses students gave to the question asking them to describe any common- alities they saw among recommendations made by each algorithm to their favorite course . i a a o wo a Average Rating o ° nN a —— BOW ( div ) 20 —— Analogy ( div ) —— Equivalency ( div ) 15 » Equivalency ( non-div ) » RNN ( non-div ) 4 6 Course Result Rank Figure 4 : Successfulness comparison 50 BOW ( div ) 50 Equivalency ( non-div ) 45 45 40 40 > D £ = = 35 = 35 TNA a a @ 3.0 @ 3.0 a a © £ G25 G25 $ $ < = < 20 2.0 18 15 109 2 4 6 8 10 Wy a 4 6 8 10 Course Result Rank Course Result Rank [ == _unexpectness —-— successfulness — —-— novelty | Figure 5 : BOW ( div ) vs. Equivalency ( non-div ) comparison 6.3.1 BOW ( div ) . Several students remarked positively about rec- ommendations matching to the themes of “ art , philosophy , and society '' or `` design '' exhibited in their favorite course . The word '' language '' was mentioned by 14 of the 61 respondents answering the open response question . Most of these comments were negative , pointing out the limitations of similarity matching based solely on literal course description matching . The most common critique given in this category was of the foreign spoken language courses that showed up at the lower ranks when students specified a fa- vorite course involving programming languages . Other students remarked at the same type of occurrence when specifying a favorite course related to cyber security , receiving financial security courses in the results . 6.3.2 . Analogy ( div ) . The word `` interesting '' appeared in seven of the 54 comments left by students to describe commonalities among the analogy validation optimized algorithm . This word was not among the top 10 most frequent words in any of the other four algorithms . Several students identified broad themes among the courses that matched to their favorite course , such as `` identity '' and '' societal development . '' On the other end of the spectrum , one stu- dent remarked that the results “ felt weird '' and were only “ vaguely relevant . '' Another student stated that , `` the most interesting sugges- tion was the Introduction to Embedded Systems [ course ] which is just different enough from my favorite course that it ’ s interesting but not too different that I am not interested , '' which poignantly ar- ticulates the crux of difficulty in striking a balance between interest and unexpectedness to achieve a serendipitous recommendation . 6.3.3 Equivalency ( div ) . Many students ( seven of the 55 ) remarked positively on the commonality of the results with themes of data exhibited by their favorite course ( in most cases STATS C8 , an in- troductory data science course ) . They mentioned how the courses all involved “ interacting with data in different social , economic , and psychological contexts '' and “ data analysis with different ap- plications. ” One student remarked on this algorithm ’ s tendency to match at or around the main topic of the favorite course , further re- marking that `` they were relevant if looking for a class tangentially related '' 6.3.4 Equivalency ( non-div ) . This algorithm was the same as the above , except that it did not limit results to one course per depart- ment . Because of this lack of department filter , 15 of the 68 students submitting open text responses to the question of commonality pointed out that the courses returned were all from the same de- partment . Since this model scored highest on a validation task of matching to a credit equivalent course pair ( almost always in the sare department ) , it is not surprising that students observed that results from this algorithm tended to all come from the department of the favorite course , which also put it close to their nexus of interest . 6.3.5 RNN ( non-div ) . The RNN scored lowest in novelty , signifi- cantly lower than the other non-div algorithm , and was not signifi- cantly different from the other non-div algorithm in successfulness . In this case , what is the possible utility of the collaborative-based RNN over the non-div Equivalency model ? Many of the 47 ( of 50 ) student answers to the open response commonality question point at a potential answer of major related ( mentioned by 21 students ) and courses that fulfilled a requirement ( mentioned by seven ) as the distinguishing signature of this algorithm . Since the RNN is based on normative next course enrollment behavior , it is reasonable that it suggested many courses that satisfy an unmet requirement . This algorithm ’ s ability to predict student enrollments accurately became a detriment to some , as seven remarked that it was rec- ommending courses that they were currently enrolled in . Due to the institutional data refresh schedule , student current enrollments are not known until after the add/drop deadline . This may be a shortcoming that can be rectified in the future . 7 FEATURE RE-DESIGN Asa result of the feedback received from the user study , we worked with campus to pull down real-time information on student require- ment satisfaction from the Academic Plan Review module of the Pardos and Jiang PeopleSoft Student Information System . we re-framed the RNN fea- ture as a `` Requirements '' satisfying feature that , upon log-in , shows students their personalized list of unsatisfied requirements . After selecting a requirement category to satisfy , the system displays courses which satisfy the selected requirement and are offered in the target semester . The list of courses is sorted by the RNN to represent the probability that students like them will take the class . This provides a signal to the student of what the normative course taking behavior is in the context of requirement satisfaction . For serendipidous suggestions , we created a separate “ Explore ” tab ( Fig- ure 6 ) using the Equivalency ( non-div ) model to display results of the top five courses most similar within the same department , due to its strong successfulness ratings , and the BOW ( div ) model to surface the top five courses similar across departments , due to its strong serendipidous and novelty ratings . eran tn arr ed Course Exploration Choose a Favorite Course Closest matches Considerations across campus Figure 6 : The “ Explore ” Interface 8 DISCUSSION Surfacing courses that are of interest but not known before means expanding a student ’ s knowledge and understanding of the Univer- sity ’ s offerings . As students are exposed to courses that veer further from their home department and nexus of interest and understand- ing , recommendations become less familiar with descriptions that Designing for Serendipity in a University Course Recommendation System are harder to connect with . This underscores the difficulty of pro- ducing an unexpected but interesting course suggestion , as it often must represent a recommendation of uncommon wisdom in order to extend outside of a student ’ s zone of familiarity surrounding their centers of interest . Big data can be a vehicle for , at times , reaching that wisdom . Are recommendations useful when they suggest something expected or already known ? Two distinct sets of responses to this question emerged from student answers to the last open ended feedback question . One representative remark stated , “ the best algorithms were the ones that had more diverse options , while still staying true to the core function of the class I was searching . The algorithms that returned classes that were my major requirements/in the same department weren ’ t as helpful because I already knew of their existence as electives I could be taking '' While a different representative view was expressed with , '' [ think the fifth algorithm [ RNN ] was the best fit for me because my major is pretty standardized '' These two comments make a case for both capabilities being of importance . They are also a reminder of the desire among young adults for the socio-technical systems of the university to offer a balance of information , exploration and , at times , guidance . 9 LIMITATIONS The more semantically distal , even if conceptually similar , the less a student may be able to recognize the commonality with a favorite course . A limitation of demonstrating the utility of the neural em- beddings is that students had to rely on the course description semantics in order to familiarize themselves with the suggested course . If a concept was detected by the neural embeddings but not the BOW , this means it may have been difficult for students to pick- up on this from the descriptions alone . Future evaluations could include links to additional course information , such as course syllabi . While our diversity algorithms produced serendipitous reeommen- dations , they will not always produce the desired recommendations with respect to interest if the most salient features of the course ’ s embedding is not what the student most liked about it . REFERENCES { 1 ] Zeinab Abbassi , Sihem Amer-Yahia , Laks VS Lakshmanan , Sergei Vassilvitskii , and Cong Yu . 2009 . Getting recommender systems to think outside the box . In Proceedings of the third ACM conference on Recommender systems . ACM , 285-288 . [ 2 ] Marco Baroni , Georgiana Dinu , and German Kruszewski . 2014 . Don ’ t count , predict ! A systematic comparison of context-counting vs. context-predicting semantic vectors . In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics ( Volume 1 : Long Papers ) , Vol . 1 . 238-247 . Marco Baroni and Alessandro Lenci . 2010 . Distributional memory : A general framework for corpus-based semantics . Computational Linguistics 36 , 4 ( 2010 ) , 673-721 , Sorathan Chaturapruek , Thomas Dee , Ramesh Johari , René Kizilcec , and Mitchell Stevens . 2018 . How a data-driven course planning tool affects college students ’ GPA : evidence from two field experiments . ( 2018 ) . Hung-Hsuan Chen . 2018 . Behavior2Vec : Generating Distributed Representations of UsersaAZ Behaviors on Products for Recommender Systems . ACM Transactions on Knowledge Discovery from Data ( TKDD ) 12 , 4 ( 2018 ) , 43 . D Manning Christopher , Raghavan Prabhakar , and Schacetzel Hinrich . 2008 . Introduction to information retrieval . An Introduction To Information Retrieval 151 , 177 ( 2008 ) , 5 . Martin Dillon . 1983 . Introduction to modern information retrieval : G. Salton and M. McGill . McGraw-Hill , New York ( 1983 ) . 448 pp. , ISBN 0-07-054484-0 . Rosta Farzan and Peter Brusilovsky . 2011 . Encouraging user participation in a course recommender system : An impact on user behavior . Computers in Human Behavior 27 , 1 ( 2011 ) , 276-284 . ( 3 ( 4 [ 5 [ 6 ( 7 [ 8 [ 9 ] [ 10 ] ( 11 ] [ 12 ] [ 13 ] [ 14 ] [ 20 ] ( 21 ] [ 22 ] [ 23 ] [ 24 ] [ 25 ] [ 26 ] ( 27 ] [ 28 ] [ 29 ] [ 30 ] Li Fei-Fei , Rob Fergus , and Pietro Perona . 2006 . One-shot learning of object categories . IEEE transactions on pattern analysis and machine intelligence 28 , 4 ( 2006 ) , 594-611 . Kata Gabor , Haifa Zargayouna , Isabelle Tellier , Davide Buscaldi , and Thierry Charnois . 2017 . Exploring Vector Spaces for Semantic Relations . In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing . 1814-1823 . Balazs Hidasi , Massimo Quadrana , Alexandros Karatzoglou , and Domonkos Tikk . 2016 . Parallel recurrent neural network architectures for feature-rich session-based recommendations . In Proceedings of the 10th ACM Conference on Recommender Systems . ACM , 241-248 . Noriaki Kawamae , Hitoshi Sakano , and Takeshi Yamada . 2009 . Personalized recommendation based on the personal innovator degree . In Proceedings of the third ACM conference on Recommender systems . ACM , 329-332 . Judy Kay . 2000 . Stereotypes , student models and scrutability . In International Conference on Intelligent Tutoring Systems . Springer , 19-30 . Lili Kotlerman , Ido Dagan , Idan Szpektor , and Maayan Zhitomirsky-Geffet . 2010 . Directional distributional similarity for lexical inference . Natural Language Engineering 16 , 4 ( 2010 ) , 359-389 . Omer Levy and Yoav Goldberg . 2014 . Linguistic regularities in sparse and explicit word representations . In Proceedings of the eighteenth conference on computational natural language learning . 171-180 . Dekang Lin et al . 1998 . An information-theoretic definition of similarity . In Ieml , Vol . 98 . Citeseer , 296-304 . Sean M McNee , John Riedl , and Joseph A Konstan . 2006 . Being accurate is not enough : how accuracy metrics have hurt recommender systems . In CHI ’ 06 extended abstracts on Human factors in computing systems . ACM , 1097-1101 . Tomas Mikolov , Ilya Sutskever , Kai Chen , Greg S Corrado , and Jeff Dean . 2013 . Distributed representations of words and phrases and their compositionality . In Advances in neural information processing systems . 3111-3119 . Tien T Nguyen , Pik-Mai Hui , F Maxwell Harper , Loren Terveen , and Joseph A Konstan . 2014 . Exploring the filter bubble : the effect of using recommender systems on content diversity . In Proceedings of the 23rd international conference on World wide web . ACM , 677-686 . Gaurav Pandey , Denis Kotkov , and Alexander Semenov . 2018 . Recommending serendipitous items using transfer learning . In Proceedings of the 27th ACM international conference on information and knowledge management . ACM , 1771- 1774 , Aditya Parameswaran , Petros Venetis , and Hector Garcia-Molina . 2011 . Rec- ommendation systems with complex constraints : A course recommendation perspective . ACM Transactions on Information Systems ( TOIS ) 29 , 4 ( 2011 ) , 20 . Zachary A Pardos , Zihao Fan , and Weijie Jiang . 2019 . Connectionist recom- mendation in the wild : on the utility and scrutability of neural networks for personalized course guidance . User Modeling and User-Adapted Interaction 29 , 2 ( 2019 ) , 487-525 . Zachary A Pardos and Andrew Joo Hun Nam . 2018 . A Map of Knowledge . CoRR preprint , abs/1811.07974 ( 2018 ) . https : //arxiv.org/abs/1811.07974 Fernando Pereira , Naftali Tishby , and Lillian Lee . 1993 . Distributional clustering of English words . In Proceedings of the 31st annual meeting on Association for Computational Linguistics . Association for Computational Linguistics , 183-190 . Leonardo FR Ribeiro , Pedro HP Saverese , and Daniel R Figueiredo . 2017. struc2vec : Learning node representations from structural identity . In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining . ACM , 385-394 . Guy Shani and Asela Gunawardana . 2011 . Evaluating recommendation systems . In Recommender systems handbook . Springer , 257-297 . Peter D Turney and Patrick Pantel . 2010 . From frequency to meaning : Vector space models of semantics . journal of artificial intelligence research 37 ( 2010 ) , 141-188 . Ashish Vaswani , Noam Shazeer , Niki Parmar , Jakob Uszkoreit , Llion Jones , Aidan N Gomez , Lukasz Kaiser , and Illia Polosukhin . 2017 . Attention is all you need . In Advances in neural information processing systems . 5998-6008 . Oriol Vinyals , Charles Blundell , Tim Lillicrap , Daan Wierstra , et al . 2016 . Match- ing networks for one shot learning . In Advances in Neural Information Processing Systems . 3630-3638 . Yuan Cao Zhang , Diarmuid 6 Séaghdha , Daniele Quercia , and Tamas Jambor . 2012 . Auralist : introducing serendipity into music recommendation . In Proceedings of the fifth ACM international conference on Web search and data mining . ACM , 13-22. iversity The Open Un Open Research Online The Open University ’ s repository of research publications and other research outputs Social media and the future of open debate : a user-oriented approach to Facebook 's filter bubble conundrum Journal Item How to cite : Seargeant , Philip and Tagg , Caroline ( 2019 ) . Social media and the future of open debate : a user-oriented approach to Facebook 's filter bubble conundrum . Discourse , Context & Media , 27 pp . 41-48 . For guidance on citations see FAQs . © ) 2018 Elsevier Ltd. KOS® https : / /creativecommons.org/licenses/by-nc-nd/4.0/ Version : Accepted Manuscript Link ( s ) to article on publisher 's website : http : //dx.doi.org/doi:10.1016/j.dcm.2018.03.005 Copyright and Moral Rights for the articles on this site are retained by the individual authors and/or other copyright owners . For more information on Open Research Online 's data policy on reuse of materials please consult the policies page . oro.open.ac.uk Social media and the future of open debate 1 Abstract Drawing on a two-year project , Creating Facebook , this article explores how the actions and agency of Facebook users contribute to the distortion of information and polarisation of socio- political opinion . Facebook ’ s influence as a channel for the circulation of news has come under intense scrutiny recently , especially with regard to the dissemination of false stories . While this criticism has focused on the ‘ filter bubbles ’ created by the site ’ s personalisation algorithms , our research indicates that users ’ own actions also play a key role in how the site operates as a forum for debate . Our findings show that the strategies people use to navigate the complex social space contribute to the polarising of debate , as they seek to avoid conflict with the diverse members of their network . Keywords : context design , Facebook , filter bubbles , intradiversity , media ideologies Social media and the future of open debate 2 Social media and the Future of Open Debate : a User-Oriented Approach to Facebook ’ s Filter Bubble Conundrum Introduction This article examines data collected as part of a two-year project , Creating Facebook , to argue that users ’ online actions contribute to the creation of a filter bubble effect and to put forward user-oriented suggestions for addressing this problem as it impacts on the use of the platform as a site for discussion of ideas and opinions . Creating Facebook , which explored user perspectives on the suitability of Facebook as a forum for open debate , reveals how the communicative strategies that people employ on the site influence their exposure to and engagement with a diversity of opinion and conflicting worldviews . The concept of the online filter bubble ( Pariser , 2011 ) — the way that personalisation algorithms used in site architectures foreground material that will be of particular interest to individual users while suppressing stories which may diverge from or challenge their views — has emerged in recent years as an apparent challenge for contemporary society . The socio-political implications of the phenomenon , it is argued , include the polarisation of debate and the spread of false and highly-partisan information ( e.g . Solon , 2016 ) , including so-called ‘ fake news ’ . While algorithms are certainly an important element in the spread of false or fabricated reports about events in the world , we argue in this article that they are only one side of the story . Of equal importance is what people themselves do , how they fashion their experience of Facebook as a communicative space through their actions , and how , in effect , they contribute to the construction of these opinion-ghettos themselves , creating the conditions in which fabricated and partisan news can more easily be disseminated . Social media and the future of open debate 3 The research project which informs our argument , Creating Facebook , examined people ’ s reflections on their communication via Facebook , with a particular focus on what they considered suitable behaviour on the site , and how they regulated their own interactions in response to their emergent beliefs about appropriate behavioural norms . The data is comprised of the questionnaire responses of over a hundred Facebook users about their experiences of and beliefs about personal communication on the site ( i.e . user-shared status updates ) , as well as in- depth follow-up interviews with selected participants . The analysis explores the way that communication of this sort on Facebook apparently gives rise to recurrent examples of conflict , disagreement , or a sense of frustration with other interactants , which , we argue , is in part a result of the specific form of diversity which exists on the site . We refer to this as intradiversity , and suggest that it results from the type of “ ego-centred ’ network ( Androutsopoulos , 2014 , p. 63 ) that Facebook facilitates , whereby communication is predominantly structured around the personal connections of individual users as these are accrued across that user ’ s biography . Key to our reasoning for the importance of intradiversity and the way it influences users ’ actions is our concept of context design , which we put forward as an important theoretical model for understanding online communication . Context design , which builds on the concept of audience design ( Bell , 1984 ) as well as models concerning the interactive construction of context ( Duranti and Goodwin , 1992 ) , illuminates the ways in which Facebook users imagine and respond to a complex set of contextual variables as they design the style and content of their interactions . In combination with intradiversity , context design offers a refinement and enhancement of the widely-used notion of context collapse which has been highly influential in social science research ( Marwick and boyd , 2014 ) , and helps to explain the significance of user practices within the broader debate about the influence of filter bubbles in online civic discourse . Social media and the future of open debate 4 Filter Bubbles and their Impact on Civic Discourse Facebook continues to dominate the global social media landscape and has emerged as an important outlet for the sharing and consuming of news ( as well as discussion around it ) , with the Pew Research Center reporting that two-thirds of Facebook users in the United States — or 44 % of the general population ( Gottfried & Shearer , 2016 ) — say they get news from the site . Given its reach , concern has been voiced about the way in which the type of dialogue needed for balanced and informed public opinion-forming is poorly served by the site ( Benton , 2016 ) . This was particularly considered the case in the aftermath of the rise of the populist movements which led to the Brexit ( Viner , 2016 ) and Trump ( Solon , 2016 ) victories . The argument voiced in some quarters following the Trump victory ( e.g . El-Bermawy , 2016 ) is that polarisation , in addition to misinformation , is causing a break-down in civic discourse . Furthermore , the polarised nature of debate prevents misinformation from being challenged , thus letting its malignant influence spread ( Read , 2016 ) . The term ‘ filter bubble ’ was coined by Eli Pariser ( 2011 ) to refer to the concept that a website ’ s personalisation algorithm selectively predicts the information that users will find of most interest based on data about each individual — including signals such as their history of Likes , search history , and other past online behaviour — and that this creates a form of online isolation from a diversity of opinions . The concept , which focuses specifically on the implications of algorithmic personalisation , is a complement to research examining the way that people choose to read articles that predominantly align with their political opinions , and tend to share and discuss these with their social groups , thus creating “ echo chambers ’ of opinion ( Garrett , 2009 ) . In the days before algorithmic personalisation became commonplace , Sunstein ( 2007 ) argued that online communities resulted in people cutting themselves off from opinion Social media and the future of open debate 5 and information that challenged their belief systems , and that this was likely to have a negative impact on democratic debate . The development of algorithms , however , has led to a new situation in which people ’ s actions are increasingly shaped by processes which are hidden to most users ( Jones , 2016 ) . On Facebook , the personalisation algorithm is designed to provide an experience for users which prioritises information which is most ‘ meaningful ’ to them ( Zuckerberg , 2016 ) . Although this applies to all information that is shared on Facebook , it also includes opinions and expressions about social or political values as well as news stories , which , so the argument goes , results in a newsfeed filled predominantly with opinions with which the user agrees — a phenomenon which Jones and Hafner ( 2012 , p. 126 ) refer to as the ‘ ghetto-ization ’ of the internet . The significance of this , according to Pariser ( 2011 , p. 5 ) , is that “ [ d ] emocracy requires a reliance on shared facts : instead we ’ re being offered parallel but separate universes ’ . Pariser ’ s warning relates to the way that civic debate is not best served by intellectual segregation , and leads more readily to extremism than to consensus . Research shows that when people discuss issues with those who share their opinion , this leads to more polarized attitudes towards the topic ( Stinchcombe , 2010 ) , whereas exposure to diversity increases people ’ s tolerance for those with different or opposing views ( Garrett & Resnick , 2011 ) . It is worth pointing out that other studies have suggested a different phenomenon , whereby the extensiveness of online networks means that a small but significant fraction of ties are with people with different political outlooks , which increases exposure to different opinions ( Sharad et al . 2010 ) . Flaxman et al . ( 2016 , pp . 20-21 ) , in their study of online news consumption , arrive at the conclusion that both the above phenomena seem to occur . Their research points to an apparent paradox that , although users are pushed towards “ ideological segregation ’ in terms of Social media and the future of open debate 6 the information they consume , this is not necessarily linked to a lack of contact with people who hold divergent views . As we shall show , our user-oriented focus goes some way to explaining this apparent contradiction by pointing to the interplay between user actions and the algorithm . The way the discourse over the influence of Facebook ’ s filter bubble ‘ problem ’ was framed in the media in the aftermath of the 2016 US presidential election had a distinct element of technological determinism to it , at least in headlines which suggest , for example , that “ Donald Trump Won Because of Facebook ’ ( Read , 2016 ) . In line with the view that the solution to the filter bubble conundrum lies with the technology , numerous attempts have been made to develop software which enhance open dialogue and create an environment of open-mindedness ( Bozdag & van den Hoven , 2015 ) . In December 2016 Facebook announced a set of measures to tackle the problem themselves , including getting readers to flag stories for fact-checking , marking dubious stories as being ‘ disputed ’ and dropping them down the newsfeed ( Facebook , 2016a ) . What these solutions neglect , however , is the role that users ’ actions may play in generating the effects popularly put down to the algorithm . In his discussion of digital surveillance , Jones ( 2016 ) explores how social media communication increasingly involves users interacting with computer code ( that is , algorithms ) as well as with the actions and utterances of other users — a phenomenon he refers to as ‘ algorithmic pragmatics ’ . In communicative environments like Facebook , users tend to interpret and respond to the computer code as they would in interaction with other users , inferring the underlying intentions and shaping their subsequent actions in line with and in anticipation of the algorithm ’ s response . Jones ’ s argument points to the way in which filter bubbles are created not only through the actions implemented through the algorithm , but through the interactions that take place between the algorithm and the site users . Social media and the future of open debate 7 A less technological determinist position to tackling the issue would therefore be that , with enhanced awareness of the affordances of the technology , people would be better able to navigate them and respond to any influence the technology does produce . The concept of affordances ( i.e . the set of functional opportunities offered to a user by a platform ) is useful here in foregrounding the role that user responses to technology have in shaping user experience . An important element of this relationship between platform and user is the way people perceive the functionalities , and the extent to which they are aware of the range of possibilities available to them and how these work . Affordances therefore emerge from the interaction that users have with the technology and their critical awareness . As we discuss below , the beliefs that people have about a technology have a bearing on what they do with it , and are thus a vital element in how a particular platform is used as a communicative resource . In other words , affordances are a product not simply of the design of the technology , but people ’ s cultural judgements about it as well as their awareness of its complex and shifting functionalities ( Facebook , for example , is prone to update its software on a very frequent basis ) . Returning to the issue of the filter bubble and its role in the spread of fake news , the appeal of an explanation that focuses almost exclusively on the technology is easy to understand , as Garrett ( 2016 ) has commented , because it suggests that if you alter the algorithm you solve the problem ( and that blame lies solely with the technology company rather than with more complex social reasons ) . But as noted above , there is also research showing that people are exposed to a diversity of viewpoints , which would put into question the extent to which personalisation algorithms alone are responsible for this closing down of debate . Our project contributes to this research by highlighting a key communicative dynamic at work in Facebook interaction — specifically , how users shape and construct the communicative space of Facebook Social media and the future of open debate 8 in response to their media ideologies and their awareness of audience . It should be noted that Facebook is now a multifaceted communication space , which not only allows people to interact by means of posting and commenting on statuses , but also features extensive advertising , as well as a feed of trending topics ( mostly social or celebrity news ) , all of which is also influenced by the personalisation algorithm . However , in order to explore how users ’ interactions shape Facebook as a space for the dissemination of various kinds of news , our focus is specifically on users ’ sharing of , and commenting on , contemporary news stories and wider political issues and the debate that accompanies this . Before moving to the study itself , and an explanation of its method and rationale , we introduce three key theoretical concepts through which we theorise user agency and its implications . User Agency : Media Ideologies , Intradiverse Networks and Context Design Media ideologies Our underlying premise is that Facebook as a communicative space is shaped to a significant degree by its users ’ practices , and that these practices are themselves shaped by the ideas users have about the context in which they interact . The first of these precepts is widely accepted across social studies of the internet ; boyd ( 2001 , p. 121 ) , for example , describes how the disembodied nature of social media contexts requires users ‘ to write themselves into being ’ and to create the context for each of their posts . We theorise the second precept — that users ’ actions are shaped by their understandings of a site — with reference to the concept of media ideologies . Ideologies are entrenched beliefs about the social world which have a role in structuring the understandings people have of social reality , and the ways they interpret or justify their actions . These are understood as being dynamic , and often ‘ multiple , competing and contradictory ’ Social media and the future of open debate 9 ( Schiefflin & Doucet 1998 , p. 286 ) . As applied to media , they constitute the beliefs people have about communication technologies , and their norms and expectations regarding the nature of the communication facilitated by these ( Gershon , 2010 ) . As Gershon ( 2010 , p. 290 ) argues , the popularity of social media platforms and their penetration into people ’ s everyday communicative lives has led to the development of ‘ culturally specific , nuanced understandings of how these media shape communication ’ , which includes beliefs about what type of interaction is best suited to which media . People develop an understanding of these beliefs in complex ways , often by implicitly negotiating the norms with interactants , as well as , in the case of many of the people in our study , learning through experience by unwittingly breaching these norms . The ideologies they then develop become a means for rationalising their own behaviour on the site as well as justifying their responses to the actions of others . These ideologies are shaped by a number of different influences , including their current and previous experiences with Facebook , as well as their evaluation of the site in comparison with other channels of communication with which they now engage or have had experience of in the past ( Madianou & Miller , 2012 ) . These ideologies can be seen as both emerging from , and shaping , the wider social context . In other words , not only is how people feel about the site shaped by their experiences with it , but these attitudes go on to shape the nature of future experiences . Intradiversity Another important element in the way people shape their communication relates to their understanding of the audience for which they are writing , and the diversity of values and relationship ties this can include . In describing the way this audience is constituted on Facebook , we have developed the concept of intradiversity . A number of other studies have described the Social media and the future of open debate 10 way in which the internet helps foster a form of superdiversity — the particularly complex and often unpredictable social connections which transcend geographical distance — due to the way contact can be kept up between migrants and their home communities , and the way people from different cultural backgrounds are brought together in a single online space , often around shared interests ( Androutsopoulos & Juffermans , 2014 ) . We argue , however , that on a site such as Facebook , where the network is centred around one individual ’ s personal connections , this is less likely to be the case . It is also unlikely that the audience for a Facebook post will be primarily shaped by social characteristics such as national identity , ethnicity or common interests , but that the diversity will be related to ( and limited by ) the individual ’ s life trajectory . That is , the links which comprise the network are the result of encounters and relationships that have developed across the user ’ s biography , and while this affords a certain type of diversity ( e.g . the views and beliefs of relatives from one ’ s hometown , as well as friends from school or university , plus work colleagues ) , it is also likely that the various connections share some initial affinity with the user which produced the connection in the first place . Our recognition of intradiversity is significant because the fact that all these different people share the same communicative space makes diversity very salient and leads to the possibility of people being offended and of inadvertently causing offence . At the same time , the diverse , close and complex ties which people have with members of their audience on Facebook — and their existing offline social roles and relationships —are likely to constrain their behaviour in ways which differ from contexts in which people interact with strangers . Context Design Social media and the future of open debate 11 Our theoretical model of context design accounts for the dynamic , socially co-constructed nature of context , especially as this is a feature of social media , so as to better understand the particular nature of online communication . In doing so , it builds on the widely used concept of context collapse , which describes the way in which people from a variety of different contexts are brought together in one online space , where they form the potential audience for a user ’ s status updates ( Marwick & boyd , 2014 ) . The problem this poses in terms of communication is one of self-presentation , given the fact that users can not easily vary the way they come across to different segments of their audience , as they would in offline spaces . While context collapse has proved valuable in developing theories of networked privacy ( Marwick & boyd , 2014 ) , from a sociolinguistics viewpoint the metaphor of ‘ collapse ’ does not accurately capture how context is collaboratively co-constructed in interaction ; that is , the extent to which the context of an interaction is shaped by how interactants choose to position themselves and the linguistic choices they make . This is particularly salient in online contexts where communication is virtual and bodiless and where people must create a context for their posts through writing and other semiotic means ( boyd , 2001 ) . This means that a context is not a fixed , predetermined set of situational factors , and nor does it exist as a discrete entity ( Duranti & Goodwin , 1992 ) . In line with sociolinguistic understandings of context , we argue that offline contexts defined thus can not be said to move online and to collapse into other contexts ; but rather that people co-create new contexts in the course of their online interactions . The concept of context design thus captures the way in which people collaborate to ( re- ) design and negotiate these online contexts . In doing so , we build on theories of audience design such as Bell ’ s ( 1984 ) which similarly offer a more dynamic view of communication than that offered by context collapse , through their recognition of the way in which speakers actively position their listeners and then Social media and the future of open debate 12 style their utterances in accordance with their projected ideas about each listener . Unlike audience design , however , context design takes into account situational factors beyond that of the participants in an interaction , including the affordances of the site and of digital communication more generally , local norms of communication , users ’ immediate goals , and their media ideologies . Although context design is a feature of all forms of interaction , it is of particular salience in online written interactions because of the enhanced level of reflexivity that often occurs there ( Androutsopoulos & Staehr , 2017 ) , as well as the intradiverse and invisible nature of the online audience . Importantly , Facebook users must also take into account the multiple trajectories along which their posts may travel ( Blommaert , 2005 ) ; that is , the likelihood that their posts will be shared and thus reproduced and reinterpreted in new contexts . Processes of “ entextualisation ’ ( Bauman & Briggs , 1990 ) can transform both the meaning and value attached to a post . Given the large intradiverse nature of social networks on Facebook , and the ease with which digital text can be copied and distributed , Facebook users must attend to an almost infinite array of potentially relevant communicative spaces , including not only the multiple contexts made relevant by their intradiverse audience , but also imagined future trajectories . Central to context design is the notion of polycentricity ( Blommaert , 2005 ) and the observation that users orient towards multiple and competing centres of influence as they construct a context for an online post . Through their actions , people design contexts for their interactions in ways which draw upon ( and , in the process , sustain and extend ) existing sources of authority — the communicative expectations of friends versus those of their parents , for example — regarding what is deemed appropriate or valued behaviour . Also relevant is the agency people feel they have in acting on this awareness . Their sense of agency relates to a Social media and the future of open debate 13 number of different factors , including the communicative strategies they are able to implement in order to achieve their interactional aims ; the resources available to them ; and how they ( are able to ) use these . Agency can be constrained in various ways , both in terms of limited awareness and access to resources , as well as existing social roles and the ways in which they are positioned by others ( Tagg & Seargeant , 2016 ) . A focus on the strategies users have available to them , and how they reflect upon these , is a key element of the methodology involved in investigating the construction of context . Below we explore the relevance of this theory for understanding the contribution that users make towards the construction of social media filter bubbles , and how this relates to the circulation of opinion , information and news . Creating Facebook : Participants , Data and Methods The data for this study is drawn from our two-year project , Creating Facebook , and comprises responses to an online questionnaire and series of follow-up interviews which were conducted with the online network of the research associate on the project . An invitation to participate was sent out via personal message to all members of the researcher ’ s Facebook network in mid-2014 , with a link to the survey also placed on her wall . This link was then shared by a number of her Friends , thus extending the scope across the network . A total of 184 responses were collected , of which 43 were discarded as incomplete . The remaining 141 responses were used for analysis . An online questionnaire — rather than , for instance , face-to-face interviews — was purposefully chosen in order to access a relatively large and ‘ intradiverse ’ network of active Facebook users of the kind that we posit shapes communication on the site . The choice of individual was motivated by the fact that , as an active user of social media , and as someone who Social media and the future of open debate 14 had joined the site very early in its development , her network was likely to be representative of the intradiverse dynamics outlined above . The questionnaire comprised eighteen questions , and was carried out via the online platform SurveyMonkey . The choice of distributing the questionnaire via a single individual ’ s Facebook account was made in order to access the kind of ego-centred network we wished to examine . It should be noted that we do not claim any great generalizability for the research ; with Facebook having a global reach of over 2 billion users ( Facebook , 2016b ) any qualitative study is necessarily partial . Yet the approach does offer a means of evaluating precisely the kind of intradiversity that we posit shapes interaction on the site . The social characteristics of the participants were shaped by the node user ’ s age and gender , as well as her travels ( most notably in Japan and China ) , her life trajectory ( including working abroad as a teacher of English ) and the various kinds of connections she has made along the way : close friends , acquaintances , colleagues , and so on . The survey questions were divided into two sections : those asking general demographic details and information about individuals ’ engagement with Facebook ; and those soliciting longer answers about what people do and do not post and the rationale behind their practices . The aim was to encourage respondents to reflect on how they understood the diversity of their audience , the site affordances , and their own agency in navigating the online space , as well as the strategies they use when doing so . As noted above , the focus was specifically on the interaction which took place around status updates and comments as well as the sharing of news , rather than content generated by Facebook itself , such as its trending topics section , or adverts or other featured posts . The decision to limit the focus in this way was because the project as a whole was investigating Social media and the future of open debate 15 social relations on the site , as illuminated by users ’ reflections on their interactions with each other . Although we did not ask participants specifically about this , it is likely that many of the status updates that they found offensive were themselves comments on news articles that the “ offender ” was simultaneously sharing . Most of the questions were open-ended ones which invited respondents to elaborate in depth on their answers and thus yielded rich qualitative data . From amongst respondents who had evidenced particularly strong media ideologies in relation to their Facebook user , a selection were approached to take part in follow-up interviews and we eventually conducted interviews with three of the respondents — more was not deemed necessary given the richness of the survey data . These were semi-structured , and conducted via online voice calls , which allowed participation irrespective of physical location . The supporting interviews gave us the opportunity to reconstruct these participants ’ media ideologies in a more coherent way and , although this is not the focus of the present article , they therefore supplemented the main data set . Consent for the use of the data in the research project was collected from all those who took the questionnaire , and precautions were put in place to ensure participants ’ data were collected and stored in a secure manner . Questionnaire and interview responses have also been anonymised , with pseudonyms used for the interviews ( Heather , Jessica and Jacob ) . In analysing the data , we adopted what we call a ‘ thematic-discourse analytic approach ’ . This involved reading through the data to identify key themes ( Guest , 2012 ) , the selection of which was influenced in part by the research questions for the project , as well as current literature around relevant topics . We took care , however , not to impose a pre-existing framework on our dataset , and instead watched for emergent themes , in this way adopting a data-driven approach . Analysis then focused on the discourse generated by the questionnaire and interviews , Social media and the future of open debate 16 paying close attention to the ways our respondents ’ attitudes and perceptions were expressed linguistically . We were thus able to identify and categorise the various stances toward communication via Facebook which people discursively constructed in their answers , with particular focus on reflections around agency . Results and Discussion Our focus in this article is primarily on responses to questions in the survey which asked about the participants ’ experiences of offence on Facebook , as a means of for exploring how user actions create the experience they have of Facebook . As will be illustrated , this has particular relevance for the ways in which information ( including both news and opinion ) is circulated , and the way the construction of the communicative environment leads also to the construction of social perspectives in terms of the views , opinions and information one accesses . The extracts used below are taken from two questions asking participants to reflect on what they had been offended by , and what happened as a result ( Q26 ) ; and whether and how they had changed what they write on Facebook in response to having offended ( Q31 ) . Reflexivity over the concept of offence served as a catalyst for discussion around participants ’ beliefs regarding the sort of discursive space Facebook was or should be , and the nature of interactions — especially over political or controversial topics — which took place on it . We break the analysis up under a number of broad headings which identify the most salient ideologies underlying people ’ s reported behaviour . Being Offended by Divergent or Inaccurate Views on Politics and Other Issues Social media and the future of open debate 17 The first point of note is that a majority of those surveyed ( 60 % ) said they had been offended by others — and were able to recall specific instances , often in some detail . For most of those who had been offended ( 69 of 78 responses ) , the flashpoint for disagreement was issues around politics , or other topics considered controversial , as well as remarks considered racist or misogynistic . The following extracts illustrate the issues raised across the survey . [ 1 ] Political things that I do n't agree with , particularly negative posts about Obama , or against homosexuality . I have unfriended homophobic people , and turned off posts from a relative who has different political values . [ Q26-15 ] [ 2 ] Some people can be very ignorant to other peoples views and lives . Comments on immigration , Britishness , poverty , and racism have led me to delete friends in the past . [ Q26-75 ] What these and other responses suggest is that it is not unusual for Facebook users to be faced online with an array of divergent opinions , at least not in the case of the network of users who participated in our project , despite the alleged role of the personalisation algorithm in reducing people ’ s exposure to different viewpoints . We explain this in part by reference to the intradiverse nature of most people ’ s online networks , and the various factors — social background , education , values — that constitute this kind of diversity . A number of respondents claimed they were offended not by opinions they disagreed with but rather when they felt other people had not checked the accuracy of their posts . Social media and the future of open debate 18 [ 3 ] Recently , a bunch of friends posted things on Facebook about welfare recipients during tax season . It was both rude in my opinion , but also factually inaccurate . I posted some facts on my page because it made me so mad . [ Q26 : 5 ] [ 4 ] Stuff that I will respond to includes a lot of pseudoscience new age stuff . It doesn't offend me so much as annoy me it people do n't verify facts . [ Q26 : 22 ] The issue of inaccurate information was elaborated on in interview by Jessica , who repeatedly expressed her feeling that what she wanted to access on Facebook — and what she considered as desirable normative behaviour — was ‘ verifiable ’ information ( supported by evidence she could check ) rather than people ’ s opinions . [ 5 ] I do read some of what people post but I am also , I am getting to the point where I don ’ t want to read about your opinion . I want to read about some factual information that is coming from a credible source ... _ Because it is great that you have got your opinion but you are just sitting at your computer , the same as I am , re-posting and typing and it is not verifiable and if you are not actually linking something that is an external source that I can see and go ‘ oh really , that is something that I have learned ’ it just kind of becomes lazy and an argument for the sake of arguing [ Jessica , interview ] There are two issues of particular interest here . The first is the fairly obvious point that the way Facebook operates as a hybrid media-communications platform means that opinion and fact are mixed or juxtaposed to a far greater degree than they are for ‘ traditional ’ media platforms . In other words , a different level of criticality needs to be employed when consuming information on Social media and the future of open debate 19 the platform , yet as we can see from Jessica , this is not something she is unaware of , or unable to deal with , but simply something she finds frustrating . The second point of interest is that these users are claiming to receive information which they identify as false ( as well as that with which they disagree ) , and that they seem willing to look beyond the post itself to check the facts . In other words , these users claim not to blindly accept what is posted on Facebook but to engage with and challenge it . Another point of note is that the way Jessica presents her perspective ( ‘ I am getting to the point where ... ’ ) implies that her ideas about communication on Facebook have developed in response to prolonged experience on the site . Specifically , this experience has presumably been negative , in the sense that Jessica has become tired of reading what she sees as unverifiable opinions , and this has led to her belief that Facebook is best suited for the exchange of evidence-based facts . How Jessica responds to this through her future actions on the site constitutes her attempt to redesign the online context in line with her emergent media ideologies . Responses to being Offended In explaining what people did in response to having been offended , a clear picture of the ways in which users design the context of their Facebook experience emerges . Our respondents reported a number of different strategies for dealing with offensive or inaccurate posts . Most of these come under the general heading of avoidance ; that is , users responded by either unfriending the offender or blocking their posts so that they were no longer exposed to them . Social media and the future of open debate 20 [ 6 ] When I start realizing some one 's option is very divergent , especially when it contains any kind of prejudice , I tend to remove that person . [ Q26-39 ] [ 7 ] [ know someone who posts quite racist comments . I can not defriend her so have simply adjusted things so I never see her posts . [ Q26-2 ] These acts of avoidance constitute cases of context design , based on users ’ experiences of the site over time . In [ 6 ] , the user suggests that their decision to ‘ remove ’ someone from their newsfeed is based on their evaluation of that person ’ s political stance as markedly different from their own , as evidenced in their repeated posts . As suggested in [ 7 ] , users also take into account the nature of their connection with the offender ; in this case , [ 7 ] appears not to have taken more radical action than blocking an offender ’ s post because she is someone they ‘ can not defriend ’ . In other words , the decision about what sort of action to take depends to some extent on the nature of the tie , with close or strong ties prompting different behaviour to distant or weak ties . The variety of ties between individuals within a network on Facebook — and the fact that the audience for any one post on Facebook will comprise people with very different ties to the poster — is a crucial aspect of intradiversity . The importance of the nature of particular social ties in determining how people respond to being offended is also evident in the following example in which the respondent claims to try to resolve disagreements only with close or ‘ real ’ friends . [ 8 ] If I find someone is continually posting things that I find distasteful or against my beliefs , and I have no genuine friendship with them ( i.e . they 're an acquaintance from Social media and the future of open debate 21 junior school ) I 'll defriend them . If they 're my real friends we 'll talk in person about disagreements of views . [ Q26-30 ] The examples so far belie some of the complexity inherent in such social judgements . In [ 9 ] below , the user points to the polycentric nature of contemporary life ( Blommaert , 2005 ) and the negotiation involved in orienting to different contexts of value as these are manifest in different situations ; as someone from a Jewish family , s/he is offended by comments that a ‘ good friend ’ makes ; but their friendship and the fact that the offender is ‘ thoughtful and informative ’ in other respects mitigates against the need to unfriend them . [ 9 ] I have a good friend who occasionally posts anti-semitic comments , and this can be offensive to me as my family is Jewish . I have considered defriending him but don't because many of his other posts are quite thoughtful and informative . [ Q26-65 ] Furthermore , judgements as to whether offenders can be unfriended or blocked are made not only on the basis of the underlying relationship with the offender , but also on a myriad of other factors implicated in their relationship . In [ 10 ] , the user suggests that they can not unfriend people whose religious views they disagree with because of the wider offline context in which they know them — the workplace — and their desire not to unsettle the working environment . [ 10 ] Usually it [ disagreement or conflict ] is with facebook friends that I need to be friends with to keep the peace at work . They tend to be very conservative Christians with very Social media and the future of open debate 22 dichotomous from my ideology etc . I usually just ask to unsubscribe from their posts . [ Q26-9 ] One final example involves our interviewee Heather who reported being offended such that ‘ I am getting to the point where I just take things out my news feed ’ but who also claimed that another consideration guiding her decisions as to how to respond to offensive posts lay in her judgement as to how the offender was likely to respond to a confrontation ( whether she judges ‘ there is a chance of making a comment and educating them ’ ) , based presumably on her knowledge of the individual and their shared communicative history . As with Jessica , Heather ’ s phrase , ‘ getting to the point where ’ gives a sense of how repeated exposure to particular types of behaviour feeds into emerging media ideologies and thus future behaviour . In these examples , we can see that acts of context design on Facebook are shaped not only by people ’ s experience of being offended on the site , and their assessment of offenders ’ ideological or political viewpoints , but also the nature of their relationship with the offender , their shared communicative history , the wider contexts in which they interact , the overlapping networks to which they belong , and their assumptions about the likely future scenarios that confrontation would lead to . In most cases , respondents report a tendency to avoid conflict — overwhelmingly they claim not to engage in debate , for example — and instead to deal with the perceived offence by reducing the likelihood of future offences by blocking that user ’ s posts or removing them as a Friend . In this incremental fashion , they are likely to inadvertently redesign their newsfeed in a way which renders it increasingly inoffensive and accurate ( to their mind ) . Offending Others Social media and the future of open debate 23 In relation to the question of offending others , 32 % ( n=41 ) respondents claimed that something they had posted on Facebook had offended someone else . When prompted , the respondents talked of self-censoring to ensure they do not inadvertently provoke conflict themselves . This often involves careful scrutiny of posts , and it is driven , in the main , by three dominant motivations . The first occurs where users avoid particular behaviour because they have been offended by it in the past : [ 11 ] I would n't write poor me ' messages because I 've found other people doing that really annoying ! I think Facebook is a good tool for communicating and sharing but if you have real problems seek help in the real world . [ Q3 1-24 ] In [ 11 ] , for example , the user avoids writing a particular kind of post ( ‘ poor me ’ messages ) because they find it annoying when others do it . This reactive practice — to avoid engaging in behaviour which a user has seen and disliked in other people ’ s posts — was a recurring theme across the data . The second , related motivation is for users to avoid a certain behaviour because they have seen over time that it has offended others when people have engaged in it . [ 12 ] i 'm careful anyway , but yeah people getting upset has made me more cautious . [ Q31-10 ] The final motivation relates to examples where users modify their behaviour in direct response to their having offended others in the past . In some cases , the change in behaviour can be specifically attributed to a particular instance . Social media and the future of open debate 24 [ 13 ] A cousin publicly posted a meme-style pic of Jesus casually throwing the word `` fuckin' into a public statement . I commented telling her I 'd unfriend her if she was going to keep doing that kind of thing . She got really upset that I 'd commented that way on her wall . I deleted my comment , apologized , and thought a lot more about what should be said and done in private and what in public . [ Q26-28 ] These examples also illustrate the complex way in which communicative norms are organised on the site : evident in [ 13 ] , for instance , is the user ’ s ( growing ) realisation that actions that may be appropriate “ in private ’ may not be well received in the relatively more public space of someone ’ s wall . The comments suggest that these are emergent norms which users pick up through interaction on the site . Facebook as a Space for Debate Another aspect of people ’ s ideas about the site that was often mentioned by respondents was that Facebook is simply not a good place for debate . Jacob , for example , argued in interview that the site is not suited to ‘ fruitful genuine ’ debates , and instead ‘ I would much rather do it face to face ’ , and similar points were made by other respondents : [ 14 ] I have a particularly hard time with pro-gun posts . ... I really , really wish guns were significantly less accessible and less glorified in American culture . Still , I do n't think Facebook is really the place that people chose to listen to opposing views , so I usually ignore posts of that nature . [ Q26-4 ] Social media and the future of open debate 25 A related belief is that the affordances of digital communication — the fact that people are not co- present and must rely on graphic means to signal attitude and intention — limit the effectiveness of Facebook as a place for debate . Heather , for example , felt : [ 15 ] you can misconstrue certain comments ... I mean the obvious thing about tone , about the way we write something . I say something that is in my head or if people know me really well they would know how I would say it and respect me for saying it , whereas in that situation [ Facebook ] it has lost me friends . [ Heather , interview ] The observation that people tend not to think of Facebook as an appropriate place for debate is supported by the handful of people who claimed to have responded to an offence in a context other than on Facebook : [ 16 ] Nothing happened as a result other than that I ranted about it to someone . I took no action on Facebook . [ Q26-38 ] These beliefs about Facebook may go some way towards explaining the tendency for users to report not responding to offensive posts by challenging the offender or engaging them in debate . If so , then it is a belief that likely contributes to the creation of a filter bubble-like effect , as users instead seek to remove divergent views from their newsfeeds . Conclusion : Context Design and Filter Bubbles Social media and the future of open debate 26 The findings from our research project show , firstly , that Facebook , at the time of the study , was being used as a place for sharing news stories and opinions about them , and airing political views ; and , importantly , that viewpoints around political and other contentious issues were among the most likely cause of offence for users . The likelihood that the voicing of such opinions will offend others can be explained with reference to various affordances and features of social media interactions , among them the intradiverse nature of most Facebook users ’ potential audience ; that is , the fact that despite some similarities in class , education levels or values , Friends are likely to diverge in their thinking around particular issues , given the way in which people orient to multiple , often competing centres of influence . What is important is that , because of their intradiverse networks , users are coming across divergent opinions and alternative viewpoints , as well as information they deem to be inaccurate or false , despite the Facebook personalisation algorithm working to feed them posts which are likely to appeal most to them — and which in media commentary is often interpreted as being those which consist of news stories , opinions and values with which they are likely to agree . Secondly , the ways in which most participants reported responding to acts of unintentional offence show how many people purposefully avoid conflict on Facebook , in part because of their attempts to navigate and manage the complex set of social relations which make up their online audience . Through these actions , they create and maintain a sense of online conviviality — a term we use to describe the desire for non-confrontational co-existence through negotiating or ignoring difference and avoiding contentious debate ( for uses in non-online contexts see , for example , Blommaert 2013 ) . As an interactional principle , online conviviality on Facebook appears to encourage users not to challenge or engage with difference ( with what they see as inaccurate or offensive material ) , but to quietly ignore it . Another apparent reason behind Social media and the future of open debate 27 people ’ s lack of engagement with contentious views or disagreeable stories was their explicitly expressed opinion that Facebook was not ideally suited for effective debate . This mix of media ideologies about Facebook thus leads people to filter out of their newsfeed views and information with which they do not agree . Throughout our analysis , we have shown how this process can be theorised through the concept of context design . Context design posits that social media users draw on particularly complex sets of contextual variables in designing a context for each post . We have seen how posters of content on Facebook draw not only on their ideas about the purpose and communicative norms of the site , but also on the particular nature of their relationships with different people and their shared communicative histories , the wider offline contexts with which different interlocutors are associated , the overlapping social networks within which both the poster and their audience operate , and their previous experience on the site . When a user offends or is offended , they draw on consideration of all these variables in shaping their future behaviour , which in tum contributes towards determining the nature of communication on the site . Participants in our study expressed some awareness of this , with Jacob stating : [ 17 ] the topics that are chosen actually end up shaping what Facebook is for many people , so I think in choosing to talk about different topics , that becomes their Facebook experience [ Jacob , interview ] The idea that users ‘ control [ their own ] experience ’ , is also one of the principal values Facebook advertises for its newsfeed : ‘ [ u ] ltimately , you know what ’ s most meaningful to you - and that ’ s why we ’ ve developed controls so you can customize what you see . Features such as “ unfollow , ” Social media and the future of open debate 28 “ hide ” and “ see first ” help you design your own experience ’ ( Facebook , 2016c , italics added ) . Actions such as these are noted by the algorithm , which reads them as ‘ signals that you ’ re [ more or ] less interested ’ in seeing similar content in future , and it is this aspect of the process that has been highlighted in public and academic discussions around filter bubbles and fake news . But our research draws attention to the role that user agency plays in that process , showing that people ’ s role in shaping their own newsfeed can be explained in terms of context design . An important point in this respect is the fact that news stories which originate with established news media is circulated by and because of social relations — in other words , the media is mediated by the friendships you have with the people in your network . Although , as was noted above , stories are also circulated via the trending topics feature , and in some cases via advertisements ( those for news outlets themselves , for example ) , the core dynamic at the heart of Facebook is still social sharing , which results in the fact that material in your newsfeed , whatever the original source , has , as part of the context in which you view it , associations with the person who shared it . We argue therefore that this focus on people ’ s actual communicative behaviours is a vital counterpart to the quantitative work being done around the influence of the algorithm on information flows . Our approach is aimed at assisting understanding of the ways that online behaviour is shaped not solely — or even primarily — by the technology , but by the beliefs that users have about what the technology is best suited for , how they use it for this purpose , and the norms they develop in doing this . It is ultimately these beliefs that lead to the construction of an online social space in which false news can — or can not — easily spread . Social media and the future of open debate 29 References Androutsopoulos , J . ( 2014 ) Languaging when contexts collapse : audience design in social networking . Discourse , Context and Media , 4-5 , 62-73 . Androutsopoulos , J. , & K. Juffermans ( 2014 ) Digital language practices in superdiversity : introduction . Discourse , Context and Media , 4-5 , 7-18 . Androutsopoulos , J. , & A. Staehr ( 2017 ) Moving methods online : researching digital language practices . In Creese , A. and A. Blackledge ( Eds ) The Routledge handbook of language and superdiversity . Abingdon : Routledge . Bauman , R. , & C.L . Briggs ( 1990 ) Poetics and performance as critical perspectives on social life . Annual Review of Anthropology , 19 , 59-88 . Bell , A . ( 1984 ) ‘ Language style as audience design ’ Language in Society , 13/2 , 145-204 . Benton , J . ( 2016 ) The forces that drove this election ’ s media failure are likely to get worse , Nieman Journalism Lab , 9 November , available at www.niemanlab.org/2016/1 1/the- forces-that-drove-this-elections-media-failure-are-likely-to-get-worse/ Blommaert , J . ( 2005 ) Discourse : a critical introduction . Cambridge : Cambridge University Press . Blommaert , J . ( 2013 ) Ethnography , superdiversity and linguistic landscapes : Chronicles of complexity . Bristol : Multilingual Matters . boyd , d. ( 2001 ) Taken out of context : American teen sociality in networked publics . Unpublished doctoral thesis , University of California , Berkeley . Bozdag , E. , & van den Hoven , J . ( 2015 ) Breaking the filter bubble : democracy and design . Journal of Ethics and Information Technology , 17/4 , 249-265 . Social media and the future of open debate 30 Duranti , A. , & C. Goodwin ( Eds ) ( 1992 ) Rethinking context : Language as an interactive phenomenon . Cambridge : Cambridge University Press . El-Bermawy , M. M. ( 2016 ) Your filter bubble is destroying democracy , Wired , 18 November , www.wired.com/2016/1 1/filter-bubble-destroying-democracy/ Facebook ( 2016a ) . Retrieved from : http : //newsroom.fb.com/news/2016/12/news-feed-fyi- addressing-hoaxes-and-fake-news/ ( accessed 20 December , 2016 ) Facebook ( 2016b ) Retrieved from : http : //newsroom.fb.com/company-info/ ( accessed 20 December , 2016 ) Facebook ( 2016c ) News Feed Values . Retrieved from : https : //newsfeed.fb.com/values/ Flaxman , S. , Goel , 8S . & Rao , J . ( 2016 ) Filter bubbles , echo chambers , and online news consumption . Public Opinion Quarterly , doi:10.1093/poq/nfw006 Garrett , R. K. ( 2009 ) Echo chambers online ? Politically motivated selective exposure among internet news users . Journal of Computer-Mediated Communication , 14 , 265-85 . Garrett , R. K. ( 2016 ) Facebook ’ s problem is more complicated than fake news . Scientific American , 17 November . Retrieved from : www.scientificamerican.com/article/facebook- s-problem-is-more-complicated-than-fake-news/ Gershon , I . ( 2010b ) Media ideologies : an introduction . Journal of Anthropology , 20/2 , 283-293 . Gibbs , S. ( 2016 ) Google alters search autocomplete to remove 'are Jews evil ’ suggestion , The Guardian , 5 December . Retrieved from : www.theguardian.com/technology/20 16/dec/05/google-alters-search-autocomplete- remove-are-jews-evil-suggestion Goel , S. , Mason , W , & Watts , D. J . ( 2010 ) Real and perceived attitude agreement in social networks . Journal of Personality and Social Psychology , 99/4 , 611-621 . Social media and the future of open debate 31 Gottfried , J. , & Shearer , E. ( 2016 ) News use across social media platforms 2016 . Pew Research Center , 26 May . Retrieved from : www.journalism.org/20 16/05/26/news-use-across- social-media-platforms-2016/ Jones , R.H. ( 2015 ) Surveillance . In Georgakopoulou , A. and T. Spilioti ( Eds ) The Routledge handbook of language and digital communication ( pp . 408-411 ) . Abingdon : Routledge . Madianou , M. , & D. Miller ( 2012 ) Polymedia : towards a new theory of digital media in interpersonal communication . /nternational Journal of Cultural Studies , 16/2 : 169-187 . Marwick , A. , & boyd , d. ( 2014 ) Networked privacy : how teenagers negotiate context in social media . New Media & Society , 16/7 , 1051-1067 . Pariser , E. ( 2011 ) The filter bubble : What the Internet is hiding from you . London : Penguin . Pressman , A . ( 2016 ) Facebook resists label as media company , Fortune , 25 Oct. Retrieved from : http : //fortune.com/2016/10/25/facebook-resists-media-company/ Read , M. ( 2016 ) Donald Trump won because of Facebook . New York Magazine , 9 Nov. Retrieved from : http : //nymag.com/selectall/2016/11/donald-tramp-won-because-of- facebook . html Schiefflin , B. , & R. Doucet ( 1998 ) The “ real ” Haitian Creole : ideology , metalinguistics , and orthographic Choice . In Schieffelin , B. K.A . Woolard , & P.V . Kroskrity ( Eds ) Language ideologies : Practice and theory ( pp . 285-316 ) . New York : Oxford University Press . Sharad , G. Winter Mason , W. , & Watts , D. J . ( 2010 ) Real and perceived attitude agreement in social networks . Journal of Personality and Social Psychology , 99 , 611-21 . Solon , O . ( 2016 ) Facebook ’ s failure : did fake news and polarized politics get Trump elected ? The Guardian , 10 November . Retrieved from : www.theguardian.com/technology/20 16/nov/10/facebook-fake-news-election- Social media and the future of open debate 32 conspiracy-theories ? Stinchcombe , A. L. ( 2010 ) Going to extremes : How like minds unite and divide . Contemporary Sociology : A Journal of Reviews , 39 , 205-206 . Sunstein , C. R. ( 2007 ) . Republic.com 2.0 . Princeton : Princeton University Press . Tagg , C. , & P. Seargeant ( 2016 ) Negotiating social roles in semi-public online contexts . In Leppanen , S. , 8 . Kytéla , S $ . Peuronen , H. Jousmaki , & E. Westinen ( Eds ) Discourse and identification : diversity and heterogeneity in social media practices . Abingdon : Routledge , pp . 211-234 . Tavernisedec , S. ( 2016 ) As fake news spreads lies , more readers shrug at the truth , New York Times . Retrieved from : http : /Avww.nytimes.com/2016/12/06/us/fake-news-partisan- republican-democrat.html Van Leeuwen , B . ( 2010 ) Dealing with urban diversity : promises and challenges of city life for intercultural citizenship . Political Theory , 38 , 631-657 . Viner , K. ( 2016 ) How technology disrupted the truth , 7he Guardian , 12 July . Retrieved from : www.theguardian.com/media/20 16/jul/12/how-technology-disrupted-the-truth/ Zuckerberg , M. ( 2016 ) 11 November . Retrieved from : www .facebook.com/zuck/posts/10103253901916271 Mitigating the Filter Bubble while Maintaining Relevance : Targeted Diversification with VAE-based Recommender Systems Zhaolin Gao University of Toronto Toronto , ON , Canada zhaolin.gao @ mail.utoronto.ca Mohamed Reda Bouadjenek Deakin University Geelong , VIC , Australia reda.bouadjenek @ deakin.edu.au Ron Bodkin Vector Institute for Artificial Intelligence Toronto , ON , Canada rbodkin @ gmail.com ABSTRACT Online recommendation systems are prone to create filter bubbles , whereby users are only recommended content narrowly aligned with their historical interests . In the case of media recommenda- tion , this can reinforce political polarization by recommending topical content ( e.g. , on the economy ) at one extreme end of the political spectrum even though this topic has broad coverage from multiple political viewpoints that would provide a more balanced and informed perspective for the user . Historically , Maximal Mar- ginal Relevance ( MMR ) has been used to diversify result lists and even mitigate filter bubbles , but suffers from three key drawbacks : ( 1 ) MMR directly sacrifices relevance for diversity , ( 2 ) MMR typi- cally diversifies across all content and not just targeted dimensions ( e.g. , political polarization ) , and ( 3 ) MMR is inefficient in practice due to the need to compute pairwise similarities between recom- mended items . To simultaneously address these limitations , we propose a novel methodology that trains Concept Activation Vec- tors ( CAVs ) for targeted topical dimensions ( e.g. , political polariza- tion ) . We then modulate the latent embeddings of user preferences in a state-of-the-art VAE-based recommender system to diversify along the targeted dimension while preserving topical relevance across orthogonal dimensions . Our experiments show that our Targeted Diversification VAE-based Collaborative Filtering ( TD- VAE-CF ) methodology better preserves relevance of content to user preferences across a range of diversification levels in comparison * Affiliate to Vector Institute of Artificial Intelligence , Toronto Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . Copyrights for components of this work owned by others than the author ( s ) must be honored . Abstracting with credit is permitted . To copy otherwise , or republish , to post on servers or to redistribute to lists , requires prior specific permission and/or a fee . Request permissions from permissions @ acm.org . SIGIR ’ 22 , Fuly 11-15 , 2022 , Madrid , Spain © 2022 Copyright held by the owner/author ( s ) . Publication rights licensed to ACM . ACM ISBN 978-1-4503-8732-3/22/07 ... $ 15.00 https : //doi.org/10.1145/3477 495.353 1890 Tianshu Shen University of Toronto Toronto , ON , Canada tina.shen @ mail.utoronto.ca Isaac Waller University of Toronto Toronto , ON , Canada walleris @ cs.toronto.edu Zheda Mai Optimy AI Toronto , ON , Canada zheda.mai @ mail.utoronto.ca Ashton Anderson University of Toronto Toronto , ON , Canada ashton @ cs.toronto.edu Scott Sanner * University of Toronto Toronto , ON , Canada ssanner @ mie.utoronto.ca to both untargeted and targeted variations of Maximum Marginal Relevance ( MMR ) ; TD-VAE-CF is also much more computationally efficient than the post-hoc re-ranking approach of MMR . CCS CONCEPTS + Information systems — Information retrieval diversity ; Recommender systems ; « Computing methodologies — Neu- ral networks . KEYWORDS Recommendation Systems , Filter Bubble , Diversity ACM Reference Format : Zhaolin Gao , Tianshu Shen , Zheda Mai , Mohamed Reda Bouadjenek , Isaac Waller , Ashton Anderson , Ron Bodkin , and Scott Sanner . 2022 . Mitigating the Filter Bubble while Maintaining Relevance : Targeted Diversification with VAE-based Recommender Systems . In Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval ( SIGIR '22 ) , Fuly 11-15 , 2022 , Madrid , Spain . ACM , New York , NY , USA , 8 pages . https : //doi.org/10.1145/3477495.3531890 1 INTRODUCTION Online recommender systems are prone to create filter bubbles [ 4 , 5 , 14 ] , where users are increasingly recommended content narrowly aligned with their historical interests due to a feedback loop be- tween data collection and recommendation processes [ 12 ] . While the impacts of these recommendation feedback loops are some- what nuanced ( e.g. , in some cases they can increase homogeneity due to popularity bias in recommender systems [ 3 , 6 ] ) , in the case of media recommendation , it is observed that filter bubble effects arising from feedback loops may restrict user perspectives and viewpoints [ 1 , 13 ] . As a case in point , we consider the row for VAE- CF ( a state-of-the-art recommender system [ 10 ] ) in Figure 1 , which shows a Republican-shifted distribution of politically polarized Red- dit community content recommendations ( details in Section 3 ) for a user that has historically consumed Republican-oriented content . U-MMR ( 0.4 ) U-MMR ( 0.8 ) VAE-CF TD-VAE-CF ( 0.8 ) TD-VAE-CF ( 0.4 ) TD-VAE-CF ( 0.2 ) ~0.06 004 “ oe ovo owe 004 008 Republican < > Democratic Figure 1 : Top 50 recommendations for Republican-oriented users using a Reddit dataset . The x-axis represents the politi- cal spectrum of the recommendations ; scores are computed by projecting the item embeddings on the Concept Activation Vector ( CAV ) aligned with the Republican-Democratic politi- cal spectrum ( Section 3 ) . The recommendations for UUMMR ( Section 2 ) and TD-VAE-CF ( Section 3 ) are computed using 3 different 1 diversity levels ( 0.2 , 0.4 , 0.8 ) , where diversity increases as A decreases . Unlike TD-VAE-CF , standard MMR for diversification ( U-MMR ) is unable to improve diversity ( content balance ) in the political spectrum . ou , “ S300 es ee -e- UMMR . < n . wee ~sLL 0 e+ TD-VAE-CF 0.110 4 se * . ween a , g 0.109 | me . ~~ s — ~ , ® o108 * ss , a ‘ * s ~ 8 0.107 4 s 0.106 4 ‘ a 0.105 4 N 1 OB 0.6 a4 02 A Figure 2 : NDCG @ 50 vs. A for TD-VAE-CF and U-MMR . A val- ues are taken from ( 1 , 0.2 , 0.4 , 0.6 , 0.8 ) . However , considering that topical content of user interest such as “ the economy ” may be represented in a variety of Reddit communi- ties spanning the political spectrum , one might ask whether it is possible to mitigate this filter bubble effect by shifting the political coverage distribution to a more neutral or balanced position while preserving recommendation relevance for the user ? Historically , Maximal Marginal Relevance ( MMR ) [ 2 ] ( cf . Sec- tion 2 ) has been used to diversify content rankings , including recent methods aiming to mitigate filter bubble effects [ 11 ] . While such re- sult list diversification may decrease quantitative metrics of recom- mendation performance , user studies have shown that diversity can also improve overall satisfaction with recommendation lists [ 20 ] . However , the drawback of post-hoc reranking methods like MMR is their independent treatment of relevance and diversity [ 19 ] that inherently trades off one for the other . Furthermore , MMR typically diversifies across all content and not just targeted dimensions ( e.g. , political polarization ) . Finally , MMR ’ s post-hoc reranking approach has quadratic time complexity in terms of the ranked list size . In this paper , we propose a simple but empirically effective ap- proach to address all of the aforementioned deficiencies of MMR . Our Targeted Diversification VAE-CF ( TD-VAE-CF ) methodology intrinsically dovetails with the latent user and item representations in state-of-the-art VAE-based collaborative filtering ( VAE-CF ) [ 10 ] . Specifically , we train Concept Activation Vectors ( CAVs ) [ 7 ] for targeted diversification dimensions ( e.g. , political spectrum ) and use these to modulate latent embeddings of user preferences in VAE-CF to diversify along that targeted dimension while preserving topical relevance across orthogonal dimensions . One can observe in Figure 1 that TD-VAE-CF clearly shifts the political polarization distribution to a more neutral range as diversi- fication strength increases ( A decreases ) in comparison to standard untargeted MMR ( U-MMR ) , which is unable to shift the political spectrum ; later we will see that a targeted version of MMR ( T-MMR ) performs even worse . Furthermore , as evidenced in Figure 2 , the NDCG measure of recommendation relevance does not drop as steeply for TD-VAE-CF as it does for U-MMR when diversification strength is increased . We present more comprehensive experiments in Section 4 that confirm these results in a variety of additional settings , where we additionally show that the latent modulation approach of TD-VAE-CF induces low computation overhead in comparison to the quadratic time complexity of MMR . In summary , TD-VAE-CF combines CAVs with VAE-based collab- orative filtering to enable a novel targeted ( e.g. , political spectrum ) diversification approach for recommendation that efficiently and selectively mitigates filter bubble effects while preserving relevance . 2 MAXIMAL MARGINAL RELEVANCE ( MMR ) As one of the most popular ranked list diversification methods in the literature and our baseline for comparison , we briefly review Maxi- mal Marginal Relevance ( MMR ) [ 2 ] as it applies to the recommenda- tion setting . Given a set I of items to select s ; € F , we aim to build an optimal subset of items Sh c £ ( where Isp =kandk < |£ ] ) rel- evant to a given user wu . For computational efficiency , we will build Sj in a greedy manner by choosing the next optimal selection s ; , given the previous set of optimal selections S ’ _ , = { s ] , -- +.s ; _ , } and recursively defining with S ; = S ; _ , U { s , } . MMR greedily populates the result set according to the following criteria : sy = argmax [ ASim ( u , sg ) — ( 1 — A ) Sime ( si , s¢ ) ] ( 1 ) steD\\St , Here , similarity metric Sim , measures user-item relevance ( i.e. , recommendation score ) , metric Simz measures item-item similarity , and the parameter A ¢€ [ 0 , 1 ] trades off relevance and diversity . In the case of s } , the maximization term is vacuous ( =0 ) . From an inspection of Equation 1 , one can easily identify the key weaknesses of MMR that we seek to address in this work : ( 1 ) it directly sacrifices relevance to achieve diversity [ 19 ] ; ( 2 ) in its stan- dard form , the item diversification Sim , is generic and untargeted ( U-MMR ) [ 11 ] though we later define a targeted variant ( T-MMR ) for additional comparison ; ( 3 ) it requires a quadratic complexity computation of pairwise similarity measures between items . 3 al coor yao # # i roe ] Is ] # DemocraticSocialism 3 ab a pond poe '' + + fy Ta MaskrumpSupporters # republicans # ConservativesOnly ~ ( Tt ~\\ “ LH yeEEeEPE IT ] ( a ) Prediction TePEEEP ET | ( © ) Re-prediction by ( b ) Updating user representation Figure 3 : Step-by-step flow of TD-VAE-CF architecture . ( a ) We first obtain the user latent preference representation from the off-the-shelf VAE-CF model . ( b ) Next we find the CAV of two subtopics and update the user latent representation . ( c ) Re-predict to obtain CAV-shifted user preference ratings . 3 METHODOLOGY VAEs for Collaborative Filtering : The impressive generalization and reconstruction ability of the VAE model is particularly attrac- tive to the recommendation community and has inspired many recent deep learning-based recommendation models [ 9 , 10 , 16 ] . Fig- ure 3 ( a ) shows the basic VAE-CF model for recommendation , where a ( sparse ) vector of user preferences 7 , over n items are encoded by the VAE [ 8 ] into a Gaussian-distributed latent preference embed- ding Z , of width d. Z , is then stochastically decoded to a ( dense ) reconstruction 7 , that generalizes user preferences to unobserved items . Formally , VAE-CF optimizes the following objective over the respective parameters ¢ and @ of the encoder and decoder : Miloge Gu ) = 7 [ Egy ult ) Hogpo Fu l2u ) ] - KElgg Zu lFu ) lp Eu ) | ] . . ( 2 ) In practice , the approximation of user distribution qg ( Zul7u ) is usually a Normal distribution with learned parameters jz , and Dy . In our implementation , we use a one-layer decoder such that the weights of the decoder can be directly used as item embeddings , yenxd where the i “ vector X ; is the jth weight of the decoder that corresponds to the i item and n is the number of items . From the latent embedding space , we can obtain the user embeddings as zmxd where the u ‘ vector Z , , is the latent preference embedding Z , of user u and m is the number of users . Concept Activation Vectors : Existing work for conversational rec- ommender systems [ 17 ] leveraged the CAV [ 7 ] methodology with the VAE-CF framework to determine the alignment of keyphrase embeddings with user embeddings and applied a Bayesian update to user beliefs after each critique [ 17 ] . Here , we propose two methods for generating CAVs : I-CAVs and U-CAVs . We define a CAV as the normal to a hyperplane that separates two opposing subtopics ( e.g . Republican vs. Democratic ) in the embedding space as shown in Figure 3 ( b ) . For I-CAVs , we sample k items from each subtopic to form two subsets of items , Jj , and Ti . from decoder matrix X ” * @ , To obtain the activation vector uj € Re , multiple linear classifiers are trained to distinguish G , ! and Fj , ” and the averaged classifier is used as dj . U-CAVs sample from the user embeddings , gmxd to form two subsets of users , U , ! Table 1 : Dataset statistics . Dataset | # User # Item # Interactions Density Yelp 7,000 4,997 151,456 0.433 % Reddit Politics | 9849 9,892 449,660 0.462 % Reddit Gender | 9779 — 9,892 365,307 0.377 % and 24 , ” . Similarly , the activation vector , dy , is generated using the averaged linear classifier between Z { , ' and U , ” . Targeted Diversification VAE-CF ( TD-VAE-CF ) : TD-VAE-CF applies a targeted CAV direction to update the user-embeddings from VAE-CF in the latent space . After we generate CAV ¢ using either user or item embeddings , we update a user-embedding by subtracting its projection on the CAV with a parameter A : 3 = Zu * a . 2u=2u~ ( 1 Nae ( 3 ) where Z , is the updated user embedding for user u . As shown in Figure 3 ( b ) , the updated user embedding moves closer to the hyperplane that separates two subtopics . The parameter A is taken from [ 0 , 1 ] which controls the degree of update . Finally , the updated user-embedding is decoded using the one-layer decoder in VAE-CF to the ( dense ) reconstruction , has where the user preference rating for the opposing subtopic would increase as shown in Figure 3 ( c ) . 4 EXPERIMENTS We now experimentally compare the recommendation and diversifi- cation quality of our proposed TD-VAE-CF with a baseline VAE-CF model ( i.e. , TD-VAE-CF with A = 1 ) and MMR-diversified variants of VAE-CF to address the following research questions : ¢ RQ1 - Relevance vs. Diversity : Is TD-VAE-CF able to maintain relevance and achieve diversity better than MMR ? ¢ RQ2 - Targeted Diversification : Does TD-VAE-CF effec- tively distribute items in the targeted latent direction ? ¢ RQ3 - Running Time : Is TD-VAE-CF efficient vs. MMR ? Appendix A provides a methodology and experimental results for a variation of the TD-VAE-CF methodology to “ flatten ” the filter bubble rather than “ neutralize ” it as we currently do in Section 3 . All code to reproduce the experimental results is available on github. ! 4.1 Datasets We conduct experiments on two datasets : Reddit for recommenda- tion of communities , and Yelp for recommendation of restaurants . We follow the same preprocessing steps as in previous work [ 15 , 18 ] and randomly select 80 % for training , 10 % for validation , and 10 % for testing . For Reddit , we select two spectra to diversify along with two subtopics for each spectrum : politics ( Republican vs. Demo- cratic ) and gender ( Men vs. Women ) . Since the Reddit communities are sparse and there are , on average , less than ten communities cor- responding to one subtopic , U-CAVs are used for Reddit by selecting the users that have interacted exclusively with the communities within one subtopic in the spectrum ( e.g. , DemocraticSocialism for ‘ https : //github.com/ZhaolinGao/TD-VAE-CF — UMMR Republican vs. Democratic Men vs. Women —— TD-VAE-CF — VAE-CF Deep Fried vs . Salad Vegetarian vs. BBQ .____ -- e-_ a 0.15 Te 0.35 { eS c 0404 `` a2 a Oa os Ons 0 Se . 2 ‘ a8 034 * . 0.304 ‘ ona 2 0.354 bos 0.10 4 ON oa . . o J 080 eos 0.25 4 & 930 2 | na 08 B06 og sos wv “ ‘ o ° os aa 0.05 4 & - » 0257 OG _ -- -- ® `` Ge ani been 02 A= . 0.207 92 y= ee =e . e 0.40 4 a 4 0.2004 Joo ~ we e -- * 0.35 a 0.20 . 0 a : a2 0.4906 06 0.2 '' @ 04 0.30 4 ons us G 0354 ose 0.30 4 eos oss | 06 o2s 4 wey = 04 06 og a4 ee ° : 08 . 0.06 ue % asi ] 0.25 ce % on Ant ® soe 0.304 , ° ? _ -- 0.20 4 e 2 0.10 4 o ? , a2 © 0.20 + # oz A= A=1 + + + . + + + + r + + + + 0.1025 0.1050 0.1075 0.1100 0.1125 0.07 0.08 0.09 0.060 0.065 0.070 0.055 0.060 0.065 0.070 NDCG @ 50 Figure 4 : NDCG @ 50 vs. S-Precision and HMSP for four spectra of two datasets . 1 values for TD-VAE-CF and U-MMR are ( 0 , 0.2 , 0.4 , 0.6 , 0.8 , 1 ) and ( 0.2 , 0.4 , 0.6 , 0.8 , 1 ) respectively . Smaller 4 values ( higher diversity ) are marked with higher opacity . U-MMR ( 0.4 ) U-MMR ( 0.8 ) VAE-CF TD-VAE-CF ( 0.8 ) TD-VAE-CF ( 0.4 ) TD-VAE-CF ( 0.2 ) -0.10 0.05 0.00 0.05 o10 BBQ < > Vegetarian Figure 5 : Top 50 recommendations for BBQ lovers using Yelp dataset . X-axis represents the meat consumption spectrum of the recommendations . The scores are computed by project- ing the item embeddings on the Concept Activation Vector ( CAV ) . The recommendations for TD-VAE-CF and U-MMR are computed using three different 4 values ( 0.2 , 0.4 , 0.8 ) . U-MMR fails to diversify along the Vegetarian vs. BBQ di- mension while TD-VAE-CF can equally balance such content . Democratic and Republicans for Republican ) . Similarly , the two spec- tra we choose for Yelp are health ( Deep Fried vs . Salad ) and meat consumption ( Vegetarian vs. BBQ ) . The labels for each restaurant are generated using the ten most common key phrases in the user reviews ( e.g . DeepFried , BBQ , etc. ) . We use I-CAVs for Yelp since there is a sufficient number of items for each subtopic to generate a representable CAV . Since there is no need to perform targeted diversification on users who haven ’ t interacted with the targeted direction , we used two subsets of Reddit dataset on politics and gender . The statistics for the datasets are summarized in Table 1 . 4.2 Metrics We evaluate the relevance of top-k ranking performance using Nor- malized Discounted Cumulative Gain ( NDCG ) as done in previous work [ 10 , 16 ] . The diversity of top-k items along the targeted spec- trum is evaluated using S-Precision [ 19 ] and Harmonic Mean of Subtopic Probabilities ( HMSP ) since these two metrics can capture the distribution difference of the two ends of the targeted spectrum . NDCG : NDCG is a measure of ranking quality using Discounted Cumulative Gain ( DCG ) . Formally , it is defined as : rel ; NDCG @ K = DCG @ K ( 4 ) .g2 ( i + 1 ) IDCG @ K K DCG @ K = @ 2d lo i=1 where rei ; is the graded relevance score of the i ? ” itemandI DCG @ K is ideal discounted cumulative gain . S-Precision : S-Precision reflects the number of subtopics covered in the recommended items and is derived from S-Recall that mea- sures the number of subtopics covered among the top-k items : UX_ subtopics ( d ; S-Recall @ K = [ Ming subtopics dil ( 5 ) nA where n , is the number of subtopics . If S is a recommendation system , we define minRank ( S , r ) as the minimal rank K at which the ranking produced by S has S-Recall r. Then , we can define : minRank ( Sopt , 1 ) minRank ( S , r ) ° ( 6 ) S-Precision @ r = where Sopr is a system that produce the optimal ranking ( ie. , minRank ( Sopr , 1 ) is the smallest K for a S-Recall r ) . Since we focus on two subtopics , we use S-Precision @ 1 such that the minRank ( S , r ) would be the minimum rank that covers both subtopics . Harmonic Mean of Subtopic Probabilities ( HMSP ) : Harmonic Mean of Subtopic Probabilities ( HMSP ) measures the empirical prevalence of each subtopic in the recommendation list ; we choose the harmonic mean since it is strictly greater than or equal to the minimum subtopic probability and thus guarantees at least that much coverage for each subtopic . In contrast , the arithmetic mean could be relatively high even if one subtopic probability is 0 . Given empirical probabilities p4 and pg of subtopics A and B in the recommendation list , HMSP = 2Pape PAtPB 4.3 Methods Compared We compare the following ( diversified ) recommendation methods : e TD-VAE-CF : Our Targeted Diversification VAE-CF as de- fined in Section 3 with U-CAVs ( Reddit ) and I-CAVs ( Yelp ) . Gaussian negative log-likelihood loss is used for VAE-CF . 100 CAVs are generated using 10 embeddings for each of the two subtopics which are randomly sampled and the final CAV is the mean of the 100 CAVs . VAE-CF : The undiversified baseline collaborative filtering system defined in Section 3 ( VAE-CF = TD-VAE-CF @ A = 1 ) . Gaussian negative log-likelihood loss is used . @ U-MMR : Untargeted MMR defines Sim , as the VAE-CF user- item embedding dot product and Simg as VAE-CF item-item embedding dot product ( VAE-CF = U-MMR @ A = 1 ) . e @ T-MMR : To see if we can achieve a Targeted MMR , we first project the user and item embeddings on the CAV to obtain their preference scores in the targeted spectrum . Then , the similarity metrics Sim , and Simg are computed by taking the negative absolute value of the difference between the user-item and item-item scores , respectively . 4.4 Performance Evaluation RQ1 - Relevance vs. Diversity : Overall , the targeted variation of MMR ( T-MMR ) demonstrates relevance scores that are extremely low ( 0.0043 for Yelp , 0.0036 for Reddit Politics , and 0.0038 for Reddit Gender on NDCG @ 50 ) . Therefore , in the remaining results , we omit T-MMR and only report results of the three other methods that have acceptable relevance scores . The results of relevance and diversity on TD-VAE-CF , VAE-CF , and U-MMR are shown in Figure 4 . For any fixed level of NDCG recommendation performance ( x-axis ) , the TD-VAE-CF method sirictly dominates U-MMR ’ s diversity metrics . Since U-MMR performs untargeted diversification while the metric for diversity is measured along the targeted direction , U-MMR ’ s diversity and relevance may both decrease for some datasets . RQ2 - Targeted Diversification : The distribution of recommended items on the target CAV are shown in Figure 1 and 5 . We see a clear shift of the distribution from one side to the middle , showing the diversified recommendations from TD-VAE-CF are well-balanced between the two targeted subtopics of the spectrum , unlike U-MMR . RQ3 - Running Time : Empirical running times for TD-VAE-CF and U-MMR are shown in Figure 6 ( T-MMR would be identical to U-MMR ) . U-MMR reranks items according to Equation 1 . At the Kth rank selection step U-MMR compares all non-selected items with 400 4 - @ - U-MMR a e+ TD-VAE-CF “ uA 300 4 ” a - E 2004 Dead F wa 100 + oe ee -- « - po @ ===tS5-0 -- -- e -- -- e -- - 0 -- 0-H ne + T T T r 20 40 60 80 100 kK Figure 6 : Time for generating top-K recommendations . K - 1 selected items . Therefore , the time complexity for UU-MMR is O ( mnK * ) where m is the number of users , n is the number of items , and K is the number of recommendations to generate . For TD-VAE-CF , the time complexity can be divided into two parts : the user embedding update requires O ( m ) , and user-item rating generation and sorting need O ( mn ) to generate the ratings and O ( m ( K + Klog ( K ) ) ) to select and sort the top-K ratings . Then , the total time complexity for TD-VAE-CF is : O ( m +mn+ m ( K + Klog ( K ) ) ) = O ( m ( K + K log ( K ) +n ) ) , ( 7 ) Since the complexity of U-MMR has a quadratic growth with respect to K while TD-VAE-CF has a dominant term of K log ( K ) growth , the time difference of each increases drastically with higher K. Conclusion : Overall , in comparison to popular MMR-based diver- sification methods , these results collectively confirm that our novel TD-VAE-CF can mitigate filter bubble effects via targeted modula- tion of a user ’ s latent preference embeddings , while maintaining relevance and having lower computational complexity than MMR . REFERENCES { 1 ] Guy Aridor , Duarte Goncalves , and Shan Sikdar . 2020 . Deconstructing the Fil- ter Bubble : User Decision-Making And Recommender Systems . Association for Computing Machinery , New York , NY , USA , 82-91 . [ 2 ] Jaime Carbonell and Jade Goldstein . 1998 . The Use of MMR , Diversity-Based Reranking for Reordering Documents and Producing Summaries . In Proceed- ings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval ( Melbourne , Australia ) ( SIGIR 98 ) . As- sociation for Computing Machinery , New York , NY , USA , 335-336. https : //doi.org/10.1145/290941.291025 [ 3 ] Allison J . B. Chaney , Brandon M. Stewart , and Barbara E. Engelhardt . 2018 . How Algorithmic Confounding in Recommendation Systems Increases Homogeneity and Decreases Utility . In Proceedings of the 12th ACM Conference on Recommender Systems ( Vancouver , British Columbia , Canada ) ( RecSys '18 ) Association for Computing Machinery , New York , NY , USA , 224-232 . [ 4 ] Seth Flaxman , Sharad Goel , and Justin M. Rao . 2016 . Filter Bubbles , Echo Cham- bers , and Online News Consumption . Public Opinion Quarterly 80 ( 2016 ) , 298-320 . Yingqiang Ge , Shuya Zhao , Honglu Zhou , Changhua Pei , Fei Sun , Wenwu Ou , and Yongfeng Zhang . 2020 . Understanding Echo Chambers in E-Commerce Rec- ommender Systems . In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval . 2261-2270 . [ 6 ] Kartik Hosanagar , Daniel Fleder , Dokyun Lee , and Andreas Buja . 2014 . Will the Global Village Fracture Into Tribes ? Recommender Systems and Their Effects on Consumer Fragmentation . Management Science 60 , 4 ( 2014 ) , 805-823 . Been Kim , M. Wattenberg , J. Gilmer , C. J. Cai , James Wexler , F. Viégas , and Rory Sayres . 2018 . Interpretability Beyond Feature Attribution : Quantitative Testing with Concept Activation Vectors ( TCAV ) . In ICML . Stockholm , Sweden . [ 8 ] Diederik P. Kingma and Max Welling . 2014 . Auto-Encoding Variational Bayes . In 2nd International Conference on Learning Representations , ICLR 2014 , Banff , AB , Canada , April 14-16 , 2014 , Conference Track Proceedings , Yoshua Bengio and Yann LeCun ( Eds. ) . http : //arxiv.org/abs/1312.6114 [ 5 ( 7 [ 9 ] 10 ] f4 ] ( 12 ] ( 13 ] ( 14 ) Xiaopeng Li and James She . 2017 . Collaborative variational autoencoder for recommender systems . In Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining . ACM , 305-314 . Dawen Liang , Rahul G Krishnan , Matthew D Hoffman , and Tony Jebara . 2018 . Variational Autoencoders for Collaborative Filtering . arXiv preprint arXiv:1802.05814 ( 2018 ) . Gabriel Machado Lunardi , Guilherme Medeiros Machado , Vinicius Maran , and Jose Palazzo M. de Oliveira . 2020 . A metric for Filter Bubble measurement in recommender algorithms considering the news domain . Applied Soft Computing 97 ( 2020 ) , 106771 . Masoud Mansoury , Himan Abdollahpouri , Mykola Pechenizkiy , Bamshad Mobasher , and Robin Burke . 2020 . Feedback Loop and Bias Amplification in Recommender Systems . In Proceedings of the 29th ACM International Conference on Information & Knowledge Management . Tien T. Nguyen , Pik-Mai Hui , F. Maxwell Harper , Loren Terveen , and Joseph A. Konstan . 2014 . Exploring the Filter Bubble : The Effect of Using Recommender Systems on Content Diversity . In Proceedings of the 23rd International Conference on World Wide Web . Association for Computing Machinery , New York , NY , USA , 677-686 . Eli Pariser . 2011 . The Filter Bubble : What the Internet Is Hiding from You . Penguin Group , The . [ 15 ] [ 16 ] [ 17 ] [ 18 ] [ 19 ] [ 20 ] Isaac Waller and Ashton Anderson . 2021 . Quantifying social organization and political polarization in online platforms . Nature 600 , 7888 ( 2021 ) , 264-268. https : //doi.org/10.1038/s41586-021-04167-x Ga Wu , Mohamed Reda Bouadjenek , and Scott Sanner . 2019 . One-Class Collabo- rative Filtering with the Queryable Variational Autoencoder . In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval ( SIGIR-19 ) . Paris , France . Hojin Yang , Scott Sanner , Ga Wu , and Jin Peng Zhou . 2021 . Bayesian Preference Elicitation with Keyphrase-Item Coembeddings for Interactive Recommendation . In Proceedings of the 29th ACM Conference on User Modeling , Adaptation and Personalization . 55-64 . Hojin Yang , Tianshu Shen , and Scott Sanner . 2021 . Bayesian Critiquing with Keyphrase Activation Vectors for VAE-based Recommender Systems . In Proceed- ings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval ( SIGIR-21 ) . Online . ChengXiang Zhai , William W. Cohen , and John Lafferty . 2015 . Beyond Indepen- dent Relevance : Methods and Evaluation Metrics for Subtopic Retrieval . SIGIR Forum 49 , 1 Gun 2015 ) , 2-9. https : //doi.org/10.1145/2795403.2795405 Cai-Nicolas Ziegler , Sean M. McNee , Joseph A. Konstan , and Georg Lausen . 2005 . Improving Recommendation Lists through Topic Diversification . In Proceedings of the 14th International Conference on World Wide Web ( Chiba , Japan ) ( WWW ’ 05 ) . Association for Computing Machinery , New York , NY , USA , 22-32 . A FLATTENING THE FILTER BUBBLE BY INJECTING NOISE IN THE TARGETED CAV DIMENSION One side effect of diversifying with the TD-VAE-CF methodology of Section 3 is that it tends to neutralize the targeted spectrum by shifting the user ’ s latent preference towards the center of the spectrum . One caveat is that this method tends to recommend fewer items that are at the extremes of the spectrum , which can alternately be seen as a benefit or drawback according to the intent of the diversification . We can observe this effect in Figure 1 and 5 : while the distributions of the recommended items shifted to the middle , the range of the distributions also decrease . In this section , we present a method that can diversify across both sides of the targeted spectrum by effectively “ flattening ” the distribution via the injection of Gaussian noise . To achieve this , first we update the user-embedding , Z , , , following the same method in Section 3 with A = 0 which removes preference information of the user in the targeted CAV direction d : Zy 0 4 > ud . Zu =Zy A =U ( 8 ) llell ? Then , we compute perturbations of the user ’ s latent embedding 2 n times along the targeted CAV direction ¢ by computing 2 =2 , -al8 ( 9 ) where j € { 1 , ... , n } and a7 ~ N ( 0 , 0 '' ) randomly determines the magnitude of noise injection in the CAV dimension ( sometimes sampling more extreme ends of the CAV spectrum ) . Clearly , as o increases , the amount of extreme content from both ends of the spectrum that is sampled also increases . Finally , the n perturbed user-embeddings zh are decoded to pro- duce n VAE-CF recommendation predictions rj ; for each item i and perturbation j . The final rating score r ; for item i is computed by averaging the n scores produced by each perturbed user embedding : 12 nay ny ( 10 ) = The resulting targeted spectrum distributions are shown in Fig- ure 7 and the results of relevance and diversity analysis are shown in Figure 8 . We fixed n at 10 and varied o within ( 0 , 1 , 2,5 , 10 , 20 ) . When o = 0 , the perturbation process does not change the user embeddings and it is the same method as TD-VAE-CF in Section 3 with A = 0 . We can clearly see that the distribution is flattened with higher o and a wider range of items on the targeted spectrum , although still balanced and thus yielding relatively high diversity measures . The diversity continues to increase with higher o while the relevance de- creases more rapidly than TD-VAE-CF since extreme recommendations are less likely to be relevant for most users . Whether one should “ neutralize ” the curve ( and remove extreme content for potentially sensitive users ) using TD-VAE-CF as pro- posed in Section 3 or “ flatten ” the curve as shown here ( and recom- mend content at all points on the spectrum - even extreme points of view from both sides ) is a decision that ultimately rests with the recommendation system designer and depends on the desiderata that motivate the need for diversification w.r.t . the target audience . U-MMR ( A=0.2 ) U-MMR ( A=0.8 ) VAE-CF TD-VAE-CF ( o=0 ) TD-VAE-CF ( o=1 ) TD-VAE-CF ( 0=2 ) TD-VAE-CF ( o=5 ) TD-VAE-CF ( o=10 ) TD-VAE-CF ( 0=20 ) 0.10 0.00 Republican + Democratic U-MMR ( A=0.2 ) U-MMR ( A=0.8 ) VAE-CF TD-VAE-CF ( o=0 ) TD-VAE-CF ( o=1 ) TD-VAE-CF ( o=2 ) TD-VAE-CF ( a=5 ) TD-VAE-CF ( o=10 ) -- TD-VAE-CF ( 0=20 ) - - 0.10 ~0.05 o.oo 0.05 oro Republican < > Democratic Figure 7 : Top 50 recommendations for Republicans and BBQ lovers using Reddit and Yelp dataset respectively . X-axis represents the political spectrum or the meat consumption spectrum of the recommendations . The scores are computed by projecting the item embeddings on the Concept Activation Vector ( CAV ) . The recommendations for TD-CAE-CF and U-MMR are computed using three different o values ( 0 , 1 , 2 , 5 , 10 , 20 ) . — UMMR —— TDVAE-CF —— VAE-CF Republican vs. Democratic Men vs. Women Deep Fried vs . Salad Vegetarian vs. BBQ e eo e- 0.5 420 ~~ 20 02048 051 % 6. c eH 10 “ se . 20 . 10 ™s 6 19 77 ® 0 0.44 Pp , 8 woe 0 ~ . Boa | 2 Poe e ois 5 eH o44 5 , oo ” 4 8 0.3 1 P-~ » 0.10 4 034 & o34 02-4 ° ° - -— 0.05 s « .05 + 024 — o-_~._ _ « eA 20 PP 7 -- -- - « * . 0.4 Jags 0.40 5 0 Sapo 0.4 5p 0.254 10 % . : Ne o , ? 5 . : 10 `` ~® e- 00 wo 0.20 4 03 . a = 0.354 034 .3 * ) 0154 f ae 030 ] T T T T s 0.25 T T s T 9.10 4 T T T 0.24 T T T 0.04 0.06 0.08 0.10 0.04 0.06 0.08 0.02 0.04 0.06 0.02 0.04 0.06 NDCG @ 50 Figure 8 : NDCG @ 50 vs. S-Precision and HMSP for four spectra of two datasets with different o values ( 0 , 1 , 2 , 5 , 10 , 20 ) . Higher o values ( higher standard deviation ) are marked with higher opacity . o = 0 for TD-VAE-CF is the same as 4 = 0 without any remapping . U-MMR results are the same as Section 4 since its not possible to perform the same remapping process for U-MMR . Australasian Conference on Information Systems Amrollahi 2019 , Perth Western Australia Burst the filter bubble Burst the Filter Bubble : Towards an Integrated Tool Full Paper Alireza Amrollahi Peter Faber Business School Australian Catholic University Sydney , Australia Email : alireza.amrollahi @ acu.edu.au Abstract Formation of filter bubbles is known as a risk for democracy and can bring negative consequences like polarisation of the society , users ’ tendency to extremist viewpoints , and the proliferation of fake news . Previous studies , including prescriptive studies , focused on limited aspects of filter bubbles . The current study aims to propose a model for an integrated tool that assists users in avoiding filter bubbles in social networks . To this end , a systematic literature review has been adopted and 571 papers in six top-ranked scientific databases have been identified . After excluding irrelevant studies and an in-depth study of the remaining papers , a classification of research studies is proposed . This classification is then used to propose an overall architecture for an integrated tool that synthesises all previous studies and proposes new features for avoiding filter bubbles . The study explains the components and features of the proposed architecture and describes their focus on content and agents . Keywords : Filter bubble , Social networks , Prescriptive study , Information bubble . Australasian Conference on Information Systems Amrollahi 2019 , Perth Western Australia Burst the filter bubble 1 INTRODUCTION The notion of filter bubble refers to the impact of our preferences and desires on the content and results we view on search engines , social media , and other online platforms . This concept has been central to social media and internet research since it was developed by Eli Pariser ( Pariser 2011 ) and have been investigated by various scholars using various terms . Some of the terms used in the literature are information bubble ( Liao and Fu 2013 ) , [ online ] echo chamber ( Moller et al . 2018 ) , personal ecosystem of information ( Helberger et al . 2015 ) , partial information blindness ( Haim et al . 2018 ) , and information cocoons ( Sunstein 2007 ) . Several undesirable impacts have been mentioned in the literature for filter bubbles . Especially , a potential risk to narrow the information sources for online users and “ pushing users into the psychological comfort zone of self-confirmation and risking polarisation on a societal level '' ( Courtois et al . 2018 , p. 2008 ) that can lead to polarisation of online debates ( Seargeant and Tagg 2018 ) and even extremism ( Costello et al . 2016 ; Liao and Fu 2013 ) . To avoid these negative impacts , several studies in the literature have recommended solutions to understand , avoid , and decrease the negative impacts of filter bubbles . These studies are focused on various topics including quantification of the bubble in social networks ( Hannak et al . 2013 ) , developing secondary apps ( Wood et al . 2018 ) , and approaches to stay anonymous in order to avoid filter bubbles ( Ridgway 2017 ) . However , none of the studies in the literature , offer a comprehensive and integrated tool to help users avoid the filter bubbles . To tackle this shortcoming , in this study , we searched seven scientific databases with related phrases in an attempt to systematically review the prescriptive literature and suggest a conceptual model for an integrated tool . We investigated these studies based on their aim and approach to avoid filter bubble , used technology , and the effectiveness of the approach . The results of this research can help future research to find possible gaps in the literature and provide practitioners with a better understanding of the tools available to them for avoiding filter bubbles . The remainder of this paper , in section two , provides a background to the concept of the filter bubble and posits the current study within the body of research . Section three introduces our methodology and approach for review and analysis of the literature . In section four the integrated framework is presented and results are discussed with possible implications for research and practice in section five . The paper is concluded with explaining the contributions to the body of research in section six . 2 RESEARCH BACKGROUND 2.1 Filter Bubble Although the notion of limiting sources of information to one ’ s preferences has been largely studied in areas such as media ( Jamieson and Cappella 2008 ) and psychology ( Nickerson 1998 ) , the application of this notion on online and social media came under the spotlight after the development of the term filter bubble . There are two main research streams on the filter bubble . The first stream ( inspired by the work of Pariser ( 2011 ) is mainly focused on the impact of recommendation systems ( LR et al . 2018 ; Nguyen et al . 2014 ; Sanz-Cruzado and Castells 2018 ) . These recommendation systems consider the user's demographic information , history , and search behaviour in suggesting new content by social media and search engines , creating a filter bubble for the information the user receives . This stream of research has been increasingly challenged by the second wave of studies that focuses on the role of social media users rather than recommendation system technologies ( Garrett 2017 ; Moller et al . 2018 ) . This perspective is supported by empirical research including a study on Facebook content that found only 5-8 % of the content provided to people with various political viewpoints is based on their profile ( Bakshy et al . 2015 ) . Among previous studies , we found review research by Bozdag and van den Hoven ( 2015 ) . The study considers two different perspectives about democracy ( namely : liberal view of democracy and deliberative democracy ) and introduces several software designs which have been introduced to combat filter bubble . The study then suggests design criteria against filter bubble based on the two models of democracy and concludes that the reviewed tools “ do not define the filter bubble explicitly ” and most of them “ are performed for US politics ” ( Bozdag and van den Hoven 2015 , p. 263 ) . Except for Australasian Conference on Information Systems Amrollahi 2019 , Perth Western Australia Burst the filter bubble this comparison of tools , we did not find any research to go beyond algorithmic enhancements of recommendation systems and investigate possible social concepts leading to the formation of filter bubbles and how the system can deal with these factors . 2.2 Impacts of filter bubbles The negative consequences associated with filter bubbles are extensively studied in the literature . Some of these impacts could be directly associated with the filter bubble . Some examples are a decline in user trust ( Nagulendra and Vassileva 2016 ) , limiting people 's access to information ( Valdez et al . 2018 ) , and social fragmentation ( Moller et al . 2018 ) . A negative consequence that has been cited more specifically in the literature , is the polarization of political discussions in social media when people are stuck in a bubble that prevents them from receiving outsider information ( Foth et al . 2016 ; Lahoti et al . 2018 ; Quraishi et al . 2018 ; Thonet et al . 2017 ; Yang et al . 2017 ) . Previous literature has not found a significant relationship between exposure to the opposite political view and a change in people 's political opinion ( Bail et al . 2018 ) . However , there are many studies which investigated the impact of filter bubbles on commitment to a populist cause ( Postill 2018 ) , avoidance of cross-referencing ( Van den Bulck and Moe 2018 ) , creating a risk to diversity of opinions and well-functioning democracy as a result ( Bozdag and van den Hoven 2015 ; Dylko et al . 2018 ) . On the other hand , filter bubble can indirectly impact or result in proliferation of recent challenges in online media including fake news ( Bhatt et al . 2018 ; Seargeant and Tagg 2018 ) as they “ amplify any content , from genuine , factual news to emotionally charged , politically biased news ” ( Rehm 2017 , p. 218 ) . As social science studies have found that homogenous groups are more likely to become extreme in their thinking ( Spohr 2017 ) , the formation of these groups as a result of a filter bubble can lead to extremism . Finally , the negative impacts of filter bubbles have been studied in specific areas . For example , Taramigkou et al . ( 2013 ) investigated filter bubbles in music platforms and how the impacts platform users ’ taste of music . Other researchers have studied the negative impacts of filter bubbles in areas such as online retail ( Matt et al . 2014 ) and the source of information financial analysts receive ( Shah et al . 2016 ) . Despite these breakthroughs in the literature , previous studies are less focused on the long-term of filter bubbles . For example , although there are several studies on the impact of social networks on extremism ( Awan 2017 ; O'Callaghan et al . 2013 ; Spohr 2017 ) , no empirical has investigated the impact of filter bubbles and human authority on the formation of extremist groups . 3 RESEARCH METHOD The current paper aims to suggest an integrated tool that can deal with the problem of filter bubble in social networks . To do this a systematic literature review has been adopted and previous prescriptive studies on bursting filter bubbles have been reviewed . To conduct a systematic literature review the following steps were undertaken as suggested by Kitchenham and Charters ( 2007 ) : ( 1 ) identifying resources ; ( 2 ) study selection ; ( 3 ) data extraction ; ( 4 ) data synthesis ; and ( 5 ) writing up the study as a report . To follow these steps , we searched six scientific databases : Science Direct , Scopus , ProQuest , ACM Digital Library , Association for Information Systems electronic library , and Springer Link . Table 1 shows the final set of papers in each scientific database . Database The first setof The final set of papers papers Association for Information Systems electronic library 99 2 Pro Quest 119 5 Science Direct 19 8 Scopus 147 32 Springer Link 146 4 ACM Digital Library 41 20 Total 571 71 Table 1 - Distribution of first/final set of papers in different databases We searched for the following terms in title , keywords and abstracts depending on the services offered by the relevant search engines : Australasian Conference on Information Systems Amrollahi 2019 , Perth Western Australia Burst the filter bubble ” 6 '' filter bubble '' or `` information bubble '' or “ social recommendation systems ” , “ social personalisation ” , ” « 6 ” 6 ” 6 “ news gatekeepers ” , “ information gatekeepers ” , “ personalised filtering ” , “ online echo chamber ” We found 571 papers after our initial search for the above keywords . This number was reduced to 147 papers when reading the titles and abstracts and excluded irrelevant papers . Finally , duplicated papers included in more than one database were removed and in another round , we referred to papers in full text to formulate the final pool of 71 papers . Table 2 illustrates the process through which we arrived at the final pool of research papers . Round Number of Papers Number of Papers Excluded Remaining The initial list of papers - 571 Exclusion based on the title 107 464 Exclusion based on abstract 317 147 Removal of duplicate papers 9 138 Exclusion based on full text ( Final list ) 67 71 Table 2- Different Stages of Inclusion / Exclusion and Number of Papers in Each Round For the current paper , we studied all the papers in our pool of 71 papers and focused on those which were prescriptive and suggested an approach for dealing with filter bubbles . The results of further analysis on the content of those papers are presented in the future sections . While the study focuses on the prescriptive approaches suggested in each article to prevent the formation of filter bubbles , there is less focus on the approach used to evaluate the rigour research data or data analysis . Instead , we have focused on the robustness of the proposed approach and if it can be applied in practice . 4 RESULTS The final set of prescriptive papers formed the basis of the results described below . These final papers are studied in detail , and their advice on how to overcome the filter bubble phenomenon has been investigated . The results of this study helped us to differentiate two different perspectives in the reviewed studies on the filter bubble . Each of these perspectives is studied in further detail to understand and categorise their reeommended approach . There was a group of papers which proposed approaches to identify the filter bubble . This category includes identification of the bubble , confirming its existence , and quantification of the impact of the bubble . The second category of research studies , however , is directly focused on approaches to take users out of the filter bubble or as we call it in this paper , burst the bubble . Details about each category are explained below : 4.1 . Alert about the bubble Research studies under this category are focused on the identification and evaluation of filter bubbles . Filter identification studies are mainly focused on tools that check and alert users ( in different ways ) if they are trapped in a filter bubble . Nagulendra and Vassileva ( 2014 ) for example , proposed an interactive visualisation to enable the user to see the filtering . According to the authors , the tool has four goals which are : awareness , understanding , control of personalised filtering , and to increase the users ’ trust in the system . The tool has implemented and tested on an independent platform . The authors have extended this tool in their future work ( Nagulendra and Vassileva 2016 ) to include both content and agent ( users ) in visualisation . This goal to detect the bubble has been continued in future studies using different approaches including diffusion of topics ( content ) ( TK et al . 2015 ) , network theory ( agents ) ( Thonet et al . 2017 ) , and machine learning ( Lahoti et al . 2018 ) . Another stream of research on alerting filter bubble goes one step beyond bubble identification and considers evaluation and quantification of filter bubbles . Hannak et al . ( 2013 ) for example , developed a methodology for measuring personalisation in Web search results . The proposed methodology compares different search results on Google considering the attributes of the agent ( user ) who performs the search . Also , Matakos et al . ( 2017 ) developed an index to measure the tendency of opinion polarisation in network communities that can lead to the development of filter bubbles . This measure considers the opinion of agents ( users ) and the structure of the network . Despite these studies and a few in-progress studies , no study has been used as a comprehensive framework for measuring the filter bubble . The proposed frameworks are mainly focused on agent and less focused on the content . Finally , the proposed frameworks are less applied in real-time on social networks to show the users existence or significance of a filter bubble . Australasian Conference on Information Systems Amrollahi 2019 , Perth Western Australia Burst the filter bubble 4.2 Burst the bubble This category of studies explains the suggested approach to disable or decrease the negative impact of recommendation systems creating filter bubble through exploring new ideas and diverse perspectives . The first stream of research in this category is formed around bypassing or changing algorithms . Ridgway ( 2017 ) for example , suggest staying anonymous while being online as a solution to avoid potential filter bubbles . Bozdag and van den Hoven ( 2015 ) on the other hand , reviewed possible design criteria proposed for bursting filter bubble . Another stream of research under this category is focused on bursting the bubble by extending users ’ awareness and encouraging them to explore different ideas . In this stream of research , again the focus is on either new content or new agents . The majority of studies in our final pool are focused on viewing new content . Among them , the work of Taramigkou et al . ( 2013 ) is the first study we identified that proposed a methodology helping users to explore new music genres outside their zone of interest . Webberley et al . ( 2016 ) also suggested an algorithm for avoiding filter bubble through focusing on re- twitting behaviour of users rather the scope of the user ’ s social circle . Finally , several studies have suggested applications to enable users to view new content outside their preference ( Linder et al . 2018 ; Wood et al . 2018 ) . Recent studies , however , have shifted the focus from content to the agent . Quraishi et al . ( 2018 proposed a graph partitioning method that exploits social interactions to represent different viewpoints in a social network . A qualitative evaluation of the proposed method is also presented based on implementing the method on a dataset retrieved from Twitter . Also , Sanz-Cruzado and Castells ( 2018 ) focused on contact recommendation and based on the concept of weak connection , proposed an index for diversity . Despite the diversity of research studies in this category , a lack of focus on the real-time application of the proposed methods in social networks is observable among all the studies . 5 DISCUSSION The results of our review indicate that studying the filter bubble phenomenon is an interdisciplinary research area . Our final pool of research studies includes work from areas ranging from information systems , information technology , and management to political science , sociology , law , and journalism . In the analysis of the related literature , we could observe a focus on the content provided in social networks in few studies in various categories while many others were focused on the users posting the content ( agent ) and how they impact the formation of filter bubbles . Based on the outcome of our review we propose an architecture for an integrated tool that can be implemented in social networks ( regardless of the content type ) and help to avoid the formation of filter bubbles . Based on the outcome of our literature review , we propose two major functions for this integrated tool : ( i ) alerting users about a potential filter bubble ; and ( ii ) bursting the bubble . Under the alert component , the integrated tool first focuses on the identification of a filter bubble . While many users of social networks are not aware of the filter bubble they were kept in as a result of a lack of transparency in the algorithms used by social networks ( Bozdag and Timmermans 2011 ) , the tool needs to alert users . As the cause of filter bubbles shift from the recommendation algorithms to features enabling users to put themselves in filter bubble ( Amrollahi and McBride 2019 ) , this is important to also inform the users about the consequences of their actions . For example , users should have the right to see how blocking or muting one specific user , may result in missing out a network of users and their perspective . Therefore , this bubble identification feature should be designed in connection with a bubble evaluation feature that assesses the significance of the bubble and also can predict future significance after certain events . Potential improvements in the recommendation systems have been suggested as a possible solution for bursting the bubble . However , in the current study we have not considered this as a feature in the proposed tool . Recommendation systems are not included in the tool for two reasons : ( i ) the proposed tool is proposed independent to the social network , type of content they provide , and the recommendation algorithm they use ; ( ii ) the proposed integrated tool is focused on not only the recommendation algorithm , but also on social network facilities that enable users to build a bubble around them . The architecture of the proposed integrated tool is illustrated in Figure 1 . As illustrated in Figure 1 , the proposed tool , will focus on both agent and content . It means that in order to identify filter bubbles ( as part of the alert component ) , both connections of and the content viewed by the user under study should be investigated . Also , the significance of the bubble should be evaluated by considering both the recommended content and recommended users . Finally , the Australasian Conference on Information Systems Amrollahi 2019 , Perth Western Australia Burst the filter bubble awareness of users should be increased by suggesting both novel ( out of bubble ) content and connections . Identify Evaluate Increasing Awareness QA ee a Agent Content Agent Content Tm ‘ Tm Figure 1 The proposed architecture for an integrated tool 6 CONCLUSION Filter bubbles are problematic consequences of modern media and social networks as they create barriers to rational and diversified dialogue that is necessary for a democratic society . This research looks at filter bubble as not only a product of recommendation algorithms in social networks but also a social issue which considers an active role for users building a filter bubble around them . In the current paper , we proposed an architecture for an integrated tool that can be incorporated into social networks to prevent the formation of filter bubbles around users . This tool is proposed based on a systematic review of the literature and classification of the studies under different categories considering their aim . The proposed components of the integrated tool cover both liberal ( through alert component ) and deliberative ( through awareness component ) models of democracy ( Bozdag and van den Hoven 2015 ) . The results of our review show a lack of empirical studies on the effectiveness of the proposed tools . Even those studies which included their empirical results , did so by using test data on developed hypothetical platforms . Therefore , the application of the proposed methods in social networks should be considered in future studies . This improvement in future research will lead to a better evaluation of the effectiveness of the proposed methods which is another shortcoming we identified in the literature . Based on the results of our literature review , the components of an integrated tool are proposed in the form of an architecture map . The proposed method , unlike what is proposed in the previous literature , considers different perspectives on filter bubbles . These perspectives include a concurrent focus on alerting users about the formation of bubble and bursting bubbles through increasing users ’ awareness . The proposed integrated tool also has a dual focus on both content and agent which can not be found in the previous literature . Although the proposed framework in this study is expected to consider various approaches for busting the filter bubble in the literature , it has not been put to practice as a solution in any social network . 17 Australasian Conference on Information Systems Amrollahi 2019 , Perth Western Australia Burst the filter bubble Therefore , we propose future study to consider this as a principle of implementation and evaluation of the system . In particular , the results of the current study can inform future studies especially upcoming design research . Moreover , there is currently no evidence of effectiveness of the proposed components of the system as a whole . Future studies should focus on the effectiveness of the proposed approach and check if people in such filter bubbles will break free when given an opportunity . Future studies can also focus on different parts of the proposed tool and develop algorithms for each part . The study also proposes a real-time ( predictive ) bubble evaluation which is not developed in the previous studies . Finally , the results of this study can benefit practitioners and managers of social networks to see various avenues for improving their service or possible pitfalls in their social network allowing the formation of filter bubbles . 7 REFERENCES Amrollahi , A. , and McBride , N. 2019 . `` How to Burst the Bubble in Social Networks ? , '' in : 24th UK Academy for Information Systems International Conference . Oxford , UK . Awan , I . 2017 . `` Cyber-Extremism : Isis and the Power of Social Media , '' Society ( 54:2 ) , pp . 138-149 . Bail , C. A. , Argyle , L. P. , Brown , T. W. , Bumpus , J. P. , Chen , H. , Hunzaker , M. F. , Lee , J. , Mann , M. , Merhout , F. , and Volfovsky , A . 2018 . `` Exposure to Opposing Views on Social Media Can Increase Political Polarization , '' Proceedings of the National Academy of Sciences ( 115:37 ) , pp . 9216-9221 . Bakshy , E. , Messing , S. , and Adamic , L. A . 2015 . `` Exposure to Ideologically Diverse News and Opinion on Facebook , ” Science ( 348:6239 ) , pp . 1130-1132 . Bhatt , S. , Joglekar , S. , Bano , S. , and Sastry , N. 2018 . “ Illuminating an Ecosystem of Partisan Websites , ” arXiv preprint arXiv:1803.03576 ) . Bozdag , E. , and Timmermans , J . 2011 . `` Values in the Filter Bubble Ethics of Personalization Algorithms in Cloud Computing , ” ist International Workshop on Values in Design— Building Bridges between RE , HCI and Ethics . Bozdag , E. , and van den Hoven , J . 2015 . `` Breaking the Filter Bubble : Democracy and Design , '' Ethics and Information Technology ( 17:4 ) , pp . 249-265 . Costello , M. , Hawdon , J. , Ratliff , T. , and Grantham , T. 2016 . `` Who Views Online Extremism ? Individual Attributes Leading to Exposure , '' Computers in Human Behavior ( 63 ) , pp . 311-320 . Courtois , C. , Slechten , L. , and Coenen , L. 2018 . `` Challenging Google Search Filter Bubbles in Social and Political Information : Disconforming Evidence from a Digital Methods Case Study , '' Telematics and Informatics ( 35:7 ) , pp . 2006-2015 . Dylko , I. , Dolgov , I. , Hoffman , W. , Eckhart , N. , Molina , M. , and Aaziz , O . 2018 . `` Impact of Customizability Technology on Political Polarization , '' Journal of Information Technology & Politics ( 15:1 ) , pp . 19-33 . Foth , M. , Tomitsch , M. , Forlano , L. , Haeusler , M. H. , and Satchell , C. 2016 . `` Citizens Breaking out of Filter Bubbles : Urban Screens as Civic Media , '' Proceedings of the 5th ACM International Symposium on Pervasive Displays : ACM , pp . 140-147 . Garrett , R. K. 2017 . `` The “ Echo Chamber ” Distraction : Disinformation Campaigns Are the Problem , Not Audience Fragmentation , '' Journal of Applied Research in Memory and Cognition ( 6:4 ) , pp . 370-376 . Haim , M. , Graefe , A. , and Brosius , H.-B . 2018 . `` Burst of the Filter Bubble ? Effects of Personalization on the Diversity of Google News , '' Digital journalism ( 6:3 ) , pp . 330- 343 . Hannak , A. , Sapiezynski , P. , Molavi Kakhki , A. , Krishnamurthy , B. , Lazer , D. , Mislove , A. , and Wilson , C. 2013 . `` Measuring Personalization of Web Search , ” Proceedings of the 22nd international conference on World Wide Web : ACM , pp . 527-538 . Australasian Conference on Information Systems Amrollahi 2019 , Perth Western Australia Burst the filter bubble Helberger , N. , Kleinen-von Konigsléw , K. , and van der Noll , R. 2015 . “ Regulating the New Information Intermediaries as Gatekeepers of Information Diversity , '' info ( 17:6 ) , pp . 50-71 . Jamieson , K. H. , and Cappella , J. N. 2008 . Echo Chamber : Rush Limbaugh and the Conservative Media Establishment . Oxford University Press . Kitchenham , B . A. , and Charters , S. 2007 . `` Guidelines for Performing Systematic Literature Reviews in Software Engineering , '' ) . Lahoti , P. , Garimella , K. , and Gionis , A . 2018 . `` Joint Non-Negative Matrix Factorization for Learning Ideological Leaning on Twitter , '' Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining : ACM , pp . 351-359 . Liao , Q. V. , and Fu , W.-T. 2013 . `` Beyond the Filter Bubble : Interactive Effects of Perceived Threat and Topic Involvement on Selective Exposure to Information , '' Proceedings of the SIGCHI conference on human factors in computing systems : ACM , pp . 2359-2368 . Linder , R. , Stacy , A. M. , Lupfer , N. , Kerne , A. , and Ragan , E. D. 2018 . `` Pop the Feed Filter Bubble : Making Reddit Social Media a Vr Cityscape , '' 2018 IEEE Conference on Virtual Reality and 3D User Interfaces ( VR ) : IEEE , pp . 619-620 . LR , D. , Tamhane , A. , and Pervin , N. 2018 . `` A Clustering Based Social Matrix Factorization Technique for Personalized Recommender Systems , '' ) . Matakos , A. , Terzi , E. , and Tsaparas , P. 2017 . `` Measuring and Moderating Opinion Polarization in Social Networks , '' Data Mining and Knowledge Discovery ( 31:5 ) , pp . 1480-1505 . Matt , C. , Benlian , A. , Hess , T. , and Wei } , C. 2014 . `` Escaping from the Filter Bubble ? The Effects of Novelty and Serendipity on Users ’ Evaluations of Online Recommendations , '' ) . Moller , J. , Trilling , D. , Helberger , N. , and van Es , B . 2018 . `` Do Not Blame It on the Algorithm : An Empirical Assessment of Multiple Recommender Systems and Their Impact on Content Diversity , '' Information , Communication & Society ( 21:7 ) , pp . 959- 977 . Nagulendra , S. , and Vassileva , J . 2014 . `` Understanding and Controlling the Filter Bubble through Interactive Visualization : A User Study , '' Proceedings of the 25th ACM conference on Hypertext and social media : ACM , pp . 107-115 . Nagulendra , S. , and Vassileva , J . 2016 . `` Providing Awareness , Explanation and Control of Personalized Filtering in a Social Networking Site , '' Information Systems Frontiers ( 18:1 ) , pp . 145-158 . Nguyen , T. T. , Hui , P.-M. , Harper , F. M. , Terveen , L. , and Konstan , J . A . 2014 . `` Exploring the Filter Bubble : The Effect of Using Recommender Systems on Content Diversity , '' Proceedings of the 23rd international conference on World wide web : ACM , pp . 677- 686 . Nickerson , R. S. 1998 . `` Confirmation Bias : A Ubiquitous Phenomenon in Many Guises , ” Review of general psychology ( 2:2 ) , pp . 175-220 . O'Callaghan , D. , Greene , D. , Conway , M. , Carthy , J. , and Cunningham , P. 2013 . `` The Extreme Right Filter Bubble , '' arXiv preprint arXiv:1308.6149 ) . Pariser , E. 2011 . The Filter Bubble : What the Internet Is Hiding from You . Penguin UK . Postill , J . 2018 . `` Populism and Social Media : A Global Perspective , '' Media , Culture & Society ( 40:5 ) , PP . 754-765 . Quraishi , M. , Fafalios , P. , and Herder , E. 2018 . “ Viewpoint Discovery and Understanding in Social Networks , '' Proceedings of the 10th ACM Conference on Web Science : ACM , pp . 47-56 . Australasian Conference on Information Systems Amrollahi 2019 , Perth Western Australia Burst the filter bubble Rehm , G. 2017 . `` An Infrastructure for Empowering Internet Users to Handle Fake News and Other Online Media Phenomena , ” International Conference of the German Society for Computational Linguistics and Language Technology : Springer , pp . 216-231 . Ridgway , R. 2017 . `` Against a Personalisation of the Self , '' ephemera : theory & politics in organization ( 17:2 ) . Sanz-Cruzado , J. , and Castells , P. 2018 . `` Enhancing Structural Diversity in Social Networks by Recommending Weak Ties , '' Proceedings of the 12th ACM Conference on Recommender Systems : ACM , pp . 233-241 . Seargeant , P. , and Tagg , C. 2018 . `` Social Media and the Future of Open Debate : A User- Oriented Approach to Facebook ’ s Filter Bubble Conundrum , ” Discourse , Context & Media ) . Shah , D. , Koneru , P. , Shah , P. , and Parimi , R. 2016 . `` News Recommendations at Scale at Bloomberg Media : Challenges and Approaches , '' Proceedings of the 10th ACM Conference on Recommender Systems : ACM , pp . 369-369 . Spohr , D. 2017 . `` Fake News and Ideological Polarization : Filter Bubbles and Selective Exposure on Social Media , '' Business Information Review ( 34:3 ) , pp . 150-160 . Sunstein , C. 2007 . `` Republic . Com 2.0 . '' Princeton , NJ : Princeton University Press . Taramigkou , M. , Bothos , E. , Christidis , K. , Apostolou , D. , and Mentzas , G. 2013 . `` Escape the Bubble : Guided Exploration of Music Preferences for Serendipity and Novelty , ” Proceedings of the 7th ACM conference on Recommender systems : ACM , pp . 335-338 . Thonet , T. , Cabanac , G. , Boughanem , M. , and Pinel-Sauvagnat , K. 2017 . `` Users Are Known by the Company They Keep : Topic Models for Viewpoint Discovery in Social Networks , ” Proceedings of the 2017 ACM on Conference on Information and Knowledge Management : ACM , pp . 87-96 . TK , A. K. , George , K. , and Thomas , J. P. 2015 . `` An Empirical Approach to Detection of Topic Bubbles in Tweets , '' 2015 [ IEEE/ACM 2nd International Symposium on Big Data Computing ( BDC ) : TEEE , pp . 31-40 . Valdez , A. C. , Kluge , J. , and Ziefle , M. 2018 . `` Elitism , Trust , Opinion Leadership and Politics in Social Protests in Germany , '' Energy Research & Social Science ) . Van den Bulck , H. , and Moe , H. 2018 . `` Public Service Media , Universality and Personalisation through Algorithms : Mapping Strategies and Exploring Dilemmas , '' Media , Culture & Society ( 40:6 ) , pp . 875-892 . Webberley , W. M. , Allen , S. M. , and Whitaker , R. M. 2016 . `` Retweeting Beyond Expectation : Inferring Interestingness in Twitter , ” Computer Communications ( 73 ) , pp . 229-235 . Wood , G. , Long , K. , Feltwell , T. , Rowland , S. , Brooker , P. , Mahoney , J. , Vines , J. , Barnett , J. , and Lawson , S. 2018 . `` Rethinking Engagement with Online News through Social and Visual Co-Annotation , ” Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems : ACM , p. 576 . Yang , M. , Wen , X. , Lin , Y.-R. , and Deng , L. 2017 . `` Quantifying Content Polarization on Twitter , ” 2017 IEEE 3rd International Conference on Collaboration and Internet Computing ( CIC ) : IEEE , pp . 299-308 . Copyright : © 2019 Amrollahi . This is an open-access article distributed under the terms of the Creative Commons Attribution-NonCommercial 3.0 Australia License , which permits non-commercial use , distribution , and reproduction in any medium , provided the original author and ACIS are credited . 20 a View metadata , citation and similar papers at core.ac.uk brought to you by 2 . CORE DAN ILMU POLITIK provided by Jurnal Ilmu Sosial dan Ilmu Politik Jurnal Ilmu Sosial dan Hmu Politik Volume 22 , Issue 2 , November 2018 ( 112-126 ) ISSN 1410-4946 ( Print ) , 2502-7883 ( Online ) doi : 10.22146/jsp.33244 Persecution Act as Filter Bubble Effect : Digital Society and The Shift of Public Sphere Arina Rohmatul Hidayah Department of Communications Science , Faculty of Social and Political Sciences , Universitas Gadjah Mada ( email : arinarohmatulh @ gmail.com ) Abstract This article discusses persecution acts associated with the filter bubble effect , the condition of digital society , the concept of the public sphere and the rational action theory of Jurgen Habermas . The results , obtained through the literature research method , show that acts of persecution in social media can be caused by the personalization of the web . Social media allows the occurrence of large bubbles ( filter bubbles ) that make users reject ideologies or other truths . This becomes a revolution of mindset due to the freedom of information . Meanwhile , in the Habermas public sphere concept , which emphasizes the existence of a critical and rational discussion , this phenomenon indicates a shift . The shift that occurs brings about the lifeworld realm as the basis for the formation of the public sphere with its communicative action , again dominated by the system realm that is dominated by capitalist forces through strategic action . Thus , Habermas's initial goal of strengthening civil society 's position against the dominance of the system is now changing . Keywords : persecution ; filter bubble effect ; social media ; digital society ; public sphere Introduction Still remember clearly how the sovereignty of Indonesia a bit shaky with the events of December 2 , 2016 ( 212 ) yesterday . On the official site of tirto.id , explained that the action began when Ahok paid a working visit to the Kepulauan Seribu on Tuesday , September 27 , 2016 . During a speech in front of the people , Ahok said not to force citizens to vote himself in the elections 2017 . The statement was accompanied by quotation from Al Maidah verse 51 reaping public reactions . On Thursday , October 6 , 2016 , Ahok ’ s video about Al Maidah verse 51 was viral on social media , through a Facebook network owned by Buni Yani ( Debora , 2016 ) . This case has created tension among the Muslim community who became the majority religion in Indonesia . Jokowi as Head of Government seeks to consolidate with a number of religious leaders so that the condition of society can be controlled . In those days the public voice was split between those who thought that Ahok was innocent and those who considered him “ toying with ” QS . Al-Maidah verse 53 . This condition is then allegedly caused many cases of persecution . In the official website , www.ccnindonesia . com , explained that the network of freedom of expression volunteers in Southeast Asia , Safenet noted as many as 59 people have been subjected to target persecution or ‘ hunt ’ intimidative post- rolling cases of blasphemy that ensnare Basuki Tjahaja Purnama alias Ahok . The so-called ‘ The Ahok Effect ’ precision waves appear especially after Ahok is convicted . Safenet has since recorded a drastic rise in reporting referring to €JoP HUUIIIAUTTELLLLLIMMHIEELLL 242 JURNAL ILMU SOSIAL DAN ILMU POLITIK Arina Rohmatul Hidayah , Persecution Act as Filter Bubble Effect : Digital Society and The Shift of Public Sphere Article 28 paragraph 2 of the Information and Electronic Transactions Act ( Gual , 2017 ) . Ahok ’ s case is asmall part of various other persecution cases . According to Big Indonesian Dictionary , persecution is the arbitrary hunting of a person or a number of citizens and is harmed , harassed , or crushed ( www.kbbi . web.id , 2017 , para . 1 ) . And interestingly , the persecution is rife in social media as the impact of web personalization or familiarly called filter bubble effect . It must be admitted that social media has complicated algorithms , one click and like methods will determine what information we receive next . Recently others have argued that personalization algorithms used by online services such as Facebook and Google display users similar perspectives and ideas and remove opposing viewpoints on behalf of the users without their consent ( Pariser 2011 as cited in Bozdag & Hoven , 2015 , p. 249 ) . Furthemore , Pariser ( 2011 ) mention that this might lead to the situation in which the user receives biased information . In case of political information , it might lead to the situation that the user never sees contrasting viewpoints on a political or moral issue . Users will be placed ina “ filter bubble ” and they will not even know what they are missing ( as cited in Bozdag & Hoven , 2015 , p. 249 ) . People ’ s life is likely to change since the arrival of new media . Information plays an important role for now , so it is reasonable if the state of society in the digital age referred to as the information society . Digital society has made digital communication and information flow a vital part of everyday life , although access to the Internet and digital technologies varies around the globe ( Hansen et al. , 2017 , p. 80 ) . Through that information , someone has full authority to regulate himself and others will be like what . Includes issues of persecution due to the shackled mindset at a certain point of view . The world is created by someone with information that he gets in social media . Referring to the above issues , it can not be separated from the role of social media as a public sphere . Social media becomes a facility for anyone , both ordinary citizens and government officials to connect and communicate as well as the principle of public sphere described by Charles & Rohwer ( 2015 , p. 1 ) that this was a space where individuals gathered to discuss with each other , and sometimes with public officials , matters of shared concern . The aim of these gatherings was not simply discourse ; these gatherings allowed the bourgeoisie to use their reason to determine the boundaries of public and private and to self-consciously develop the public sphere . The term “ discussion ” refers to social media as a public sphere that allows for the rational exchange of ideas about policies relating to citizens . Each member engages in critical discussions with different points of view . There is an interaction going on , so a more rational and well-judged argument will be accepted . From that concept , the phenomenon that occurs today has shifted from the basic function of public sphere . With the act of persecution as a filter bubble effect , indicates the loss of critical power and the absence of arguments . Social media can be a space for anyone to lead public opinion to be the same as their beliefs . Forgings are so strong , something that is consumed every day , even every second , can change a person ’ s perspective . In addition to sparking the concept of public sphere , as a continuation , Habermas also reveals the theory of actor ’ s rational action that emphasize the rationality in the public sphere itself . Divided into two types of actions , namely the act of instrumental rationality and communicative rationality . These two actions can be used as an analytical tool in seeing the persecution act in social media as filter bubble effect . Departing from this issue , it will be discussed more deeply how acts of persecution in social media are associated with filter bubble 113 UULTTNTTTTTTTTTTTT TTT TTT @ JoP JURNAL ILMU SOSIAL DAN ILMU POLITIK Jurnal IImu Sosial dan Ilmu Politik , Volume 22 , Issue 2 , November 2018 effect , digital society contexts , actors ’ rational actions and the loss of critical discussions in public sphere such as Yetkinel & Colak ’ s ( 2017 , p. 5011 ) statement that the 18 '' century concept developed by Jurgen Habermas , where public sphere got to be known for its undiluted , critical nature backed by the power of reasoning . This discussion is important because not many journal articles have linked the five keywords above . Previous studies have dealt with it more separately , whereas in terms of the fifth concept , they are related to each other , both as cause and effect factors . Such as research from Caplan & Boyd ( 2016 , p. 15 ) that only associate algorithms on social media like Facebook and Twitter with the concept of public sphere . From his research shows , all systems of power are manipulated and there is little doubt that public spheres constructed through network technologies and algorithms can be manipulated , both by the architects of those systems and by those who find techniques to shape information flows . On the other hand , there are related research on the persecution associated with online shaming and the right to privacy . This paper advances privacy theory through examination of online shaming , focusing in particular on persecution by internet mobs ( Laidlaw , 2017 , p. 1 ) . Unfortunately , this research does not include filter bubble effect as the cause of online shaming or basic concept of public sphere that essentially upholds rationality and critical discussion without unilateral thought like the phenomenon . Literature Review Social Media and Digital Society Digitalization of media resulted in an interactive platform of social media . Related to the definition , Kaplan & Haenlein ( 2010 , p. 61 ) mentions that there is no single definition “ What is Social Media ’ There is more of a kind of description of what the process of social media by underlying the interaction among DAN ILMU POLITIK people in which they are creating , sharing , exchanging , modifying their ideas in virtual communities or networks : “ Social Media is a group of Internet based applications that build on the ideological foundations of Web 2.0 , and that allow the creation and exchange of User Generated Content ” ( as cited in Bank , 2014 , p. 1185 ) . In social media , users have a freedom to access the desired information . Unlike the previous traditional media where information obtained by the public is determined by the media or the so-called agenda setting . They have no authority over what is consumed . What is important for the media to be important also for the audiences . As for now , the statement instead turned what is important for the audiences , is that important for the media . Because , through social media users can determine which topics are most in demand , resulting in anumber of traditional media such as television and newspapers are competing proclaimed it . Therefore , the spread of social media platforms provides an opportunity for enhanced access to information and a diversification of sources and opinions . Social media have greatly advanced the possibilities of “ citizen journalism ” . They provide channels for everyone to reach out to the public , to share information , and to express opinions without formal requirements and with a minimum interference in form of regulation and censorship ( Kamp , 2016 , p. 5 ) . Furthermore , Dr. William Tayeebwa , Head of the Department of Journalism and Communication at Makerere University , in his keynote address at the KAS Social Media Conference 2015 , explained about opportunities and challenges of the use of new media technologies , particularly social media . According to William , the chance encompasses : first , social media can improve accessibility as it allows citizens to reach out to political leaders through different channels , second , social media can facilitate the dissemination EOP . TETTET TET TTT 214 Arina Rohmatul Hidayah , Persecution Act as Filter Bubble Effect : Digital Society and The Shift of Public Sphere of information for decision-making and the transfer of knowledge to the citizens , third , social media can provide platforms for discussion of pertinent issues between citizens and their leaders and among the citizens themselves , fourth , social media can facilitate effective networking among the citizens and the creation of different forms of organisations and communities , fifth , social media can provide avenues for more participatory , inclusive and deliberative processes of decision-making , sixth , social media can mobilise citizens around a cause and can spur social-political action . While the challenge is : firstly , accessibility may be impeded by a number of barriers such as poor infrastructure , poor literacy , cultural apprehension to new technologies , or profit interests , secondly , there appears to be a generational gap , with the younger generation making much more use of the opportunities of the internet and social media , thirdly , some observers see a tendency of the state to try to monitor , regulate or even block social media in a way that may threaten the freedom of expression online , fourthly , social media has increasingly become a channel for different forms of offenses and so-called “ cyber- crime ” - such as “ cyber-bullying ” , stalking , defamation , spread of false information and inciting messages , fifthly , social media increase the trend of “ information overload ” which makes it harder to filter out relevant and useful information and can lead to “ social fragmentation ” and “ digital isolation ” ( Kamp , 2016 , p. 7-8 ) . Responding to the statement above , the advantages and challenges of using new media , especially social media , can not be separated from its role in giving and receiving information . The flow of information is so dense , resulting in a condition called the information society . This is the condition of society in the digital era today . People become heavily dependent on information every second and minute in their daily lives . Becla in the journal Information Society and Knowledge- Based Economy-Development Level and The Main Barriers-Some Remarks explained that the notion of the information society was introduced Tadlo Umeaso in 1963 . He defined the information society as the society getting informed through the computer . The first group of definition which one can name “ technological ” came into being this way . The influence of technology on people 's lives is mentioned by Martin Bangemann as “ the revolution based on the information , which is a picture of human knowledge ” . Technological progress makes possible to process , storage , regain , and pass the information , in every possible form — verbal , written , or visual — unrestricted by distance , time and volume ( Bangemann , 1994 , as cited in Becla , 2012 , p. 126 ) . Borrowing the term “ revolution based on the information ” mentioned by Martin , certainly not only related to the geographical aspects in which the technology can merge the boundaries of distance and time . It also includes aspects of the behavioral revolution , lifestyle , and the mindset of people , which is currently heavily influenced by the information they consume through new media . One illustration of the change has been explained by Dr. William Tayeebwa above about cybercrime that allows anyone to commit an information crime , either spreading false news to slander a person or particular group , spreading radical information , and so on . Filter Bubble Effect The main point that can be captured from the role of social media and its relation to the current state of digital society is access to information . The access generates several advantages and challenges like statement of Dr. William Tayeebwa before . There are many advantages gained when using social media , information from different regions and even countries that are so abundant , long distance communication is made easier , and so on . But 105 UALTNTTTITTTTTTTT TTT @ JoP JURNAL ILMU SOSIAL DAN ILMU POLITIK Jurnal IImu Sosial dan Ilmu Politik , Volume 22 , Issue 2 , November 2018 that is not less important to note here is , the challenge of using social media itself . In one aspect , William mentions that the challenge of using social media is social media increasing the trend of “ information overload ” which makes it harder to filter out relevant and useful information and can lead to “ social fragmentation ” and “ digital isolation ” . The information is so abundant that it makes it more difficult for people to distinguish what is right , what is wrong , and what is useful to them . Moreover through the click and like features , social media is able to present similar information based solely on the interests or likes of users , without considering the truth . This condition is very dangerous . Referring to William ’ s terms , when a person consumes similar information or only based on single point of view continuously , he will experience digital isolation or can be said as a filter bubble effect . In 2011 , Eli Parisier released The Filter Bubble : What the Internet Is Hiding From You . In this book , Parisier explains how the internet search engines and their algorithms are creating asituation where users increasingly are getting information that confirms their prior beliefs ( In Holone , 2016 , p. 298 ) . Adam ( 2017 , para . 10 ) also explains that Eli Pariser , an internet activist , look no harmful irregularities of the system algorithms . The algorithm eventually create a “ big bubble ” that makes someone intellectually isolated . That is , when a person never see a different perspective of another person , then it is likely he is to drag on very large in its own judgment . Prakash ( 2016 , p. 18321 ) confirms this opinion that filter bubble is the result of web personalization and as a result the user get isolated from the views which he did not agree . The problem which lies here is that the user ’ s likes and dislikes are guessed by algorithms which apply personalized search and sometimes relevant information for the user may be hided . Therefore , Prakash ( 2016 , DAN ILMU POLITIK p. 18321 ) describes what he meant by web personalization . Web personalization is the process of customizing a website to the needs of each specific user or set of users , taking advantage of the knowledge acquired through the analysis of the user ’ s navigational behavior . Integrating usage data with content , structure , or user profile data enhances the results of the personalization process . Ultimately , we can say that web personalization is done to provide each user their personal web . What is meant by Prakash above can be felt through a number of social media like Instagram , YouTube , and Facebook . According to Guy et al. , ( 2010 , p. 194 ) , in recent years , quite a few personalized recommendation services for social media have emerged . For instance , StumbleUpon ] is a personalized recommender engine that suggests web pages based on a user ’ s past ratings , ratings by friends , ratings by users with similar interests , and topics of interest selected by the user from a list of nearly 500 subjects . The term of filter bubble , has a similar meaning to black hole . Black hole is the online isolated field of communication where critical views and transparency are avoided . It is used to describe relatively closed social networks representing particular viewpoints on health ( anti-vaccination ) , society ( Anders Behring Breivik , white supremacy , and similar ) , religion ( apocalyptic visions in relation to on-going incidents , for example , the last Ebola breakout or AIDS in the 1980s ) ( Hansen et al. , 2017 , p. 81 ) Previous research in this regard explained that the search history is more effective in providing information to the user recommendation . It means that when we write a keyword in the search field , social media will record the traces are then such information will emerge in our social media pages . Or it could just as in the case above , a click on a particular post , subsequent postings from the same source or the like will continue until there are no clicks from us . Freyne et al . ( 2010 , p. 280 ) , in a journal EOP . TET ETT 116 Arina Rohmatul Hidayah , Persecution Act as Filter Bubble Effect : Digital Society and The Shift of Public Sphere Social Networking Feeds : Recommending Items of Interest , shows that harnessing the browsing patterns of users , what and whom they view , are more accurate predictors of relevance than what actions they carry out or with whom they communicate . Persecution Act in Social Media As result of filter bubble , many persecutions act in social media . Just based on his point of view , it is not uncommon for anyone to commit a persecution against another person or group . Persecution term is defined in Indonesian dictionary as hunting arbitrary one or a number of residents , and hurt , be troubled , or crushed ( www.kbbi-web . id , 2017 , para . 1 ) . Rohmatin ( 2016 , p. 134 ) also pressure the same thing , namely maltreatment systematic persecution committed by an individual or a group against other groups . Reinforced by Gummow J , the action of persecuting or pursuing with enmity and malignity : the infliction of death , torture or penalties for adherence to a religious belief or an opinion as such , with a view to the repression or extirpation of it ; the fact of being persecuted ; an instance of this ... ( in Vrachnas , et al. , 2012 , p. 227 ) . Of the three opinions above are similarities in defining acts of persecution . Some of the points that should be highlighted is related to the mistreatment of persecution against individuals or groups and there is an effort both physical and psychological harm . It is quite possible to do in social media that defines as “ medium in internet that enable users to present and express their selves or to interact , to work together , to share , to communicate with other users and building social bounding virtually ” ( Nasrullah , 2015 , as cited in Jamilah et al. , 2016 , p. 924 ) . When someone has a belief or ideology that is opposed to the ideology of others and want to make it the same , it would be easy to do through social media . And persecution is a negative step to get those similarities . Public Sphere and Actor Rational Action Based on some theories above , from social media and society in the digital age , filter bubble effect and persecution act , it should be underlined that all this can not be separated from the public sphere theory of Habermas . What makes the author ’ s reason link some of these concepts with the concept of public sphere is the existence and role of social media . Social media is a form of public sphere in this era . Therefore , social media has fulfilled the criteria of public sphere that is meant by Habermas , namely the public sphere must be open and accessible to all , and in the public sphere of all has equal voice , with influence determined by the force of reason . Social media provides an opportunity for anyone to participate and express an opinion . Moreover , in social media there is no categorization of whether they are government officials or ordinary people , all have the right to argue . Unfortunately , though structurally , social media has conformity to the concept of public space , substantially , it is not . The public sphere of Habermas emphasizes rationality in expressing opinions . There are various reasons and points of view put forward , thus creating a critical discussion , the best argument that will be taken . But not so with social media as the public sphere today . Through the concept of a bubble filter proposed by Eli Pariser , social media can lead one to isolate in his own viewpoint . And , ultimately , the condition triggers the act of persecution against another person or group that is a reflection of the condition of society in the digital age today . The relationship between the public space and the actors ’ rational actions is clearly described by Gunaratne ( 2006 , pp . 6-7 ) . He emphasized the battle between the lifeworld realm and system sphere . The system is a territory controlled by state or government forces that have a policy with lifeworld domains filled by the public with critical argument 107 VNNTTUTTTTTETTTETT TET @ JoP JURNAL ILMU SOSIAL DAN ILMU POLITIK Jurnal IImu Sosial dan Ilmu Politik , Volume 22 , Issue 2 , November 2018 through discussion in the public space . Eventually , Habermas ( 1981/1984 ) developed the notion of communicative rationality based on an in-depth reading of what he originally termed “ universal ” pragmatics and implanted the public sphere in the lifeworld realm , as opposed to the system realm , of society built into his communicative action theory ( as cited in Gunaratne , 2006 , p. 6 ) . From the explanation , it can be said that the lifeworld aspect consists of civil society who conducts critical dialogue or social dialogue through its communicative action in correction or even against state policy , while in the realm of system , filled by governmental authority , using instrumental or strategic action rationality to impose his interest in society in the lifeworld realm . Therefore , in his explanation , Gunaratne ( 2005 , p. 7 ) mentions that this uncoupling gave rise to the pathologies of modernity , or “ colonization of the lifeworld ” . Methods The research method used is literature research . Literature research methodology is to read through , analyze and sort literatures in order to identify the essential attribute of materials . Its significant difference from other methodologies is that it does not directly deal with the object under study , but to indirectly access to information from a variety of literatures , which is generally referred to as “ non-contact method ” ( Lin , 2009 , p. 179 ) . Based on the concept , the initial step of this paper is to formulate the first topic to be discussed . Then look for related theories or literature to answer and analyze the topic . Result Of the several theories already mentioned and based on the literature research method used by the author , then the following are the results obtained through the correlation between theories to answer the issues to be discussed later . DAN ILMU POLITIK Persecution Act in Social Media as Filter Bubble Effect : Overview of Digital Society Today Referring to the statement Gummow that the action of persecuting or pursuing with enmity and malignity : the infliction of death , torture or penalties for adherence to a religious belief or an opinion as such , with a view to the repression or extirpation of it ; the fact of being persecuted ; an instance of this ... ( in Vrachnas et al. , 2012 , p. 227 ) . Compliance with the beliefs or opinions referred to above may be due to personalization of the web on social media or the so-called bubble effect filter . When we like or click a post , then on the next occasion the posting of the account reappears on our media homepage . Until finally the information bias occurs . As an explanation of Eli Parisier in The Filter Bubble : What The Internet Is Hiding From You that the internet search engines and their algorithms are creating a situation where users increasingly are getting information that confirms their prior beliefs ( Holone , 2016 , p. 298 ) . Luckily if the information contains a positive charge . If , on the contrary , one tends to follow continuously radical or extremist information , he may commit an act of persecution through hoaxes or other means , to equate views . Related to this , Nukman Luthfie , a social media observer , told to www.bbc.com ( 2017 , para . 9 ) , “ the core algorithm is the fun of the user , so if we use our Facebook it ’ s actually , in our time line it ’ s contents that ’ s it . Although we have 5000 friends for example , our time line content is the person-that ’ s it . Content and friends , we often respond to , whether we like and we reply or content we share . “ Persecution act as a filter bubble effect is explained by Setiawan ( 2017 , pp . 292-293 ) from the standpoint of communication barriers . He referred to the opinion of Onong Uchjana Effendy ( 2003 ) that communication barriers occur due to several things : Firstly , mechanical disturbances in which the occurrence of interference in communication EOP . TETTED TET 118 Arina Rohmatul Hidayah , Persecution Act as Filter Bubble Effect : Digital Society and The Shift of Public Sphere channels or physical noise , this interference ismore towards the medium used in communicating , like a double voice on radio because of the waves that coincide , or the boisterous noise of the audience when people make a speech . Secondly , because of semantic disorder . This type of disorder is concerned with the notion of actual words or changes in the meaning of words . Symbols of the same words have different meanings for different people . Thirdly , because of interest ( interest ) . Factors of interest will also hinder effective communication , because the importance of the communicant that makes the communicant will be selective in receiving and responding to messages . People will be aroused by messages that become their needs . Fourthly , barriers due to motivation ( motivation ) . The motivation factor of the communicant will also affect the level of awareness , attention , and stimulus to the message conveyed by the communicator . More appropriate , the message with one ’ s motivation , higher the level of intensity and attention . Fifthly , the obstacle due to prejudice . Prejudice is a severe obstacle to the communication process , if not anything communicant has been suspicious both to communicators and messages to be delivered , the the communication will not run effectively . The five obstacles presented above , two of which can be used as one of the causes of the emergence of the persecution act as a filter bubble effect . Departing from ignorance of anything , one can take sides due to the personalization of the web . So when they already have a certain belief or view , they will be more selective in choosing information to strengthen it . And this is what is meant by Onong as a factor of interest and motivation . Communication is not effective because someone tends to ignore information that is not in accordance with the interests and needs . From that condition , it falls into the challenges of using new media technologies as defined by Dr. William Tayeebwa that social media has increasingly become a channel for different forms of offenses and so-called “ cybercrime ” - such as “ cyber- bullying ” , stalking , defamation , spread of false information and inciting messages , and social media increase the trend of “ information overload ” which makes it harder to filter out relevant and useful information and can lead to “ social fragmentation ” and “ digital isolation ” ( Kamp , 2016 , p. 8 ) . Spreading false information , inciting through messages , and digital isolation is the trigger of filter bubble effect in social media , a person or a particular group can freely spread its ideology , like a radical ideology that causes persecution of others . Nath ( 2009 , p. 5 ) confirms this by stating , the exchanges of information in these instances through an ICT infrastructure . According to Nath , or a more radical idea of information super highways , largely facilitated by technology have been the basic tenet of an information society . Social change of society as a result of the use of new media , has been predicted by Martin Bangemann that that the information society is “ the revolution based on the information , which is a picture of human knowledge ” ( Bangemann 1994 as cited in Becla , 2012 , p. 126 ) . With information , people create their own world though not necessarily true . This condition is attached to the term “ post-truth ” , which explains how in the information age , truth is often ruled out . Post-truth is an adjective defined as ‘ relating to or denoting circumstances in which objective facts are less influential in shaping public opinion than appeals to emotion and personal belief ( Lambert , 2016 , p. 63 ) . In addition , in www . remotivi.or.id ( 2017 ) it is explained that Ralph Keyes in his book The Post-truth Era ( 2004 ) and comedian Stephen Colber popularized the term related to post-truth that is more or less truthiness as something as if true , though not true at all . Excessive information and social media ’ s ability to select information based JURNAL ILMU SOSIAL DAN ILMU POLITIK 119 TALTTNTTTITT TTT TTT TTT @ JoP Jurnal IImu Sosial dan Ilmu Politik , Volume 22 , Issue 2 , November 2018 on user preferences leads them to a digital isolation , a bias of facts and reality . This is the condition of today ’ s digital society . And the persecution act becomes a proof . Both extremist and private groups with deep-rooted convictions tend to do so . The important role of social media as an interactive medium that is easily accessible every day and even every second , increases the likelihood for individuals or groups to resist other truths . According to Lambert ( 2016 , p. 63 ) , scholars have tried to explain the factors that have caused this phenomenon of post-truth . The easy access to social media , blogs and internet stories are largely to blame . The Substantial Shift of Public Sphere and Actor Rational Action When associated with Juergen Habermas ’ s public sphere concept , the first requirement is that public sphere must be open and accessible to all . In it , there is a critical discussion in response to public issues . This is relevant when associated with digital media . Introducing people to the internet brings a structural shift in the public sphere , especially its geographical aspects . Discussions and critical debates that are central components of the Habermas concept can be undertaken by various circles with no limited distance and time . If Habermas describes the public sphere with a forum where many people gather and discuss together , then in the context of new media today , people in one area with another can do so as if they meet face-to-face . According to Crack ( 2007 ) , the contemporary information society and knowledge industries are characterized with the removal of all the temporal and spatial barriers to distanced communication with the help of information communication technologies ( ICTs ) . A structural precondition of transnational public spheres is communicative networks to enable broad participation across state borders ( Khan et al . 2012 , p. 44 ) . The new public sphere is DAN ILMU POLITIK emerging out of the digital gadgets starting from a ‘ computer ’ then connecting them into ‘ Network ’ , which started within a building , then cities , states and finally ‘ global-networks ’ came up with the gadget of ‘ Internet ’ , a global platform giving every citizen an opportunity to become an ‘ international-citizen ’ ( Chan & Lee , 2007 , in Khan et al. , 2012 , p. 44 ) . Unfortunately , when viewed in the current context , social media as a part of digital media , it causes a substantial shift in the public sphere through filter bubble effect that removes dialogue and critical discussion and finally the act of persecution is easily done . Social media keeps them chained at their own point of view without any discussion or debate with other points of view by consuming the same information continuously in social media , especially negative information , can cause a person or group to be provoked to have the same point of view so as to enable them to commit in violence or intimidation against others . Especially when the layman who does not know anything , with the exposure is so strong , can be made believe . They will not seek to prove or compare with other information and sources . Though the truth was obtained from the objective search results as a form of critical discussion from the users of social media . Such statements of Gooch ( 2017 , p. 14 ) , in fact , truth requires the analysis of objective facts and a discussion of the evidence—requirements that bestow it with great value which professionals in any field have a duty to preserve . Responding to this problem , Fuchs ( 2014 , p. 61 ) attributed it to capitalism . He states that capitalism is the basis for the emergence of modern society . Social media , like Facebook , Twitter , WhatsApp , and all its types , can not be separated from those influences . With the initial goal of profit , global media companies have managed to reach out and attract markets across the country . Capital domination then penetrates to state autonomy and culminates in the private authority of civil society . That EOP . HTTE TTT 120 Arina Rohmatul Hidayah , Persecution Act as Filter Bubble Effect : Digital Society and The Shift of Public Sphere means , the presence of digital media makes people have full authority over public issues . And this is the characteristic of modern society . The point that needs to be underlined from statement above is that in modern society , they have power over the means , including social media , allowing them to control the movement of information . Information on public issues is widely disseminated in social media which then through the media , public opinion and ideology can be directed by certain parties according to their interests . Therefore , Fuchs ( 2014 , p. 61 ) adds that as modern society is based on structures of accumulation and a separation of roles within different realms , there are conflicts of interest over the control of property , collective decisions and meanings that can result in social struggles . Economic , political and cultural roles in modern society are organized in the form of classes , parties and political groups , and communities of interest that compete over the control of property/surplus , collective decision , and social meanings . The relevance of the concept proposed by Fuchs above with the main issue in this paper lies in the different situations . If something is public , it is “ open to all ” ( Habermas , 1991 , p. 1 ) . The task of a public sphere is that society can become engaged in “ critical public debate ” ( Habermas , 1991 , p. 52 ) . The public sphere would therefore require media for information and communication and access by all citizens . The logic of the public sphere is independent of economic and political power ( Habermas , 1991 , p. 36 ) : “ Laws of the market ( ... ) ( are ) suspended as were laws of the state ” Habermas thereby stresses that the public sphere is not just a sphere of public political communication , but also a sphere free from state censorship and from private ownership . It is free from particularistic controls ( as cited in Fuchs , 2014 , p- 60 ) . The concept proposed by Habermas above is in a situation where capital forces have not yet dominated the global market . The mass media that existed at that time has not mobilized the public to have the authority and even the full power over the choice of information . So , Habermas still emphasizes the independence and neutrality of the public sphere , without the political economic interests in it . Unlike the condition of modern society today . Social media as a representation of public sphere in the digital age , no longer neutral . Social media can take sides , depending on the interests of the consumer . When they want to affirm their belief , social media is able to provide supportive information . Conversely , when they want to influence others to be equal to their beliefs and interests , social media is also able to provide that facility . Thus , the critical debate in Habermas ’ s public sphere leading to consensus , the best argument to be accepted , has shifted . Habermas 's shadow is a group of people sitting together , conducting discussions to reach a consensus on public affairs . But what happens now is social media as a public sphere , it is very easy to present a variety of information by only loading one point of view according to user preferences and through click and like method . In fact , if adjusted to the ideal concept of public sphere , although there are features of click and like , social media should remain neutral ( not only neutral from global interests or the state , but also personal or group interests ) by providing facilities for information from various points of view can emerge . They will be trained to choose which information is true and not the absolute truth , according to their own convictions . Previously , it has been explained that there is a shift in the concept of public sphere , according to Habermas with the current context . The public sphere in question can be attributed to the actor ’ s rational action it installs . Habermas ’ s conviction that human action or social interaction within a society does not occur arbitrarily but is essentially rational JURNAL ILMU SOSIAL DAN ILMU POLITIK 120 VUNTTVTETTTTETTTTETT TET @ JoP Jurnal IImu Sosial dan Ilmu Politik , Volume 22 , Issue 2 , November 2018 ( Hardiman , 2009 , p. 34 ) . Among the two types of rational action are instrumental rationality and communicative rationality , debates and critical conversations to reach a consensus on the basis of the best argument included in communicative rationality . While the act of persecution and the facilities provided by social media in creating a bubble effect filter is an instrumental rationality . Although equally included in rational action , according to Hardiman ( 2009 , p. 36 ) , in strategic action people use language not as a medium of understanding , but as a tool to impose the will . A tool for imposing will through words or even violence can be used to generate consensus . But one can not recognize such consensus as legitimate . It is for this reason that Habermas considers communicative actions ( Handeln ’ s kommunikatives ) -means : actions directed at consensus-more fundamental than strategic action to produce social coordination mechanisms . For indeed in rationality or communicative action , there is a discussion of claims of validity , which includes truth claims , honesty and accuracy ( Hardiman , 2009 , p. 37 ) . In the public sphere there should be discussion from multiple points of view , rather than highlighting personal beliefs and rejecting the other truth . If the picture above shows how the consensus consists of several claims , then it is not so in instrumental rationality . Someone affected by filter bubble in social media and finally dare to act persecution , only in the subjective world itself . One example is explained by Azali ( 2017 , p. 5 ) that the FPI members and sympathisers have grown savvy in using digital media to systematically identify and harass those they disagree with , both online and offline . In this condition , a person judges something only from his perspective does not seek to find other evidence ( claims of truth ) nor confirm to various parties ( claims of accuracy ) . So it can be said that social media as a public sphere can be a container of instrumental rationality . Habermas ( 1984 , p. 285 ) talks about instrumental action as a nonsocial action oriented towards success or control ( as cited in Kernstock & Brexendorf , 2009 , p. 395 ) . Figure 1 . In a communication taken three kinds of performative attitude toward the world . Consensus can be achieved only if all three validity claims that simultaneously met . CLAIMS HONESTY SUBJECTIVE WORLD ( INDIVIDUAL ) CLAIMS PRECISION Source : Hardiman , F. , B . ( 2009 , p. 37 ) €JoP MUU INIATTTELLLLLLIMMHIEELLL 222 JURNAL ILMU SOSIAL DAN ILMU POLITIK Arina Rohmatul Hidayah , Persecution Act as Filter Bubble Effect : Digital Society and The Shift of Public Sphere Discussion From the above theoretical explanation , it can be attributed to one big case that has just been the world ’ s attention is about the theft of Facebook user data by Cambridge Analytica . There are two cases behind Cambridge Analytica stealing user data . Facebook is Donald Trump ’ s winning campaign in the 2016 presidential election of the United States and affecting users in the Brexit referendum . In the Trump case , for example on www.nytimes.com website explained that Cambridge Analytica , a political data firm hired by President Trump ’ s 2016 election campaign , gained access to private information on more than 50 million Facebook users . The firm offered tools that could identify the personalities of American voters and their influence behavior ( Granville , 2018 , para . 2 ) . Also , it was added by www.theguardian.com that a wholly-owned company has revealed to the Observer how Cambridge Analytica - a company owned by the hedge fund billionaire , Robert Mercer , and headed at the time by Trump ’ s key adviser , Steve Bannon - used personal information taken without authorization early 2014 to build a system that could profile individual US voters , in order to target them with personalized political advertisements ( Cadwalladr & Harrison , 2018 , para . 2 ) . Both cases explain how social media as a public sphere that basically has a concept about the occurrence of critical and rational discussion actually makes someone shackled in his own belief and truth . And Trump ’ s case is one proof that by putting a pro ad for Trump on Facebook , it can increase the number of supporters and ultimately give the victory to the presidential election . The public who initially did not understand or did not even support Trump with such powerful media exposure , made them turn to support ( it must be admitted that for US presidential election 2016 , Facebook is very subtle in shaping polarization in society ) . And just like any other election , when the public has made a choice , let alone fanatical of a certain character allows them to do everything , including persecution act , one of which is manifested through fake news in social media . Allcott & Gentzkow ( 2017 , p. 212 ) writes that following the 2016 election , a specific concern has been the effect of false stories - “ fake news ” as it has been dubbed- circulated in social media . Recent evidence shows that : 1 ) 62 % of US adults get news on social media ( Gottfried and Shearer 2016 ) ; 2 ) the most popular font news mainstream news stories ( Silverman 2016 ) ; 3 ) many people who see them ( Silverman and Singer-Vine 2016 ) ; and 4 ) the most discussed font news stories tended to favor Donald Trump over Hillary Clinton ( Silverman 2016 ) . Putting these facts together , anumber of commentators have suggested that ( Parkinson ’ s 2016 ; Read 2016 ; Dewey 2016 ) . This case can be attributed to Fuchs ’ s theory of connecting modern society with the present presence of social media with capitalism . Habermas , with the concept of public sphere that emphasizes critical discussion see the public sphere is still within the neutral limit . While Fuchs judge that in the modern era , especially with the social media , political economy has entered into it . So if Habermas creates a public sphere with his communicative actions as opposed to the system realm , it is now likely to shift to the control of the capitalist side . That means there is a tendency of the system realm to be dominant over the lifeworld realm . And this is not in line with the original intention that Habermas ’ s critical theory is an attempt to emancipate the lifeworld from system “ colonization ” through the revival of an uncoerced and unrestricted public sphere operating on the “ universal ” pragmatics of communicative rationality ( Gunaratne , 2016 , p. 7 ) . Conclusion The filter bubble in social media is one of the causes of persecution of someone or group against someone and other groups . JURNAL ILMU SOSIAL 123 UALTNTTINTTTTTTTTTTTT TTT @ JoP DAN ILMU POLITIK Jurnal IImu Sosial dan Ilmu Politik , Volume 22 , Issue 2 , November 2018 The filter bubble takes place through web personalization where the algorithm on social media allows one to consume the information they like only . So there is bias information in it . When viewed from the context of today ’ s digital society , the condition is a revolution based on information . Information has brought so great a change , not only in the geographical domain by melding distance and time , but also changing all aspects of life , especially in terms of the mindset and ideology of society . Post-truth era becomes a proof that someone can be shackled in the beliefs and ideologies it creates itself . While in the concept of public sphere , Habermas , which emphasizes on rationality and critical discussion among members , the phenomenon that occurs now actually shows a substantial shift . With the filter bubble effect , it can be said there is no critical discussion conducted by someone or a particular group . They take for granted information on social media without compromising , confirming , or seeking other evidence to support their beliefs . The substantial shift can also be attributed to the actors ’ rational actions . Habermas in the concept of public sphere , wants a critical discussion of validity claims that include claims of accuracy , truth , and honesty . This action he then calls communicative rationality . Discussions that lead to consensus without coercion from others . Unlike the case with social media as a public sphere today . Social media actually provides facilities for the occurrence of strategic action or instrumental rationality , a control effort of someone to have others have the same ideology with him . Although there has been no empirical research , this article tries to offer anew discussion about the function of social media as a public sphere and all the attributes of action in it . Therefore , the suggestion for the future is that further research is needed in this regard to obtain strong evidence and objective facts on the ground . References Adam , A . ( 2017 ) . Filter bubble : Sisi gelap algoritma media sosial . Retrieved December 17 , 2017 , from https : //tirto.id/ filter-bubble-sisi-gelap-algoritma-media- sosial-cwSU Allcott , H. , & Gentzkow , M. ( 2017 ) . Social media and fake news in the 2016 election . Journal of Economic Perspective , 31 ( 2 ) , 211- 236. doi : =10.1257/jep.31.2.211 Arti Persekusi . ( 2017 , December 17 ) . Retrieved from https : //kbbi.web.id/persekusi Azali , K. ( 2017 ) . Fake news and increased persecution in Indonesia . ISEAS Yusof Ishak Institute , 61 , 1-10 . Retrieved from https : //www.iseas.edu.sg/images/pdf/ ISEAS_Perspective_2017_61.pdf Bank , N. , Z . ( 2014 ) . Social media and its effects on individuals and social system . Human Capital Without Borders : Knowledge and Learning for Quality of Life . International Conference . Retrieved from http : //www . toknowpress.net/ISBN/978-961-6914-09- 3/papers/ML14-714.pdf Becla , A . ( 2012 ) . Information society and knowledge-based economy- Development level and the main barriers -some remarks . Interdisciplinary Approach to Economics and Sociology , 5 ( 1 ) , 125-132 . Bozdag , E. & Hoven , J. v. d. ( 2015 ) . Breaking The Filter Bubble : Democracy and Design . Ethics Inf . Technol , 1-17. doi : 10.1007/ $ 10676-015-9380-y . Cadwalladr , C. & Harrison , E. , G. ( 2018 ) . Revealed : 50 Million Facebook Profiles Harvested for Cambridge Analytica in Major Data Breach . Retrieved May 7 , 2018 , from https : //www.theguardian . com/news/2018/mar/17/cambridge- analytica-Facebook-influence-us- election Caplan , R. & Boyd , D. ( 2016 ) . Who Controls the Public Sphere in An Mediation , Automation , Power , 1-19 . Retrieved Era of Algorithms ? . EOP . PETE ETT 124 DAN ILMU POLITIK Arina Rohmatul Hidayah , Persecution Act as Filter Bubble Effect : Digital Society and The Shift of Public Sphere from https : //datasociety.net/pubs/ap/ MediationAutomationPower_2016.pdf Charles , G. , -U . & Rohwer , L. , F. ( 2015 ) . Habermas , the Public Sphere , and the Creation of a Racial Counterpublic . Michigan Journal of Race and Law , 21 ( 1 ) , 1-21 . Retrieved from https : //repository . law.umich.edu/cgi/viewcontent . cgi ? referer=https : //www.google.co.id/ & httpsredir=1 & article=1048 & context=mjrl Debora , Y . ( 2017 ) . Kronologi kasus dugaan penistaan agama . Retrieved May 1 , 2018 , from https : //tirto.id/kronologi-kasus- dugaan-penistaan-agama-b457 Facebook FPI Picu Kekerasan atau Menyebar Pesan Kemanusiaan ? . Retrieved January 31 , 2018 , from www.bbc.com/indonesia/ indonesia-42442733 Fuchs , C. ( 2014 ) . Social media and the public sphere . Triple C , 12 ( 1 ) , 57-101 . Retrieved from http : //www.triple-c.at/index.php/ tripleC/article/viewFile/552/529 Freyne , J. , Daly , E. , M. , Berkovsky , S. , & Geyer , W. ( 2010 ) . Social networking feeds : Recommending items of interest . Proceedings of the 2010 ACM Conference on Recommender Systems , 277-280. doi : 10.1145/ 1864708.1864766 Gooch , A . ( 2017 ) . In pursuit of the truth . In UNO Magazine “ The Post-Truth Era : Reality vs. Perception ” ( pp . 14-15 ) . Spain : Llorente & CUENCA . Granville , K. ( 2018 ) . Facebook and Cambridge Analytica : What you need to know as fallout widens . Retrieved May 7 , 2018 , from https : //www.nytimes . com/2018/03/19/technology/Facebook- cambridge-analytica-ex plained html Gual , M. ( 2017 ) . Korban persekusi ‘ The Ahok Effect ’ tercatat mencapai 59 orang . Retrieved December 17 , 2017 , from https : //www.cnnindonesia.com/ nasional/20170601163649-20-218744/ korban-persekusi-the-ahok-effect- tercatat-mencapai-59-orang/ . Gunaratne , S. A . ( 2006 ) . Public sphere and communicative rationality : Interrogating Habermas 's Eurocentrism . Journalism & Mass Communication Monographs , 8 ( 2 ) . 4-115. doi : 10.1177/152263790600800201 Guy , I , Zwerdling , N. , Ronen , I. , Carnel , D. , & Uziel , E. ( 2010 ) . Social media recommendation based on people and tags . SIGIR . Retrieved from https : //www . research.ibm.com/haifa/dept/imt/papers/ guySIGIR10.pdf Hansen , H. , A. , Bjorktomta , S. , B. , & Svalastog , L. ( 2017 ) . Digital Society generates New Challenges On Child Welfare Services . Croat Med Journal , 58 , 80-83 . Retrieved from http : //neuron.mefst.hr/ docs/CMJ/issues/2017/58/1/cmj_58_1_ hansen_28252879.pdf Hardiman , F. , B . ( 2009 ) . Demokrasi Deliberatif : Menimbang Negara Hukum dan Ruang Publik dalam Teori Diskursus Jurgen Habermas . Yogyakarta : Kanisius . Holone , H. ( 2016 ) . The filter bubble and its effect on online personal health information . Croatian Medical Journal , 57 ( 3 ) , 298-301. doi:10.3325/cmj.2016.57.298 Jamilah , I. , Akbar , K. , F. , Gunawan , M. , A. , & Marantika , S. ( 2016 ) . Political communication , social media , and public sphere : An analysis to a phenomenon in Bandung towards Smart City . International Journal of Social Science and Humanity , 6 ( 12 ) , 923-928. doi : 10.18178/ ijssh.2016.6.12.774 Kamp , M . ( Ed. ) . ( 2016 ) . Reality Check Assessing The Impact of Social Media on Political Communication and Civic Engagement in Uganda . Uganda : Konrad Adenaur Stiftung : Kernstock , J . & Brexendorf , T. , O . ( 2009 ) . Implications of Habermas 's “ theory of communicative action ” for corporate brand management . Corporate Communications : An International Journal , 14 ( 4 ) , 389-403. doi : 10.1108/13563280910998745 JURNAL ILMU SOSIAL 125 UALTUTTNTTITTT TTT TTT @ JoP DAN ILMU POLITIK Jurnal IImu Sosial dan Ilmu Politik , Volume 22 , Issue 2 , November 2018 Khan , M. , Z. , Gilani , I , S. , & Nawaz , A . ( 2012 ) . From Habermas model to new public sphere : A paradigm shift . Global Journal of Human Social Science , 12 ( 5 ) , 42-52 . Laidlaw , E. , B . ( 2017 ) . Online Shaming and The Right to Privacy . Journal of Laws , 6 ( 3 ) , 1-26. doi : 10.3390/laws6010003 Lambert , M. ( 2016 ) . Post-truth era and impact on the science associated with sport and exercise medicine . S Afr J Sports Med , 28 ( 3 ) , 63. doi : 10.17159/2078-516X/2016/ v28i3a1838 Lin , G. ( 2009 ) . Higher Education Research Methodology-Literature Method . International Education Studies , 2 ( 4 ) , 179-181 . Prakash , S. ( 2016 ) . Filter Bubble : How to Burst Your Filter Bubble . International Journal Of Engineering And Computer Science , 5 ( 10 ) , 18321-18325. doi : 10.18535/ijecs/v5i10.15 Rohmatin , T. ( 2016 ) . Nilai-Nilai Pluralisme dalam Buku Pendidikan Agama Islam ( PAI ) untuk Sekolah Menengah Atas ( SMA ) . [ imu Ushuluddin , 3 ( 1 ) , 133-152 . Selamat Datang di Era Post-Truth . ( 2017 , January 17 ) . Retrieved from www . remotivi.or.id/kabar/345/Selamat- Datang-di-Era-Post-Truth . Setiawan , I . ( 2017 ) . Kajian Yuridis terhadap Persekusi . Jurnal Ilmiah Galuh Justisi , 5 ( 2 ) , 291-299 . Vrachnas , J. , Bagaric , M. , Athula , P. , & Dimoploulos , P. ( 2012 ) . Migration and Refugee Law : Principles and Practice in Australia ( 3° Ed. ) . New York : Cambridge University Press . Yetkinel , O . & Colak , M. ( 2017 ) . The Effects of Transformation of Public Sphere with the New Media in Academy . EURASIA Journal of Mathematics Science and Technology Education , 13 ( 8 ) , 5009-5018. doi : 10.12973/eurasia.2017.00979a EOP . HET ETE 126 DAN ILMU POLITIK See discussions , stats , and author profiles for this publication at : https : //www.researchgate.net/pu blication/33537 6707 ResearchGate Counteracting the filter bubble in recommender systems : Novelty-aware matrix factorization Article - August 2019 DOL : 10.3233/1A-190017 CITATIONS 6 3 authors : a Panagiotis Symeonidis s . we ae ea Aristotle University of Thessaloniki 111 PUBLICATIONS 2,632 CITATIONS SEE PROFILE Markus Zanker ; Free University of Bozen-Bolzano 228 PUBLICATIONS 5,107 CITATIONS SEE PROFILE Some of the authors of this publication are also working on these related projects : Project © DSSApple View project Proect ‘ Seller View project All content following this page was uploaded by Ludovik Coba on 27 August 2019 . The user has requested enhancement of the downloaded file . READS 393 Ludovik Coba of Free University of Bozen-Bolzano 19 PUBLICATIONS 146 CITATIONS SEE PROFILE Undefined 1 ( 2014 ) 1-5 1 IOS Press Counteracting the Filter Bubble in Recommender Systems : Novelty-aware Matrix Factorization Panagiotis Symeonidis , Ludovik Coba * and Markus Zanker Free University of Bozen-Bolzano , 39100 , Bozen-Bolzano , Ttaly E-mail : { psymeonidis , mzanker } @ unibz.it Abstract . The search for unfamiliar experiences and novelty is one of the main drivers behind all human activities , equally im- portant with harm avoidance and reward dependence . A recommender system personalizes suggestions to individuals to support and guide them in their exploration tasks . Personalization mechanisms and recommender systems limit serendipitous encounters by selectively guessing the next item to show to users and potentially leading them into so-called filter bubbles . In the ideal case , these recommendations , except of being accurate , should be also novel . However , up to now most platforms fail to provide both novel and accurate recommendations . For example , a well-known recommendation algorithm , such as matrix factorization ( MP ) , tries to optimize only the accuracy criterion , while disregarding the novelty of recommended items . In order to counteract the filter bubble , we propose two models , denoted as popularity-based and distance-based NMF , that allow to trade-off the MF performance with respect to the criteria of novelty , while only minimally compromising on accuracy . Our experimental results demonstrate that we attain high accuracy by recommending also novel items . Keywords : Recommendation algorithms , Evaluation , Novelty , Collaborative Filtering , Matrix Factorization 1 . Introduction The filter bubble is the unique universe of informa- tion created around the users by prediction engines or recommendation algorithms [ 26 ] . Based on the princi- ple that users consume media of their interest , the filter bubble creates a tinted view of the world around the users by recommending items from the catalogues . A concrete example of the filter bubble is when a user buys a book on an e-commerce platform and repeat- edly receives recommendations only about books dis- cussing the same topic . This kind of recommendation engine are based on incomplete evidence of interest and neglect the inherent need of users for non-obvious recommendations [ 31 ] . “ Corresponding author . E-mail : lucoba @ unibz.it 0000-0000/14/ $ 00.00 © 2014 — Pre-print Recommender systems research aims primarily at providing accurate item recommendations [ 19 ] while ignoring many times additional quality criteria such as the novelty of a recommended item [ 3 ] . There are many definitions of item novelty [ 3 ] . For example , the popularity-based novelty focuses on discovering non- popular products that match the crowd ’ s interest . In terms of MF for providing novel item recommenda- tions , related work [ 9,32 ] observed that by raising the dimensionality of the MF model ( i.e. , by increasing the number of latent factors ) , we can recommend items coming from the long tail ( i.e . more novel items ) , but with big losses in terms of accuracy . In addition , an in- creased number of latent factors directly affects the ef- ficiency of MF models . Generating novel recommen- dations lead to the following benefits : — Provide non-trivial recommendations . 2 P. Symeonidis et al . / Counteracting the Filter Bubble in Recommender Systems — Discover items that could not have been found by the users themselves and increasing the array of choices ( avoids the filter bubble ) . — The business can leverage revenues from market niches ( sales diversity ) . In this paper , we extend our previous work on gen- erating novel item recommendations based on matrix factorization [ 7 ] . We propose a MF method that si- multaneously recommends accurate and novel items . Our proposed method , denoted as NMF , has the advan- tage of controlling through a regularization term how novel items will be recommended , without increasing the number of latent factors of MF [ 9,32 ] . Moreover , we introduce an integrated way to evaluate novelty , de- noted as Novelty-nDCG , which is based on the well- known nDCG [ 4 ] , but adjusted for our case-scenario in recommender systems , and distinguishes a more novel item from a less novel item . N-nDCG also can be used with different definitions [ 3,30 ] of item novelty , as will be described later . However , item novelty should not be considered equal to the diversity of a recommenda- tion list . In the remainder of this paper , Section 2 discusses the related work . In Section 3.1 , we define item nov- elty , and the evaluation of a recommendation list of items . Then , we propose a framework for novel MF . Section 4 presents our experimental results on two well-known datasets . Finally , Section 5 concludes and describes future work . 2 . Related Work Recommender systems ’ effectiveness can not be measured by considering only the accuracy of recom- mendations . Jannach et al . [ 18 ] , outline that the re- search community is becoming increasingly aware of this problem , and that aspects related to the users ’ ex- perience like explanations , novelty and serendipity are starting to receive more attention . Furnas et al . [ 13 ] proposed Singular Value Decom- position ( SVD ) to factor a matrix into three matrices . An instance of SVD , known as classic matrix factor- ization ( MF ) , searches for two matrices ( U and V ) , whose multiplication gives an approximation of the original matrix A . That is , if we have a matrix A with n rows and m columns , we can find two matrices , one U with n rows and k columns and one V with m rows and k columns , such that UV ! produces A with the blank entries filled and a small deflection of the initial values . Another MF method is known as CUR Matrix Decomposition [ 23 ] , because the initial matrix is fac- torized to 3 matrices ( C , U and R ) . One quick observa- tion about CUR decomposition is that row and column that are used to construct matrices C ' and F are ran- domly selected from matrix A . It is obvious that this selection will affect CUR-approximation . Several methods have been proposed to compute matrices U and V. For example , Lee and Seung [ 21 ] proposed the definition of a cost function ( ie. , ||A — UV || ? ) , which can be minimized either by using mul- tiplicative update rules or by using additive update rules of the well-known gradient descent method . In addition , Dhillon and Sra [ 11 ] proposed multiplica- tive update rules that incorporate weights for the im- portance of each element of the approximation pre- dicted matrix A . Please notice that the objective func- tion ||A — UV|| ? is convex either in U only or V only . However , since it is not convex in both variables to- gether , we can only guarantee finding a local mini- mum solution , rather than a global minimum of the cost function . Thus , since in general the problem has not an exact solution , the computation of U and V is commonly approximated numerically with methods , such as gradient descent or alternating least squares ( ALS ) . Recently , Lin [ 22 ] proposed an algorithm to re- solve the convergence issues of the optimization pro- cedure . His algorithm guarantees the convergence to a stationary point . However , Lin ’ s algorithm requires even more execution time per iteration than the slow in execution time of Lee and Seung [ 21 ] MF algorithm . As far as item novelty is concerned , Jannach et al . [ 17 ] mention in their research that recommender sys- tems aim at boosting recommendations from the long tail of the item popularity distribution , as it increases sales of novel items . There are several works that try to provide both accurate and novel [ 3,4,30 ] or diversified item recommendations [ 4,5 ] , where a diversified item recommendation list tries to capture more aspects of the user ’ s interest . In terms of MF , related work [ 9,32 ] has claimed that by increasing the number of latent factors of the basic MF model [ 20 ] , we can more ac- curately recommend novel items . A different research direction in MF formulates the item recommendation problem not as a classification problem , but as a rank- ing problem using pairs of positive items ( in the train set ) and negative items ( not in the train set ) as pair- wise input . For example , Bayesian Personalized Rank- ing ( BPR ) [ 27 ] optimizes a simple ranking loss such as AUC ( the area under the ROC-curve ) and uses matrix factorization as the ranking function , that can be di- P. Symeonidis et al . / Counteracting the Filter Bubble in Recommender Systems 3 rectly optimized using a stochastic gradient algorithm . Similarly to BPR , Ning and Karypis [ 24,25 ] proposed a set of Sparse LInear Methods ( SSLIM ) , which in- volve an optimization process to learn a sparse ag- gregation coefficient matrix based on both a user-item purchase matrix and side information on items . In contrast to the aforementioned work of Cre- monesi et al . [ 9 ] , and Yin et al . [ 32 ] , our proposed method incorporates an additional constraint term for novelty into the basic MF formula . Note , that this is in analogy to [ 6 ] where an additional constraint term models the perceived utility of users of the different parameters of the rating summary statistics like the av- erage rating value or the total number of rating . In con- trast , here the information on the novelty of an item is taken from an external resource of a user-item novelty matrix , which will be defined in the next section . While novelty and accuracy of recommended items are seen as a key feature of the recommendation utility in real scenarios , to our knowledge , there is not much work relating them and systematically measuring trade-offs . It is useful to make a clear distinction between nov- elty , diversity and serendipity . Vargas et al . [ 30 ] ex- plain that the novelty of an item refers to how differ- ent an item is with respect to what has already been experienced by a user or the community . While diver- sity refers to a set of items , and it is related to how different items are with each other . While serendipity [ 10 ] refers to how surprising and interesting is an item for a user . Tomeo et al . [ 28 ] extended the regression tree to generate diversified recommendations lists in a multi-attribute setting . In the same direction , Di Noia et al . [ 12 ] proposed a method for diversified recom- mendations by introducing an adaptive multi-attribute diversification method according to the hypothesis that a user who selected many diverse items in the past could be more willing to receive diverse recommen- dations . Wasilewski and Hurley [ 16 ] have proposed a matrix factorization framework to trade-off between the accuracy of item recommendations and the diver- sity of the items in the recommendation list . In the fol- lowing , we argue why there is very small overlap be- tween their and our work , by identifying two impor- tant differences . The first is that similar to the previ- ous approaches , their MF model computes the pair- wise ranking loss of the objective function ( not the element-wise square loss like our methodology ) . In other words , our MF model is element-wise and pre- dicts the missing values of the user-item rating matrix , whereas their model tries to optimize items ’ pairwise ranking . The second difference is that we are explor- ing the trade-off between item recommendation accu- racy and item novelty , whereas they explored the trade off between item recommendation accuracy and item diversity . This difference is discussed further in the discussion section . De Gemmis et al . [ 10 ] proposed a methodology to propose non-obvious items and to measure their serendipity by measuring via web-cam the facial expressions of users . 3 . Novelty In this section , we will define the novelty of an item for a target user . We want to be able to measure if an al- gorithm will recommend more novel items to the users . Table 1 summarizes the symbols used in the following sections . The premise of recommender systems is to suggest to users non-trivial items that match their interest , i.e . to make novel item recommendations . By doing this , businesses can increase their profits , since these novel items usually might have higher profit margins . More- over , users will not get bored and disappointed by just getting trivial recommendations of popular items . In the following , we will define the novelty of a recom- mended item and how to measure the novelty of a rec- ommendation list . Symbol Definition k number of nearest neighbors Da recommendation list for user 2 Top—N _ size of recommendation list NN ( u ) nearest neighbors of user w P , threshold for positive ratings I domain of all items U domain of all users R domain of the rating scale U , V some users a9 some items Lu set of items rated by user wu U ; set of users rated item z Pui the rating of user u on item 7 |Z ] size of the test set Ni novelty of item ¢ Table 1 Symbols and definitions . 4 P. Symeonidis et al . / Counteracting the Filter Bubble in Recommender Systems 3000 ings 2000 1000 ¢t of ra 0 i Oo 1000 2000 3000 Items by descending popularity Fig . 1 . Popularity distribution of items . 3.1 . Popularity-based Item Novelty Figure 1 depicts the item popularity distribution of a well-known dataset , MovieLens 1ML [ 14 ] , where items are ranked depending on how frequently they have been rated by users . As it is shown in Figure 1 , the ratings of items follow a long-tailed distribution and the novel items correspond to the long-tail items of this item popularity distribution , where few users have rated or interacted with , whereas items of low novelty correspond to popular items . Related work [ 3 ] in recommender systems has pro- posed a lot of definitions of item novelty . However , for a recommender system that consists only of a user-item rating matrix ( without any other informa- tion about categories of items , domains of users ’ inter- ests , etc . ) , the simple popularity-based novelty defini- tion [ 3 ] is more suitable , also known as global long- tail novelty , which focuses on discovering relatively unknown items ( coming from the long-tail of the item popularity distribution ) . Based on the aforementioned arguments , novelty can be defined as the opposite of popularity , which means that an item is more novel if fewer people are aware of it . Thus , we adopt the notion of user inverse frequency [ 3,30 ] to measure the novelty N ; of a rec- ommended item 7 , by taking the inverse of its popular- ity , as can be shown by Equation 2 : Novelty ( t ) = —Popularity ( { i ) ( 1 ) where Popularity ( i ) corresponds to the probability that an item is rated or observed or had any other type of an interaction with a user . Novelty ( t ) = N ; = — ( 2 ) where U ; is the set of users that rated item 7 , and U is the set of all users . Based on Equation 2 , an item can be considered as more novel , if the users have interacted less with it ( i.e. , it received less ratings , or it is not enough purchased or it is less observed/viewed ) . In order to highlight the existence of highly novel items ( favoring few very novel items and penalizing many less novel items ) , we can consider the logarithm of the novelty , as it is shown in Equation 3 [ 3 ] : [ Ui |V| N ; = —log2 ( 3 ) The maximal novelty achieved on an items will be considered as : 1 Nmae = —logza— , ( 4 ) | where U is the set of users , |U ; | , from Equation 3 , the number of times item 7 was rated is considered to be null . 3.2 . Distance-Based Item Novelty There are recommender systems which possess in- formation - except the user-item rating matrix - about the categories that the items ’ belong to , or the focus of users ’ interests . For example , in news articles rec- ommendation , we know the category that each article belongs to ( i.e. , politics , sports , etc. ) . Thus , when we recommend a news article about sports to a user that has seen a lot of articles about sports , this recommen- dation can not be considered to be the same degree of novelty than in case we provide the same article to a person that has never seen an article about sports be- fore . That is , for every user the same item may be dif- ferently novel . In the following section , we will define how we can capture this notion of novelty of an item for a user . Differently to the case of popularity-based item nov- elty , in the distance-based model [ 3 ] , also known as unexpectedness , for capturing an item ’ s novelty we de- fine a distance function between the target item i from the set of items J and the set of items J , that a user has already interacted with ( the user ’ s past experience ) . We can formulate this novelty as shown in Equation 5 : P. Symeonidis et al . / Counteracting the Filter Bubble in Recommender Systems 5 d > dG,3 ) Vjelu 5 Ful © ) Nui = Please notice that the distance between two items can be also considered as the complement ( i.e . d ( i , 7 ) = 1—sim ( { i , j ) ) of any similarity measure ( cosine-based , Jaccard coefficient , etc . ) in terms of the item features ( i.e. , the category that an item belongs to , the features of an item , etc . ) or the user ’ s item categories profile ! ( i.e . the item categories that a user prefers ) . To capture how novel a topic category is for a user , we can use Equation 6 , which is based on the well-known subtopic recall metric ( S-recall ) [ 3 ] , but adjusted to our case scenario : 1 Nuc === > ( 6 re | { i € I , : i belongs to category C } | ( © ) where 7 is an item and C is the set of all topic cate- gories . Thus , when a user wu has interacted with many items that belong in the same category C , then this category will be not so novel for her . In the results we show measurements considering the topic coverage notion of novelty . An item will be novel if it belongs to a category that has never been seen before , thus , Nmaz = 1 ? . 3.3 . Novelty of recommendation list For a user u who is recommended N different items , we define as novelty of the L , , recommendation list of items , as follows : 1 Ni= Hy » Nuvi ( 7 ) VWiebu where N , , , ; is the novelty as explained in Section 3.1 if using the popularity-based notion , or Section 3.2 if using the distance-based notion . We have to mention that the aforementioned definitions of Novelty can not 'To capture the interaction between users and the item categories they have interacted with , we can build a user-category profile , com- posed of the user-item rating profile and the item-category profile ( e.g. , their dot product ) . ? Please notice that every item in our datasets belongs to at least 1 category . penalize the fact that an item that is less novel is ranked in the recommendation list L , , , above another item that is more novel . To do this , we will define in the follow- ing the N-nDCG . Thus , to obtain a more fine-grained level of granu- larity we adopt the notion of Novel - normalized Dis- counted Cumulative Gain ( N—DCG. , ) [ 4 ] , which also takes under consideration the relative position of the recommended items inside L , , . The first step in the computation of N — DCG , is the creation of the gain vector . In our case , the gain vector for each item | in Lu , consists of its Novelty ( N ) ) ( i.e . as defined in Equation 3 or Equation 6 ) . The second step in the computation of N — DCG , applies the Discounted Cumulative Gain to the afore- mentioned gain vector , as shown in Equation 8 . N N N-DCG , =™M , +50 i=2 logs ( 8 ) ogat Based on Equation 8 , we discount the gain at each rank inside L , , to penalize items , which are recom- mended lower in the ranking , reflecting the additional user effort in order to reach them and take the corre- sponding explanation [ 30 ] . The third step is to normalize the N — DCG , against the “ ideal ” gain vector . In our case , the “ ideal ” gain vector considers all recommended items in L , , as having maximum Novelty , Ning « ( i.e . as defined in Equation 3 or Equation 6 ) . That is , all recommended items in L , , are considered as never seen by any user . Thus , the ideal N-IDCG is calculated as : “ VN , N-IDOG = Ninax + ) 7 ( 9 ) jag 092 '' Finally , the N-n DCG , is the ratio between N-DCG , to N-IDCG : N-DCOGu N1DOCGu = SHG ( 10 ) 3.4 . Other novelty metrics In this section , we adopt two additional metrics for evaluating the novelty . From the work of Vargas et al . [ 31 ] we use Expected Popularity Complement ( EPC ) to measure the popularity based novelty and the Ex- 6 P. Symeonidis et al . / Counteracting the Filter Bubble in Recommender Systems pected Profile Distance ( EPD ) to measure the distance based novelty , as follows : EPC =C ) - dise ( k ) p ( rellix , u ) Ni ) da ) ieL EPD=C ' S- dise ( k ) p ( rellix , u ) p ( rell|j , u ) d ( tn , J ) iE€L , jeu ( 12 ) Where C is a constant , k is the position of an item in the recommendation list L , and p ( rel|i , ,u ) = 1 if the item is in the test set else it is 0 , and disc = ——+— . toga ( k+2 ) 3.5 . Matrix Factorization Matrix factorization methods are used in recom- mender systems to derive a set of latent factors , from the user x item rating matrix , to characterize both users and items by this factor vector . The user-item in- teractions are modeled as the inner product of the la- tent factors space [ 20 ] . Accordingly , each item j will be associated with a vector of factors v ; , and each user zis associated with a vector of factors u ; . An approx- imation of the rating of a user 7 on an item 7 can be derived as the inner product of their factor vectors : Pag = UV , ( 13 ) The u ( user ) and v ( item ) factor matrices are cropped to k features and initialized at small values . Each fea- ture is trained until convergence ( where convergence specifying the number of updates to be computed on a feature before considering it converged , it can be ei- ther chosen by the user or calculated automatically by the package ) . On each loop the algorithm predicts 7 ; , ; , calculates the error and the factors are updated as fol- lows : Ujk < Ujn+A * ( riz — Ui ; ) * Wik —Y * Ujk ) ( 14 ) Uik — Win FAx ( riz — Ui ; ) * Ujk —Y * UjR ) ( 15 ) The attribute A represents the learning rate , while y corresponds to the regularization term . 3.6 . Novel Matrix Factorization In this section , we propose an algorithmic frame- work to trade-off between accuracy and novelty in ma- trix factorization . For popularity-based novelty , to provide more novel item recommendations , we add an additional soft con- straint for novelty into the classic regularized matrix factorization formula as shown in Equation 16 : Grovet = > . ( rig — Uiv7 P+ LjER B ugll ? + loyl2 ) + dllen — vjlIMiy , 16 ( tall + lleyll ) + Slur — vy |/Miz , 16 ) where 4 controls the novelty vector and Nj ; holds the information of how novel item 7 is for user 2 , and 8 weights the effect of the L1 regularization term . Please notice that ||u ; — v , ; || constrains the representations of the user/item vectors in the latent space , such that they are close to each other ( i.e. , their difference is close to zero ) , in order to minimize the objective function . In other words , we want to bring the user closer to the novel items in the latent space . To do this , we use the Manhattan distance , which overcomes the problem of Euclidean distance ’ s metric over high dimensional spaces , since it does not place more emphasis on out- liers , which may dominate other smaller weights com- puted for other normal data points [ 1 ] . Then , to min- imize the objective function Grover , we Compute the error of the difference among the real and the predicted rating values of items by using a numerical method , such as Gradient Descent , and by applying the follow- ing update rules : wou tn : ( 2+ ( riz — ua : B- uj , —A- sgn ( uz — v ; ) vy ) Uy — - Niz ) vy 0p + ( 2+ ( rig — Fs — B-v ; —A- sgn { u ; — v ; ) -Niz ) Henceforth , we call this method Novel Matrix Fac- torization ( NMF ) . Please notice that MF is just a sim- plified special case of NMF and can be easily derived from it . P. Symeonidis et al . / Counteracting the Filter Bubble in Recommender Systems 7 Table 2 Dataset Characteristic ML-100K ML-1M ML-20M Yelp - L.V . # of ratings 100,000 1,000,209 = 20,000,263 215,318 # of users 943 6,040 138,493 5,180 # of items 1,682 3,952 27,278 4,111 # of genres 19 18 19 130 Average # of genres per item 1.67 1.99 1.99 2.02 Rating ’ s domain [ 1,5 ] [ 1,5 ] [ 1,5 ] [ 1,5 ] 4 . Experimental Results In this section , we compare experimentally our ap- proach NMF with the Matrix Factorization [ 20 ] al- gorithm ( MF ) . Moreover , we will use the Maximal Marginal Relevance re-ranker ( MMR ) [ 2 ] combined with the MF algorithm , such that we have in our ex- periments also a variation of MF , which focuses on providing novel item recommendations . In particular , for re-ranking the item recommendation list provided from classic MF algorithm with MMR , we adapt the following greedy objective function of Satil Vargas [ 29 ] , as shown by Equation 17 : argmaz| ( 1 — A ) * Frorm { u , i ) + A * avgjet , , ( 1 — sim ( i , j ) ) ] , ( 7 ) where ? , orm ( { u , 1 ) is the normalised predicted rating of user u over item 7 . It is normalised on the [ 0,1 ] scale , such that it can be combined with Jaccard similarity ? ( see the second term of Equation 17 ) , which measures the dissimilarity of items . In particular , it measures the average similarity of an item with all other items which have already taken a position inside the L , , recommen- dation list , which is to be re-constructed for user u . As can be shown by the » parameter of Equation 17 , there is a trade-off between how relevant an item is being considered by a user , and how much this item differs from the items , which have been already included in- side the currently constructed recommendation list . In our experiment we kept the trade-off \\ = 0.5 . We implemented the experiment using the func- tionalities of rrecsys [ 8 ] and proxy * . To ensure repro- 3Jaccard similarity is particularly adequate for binary data . In this case we are considering the similarity in the context of the topic coverage . “ https : //cran.r-project.org/package=proxy ducibility of experimental results we share our imple- mentation® . 4.1 . Data Sets Our experiments are performed with four datasets , MovieLens 100K ( ML100K ) , MovieLens 1ML ( ML1M ) , MovieLens 20 ML ( ML20ML ) [ 15 ] , and Yelp © ( see Table 2 ) . ML100K consists of 100,000 ratings assigned by 943 users on 1,682 movies . ML1M contains 1,000,209 anonymous ratings of approximately 3,900 movies made by 6,040 users . ML20ML consists of 20 mil- lion plus ratings , consisting of 27,278 items rated by 138,493 users . All the MovieLens datasets have at least 20 ratings per user ( Vu € U : |I , ,| > 20 ) . The Yelp dataset consists of a large collection of rat- ings on businesses . We took a sub-dataset of the dataset consisting only of restaurants , where the novelty hy- pothesis is more plausible ( e.g . if a user eats pizza one day , the next time she might want to try something else ) . In addition , we limited the recommendations to Las Vegas since the dataset contains more businesses from this city . Still , the dataset displays large spar- sity , thus we took a sub-sample of 40 ratings per user ( Vu EU : |I , ,| > 40 ) . 4.2 . Experimental Protocol and Evaluation Our evaluation considers the division of items of each target user into two sets : ( i ) the training set E ? is treated as known information and , ( ii ) the test set EB ? is used for testing and no information from the test set is allowed for learning for computing predictions . It is obvious that , F = BE ? UEP and EP NEP = © . Therefore , for a target user we generate the recommen- dations based only on the items in E * . Shttps : //github.com/ludovikcoba/NMF Shttps : //www.yelp.com/dataset 8 P. Symeonidis et al . / Counteracting the Filter Bubble in Recommender Systems In addition to the N-nDCG metric introduced in Sec- tion 3.3 we use classic precision and nDCG metrics for measuring the accuracy performance of recommenda- tions . We perform all experiments with 4-fold double- cross validation , with a training-test split percentage , 75 % -25 % . The default size of the recommendation list N is set to 10 , except to the cases where written dif- ferently . All algorithms predict the items of the target users ’ in the test set . For ML100K , ML1M and ML20M the number of latent factors , update cycles , the regularization term £ , the learning rate 7 to 80 , 100 , 0.001 and 0.001 , respec- tively . For Yelp-L.V . we set the number of latent fac- tors , update cycles , the regularization term 3 and the learning rate 7 is set to 80 , 50 , 0.0001 and 0.001 , re- spectively . For MMR we keep the trade-off at 0.5 , while for the NMF we variate the Novelty-regTerm . 4.3 . Sensitivity analysis of NMF In this section , we want to explore how the per- formance of both popularity-based and distance-based NMF in terms of providing novel and accurate rec- ommendations is affected , as we increase the impact of the regularization term 6 , which controls novelty in Equation 16 . Figures 2a , 2b , 2c and 2d show the Popularity-based NMF as we increase 5 . As shown , N- nDCG and nDCG are negatively correlated , which sig- nifies that as we increase N-nDCG the nDCG drops . In Figures 3a , 3b , 3d and 3c we depict the distance- based NMF as we increase 6 . For the first three datasets , the trend that we noticed with the popularity- based NMF can be also noticed with the distance- based NMF . That is , as N-nDCG increases , accuracy drops and vice versa . While on the Yelp dataset , Figure 3c , we notice that novelty ( both in terms of N-nDCG and EPD ) and precision increase together . Given the scenario , this could relate to the users ’ inherent need for novelty and the notion of discovery [ 31 ] . Although , this first experimental result requires further and inten- sive investigation . Please notice that the difference in terms of N- nDCG between distance-based and popularity-based NMF is related to the different notions of novelty ( see Section 3.1 and 3.2 ) . In summary , for all Movielens datasets , as we in- crease 6 , NMF recommends more novel items but the recommendation accuracy drops drastically , while for the Yelp dataset on the distance-based NMF novelty and precision seem correlated . 4.4 . Comparison with other algorithms Table 3 shows the performance results for popularity- based novelty ( ie. , pop-NMEF ) and MF on four datasets , respectively , when we provide top-10 item recommen- dations . As it is shown in Table 3 , our pop-NMF out- performs MF in terms of a more balanced performance between accuracy and novelty in all four data sets . The reason is that we put in the objective function of the classic matrix factorization and additional soft constraint , which pushes the more novel items to be recommended to the target user . These recommended items are those items which have not been seen by the users in the database ( not the popular ones ) . While compared to MMR , for ML100K , ML1M and Yelp , our proposed approach displayed again a bal- anced trade-off between novelty ( N-nDCG and EPC ) and precision ( precision and nDCG ) . Lastly , for the distance-based NMF as shown in Ta- ble 4 , our Cat-NMF method provides in both data sets ( ie. , ML and Yelp ) more novel item recommendations , when it is compared with MF + MMR , with minimum losses in terms of precision/nDCG . We were not able to get results on ML20M with MMR due to size of the dataset , it either required too much time ( > 5 days ) or incurred in memory starva- tion . 5 . Conclusions and Future Work In this paper , we proposed a new framework for novel matrix factorization , denoted as NMF , that pro- vides both novel and accurate item recommendations . In particular , this article introduced the distance-based item novelty , which extends the simple popularity- based item novelty model . Our empirical results have revealed the trade-off relationships between algorith- mic item accuracy and novelty , and our proposed distance-based NMF effectively deals with both of these two aspects . In future work we also want to con- sider the diversity of recommendation lists . Finally , we want to perform more offline experiments with addi- tional datasets , but also online evaluations of our NMF algorithm with real users to assess if and how users notice the increased novelty according to our proposed measure . References [ 1 ] Aggarwal , C.C. , Hinneburg , A. , Keim , D.A . : On the surpris- ing behavior of distance metrics in high dimensional space . P. Symeonidis et al . / Counteracting the Filter Bubble in Recommender Systems Table 3 Algorithms ’ comparison performance with top-10 recommended items on 4 data sets . Dataset Algorithm RegTerm ( 6 ) Prec . nDCG N-nDCG EPC MF - 12.3 % 13.6 % 28.7 % 19.2 % MF + MMR * - 3.7 % 6.6 % 62.8 % 18.5 % ML100K Pop-NMF 0.2 7.3 % 7.7 % 30.9 % 25.8 % Pop-NMF 0.5 4.6 % 4.7 % 32.3 % 30.8 % MF - 11.6 % 12.6 % 17.6 % 11.3 % MF + MMR * - 3.2 % 6.0 % 56.8 % 10.0 % MLIM Pop-NMF 0.2 5.1 % 5.0 % 20.6 % 14.4 % Pop-NMF 1 0.8 % 0.8 % 38.3 % 35.4 % MF - 6.5 % 7.0 % 18.2 % 10.4 % MF + MMRt - - - - - ML20M Pop-NMF 0.02 3.7 % 3.7 % 19.4 % 14.8 % Pop-NMF 0.08 2.8 % 3.3 % 32.8 % 9.8 % MF - 4.7 % 4.9 % 13.5 % 12.6 % MF + MMR * - 3.2 % 3.7 % 17.2 % 16.6 % Yelp-L.V . Pop-NMF 0.50 4.5 % 4.8 % 13.9 % 13.1 % Pop-NMF 1 4.3 % 4.5 % 14.6 % 14.8 % * Trade-off set at 0.5. } Server terminated the process due to resource starvation . Table 4 Algorithms ’ comparison performance with top-10 recommended items on 4 data sets . Dataset Algorithm RegTerm ( 6 ) Prec . nDCG = N-nDCG EPD MF - 12.0 % 12.7 % 6.9 % 3.0 % MF + MMR * - 10.4 % 12.1 % 10.6 % 4.2 % ML100K Cat-NMF 0.5 11.2 % 11.5 % 16.1 % 4.5 % Cat-NMF 0.9 10.7 % 11.0 % 21.8 % 6.2 % MF - 11.5 % 12.4 % 9.9 % 4.0 % MF + MMR * - 11.0 % 12.1 % 10.4 % 6.8 % MLIM Cat-NMF 0.4 9.7 % 9.5 % 40.6 % 7.5 % Cat-NMF 0.7 7.8 % 74 % 52.1 % 9.7 % MF - 6.5 % 7.1 % 6.1 % 2.6 % MF +MMRt - - - - - ML20M Cat-NMF 0.06 5.9 % 5.6 % 37.9 % 6.1 % Cat-NMF 0.1 5.2 % 4.8 % 50.3 % 7.7 % MF - 4.5 % 4.5 % 26.1 % 27.2 % MF + MMR * - 4.3 % 4.7 % 21.8 % 18.7 % Yelp-L.V . Cat-NMF 0.5 4.9 % 4.9 % 30.8 % 32.7 % Cat-NMF 1 5.1 % 5.2 % 34.2 % 33.7 % * Trade-off set at 0.5. } Server terminated the process due to resource starvation . P. Symeonidis et al . / Counteracting the Filter Bubble in Recommender Systems = N-nDCG = nDCG 14.0 40.0 12.0 ~ z 10.0 30.04 =~ a g 8 2 80 3 £ 20.0 6.0 4.0 ) 0.00 0.25 0.50 0.75 1.00 RegTerm ( a ) — N-nDCG — nDCG 8.0 30.0 7.0 = > 25.07 $ X60 3 g 8 a = = 5.0 20.0538 40 15.0 3.0 0.00 0.02 0.04 0.06 0.08 RegTerm ( c ) = N-nDCG = nDCG 40.0 12.5 10.0 30.0 s T rg £75 a 8 20.063 a = = 50 ss 10.0 25 0.00 0.25 0.50 0.75 1.00 RegTerm ( b ) — N-nDCG — nDCG 49 14.7 48 14.4 _~ z x 4 — a B47 1419 a = © se 46 13.8 45 13.5 0.00 0.25 0.50 0.75 1.00 RegTerm ( d ) Fig . 2 . Sensitivity Analysis of Popularity-based NMF for ( a ) the ML100K , ( b ) the ML1M , ( c ) the ML20M and ( d ) Yelp - Las Vegas data sets . [ 2 BB [ 4 [ 5 ] [ 6 ] In : International conference on database theory . pp . 420-434 . Springer Carbonell , J. , Goldstein , J. : The use of MMR , diversity-based reranking for reordering documents and producing summaries . In : Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information re- trieval - SIGIR 98 . ACM Castells , P. , Hurley , N.J. , Vargas , S. : Novelty and diversity in recommender systems . In : Ricci , F. , Rokach , L. , Shapira , B . ( eds . ) Recommender Systems Handbook , 2nd edition . pp . 881— 918 Charles , C. , Kolla , M. , Cormack , G. , Vechtomova , O. , Ashkan , A. , Buttcher , $ . , MacKinnon , 1 : Novelty and diversity in in- formation retrieval evaluation . In : SIGIR Conference . pp . 659— 666 . SIGIR 2008 . ACM Cheng , P. , Wang , S. , Ma , J. , Sun , J. , Xiong , H. : Learning to recommend accurate and diverse items . In : Proceedings of the 26th International Conference on World Wide Web . pp . 183- 192 . WWW °17 Coba , L. , Rook , L. , Zanker , M. , Symeonidis , P. : Decision mak- ing strategies differ in the presence of collaborative explana- tions : Two conjoint studies . In : Proceedings of the 24th Inter- national Conference on Intelligent User Interfaces . pp . 291— 302 . TUL ’ 19 , ACM , New York , NY , USA 7 ] [ 8 ] 19 ] [ 10 ] fi ) [ 12 ] [ 13 ] Coba , L. , Symeonidis , P. , Zanker , M. : Novelty-aware matrix factorization based on items ’ popularity . In : International Con- ference of the Italian Association for Artificial Intelligence ( 2018 ) . pp . 516-527 . Springer Coba , L. , Zanker , M. : Replication and Reproduction in Rec- ommender Systems Research - Evidence from a Case-Study with the rrecsys Library . In : 30th International Conference on Industrial Engineering and Other Applications of Applied In- telligent Systems , IEA/AIE 2017 , Arras , France , June , 2017 , Proceedings . Springer International Publishing , Cham ( 2017 ) Cremonesi , P. , Koren , Y. , Turrin , R. : Performance of recom- mender algorithms on top-n recommendation tasks . In : Pro- ceedings of the Fourth ACM Conference on Recommender Systems . pp . 39-46 . RecSys ’ 10 , ACM , New York , NY , USA De Gemmis , M. , Lops , P. , Semeraro , G. , Musto , C. : An inves- tigation on the serendipity problem in recommender systems . Information Processing and Management 51 ( 5 ) , 695-717 Dhillon , LS. , Sra , S. : Generalized nonnegative matrix approxi- mations with bregman divergences . In : NIPS . pp . 283-290 Di Noia , T. , Rosati , J. , Tomeo , P. , Di Sciascio , E. : Adaptive multi-attribute diversity for recommender systems . Informa- tion Sciences 382 , 234-253 Furnas , G. , Deerwester , S. , Dumais , S.e.a . : Information re- trieval using a singular value decomposition model of latent se- mantic structure . In : Proccedings ACM SIGIR Conference . pp . P. Symeonidis et al . / Counteracting the Filter Bubble in Recommender Systems = N-nDCG = nDCG 20.0 20.0 ~ z g 4 on 15.0 1509 g 8 a = = & 10.0 10.0 0.00 0.25 0.50 0.75 1.00 RegTerm ( a ) — N-nDCG — nDCG 50.0 8.0 40.0 6.0 z x 4 am 30.09 8 3 O40 zs © s 20.0 '' 2.0 10.0 0.00 0.05 0.10 RegTerm ( c ) = N-nDCG = nDCG 50.0 15.0 ) 40.0 z 1 3 8 10.0 30.05 & 20.0 5.0 10.0 0.0 0.2 04 0.6 0.8 RegTerm ( b ) — N-nDCG — nDCG 5.0 40.0 45 f 3 35.0 % Q a ) 40 zg 30.0 3.5 0.00 0.25 0.50 0.75 1.00 RegTerm ( d ) Fig . 3 . Sensitivity Analysis of Distance-based NMF for ( a ) the ML100K , ( b ) the ML1M , ( c ) the ML20M and ( d ) Yelp - Las Vegas data sets . [ 14 ] [ 15 ] [ 16 ] 117 ) [ 18 ] [ 19 ] [ 20 ] [ 21 ] [ 22 ] 465-480 Harper , F.M. , Konstan , J.A . : The movielens datasets : History and context . ACM Trans . Interact . Intell . Syst . 5 ( 4 ) , 19:1- 19:19 Harper , F.M. , Konstan , J.A . : The MovieLens Datasets . ACM Transactions on Interactive Intelligent Systems 5 ( 4 ) , 1-19 Hurley , N.J. : Personalised ranking with diversity . Proceedings of the 7th ACM conference on Recommender systems - Rec- Sys °13 2 ( 1 ) , 379-382 Jannach , D. , Lerche , L. , Kamehkhosh , 1 , Jugovac , M. : What recommenders recommend : An analysis of recommendation biases and possible countermeasures . User Modeling and User- Adapted Interaction 25 ( 5 ) , 427-491 Jannach , D. , Resnick , P. , Tuzhilin , A. , Zanker , M. : Rec- ommender systems — beyond matrix completion . Commun . ACM 59 ( 11 ) , 94-102 Jannach , D. , Zanker , M. , Ge , M. , Groening , M. : Recommender Systems in Computer Science and Information Systems — A Landscape of Research 123 , 76-87 Koren , Y. , Bell , R. , Volinsky , C. : Matrix Factorization Tech- niques for Recommender Systems . Computer 42 ( 8 ) , 42-49 Lee , D.D. , Seung , H.S . : Learning the parts of objects by non- negative matrix factorization . Nature 401 , 788-791 Lin , C.J . : On the convergence of multiplicative update algo- rithms for nonnegative matrix factorization . IEEE Transactions [ 23 ] [ 24 ] [ 25 ] [ 26 ] [ 27 ] [ 28 ] [ 29 ] on Neural Networks 18 ( 6 ) , 1589-1596 Mahoney , M.W. , Drineas , P. : Cur matrix decompositions for improved data analysis . Proceedings of the National Academy of Sciences 106 ( 3 ) , 697-702 Ning , X. , Karypis , G. : Slim : Sparse linear methods for top-n recommender systems . In : 2011 IEEE 11th International Con- ference on Data Mining ( ICDM ) , pp . 497-506 . IEEE Ning , X. , Karypis , G. : Sparse linear methods with side in- formation for top-n recommendations . In : Proceedings of the sixth ACM conference on Recommender systems . pp . 155- 162 . ACM Pariser , E. : The filter bubble : what the Internet is hiding from you . 2011 , Penguin Press Rendle , S. , Freudenthaler , C. , Gantner , Z. , Lars , S.T . : BPR : Bayesian personalized ranking from implicit feedback . In : Pro- ceedings of the Twenty-Fifth Conference on Uncertainty in Ar- tificial Intelligence . pp . 452-461 . UAI °09 , AUAI Press , Ar- lington , Virginia , United States Tomeo , P. , Di Noia , T. , de Gemmis , M. , Lops , P. , Semeraro , G. , Di Sciascio , E. : Exploiting regression trees as user models for intent-aware multi-attribute diversity . In : 2nd Workshop on New Trends in Content-Based Recommender Systems - 2015 ( CBRecSys co-located with RecSys ) . pp . 2-9 Vargas , S. : New approaches to diversity and novelty in recom- mender systems . In : Fourth BCS-IRSG symposium on future 12 P. Symeonidis et al . / Counteracting the Filter Bubble in Recommender Systems directions in information access ( FDIA 2011 ) , Koblenz . vol . 31 the fifth ACM conference on Recommender systems - RecSys [ 30 ] Vargas , S. , Castells , P. : Rank and relevance in novelty and °11 . p. 109 . ACM Press , New York , New York , USA diversity metrics for recommender systems . In : Proceedings [ 32 ] Yin , H. , Cui , B. , Li , J. , Yao , J. , Chen , C. : Challenging the long of the Fifth ACM Conference on Recommender Systems . pp . tail recommendation . Proceedings of the VLDB Endowment 109-116 . RecSys ’ 11 , ACM , New York , NY , USA 5 ( 9 ) , 896-907 [ 31 ] Vargas , S. , Castells , P. : Rank and relevance in novelty and di- versity metrics for recommender systems . In : Proceedings of ISSN 2324-7878 ( online ) palrap.org |e iF A College & Research a Division ( CRD ) Pennsylvania Libraries : Research & Practice Research Using The Filter Bubble to Create a Teachable Moment A Case Study Utilizing Online Personalization to Engage Students in Information Literacy Instruction Allyson Valentine & Laura Wukovitz York College of Pennsylvania Allyson Valentine is now a Reference and Instruction Librarian at Harrisburg Area Community College ( HACC ) , Lancaster Campus , and Adjunct Instructor of Foundational Studies Courses at HACC , afvalent @ hacc.edu Laura Wukovitz is now Campus Library Director of Harrisburg Area Community College ( HACC ) , Harrisburg and York campuses , Idwukovi @ hacc.edu Engaging students in information literacy instruction is often a challenge . The authors discuss ways they adapted information literacy instruction at York College of Pennsylvania based on concepts discussed in Eli Pariser ’ s book , The Filter Bubble . By approaching the students with a course theme that was interesting , timely , and personally relevant , the authors were able to break through student ’ s own filters to explore higher level information literacy concepts and critical thinking . Students took a personal interest in the topic , which translated into greater student engagement and increased participation . It also fostered deeper reading and reflection about how information is communicated and used by a variety of audiences . t Introduction For several years , Information Literacy 101 ( IFL ) was a 2-credit , required course at York College of Pennsylvania . The course was officially dissolved in May of 2012 . During the time period it was offered , student response to the course was often mixed . While some students saw the value in the instruction , others felt that the course was not relevant . Like many institutionally-mandated courses , faculty sometimes found engaging students to Vol . 1 , No . 1 ( Spring 2013 ) DOI 10.5195/palrap.2013.18 24 ( ) Ea New articles in this journal are licensed under a Creative Commons Attribution 3.0 United States License . This journal is published by the University Library System of the University of Pittsburgh as part of its D-Scribe Digital oT Publishing Program and is cosponsored by the University of Pittsburgh Press . Pennsylvania Libraries : Research & Practice . : palrap.org Using The Filter Bubble to Create a Teachable Moment be difficult . In the spring of 2012 , the authors made a radical shift in their curriculum , hoping to improve the level of student engagement and participation within their classes . In previous semesters , the authors had based their instruction on the course ’ s electronic text ( library.ycp.edu/ifl ) , integrated with supplementary materials within the course-management system . In the fall 2011 semester , one of those supplementary items was a TED Talk video , “ Beware Online Filter Bubbles , ” with Eli Pariser ( 2011a ) . The video was used as a springboard to prompt in-class discussion about bias and its effects . Based on student responses to the video and their expressed interest in the topic of online personalization , we decided to try using this concept as the theme for the entire class . Pariser ’ s book , The Filter Bubble ( 2011b ) , was chosen as a required textbook for our sections of the course . In The Filter Bubble , Pariser explains that materials perceived as relevant are allowed past the filter ; messages perceived as irrelevant are filtered out , not just by Google & Facebook , but by our human brains as well ( Pariser , 2011b ) . In order for instruction to be truly effective , we have to penetrate our students ’ filters , convincingly demonstrating that strong information literacy skills are relevant to their daily lives . Pariser ’ s book served as an anchor for course content , allowing us to connect our exploration of information literacy skills , tools , and methods back to a larger theme—a theme that students were readily interested in because they have experienced “ the filter bubble ” themselves . The goal of this article is to present a novel way to teach information literacy skills by using the concept of online personalization as a starting point for research and reflection on the nature of information , how information is communicated , and how it is used . The chief benefit of this approach is that it addresses one of the major challenges facing any teaching librarian who steps into a classroom : convincing students that the material being taught is relevant to their lives . It also offers the librarian a starting point for teaching a variety of other concepts , including ( but certainly not limited to ) evaluating information , researching current events , and information ethics . Literature Review As many authors have discussed , traditional information literacy instruction can often be challenging for both students and instructional librarians ( Drabinski , 2011 ; Piper & Tag , 2011 ; Spence , 2004 ) . One widespread difficulty is presenting materials in effective ways that promote student interest and engagement . Piper and Tag ( 2011 ) explain that “ there has been a growing disconnect between the instructor experience and the student experience , ” especially in terms of motivation ( p. 322 ) . Whilst librarians see the value in information literacy instruction , students often enter instruction sessions expecting the sessions to be “ dry , boring , and easy ” ( Piper & Tag , 2011 , p. 322 ; Spence , 2004 ) . For a variety of reasons , librarians struggle to create classes that are “ creative ” and “ compelling ” to students ; instruction is often taught using texts and materials that , while informative , do not capture student interest ( Piper & Tag , 2011 , p. 319 ) . Our own experience bears this out . Despite consistently high ratings regarding the instructor ’ s performance , in course evaluations during the fall 2009 and 2010 semesters , only about 50 % of students rated the course to be of overall value to them . As a result of constant efforts to enhance instructional methods and course materials , by the spring 2010 semester , the number of students rating the course to be of overall value had risen to 64.7 % . Of the students who did not rate the course to be of overall value , several students used the comments box to clarify that it was “ the subject itself , not the instructor ” they were taking issue with . One of the most telling comments was that the instructor does “ as best she could with the information being taught . I like how she got outside sources of things we covered in class to make the comparison. ” Piper and Tag ( 2011 ) do concede that many librarians attempt to include active learning in their information literacy instruction , but they stress that “ without a thematic content that provides intellectual challenge , these efforts do not solve the issue of student engagement ” ( p. 323 ) . Vol . 1 , No . 1 ( Spring 2013 ) DOI 10.5195/palrap.2013.18 25 Pennsylvania Libraries : Research & Practice . : palrap.org Using The Filter Bubble to Create a Teachable Moment The challenges librarians face due to time restraints have also been heavily explored in the literature . Library instruction outside of a credit-information-literacy-course-environment often focuses on tools and mechanics rather than activities which stimulate higher order thinking ( Stevens & Campbell , 2008 ) . Detmering and Johnson ( 2011 ) argue that “ we typically find ourselves addressing practical concerns related to finding sources or using databases , rather than teaching students to think more critically about information and the information-seeking process as a whole ” ( p. 103 ) . These time restraints often prevent us from working with students to “ conceptualize research in a larger sense , as a process of critical thinking ” ( Detmering & Johnson , 2011 , p. 103 ) . Drabinski ( 2011 ) emphasizes that library instruction often is taught “ akairotically ” —at the “ wrong time , in the wrong context ” and with the wrong pedagogy ( p. 82 ) . Jacobson and Mark ( 2000 ) also worry about this , arguing “ if students do not immediately apply their information literacy skills to a content-based course assignment , they tend not to recognize the relevance of such skills to other courses ” ( p. 261 ) . This can lead to challenges when we want students to retain the skills we teach and transfer those skills beyond a single instruction session . One of the stumbling blocks for many students is that information literacy skills often have no context , thus no personal relevance or value for them . Barry ( 2011 ) discusses the importance of creating a “ real-world ” experience for students engaged in research . Leibiger ( 2011 ) points out that the traditional information literacy assignments and instruction do not promote “ natural learning. ” The generic research paper assignment often “ provides no context or justification for the writing of the paper beyond the fulfilling of a course requirement ” ( Leibiger , 2011 , p. 201 ) . Thus students see the assignment and time spent in the library as simply something needed “ to attain a certain grade , pass a certain course , or move beyond a certain semester in a student ’ s academic career ” ( Leibiger , 2011 , p. 201 ) . Since there is no real-life relevance for the student to assign a personal value to , the experience becomes in essence a “ numbers game ’ for both the student and the librarian , ” where each are simply working to locate the number of specified resources appropriate for the assignment ( Leibiger , 2011 , p. 201 ) . As Chen and Lin ( 2011 ) point out , the role of librarians and their approach to information literacy is constantly changing and we must adapt our roles in regard to students , faculty , and institutions in order to provide “ appropriate learning experiences ” ( p. 408 ) . Another struggle for librarians is finding ways to break through the grab-n-go information habits of students . Leibiger ( 2011 ) refers to these habits as “ googlitis ” and describes it as “ an over reliance on simplistic search techniques using Internet search engines and the extension of these poor searching skills to the use of library resources ” ( p. 188 ) . Badke ( 2010 ) argues in his article , “ How stupid is Google making us ? ” , that students do not take the time to choose the best results but “ rather choose the ‘ good enough ’ of picking from the first few results ” ( p. 51 ) . There may be a reason why students exhibit some of this behavior when they are doing online research . As Badke ( 2010 ) and others have demonstrated , constant exposure to the digital environment has an effect on how the brain processes information . Small and Vorgan ( 2008 ) have dubbed this effect “ the iBrain. ” In their investigations , Small and Vorgan ( 2008 ) used MRI scans to map the active areas of the brain during Internet usage . In comparing the brain function of novice Internet users with “ digital natives , ” the MRI images revealed that “ the computer-savvy subjects used a specific network in the left front part of the brain , known as the dorsolateral prefrontal cortex . The Internet- naive subjects showed minimal , if any , activation in this region ” ( Brain Changes , para . 1 ) . The dorsolateral prefrontal cortex plays an important role in our brains ; it is used for quickly processing complex information and decision- making in the working , or short term , memory areas of the brain ( Small & Vorgan , 2008 ) . When comparing the two sets of subjects , they found visible changes in the novice Internet user ’ s brain after only five hours of Internet use . They posit that these brain changes in response to Internet stimuli actually lead to enhanced cognitive abilities , such as better attention to visual stimuli and faster decision-making . Specifically , Vol . 1 , No . 1 ( Spring 2013 ) DOI 10.5195/palrap.2013.18 26 Pennsylvania Libraries : Research & Practice . : palrap.org Using The Filter Bubble to Create a Teachable Moment We develop a better ability to sift through large amounts of information rapidly and decide what's important and what isn't—our mental filters basically learn how to shift into overdrive . In this way , we are able to cope with the massive amounts of data appearing and disappearing on our mental screens from moment to moment ( Small & Vorgan , 2008 , The New , Improved Brain ? , para . 1 ) . Although it may be a perfectly natural way to deal with the onslaught of information online , the problem with this adaptive response on the part of our brains is that it can get in the way of thoughtful , reflective decision- making . The “ iBrain ” behavior essentially amounts to rapid filtering out of less-relevant content using almost exclusively short-term memory . By contrast , when engaged in deep reading , it is the long-term memory areas of the brain which are active ( Small & Vorgan , 2008 ) . The less we use these deep-thinking neural pathways , the weaker those neural connections are likely to become . Flitting from link to link across the Internet can place stress on our brains , diminish our ability to read deeply , and have serious implications for developing strong information literacy skills . After all , it is the deep reading and the careful consideration of an author ’ s arguments and evidence that lead to high-quality research projects . One of the authors ’ goals when choosing an actual book as a text for the class was an instinctive desire to counter this grab-n-go approach to information . We hoped to encourage students to engage in sustained efforts at deeper levels of thinking and reading . Plus , as Badke ( 2010 ) states , “ there is a special pleasure that can come from following a well-reasoned argument in a physical book ” ( p. 53 ) . Jacobs and Berg ( 2011 ) discuss the idea of “ critical information literacy ” as moving past simply locating and evaluating sources to developing a deeper level of critical reflection . Jacobs and Berg ( 2011 ) , describe “ critical information literacy ” as “ an attempt to help students see that information questions are deeply embedded within cultural , social , political , and economic contexts ” ( p. 389 ) . A key point in this concept is making the instruction student-centered . Rather than librarians “ depositing knowledge , ” students become “ critical co-investigators in the problem-posing education of information literacy ” ( Jacobs & Berg , 2011 , p. 390 ) . Spence ( 2004 ) stresses that in order for students to learn , they must “ make changes in the generalized patterns that make up their knowledge of the world ” ( p. 489 ) . Using The Filter Bubble in the Classroom It was precisely these challenges that pushed the authors towards a radical shift in the information literacy course at York College . While in the past we explored a variety of hands-on activities , ways to insert humor in our instruction , and focused on current events in an attempt to improve student engagement , this was the first time the authors approached the course with a consistent theme . We chose The Filter Bubble , by Eli Pariser as the required text for the course , opting for a “ textbook ” that isn ’ t a textbook at all . The Filter Bubble is a book that is equally at home on a leisure reading shelf , a computer science library , or in a media studies collection . Written for a general audience , but containing a significant amount of research , it makes an excellent introduction to the concepts of web personalization and its implications for society . Rather than ask students to read about ( or lecture to them about ) information formats and retrieval tools , we asked them to read , discuss , and investigate one of their favorite tools : the Internet . In his book , The Filter Bubble , Eli Pariser explores the personalization of information online . Nearly all major websites , from Google to The New York Times , use at least some personalization to drive the content displayed for a particular user , and what is deemed “ relevant ” to one visitor may not appear at all for another . When asked in an interview how much Google really knows about us , Pariser explains : Vol . 1 , No . 1 ( Spring 2013 ) DOI 10.5195/palrap.2013.18 27 Pennsylvania Libraries : Research & Practice . : palrap.org Using The Filter Bubble to Create a Teachable Moment It knows everything I ’ ve searched for in the last few years , and probably how long I lingered between searching for something and clicking the link . There are 57 signals that Google tracks about each user , one engineer told me , even if you ’ re not logged in . ( Popova , n.d. , “ How much does Google really know about us , ” para . 7 ) The result of this personalization , Pariser argues , is that each of us is surrounded by a unique collection of information online—our “ filter bubble ” — and the curators of that collection are mathematical algorithms that do not necessarily have our best interests at heart ( Pariser , 2011b ) . Pariser ( 2011b ) points out three dynamics of the “ filter bubble ” which make online filtering potentially damaging : users are “ alone ” in their “ filter bubble , ” it is invisible , and users do not choose to enter the bubble themselves . When you combine short-circuiting of reflective thinking processes—the iBrain effect—with the personalization of web search results , there is a very real potential for getting stuck in what Pariser terms “ The You Loop ” —stuck inside your own self-reinforcing point of view , with little that is truly new or outside of your interests ( p. 109 ) . This goes to the very core of information literacy : without exposure or access to information and ideas , our decision-making process is hamstrung . Solutions to problems may lay just out of sight— existing , but inaccessible , like a misshelved book . In our classes , there was no use denying that the Internet was typically our students ’ first choice for information retrieval . We realized that like most students , they tend to view the internet as a “ fast and reliable answer provider ” ( Chen & Lin , 2011 , p. 406 ) . Rather than fighting this concept , we decided to use ideas in Eli Pariser ’ s The Filter Bubble to allow our students to explore the web more fully . Together we became , as Jacobs and Berg ( 2011 ) would describe , “ critical co-investigators ” ( p. 390 ) . We did not prevent our students from using Google . Rather , we tried to allow them to learn and decide for themselves the limitations of web searching in the context of personalization . As Leibiger ( 2011 ) points out , “ the answer to the problem of Googlitis in higher education is not to forbid the use of Google by students ” ( p. 211 ) . After learning about personalization and seeing first hand in their own lives how this was affecting their access to information , students were not only able to recognize the limitations of web searching , they also were passionate about it . Students were asked to keep a reflective journal online as they read the book . Their journal comments revealed significant cognitive , and even emotional , engagement with the material . Many students acknowledged the importance of learning about the issue and drew connections with their own experience or related it to another class . A few students were downright offended to discover that a mathematical algorithm was making decisions on their behalf without their knowledge . Interestingly , not all students view online personalization as a problem . However , even those students who felt that online personalization is an inevitable and useful adaptation to the growth of information online were , by and large , still interested in how it works . Valuing Viewpoints One of the easiest ways we were able to make the material immediately relevant to our students was by bringing in Facebook as an example of web personalization . Since almost all of our students had Facebook accounts and most checked those accounts several times daily , explaining how Facebook personalizes their newsfeed was something our students could quickly understand and explore for themselves . Pariser ( 2011b ) explains how Facebook filters through your friends using “ EdgeRank , ” an algorithm that mathematically ranks your Facebook news feed based on your relationship with the person the post is coming from , the type of content they are posting , and the timeliness of the event . The results of this ranking can mean that friends whose opinions and ideas you value , but perhaps do not click on as frequently , may be deemed less “ relevant ” and disappear from your news feed . In fact , Pariser ( 2011b ) explains , the disappearance of his politically conservative friends from his Facebook feed was one of the catalysts that led to the writing of the book . Vol . 1 , No . 1 ( Spring 2013 ) DOI 10.5195/palrap.2013.18 28 Pennsylvania Libraries : Research & Practice . : palrap.org Using The Filter Bubble to Create a Teachable Moment This was the first real breakthrough that we had with our students . In the past , having both sides of a perspective might have only been viewed as part of a requirement for an argumentative paper assignment . Realizing that Facebook was deciding to hide status updates of friends who did not share the same viewpoints as the students ’ was a big deal . Students could immediately relate to it . They knew they had friends who never showed up in their news feed , and they did not like that they were not in control of it . Suddenly , it was the students who were arguing to us the merits of reading what someone has to say even if it does not fit exactly in line with their viewpoints . Students even included in their end-of-the-course reflection statements such as “ I firmly believe that to make an educated decision about anything a person needs to consider both sides of an issue. ” After students learned about Facebook personalization we were easily able to enter into a discussion as a class about bias . Confirmation Bias and Cognitive Dissonance In chapter three of The Filter Bubble , Pariser ( 2011b ) describes the concept of confirmation bias as “ a tendency to believe things that reinforce our existing views , to see what we want to see ” ( p. 86 ) . Pariser explains in an interview that the “ filter bubble ” is a “ comfortable place , ” a place filled with things we like and those things “ that most compel you to click , ” but he also argues that the things we are compelled to impulsively click on such as “ sex , gossip , things that are highly personally relevant ” do not equal the “ set of things we need to know ” ( Popava , n.d. , “ What , exactly , is ‘ the filter bubble ’ ? , ” para . 3 ) . Furthermore if we are only ever being exposed to things that reaffirm our belief system and make us comfortable , we are not able to really educate ourselves or engage in civil discourse . With Facebook as a starting point it was much easier for students to grasp this idea . Learning theories tell us that development occurs when the mind is forced to change in response to new information which does not fit into its existing thought patterns . It is this cognitive dissonance or friction which acts as a catalyst for learning , as the mind must reorder and reorganize what is “ known. ” Phelps ( 1990 ) posits a model of the mind based on Piagetian learning . New information is either processed by assimilation into the mind ’ s existing thought structures , or the mind accommodates the new information by revolutionary changes in thought structure . This process is a balancing act , as the mind strives to create order and patterns . Phelps ( 1990 ) also tells us that .. development itself incorporates a negative principle in that its impulse to order must be constantly defeated if growth is to occur . The internal principle for change is disequilibrium . In order to be flexible and adaptive , our mental state must be always somewhat unfinished , disorderly , with potential for new arrangements and novelty generally ( p. 391 ) . Phelps ( 1990 ) also encourages us to exploit this tension between order and disorder in our classrooms . As teachers , we should always be striving for ways to push our students out of their comfort zones , because that is where real learning occurs : when we are confused , unsure , and out on a limb , our minds must stretch to accommodate new ways of thinking . However , as Phelps ( 1990 ) reminds us , development is not inevitable . Individuals may choose to reject new information rather than make the mental adjustments necessary to assimilate and accommodate data that is contradictory . When we see disengaged , bored students , or hear comments questioning the need for research instruction , we are seeing this phenomenon in action . Stagnation of development is also one of Pariser ’ s ( 2011b ) chief complaints about online personalization , because both personal and algorithmic filters limit our ability to experience new ideas and form new mental connections . By exposing students to new information about online personalization , which they generally viewed as both new and important , we created a moment of cognitive dissonance . Recognizing that there is something you do not know is the first , essential step in the leaming process . Once we had their attention , our role as teachers became a Vol . 1 , No . 1 ( Spring 2013 ) DOI 10.5195/palrap.2013.18 29 Pennsylvania Libraries : Research & Practice . : palrap.org Using The Filter Bubble to Create a Teachable Moment much easier task . The students were much more aware of the limits of searching on the Web and more interested in refining their information literacy skills . In this approach , a class discussion of the limitations of online personalization can be used to set the stage for a lesson on the mechanics of searching research databases . Web Personalization vs. Relevancy Ranking As discussed , our students were no different than the majority , with the typical “ grab and go ” approach to searching . The results they most often chose were the first few results that appeared on a page . However , when we started exploring web personalization , they were able to really analyze these results . As part of an in-class activity , students were asked to examine their Google results , compare them with their classmates , and then hypothesize why they thought particular results were showing up for them based on their personal viewpoints , likes , needs and spending habits . In essence , students were learning about their own potential biases . Students were also asked to examine the ads that were present on their first page of results . We discussed how closely personalization is tied in with advertising . As Badke ( 2012 ) argues , “ if a search engine can optimize the user 's wants in the first four or five results , it can both please the user and get the most relevant advertising into the user 's view ” ( p. 48 ) . Students noticed that their ads on Facebook and other social networks directly tied in with their web browsing and that they often saw ads on Facebook advertising a product that they had searched for on the web only moments before . Likewise , when searching the web they were able to see advertisements that correlated with things they had mentioned or “ liked ” on Facebook . These discussions prompted reflective thinking about the implication of exposure ( or lack of exposure ) to information , such as this student comment : “ Pariser brings up a good point when he says that Google puts us in our own filter bubbles , alone . We do n't make the choice to have our searches filter to something we would ‘ rather see. ’ ” The authors also discussed how web personalization has affected students ’ expectations for research both in search engines , as well as databases . Based on the extent of personalization on the web , students now expect to get results that are immediate and relevant to them wherever they search . We considered both the positive and negative aspects of this and it allowed the instructors to easily segue into a discussion about relevancy ranking in academic databases . As Badke ( 2012 ) points out “ despite all the hopes of artificial intelligence and the semantic web , search engines are still just finding words ” ( p. 49 ) . Personalization can make researching on the web especially difficult because Badke argues , it is “ based on the assumption that what I was is what | will be ” ( Badke , 2012 , p. 49 ) . However , each time a student embarks on a new research assignment they are essentially a new person and venturing into “ fresh territory that the machinations of personalization ca n't address ” ( Badke , 2012 , p. 49 ) . Despite this , as much of the literature discusses , students still often use the same strategies in academic databases as they do in search engines like Google ( Badke , 2012 ) . Academic databases have even started to cater to this type of searching , offering a simple Google-esque search box in lieu of the multiple options in the advanced search screen . Badke ( 2012 ) argues that many of the major databases “ have advanced by leaps and bounds in tailoring search to what I ask for instead of what the software thinks I want [ but unlike search engines ] proprietary databases are not dependent on advertising to keep them going ” ( p. 48 ) . This was a major point we brought up in our classes . We asked students to carefully consider how information changes when it is being tailored to a potential audience of consumers . Evaluating Sources and Using Rhetorical Analysis Standard Three of Association of College and Research Libraries ( ACRL ) Information Literacy Competency Standards for Higher Education tells us that “ the information literate student evaluates information and its sources critically and incorporates selected information into his or her knowledge base and value system ” ( ACRL , 2000 ) . In practice , mastering these skills is often a major challenge for students . Achievement of Standard Three requires comprehension , critical thinking , evaluation , and perhaps even a re-ordering of the students ’ own mental maps . Vol . 1 , No . 1 ( Spring 2013 ) DOI 10.5195/palrap.2013.18 30 Pennsylvania Libraries : Research & Practice . : palrap.org Using The Filter Bubble to Create a Teachable Moment Research into the development of students ’ rhetorical inquiry skills offers librarians some potential explanations for why students often have difficulty selecting and critically evaluating sources ( Cooper , 1990 ; Phelps , 1990 ; Salabrici , 1999 ) , Salibrici ( 1999 ) indicates that “ reading and writing should be ‘ critical ’ activities that push students beyond the stage of comprehension and interpretation to a higher level of evaluation or critical consciousness . . . ” ( p. 628 ) . This overlap between literacy , rhetorical skills , and information literacy skills has important implications for teaching librarians . Without sufficient comprehension , evaluation is nearly impossible . Without critical evaluation of sources and their content , selecting appropriate information sources becomes a hit or miss activity for students . In advocating for a rhetorical approach to information , Salibrici ( 1999 ) encourages teachers “ to view language both in terms of production and consumption , ” as an interdependent relationship between authors and their audiences ( p. 629 ) . Source evaluation is often taught using a checklist or a rubric , such as the CRAAP test ( Meriam Library , 2010 ) , or charts delineating the characteristics of scholarly and popular sources . However , there are some risks to this approach , as it has the potential to discourage deeper engagement with the text . By focusing on discourse conventions , which Cooper ( 1990 ) defines as “ the rules that readers and writers must learn and use in order to be a member of that community , ” we risk encouraging an over-reliance on information format and surface features and discourage the deeper evaluative skills we are trying to help students develop ( p. 67 ) . Burkholder ( 2010 ) warns us against assuming that students are simply “ lazy , opting for the path of least resistance by choosing Web sites over journal articles ” and instead considers the possibility that they may be “ confused—or worse—unaware of the rhetorical implications of their choices ” ( p. 1 ) . In order to help students look beyond surface features and engage in critical inquiry , the authors introduced source evaluation not with a checklist but by using the rhetorical triangle as a framework for examining the contents of a message . The rhetorical triangle allows us to graphically represent the interdependent relationships of a text . By placing the author , the purpose , and the audience at the three points of the triangle , it becomes easy to see how the elements function together to create a particular message aimed at a specific audience . If we introduce a change to just one point of the triangle , for example , by replacing an academic author with a journalistic author , we are likely to see a dramatic shift in the language , detail , and tone of the content . The concepts presented in The Filter Bubble work particularly well using this rhetorical approach . Because the push toward personalization online is frequently driven by profit , the topic lends itself to discussions of what constitutes authority and how to evaluate sources for accuracy , evidence of bias , and ulterior motives . Librarians are frequently asked to introduce students to the differences between scholarly and popular literature , and the idea of online personalization can serve as useful way to begin the class session . Nearly all students have some experience with advertisements following them across the web , and they quickly grasp the notion that in the online environment , their likes and dislikes , click signals , and browser cookies are being used to tailor content specifically for them , usually for the purpose of selling them something . Because students relate to the experience of being sold something as a consumer , they are already familiar with the rhetorical conventions used when an item is aimed at a popular audience . Asking them to diagram the rhetorical triangle for one of these advertisements engages them actively in the lesson . At that point , the librarian can introduce a scholarly article , give students several minutes to examine it , and then ask them to diagram the rhetorical triangle for the scholarly article . This becomes a fun and simple way to introduce some of the differences between popular and scholarly rhetoric . Conclusions The authors wished that they had more time to continue exploring these concepts in a semester long course environment . However , at the end of the spring 2012 semester the college retired the required information literacy Vol . 1 , No . 1 ( Spring 2013 ) DOI 10.5195/palrap.2013.18 31 Pennsylvania Libraries : Research & Practice . : palrap.org Using The Filter Bubble to Create a Teachable Moment course , choosing to explore other curricular options for the freshman experience and orientation . Despite being only able to explore “ the filter bubble ” as a theme in our instruction for one semester , we do feel that it was a success . In past semesters , students responded to the course via formalized course reviews . As the authors noted , reviews had always been mixed and some instructors even received comments essentially applauding the instructor as doing as best as he/she could considering the material . Many students also commented about how they failed to see the relevance of the course . Due to the discontinuation of the course past spring 2012 the authors were unable to have a formal course review at the end of the spring 2012 semester . However , when we asked six different classes to reflect on the course in their research journals , student responses were overwhelmingly positive . Students praised the wu “ material , calling it “ interesting , ” “ extremely relevant , ” and “ enlightening. ” One student even added that the book filled her “ with more information than any class I had from kindergarten to high school in only the introduction. ” Others commented on how much they enjoyed reading the text , and some even encouraged friends and family who were not in the course to read course materials as well . wu creepy , ” and “ concerning. ” Even if they had noticed certain trends online , most of our students had not realized just how Most students were quite surprised to learn about Web personalization . Several found it “ scary , ubiquitous that personalization is , or taken time to consider the implications of living in a filtered environment . The authors also found the materials to be much more rewarding to teach and thoroughly enjoyed the sometimes heated class discussions with heavy student participation . Students seemed to not only grasp the concepts but were able to build on them . One student included in her course reflection : We are fortunate enough to live in a country where we are allowed to have access to any media we desire and therefore I feel by limiting ourselves to just what we like is not a good thing . It prevents us from being informed citizens and if we are not informed citizens how can we participate in democracy appropriately ? The authors feel that this course ’ s success is due largely in part to our students being able to connect the information to something that was personally relevant and interesting . Drabinski ( 2011 ) , in her thesis on Kairos in library instruction , writes : [ T ] eaching information skills at the right moment and in the right measure has the potential to transform library instruction from a dull , standards-based , technical exercise in banking education to a timely , contextualized , and highly-relevant classroom experience that equips students to critically intervene in the discourses that surround them ( p. 4 ) . The authors feel that by setting the stage with an accessible theme which was relevant , observable , and encouraged self-discovery , we were able to slip in important information literacy skills that they might have not understood , valued , or used in another context . In order to move past our students ’ “ filter bubbles , ” instruction had to first be personalized and interesting enough to get through them . In terms of achieving our goals to increase participation and foster deeper reading and reflection , using The Filter Bubble as the textbook was an unqualified success . Where previously the authors had struggled with methods for encouraging students to complete the assigned course readings , it was clear from class discussions and journal entries that most students were , in fact , reading the book . Information literacy instruction includes learning about the purposes and characteristics of various types of publications . What better way to teach this than through actively engaging in the reading of a complete book and combining it with explorations of other formats along the way ? In many ways teaching with The Filter Bubble has changed the way we approach instruction , and we are constantly trying to think of ways to present information literacy concepts in a way that students can easily Vol . 1 , No . 1 ( Spring 2013 ) DOI 10.5195/palrap.2013.18 32 Pennsylvania Libraries : Research & Practice . : palrap.org Using The Filter Bubble to Create a Teachable Moment understand , connect to , and find personally relevant . While the authors initially had the luxury of working within a semester-long course , the reality is that most students experience library instruction through course-integrated instruction or the simpler 50-minute , one-shot presentations . The time restrictions on these shorter sessions can make it difficult to include deeper thinking activities . The authors are exploring ways to incorporate larger concepts into smaller lessons . We are also exploring ways to collaborate with faculty to introduce some of these concepts and materials to their students before the library session , giving us time to work more closely with the concept while in the library . One benefit of Pariser ’ s The Filter Bubble is that it is extremely versatile and has sections that could be easily tailored to instruction in a variety of subjects including English , Sociology , Communications , Psychology , and Business , to name a few . For those interested in learning more , please visit the site we developed , Using “ The Filter Bubble ” to Create a Teachable Moment ( filterbubbleteachablemoment.wordpress.com ) , for additional ideas and more specific lesson-planning materials . We also invite those with ideas to contribute them on the site . We believe that online personalization and “ the filter bubble effect ” present an interesting , timely , and relevant opportunity to creatively examine information literacy from another viewpoint and hope our explorations prompt further research and reflection . Notes 1 The authors would like to thank Joel Burkholder , Information Literacy and Instruction Librarian at York College of Pennsylvania , for his support as we developed this project . We would also like to thank our colleagues at the Library and Information Resources department at Harrisburg Area Community College for their feedback and ideas as we continue to explore the ideas presented in this paper . References Association of College and Research Libraries ( ACRL ) . ( 2000 ) . Information literacy competency standards for higher education . Retrieved from http : //www.ala.org/acrl/standards/informationliteracycompetency Badke , W. ( 2010 ) . How stupid is Google making us ? Online 34 ( 6 ) , 51-53 . Badke , W. ( 2012 ) . Personalization and information literacy . Online , 36 ( 1 ) , 47-49 . Barry , M. ( 2011 ) . Research for the greater good : Incorporating service learning in an information literacy course at Wright State University . College & Research Libraries News , 72 ( 6 ) , 345-348 . Retrieved from http : //crin.acrl.org/content/72/6/345.full Burkholder , J. M. ( 2010 ) . Redefining sources as social acts : Genre theory in information literacy instruction . Library Philosophy and Practice ( e-journal ) . Paper 413 . Retrieved from http : //digitalcommons.unl.edu/libphilprac/413 Chen , K. N. & Lin , P. C. ( 2011 ) . Information literacy in university library user education . As/ib Proceedings , 63 ( 4 ) , 399-418. doi : 10.1108/00012531111148967 Cooper , M. M. ( 1990 ) . The answers are not in the back of the book : Developing discourse practices in First-Year English . In R. Beach & S. Hynds ( Eds . ) , Developing discourse practices in adolescence and adulthood ( pp . 386-414 ) . Norwood , Nj : Ablex . Detmering , R. & Johnson , A . ( 2011 ) . Focusing on the thinking , not the tools : Incorporating critical thinking into an information literacy module for an introduction to business course . Journal of Business & Finance Librarianship , 16 ( 2 ) , 101-107. doi:10.1080/08963568.2011.554771 Drabinski , E. ( 2011 ) , Teaching in time : Toward a kairos of library instruction ( Master ’ s thesis ) . Available from ProQuest Dissertations and Theses Database . ( UMI No . 1487300 ) Vol . 1 , No . 1 ( Spring 2013 ) DOI 10.5195/palrap.2013.18 33 Pennsylvania Libraries : Research & Practice . : palrap.org Using The Filter Bubble to Create a Teachable Moment Jacobs , H. L. M. & Berg , S. ( 2011 ) . Reconnecting information literacy policy with the core values of librarianship . Library Trends , 60 ( 2 ) , 383-394. doi:10.1353/lib.2011.0043 Jacobson , T. and Mark , B. L. ( 2000 ) . Separating wheat from chaff : Helping first-year students become information savvy . The Journal of General Education , 49 ( 4 ) , 256-278. doi:10.1353/jge.2000.0029 Leibiger , C. A . ( 2011 ) . “ Google reigns triumphant ” ? : Stemming the tide of Googlitis via collaborative , situated information literacy instruction . Behavioral & Social Sciences Librarian , 30 ( 4 ) , 187-222. doi:10.1080/01639269.2011.628886 Meriam Library . ( 2010 ) . Evaluating sources : applying the CRAAP test . Retrieved from http : //www.csuchico.edu/lins/handouts/eval_websites . pdf Pariser , E. ( 2011a ) . Beware online “ filter bubbles. ” TED ta/k . Retrieved from http : //www.ted.com/talks/eli_pariser_beware_online_filter_bubbles.html Pariser , E. ( 2011b ) . The filter bubble : What the Internet is hiding from you . New York : Penguin Press . Phelps , L. W. ( 1990 ) . Developmental tensions , developmental challenges : A heuristic for curricular thinking . In R. Beach & S. Hynds ( Eds . ) , Developing discourse practices in adolescence and adulthood ( pp . 386-414 ) . Norwood , NJ : Ablex . Piper , P. and Tag , S. ( 2011 ) . Theme-based information literacy instruction . College & Undergraduate Libraries , 18 ( 4 ) , 319-332. doi:10.1080/10691316.2011.624956 Popava , M. ( n.d. ) . The filter bubble : Algorithm vs. curator & the value of serendipity . Retrieved from http : //www . brainpickings.org/index.php/2011/05/12/the-filter-bubble/ Salibrici , M. ( 1999 ) . Dissonance and rhetorical inquiry : A Burkean model for critical reading and writing . Journal of Adolescent & Adult Literacy , 42 ( 8 ) , 628-637 . Small , G. , & Vorgan , G. ( 2008 ) . Meet Your iBrain . Scientific American Mind , 19 ( 5 ) , 42-49 . Spence , L. ( 2004 ) . The usual does n't work : Why we need problem-based learning . Portal : Libraries and the Academy , 4 ( 4 ) , 485- 493. doi:10.1353/pla.2004.0072 Stevens , C. R. , & Campbell , P. J . ( 2008 ) . Collaborating with librarians to develop lower division political science students ’ information literacy competencies . Journal of Political Science Education , 4 ( 2 ) : 225-252. doi:10.1080/15512160801998114 Vol.1 , No . 1 ( Spring 2013 ) DOI 10.5195/palrap.2013.18 34 1812.10943v1 [ cs.CY ] 28 Dec 2018 arXiv What did you see ? Personalization , regionalization and the question of the filter bubble in Google ’ s search engine Tobias D. Krafft Algorithm Accountablitiy Lab Gottlieb-Daimler-Str . 48 TU Kaiserslautern ® 0000-0002-3527-1092 krafft @ cs.uni-kl.de ABSTRACT This report analyzes the Google search results from more than 1,500 volunteer data donors who , in the five weeks leading up to the federal election on September 24th , 2017 , automatically searched Google for 16 predefined names of political parties and politicians every four hours . It is based on an adjusted database consisting of more than 8,000,000 data records , which were generated in the context of the research project ° * # Datenspende : Google und die Bun- destagswahl 2017 ” and sent to us for evaluation . The # Datenspende project was commissioned by six state media authorities . Spiegel Online acted as a media partner . Focal points of the present study are i. a. the question of the degree of personalization of search results , the proportion of regionalization and the risk of algorithm- based filter bubble formation or reinforcement by the leader in the search engine market . ACM Reference format : Tobias D. Krafft , Michael Gamer , and Katharina A. Zweig . 2016 . What did you see ? Personalization , regionalization and the question of the filter bubble in Google ’ s search engine . In Proceedings of ACM Conference , Washington , DC , USA , July 2017 ( Conference ’ 17 ) , 23 pages . DOE : 10.1145/nnnnnnn.nnnnnnn 1 INTRODUCTION : THE FILTER BUBBLE ’ S DANGERS TO SOCIETY Political formation of opinion as well as general access to informa- tion has changed significantly due to digitalization . Information sources such as newspapers , TV and radio , where large parts of the population read , heard , or saw the same news and interpreta- tions of these news stories , are being replaced by more and more diverse and personalized media offerings as a result of digital trans- formation . Personalization is enabled by algorithm-based systems : here , an algorithm - not a human - decides which contents users might be interested in , and only these are offered to them in social networks . The same is true for personalized search engines like Google , Yahoo or Bing , for which , at more than 3,200 billion search queries in 2016 ( Statista , 2016 ) , it is impossible to have a man-made sorting available . Conference ’ 17 , Washington , DC , USA 2016 . 978-X-xXXX-XXXX-x/YY/MM . .. $ 15.00 DOI : 10.1145/nnnnnnn.nnnnnnn Michael Gamer Algorithm Accountablitiy Lab Gottlieb-Daimler-Str . 48 TU Kaiserslautern ® 0000-0003-0261-0921 gamer @ cs.uni-kl.de Katharina A. Zweig Algorithm Accountablitiy Lab Gottlieb-Daimler-Str . 48 TU Kaiserslautern ( ® 0000-0002-4294-9017 zweig @ cs.uni-kl.de 1.1 The model of algorithmically generated and amplified filter bubbles The possibilities and dangers of a so-called algorithmically gener- ated filter bubble increase steadily . This term is to be understood as a partial concept of the filter bubble theory by Eli Pariser . In his 2011 book , ” The Filter Bubble : What the Internet Is Hiding from You ” ( Pariser , 2011 ) , the internet activist pointed out the possible dangers of so-called filter bubbles . In his TED talk and on the basis of two screenshots from 2011 , he showed that two of his friends had received significantly different results when searching for “ Egypt ” on the online search platform Google ! . From this he developed a theory according to which personalized algorithms in social media tend to present individuals with content that matches the user ’ s previous views , leading to the emergence of different information spheres where different contents or opinions prevail . In short , filtering the information flow individually can result in groups or individuals being offered different facts , thus living in a unique informational universe * . This is especially worrying if the respective content is politically extreme in nature and if a one- sided perspective results in impairment or total deterioration of citizens ’ discursive capabilities . A filter bubble in this sense is a selection of news that corresponds to one ’ s own perspectives , which could potentially lead to solidification of one ’ s own position in the political sphere ? . 1.1.1 Filtering search results with personalization and regional- ization . Since the number of web pages associated with a search term is more than 10 for most queries and at the same time the first 10 web pages shown receive the greatest attention from users , it is essential that search engines filter the possible search results . Certainly one of the most important filters is the user ’ s language , while topicality and popularity play an additional role as well as , to a lesser extent , embedment in the entire WWW ( e.g . measured ‘ See EH Pariser ’ s TED talk “ Beware the filter https : //www.ted.com/talks/eli_pariser-beware_online_filter_-bubbles May 12th 2018 ) amg unique universe of information for each of us ” ( Pariser , 2011 , p. 9 ) . > > Bilter bubbles ” can be understood as even more advanced concepts . Selecting websites by means of state cencorship can also create filter bubbles by restricting information . While this cencorship is supported by algorithms , this does not constitute a filter bubble through algorithm-based personalization that is hypothesized in this text . This kind of restriction of information and its possible consequences for filter bubble formation aren ’ t examined here . After all , a search engine operator or a social media platform could knowingly and intentionally limit the data base in a certain direction , thus presenting all users with the same content while only offering a selective extract of reality . This option is not examined here . bubbles ” , ( accessed Conference ’ 17 , July 2017 , Washington , DC , USA by the PageRank ) . A particularly important filtering mechanism within the framework of Eli Pariser ’ s filter bubble theory is ” personalization ” . Regarding the term of ( preselected ) personalization , we follow the state- ments given by Zuidserveen Borgesius et al . ( 2016 ) , according to which personalization allows the selection of content that has not yet been clicked by the user , but which is associated with users with similar interests . Algorithmically speaking , this is based on so-called * recommendation systems ” , which determine the inter- ests of a currently searching user from other people who have shown similar click behavior in the past . It is also also plausible that according to their own click behavior and together with known categorizations of clicked content a profile is compiled for each person , saying , for instance : ’ This person prefers news about sports and business , reads medium-length text and news that are not older than a day. ’ ( Weare , 2009 ) . Considering the vast number of users , both methods can only be achieved algorithmically , using different modes of machine learning and thus only form statistical models ( Zweig et al. , 2017 ) . Generally it can be expected that users logged into their Google accounts will tend to receive more personalized search results . Websites from the search result list which have previously been clicked by a user are delimited from personalization . For outsiders , those might not be differentiable from the entries that have been personalized by algorithms , but regarding content they don ’ t con- tribute to algorithm-based filter bubble formation or amplification , since users have chosen those contents before . We use the term regionalization for a sample of websites for a whole group of persons who currently search from a specific re- gion or are known to originate from a specific region , yet don ’ t necessarily mention a region in their search request . For instance , the current location can roughly be derived from the searching device ’ s IP address , or more accurately from smartphone location information or from the profile known to the search engine ( Teevan et al. , 2011 ) . The delivered websites themselves clearly relate to the location of interest specified by Google ; which can be the case , for example , if a nearby location ’ s name appears on the website repeatedly . It is important to note that regionalization on a particularly small scale can be counted towards personalization - for example , if a selection of regional websites is delivered to each person of a household while differing from the selection for their neighbors . 1.1.2 . When are algorithmically generated and amplified filter bubbles dangerous ? Eli Pariser ’ s filter bubble theory , with its unset- tling consequences for society , is based on these four basic mecha- nisms : ( 1 ) Personalization : An individually customized selection of contents , which achieves a new level of granularity and previously unknown scalability . Low overlap of respective news results : A low or non- existent overlap of filter bubbles , i. e. news and information from one group remain unknown to another . Contents : The nature of the content , which essentially only becomes problematic with politically charged topics and drastically different perspectives . ( 2 = GB = Krafft , Gamer and Zweig ( 4 ) Isolation from other sources of information : The groups of people whose respective news situation displays homo- geneous , politically charged and one-sided perspectives , rarely use other sources of information or only those which place them in extremely similar filter bubbles . The stronger those four mechanisms manifest themselves , the stronger the filter bubble effect grows , including its harmful conse- quences for society . The degree of personalization is essential , as politically relevant filter bubbles do not emerge if personalization of an algorithm responsible for selecting news is low . Higher or high personalization and verifiable filter bubbles do not necessarily take political effect if either their contents aren ’ t political in nature or users make use of other sources of information as well . For instance , information delivered to citizens of different languages are free of overlap by definition , if the results are displayed in those languages - regardless , content-wise those citizens aren ’ t in any way embedded in filter bubbles . 1.2 Examining Eli Pariser ’ s filter bubble theory As algorithms are capable of controlling the flow of information directed towards users , they are assigned a gatekeeper role simi- lar to journalists in traditional journalism ( see Moe & Syvertsen , 2007 ) . As a result , it is necessary to examine how powerful the algorithmically generated and hardened filter bubbles on various intermediaries and search engines actually are . The number of reliable studies is relatively low : an important German study by the Hans Bredow institute offers a positive answer to the question of the informational mix : sources of information today are diverse and capable of pervading other news and information of algorithmically generated and hardened filter bubbles ( Schmidt et al. , 2017 ) . It is pointed out that algorithms offer a possibility to burst open filter bubbles if such a functionality is explicitly implemented . To our knowledge , apart from anecdotal examinations , a quanti- tative evaluation of the degree of personalization for a larger user base hasn ’ t been deducted up until 2017 : for example , in the context of a Slate article Jacob Weisberg asked five persons to search for topics and found results to be very similar ( Weisberg , 2011 ) . Vital questions of the degree of personalization and overlap of single news flows can only be resolved with a large user base . Ex- ecuting such an investigation appears imperative , especially in light of the debate regarding influence of filter bubbles in social networks , which was sparked in 2016 after Donald Trump ’ s presi- dential election victory - unfortunately , due to insufficient APIs ‘ , this is currently not possible . Given the major political event of the federal elections we decided to realize the # Datenspende : project in order to find out whether Google already personalizes search results , as has often been speculated . Additionally , it is much sim- pler to carry out such an examination on search engines , whose results are presented on an HTML page that can easily be processed further . With this project we have introduced a study design that is capable of answering this question automatically for any sample of search engine users and for any search request . Owing to its design , users were able to comprehend at all times which search requests we presented to Google by using their account . As a result , 4An API is an interface which enables automated interaction with a program . For example , information can directly be requested from data bases by use of an API . What did you see ? Personalization , regionalization and the question of the filter bubble in Google ’ s search efiginference ’ 17 , July 2017 , Washington , DC , USA the data collection was trustworthy and the required software was downloaded more than 4000 times . Furthermore , the study design represents a proof of concept , as it enables society to permanently monitor search engines ’ degree of personalization for any desired search terms . The general de- sign can also be transferred to intermediaries , if appropriate APIs restrict selective access to content relevant to the study in order to establish a similar degree of trustworthiness . For example , on Facebook this would mean selective access to media messages or political advertisements in a respective time-line , while excluding access to private messages from friends . 2 STUDY DESIGN The study design as well as the fundamentals of the survey are explained below . This includes the data structure , relevant termi- nology and processing of the data basis . 2.1 Software structure and enrollment Google bundestagswahl Alle News Bilder Videos . Shopping Die nachste Suchanfrage startet in 3 Sekunden . Sonntag , 24 . Septemh [ soto stan Bundestagswahl 2017 Nicht wieder anzeigen . Schlagzeilen ot ae . Figure 1 : Browser plug-in , immediately before initiating a search for a user whose first result page then was transfered ( and thus “ donated ” ) to the provided server structure . The basic tool used for data collection is a plug-in that is easily integrated into the web browser and then utilizes the donating user ’ s browser to automatically run search requests and send the data to a central server . The plug-in was created in cooperation with the company filokaler ’ and was available for the web browsers Chrome and Firefox in order to achieve a market coverage of more than 60 % in Germany ( Statista , 2018 ) . All necessary insights into the plug-in source code were released at the start of the project® . At fixed points in time ( 4:00 , 8:00 , 12:00 , 16:00 , 20:00 and 0:00 ) , the plug-in searched for 16 search terms , given that the browser was open at that time® . The search requests to Google and Google News proceeded automatically and the donors ’ personal results were au- tomatically sent to our data donation servers . Consequently , for Shttps : //github.com/algorithmwatch/datenspende , published June 7th 2017 . ST the browser was turned off at one or multiple times of search , a cycle of search requests would be started when turning it on again the next time — which is why there are search result lists with different time stamps . Additionally , it was possible to manually start a search cycle in one ’ s own browser . each user and point in time 16 search terms were requested twice and the respective first page of the search results was saved . The search terms are limited to the seven major political parties and their respective leaders ( see Table 1 ) . As can be seen in Figure 1 , af- ter downloading the plug-in users were free to decide whether they wanted to be informed about future donations or if those should predominantly run in the background . Information regarding the project and the related call for the data donation were distributed via our project partners ’ communication channels as well as our media partner Spiegel Online ( Horchert , 2017 ) . As a result , 4,384 plug-in installations took place . The result- ing search results are freely accessible to the public for analytical purposes ’ . It should be pointed out that all results that can be seen in the final report are not necessarily representative , as the data donors were recruited voluntarily and by self-selection . For the most vital findings however , especially regarding the degree of personaliza- tion , we assume that they do not change much if the user base is representative . Search terms : partys Search terms : persons AFD Alice Weidel Buindnis90/Die Griinen Dietmar Bartsch CDU Alexander Gauland csU Katrin Goring-Eckardt Die Linke Christian Lindner FDP Angela Merkel SPD Cem Ozdemir Martin Schulz Sahra Wagenknecht Table 1 : The plug-in ’ s search terms for fixed search times . It should also be noted that an automated search for about an approximate dozen of search terms can have an influence on the search engine algorithm itself . On Google Trends , over the runtime of our data collection and for the search terms `` Dietmar Bartsch ” , * Katrin Giiring-Eckardt ” and * Biindnis90/Die Griinen ” it can clearly be seen that the search request volume was hereby increased ( see Figure 2 ) . Since the search requests were performed automatically and none of the offered links were actively clicked , we suspect the effects to be rather low . However , lacking exact knowledge of the underlying algorithm , this can ’ t be proven and has to remain unevaluated . 2.2 Data structure and relevant terms For further analysis , the available data was structured as follows . On the one hand we differentiated between search results directly on Google ( www.google.de ) or on the search engine provider ’ s Thttps : //datenspende.algorithmwatch.org/data.html Conference ’ 17 , July 2017 , Washington , DC , USA D Bi ntspn/frands qocgledetrancs/exslere ! date= 2017-05-16 2017-09-208iqe0-DE2q-Kavin Gsrng-Eckarct Der mar Batch “ Ot © Katrin Géring-Eckardt Suchbegrf @ ( Dietmar Bartsch suchbegrt + Vergleich hinzufugen Deutschland + 16951769 20.02.17 ~ Alle Kategorlon + Webcuche + Interease im zetilchen Verlaut Bog OG itosi/neragvoy edelerds/cnonedale=201/ 09 1820 WY 2USyLo=DERE= Bin dnnsUIRZ De Sibien ~ On @ Biindnis90/Die Griinen Suet + vergleichen Deutschland ~ 168.17 bie 20 DEAT © Alle Kategorien ~ ——— Websuche © Interesce im zeitlichen Veriaut le A Figure 2 : Chronological sequence of the search terms ” Ka- trin Géring-Eckardt ” and ” Dietmar Bartsch ” ( above ) and the search term ” Biindnis 90/Die Griinen ” ( below ) . The Google Trends diagrams clearly show the increase in search occur- rences for the search terms due to the plug-in , which was unlocked on July 7th 2017. news page ( news.google.com ) . The entire database was divided into these two categories . While usually 20 results according to the search terms were displayed on the news portal , 10 results as well as three additional so called top stories are displayed to the user using the default search feature ( see Figure 3 ) . While Google searches primarily refer to personal websites , social media accounts and aggregate subject/topic pages for the parties and persons ( cf . Section 3.4 ) , the Google news search only shows news from previously registered partners® . As a result , the lifespan of news results is limited , ie . that most news are displayed to users over a low number of search points in time , while the personal websites and social media accounts of parties and politicians are almost always shown . Thus , a separate inspection of news search and Google search results seems reasonable . For regular Google search results we drew a distinction between the ( not always received ) top stories and “ organic ” search results , ie . the 8-10 results in the lower left segment of the results page ( Figure 3 shows two organic search results for the search term ” Angela Merkel ” ) . At times , Google ’ s search result pages contain information in the right segment as well , e.g . advertisements or info See Google ’ s help center , eg . — https : //support.google.com/news/publisher- center/answer/6016113 ? hl=en & ref_topic=9010378 Krafft , Gamer and Zweig boxes regarding individuals or parties . Those were not transferred to our servers , but rather potential top stories and the actual search result page . Apart from the search type ( ’ Google ” , ” following information was saved : Google news search ” ) the e An approximate location based on the user ’ s transmitted IP address . e The user login status in their Google account . A user can be “ logged in ” or “ not logged in ” . e The browser language ( not the search language that is entered in the Google account ) . e The search term and time stamp of the search . e An ID generated by the plug-in that does not give any hints regarding the user , but remains unchanged for all data donations , as long as the plug-in is not re-installed . If available , a descriptive link text is saved as well ( usually only available for organic search results , but not always ) . If it is a top story , the corresponding date ( e.g . ” 54 minutes ago ” , ” 3 hours ago ” ) is saved as well . e The search results ’ URL . ¢ Most of the time , for top stories and Google news results the medium ( news source ) and the news title are stated and saved ( e.g . `` Dresdner Neueste Nachrichten ” with “ This is what our readers have to say regarding Cem Ozdemit ’ s appearance ’ ) . Additionally , the following terms are used in this report : Investigation period : This term is used for the time pe- riod between August 21st 2017 and September 24th 2017 . Here , only weekdays and the election weekend specifically are taken into account ( for further information , see Section 3.1 ) . Therefore , the investigation period spans 27 days . Search time : We define the search time as a day and cor- responding time of day within the investigation period , which can be 12:00 , 16:00 or 20:00 . We perform this limita- tion because the number of searching users is significantly lower for other times of search . The sum of times of search thus amounts to 81 ( three separate times for each of 27 days in total ) . ( Search ) result list : We understand a result list as the sum of URLs which are delivered to a user for a given search term and search time . Top stories and organic search results : The top stories term is used for up to three news items which Google oc- casionally displays at the top of a regular Google search request ( see Section 6.1 ) . Apart from purely textual infor- mation , a corresponding image is shown ( see Figure 3 ) . The remaining search results will hereinafter be referred to as organic search results . Top-level domain : Each URL references a main domain ( top-level domain ) and directories potentially located there . The main domain corresponds with the portion between the URL protocol specification ( http : // , https : // ) and the first following slash ( ” / ” ) . The top-level domain of http : //www.faz.net/ aktuell/wirtschaft/gruenen-chef-cem-oezdemir-will- gelaendewagen-bestrafen-wer-suv-faehrt-soll-die-kosten- fuer-die-umwelt-tragen-15201893.html consequently is www-faz.net . What did you see ? Personalization , regionalization and the question of the filter bubble in Google ’ s search efiginference ’ 17 , July 2017 , Washington , DC , USA Angela Merkel 6 Q Alle News Bild Vide Ma Mehl nstellungen Tk Schlagzeilen > Mehr zu Angela Merkel Angela Merkel https : //www.angela-merkel.de/ » Die personliche Internetseite der Vorsitzenden der CDU Deutschlands , Angela Merkel . Angela Merkel — Wikipedia htips : //de . wikipedia.org/wiki/Angela_Merkel ¥ Angela Dorothea Merkel ( * 17 . Juli 1954 in Hamburg als Angela Dorothea Kasner ) ist eine deutsche Politikerin ( CDU ) und dem 22 . November 2005 amtierende Bundeskanzlerin der Bundest Deutschland . Am 14 . Marz 2018 wurde Merkel vom Bundestag zum vierten Mal zur Bundeskanzlerin gewahit . Merkel Angela Merkel - Merkel-Raute Joachim Sauer Am Kupfergraben Figure 3 : Google search for Angela Merkel with three deliv- ered top stories . As is the case with most data collections , corrupt or divergent entries occur . The plug-in , too , did not run smoothly from the onset and produced partially corrupt data . Therefore , we describe the necessary data preparation below . 2.3 Data preparation The Firefox version ’ s first plug-in assigned the same ID to all users . As we intended to analyze the changes to search result lists over time , we decided to generally disregard that data in order to achieve a consistent database . As a result , 34 % of all donated URLs for the Google search and 41 % for Google News searches are omitted . A first analysis of the available data ( see Section 3 ) shows further irregularities . Noticeably , the database contained search result lists which in length didn ’ t conform to expected standards ( ten entries for the common Google search and 20 entries for searches on the news portal ) . For instance , the database contained some datasets with 200 entries in the search result lists . This can be traced to the possibility of individually adjusting the number of search results displayed on the first page . We have shortened these lists to the standard 10 plus potentially displayed top stories . Other errors are based on imperfect coding of the first Firefox plug-in , resulting in search result lists which contained the same URL throughout the list . Those lists were not included in our analysis . The same applies to URLs which only contained a reference to the corresponding URL at Google ( google.de/url ) or displayed a URL entry which merely referred to ’ google ” and didn ’ t contain a full link - those entries point to a private search result . Moreover , it was noticeable that a series of search result lists contained significant numbers of URLs that referred to websites in other languages . To dispose of foreign results , we manually sorted top-level domains of all websites by language . This way , we determined the share of German websites and kept those whose share was above 50 % . As a consequence , our subsequently used database was limited to German result lists . With these adjusted measures , the datasets in our investigation period for the Google search were reduced by 19,6 % ? and by 16,7 % '' for Google news data . A short list of the adjusted datasets can be found in Table 2 . Google search |Google News data after data after prep- preparation aration Number of datasets 3.564.583 5.597.480 Number of users 1.705 1.550 Number of result lists [ 302.813 279.874 Table 2 : Tabular overview of donated data after data prepa- ration . 3 DATA OVERVIEW In this section we give a first overview of the data . 3.1 Chronological distribution of search requests When looking at the daily distribution of our data donations , a clear decrease in donated search result lists during weekends showed . In Figure 4 the number of received URLs per day and search term are displayed and a wave-like pattern can be seen , while the lowest points are located at the weekends . Consequently , significantly fewer users had their browsers open on weekends and donated data , which can be attributed to a lower computer usage on week- ends . The daily number of data donors were mostly kept stable for both Google Search ( see Figure 5 ) and Google News ( see Figure 6 ) by limiting our observations to weekdays over the investigation period . Thus , between 450 and 550 users were online and donated their search results on the respective days . Also , the ratio between logged in and not logged in users remained similar over the in- vestigation period . The weekend from September 23rd/24th was only added due to its proximity to the election and appears slightly out of the ordinary due to its 350 users . Statistically speaking , the numbers of cases are still sufficiently high to obverse those days as well . `` From 4.416.585 to 3.564.583 10From 6.712.733 to 5.597.480 Conference ’ 17 , July 2017 , Washington , DC , USA Figure 4 : Number of submitted URLs for Google Search dur- ing the last 5 weeks before the 2017 federal election . Anzahl Nutzer Google Suche , Mittelwert = 506.9 2017-08-21 ] 2017-08-22 } 2017-08-23 } 2017-08-24 2017-08-25 } 2017-08-23 } 2017-08-29 } 2017-08-30 } 2017-08-31 ] 2017-09-01 ] 2017-09-04 2017-09-05 } 2017-09-06 } 2017-09-07 2017-09-03 } 2017-09-11 2017-09-12 } 2017-09-13 } 2017-09-14 } 2017-09-15 2017-09-13 } 2017-09-19 } 2017-09-20 } 2017-09-21 ] 2017-09-22 } 2017-09-23 } 2017-09-24 Anzahl Nutzer Google Suchen Eingelogat , Mittelwort : Nicht cingslogat , Mittawert : 149.4 2017-00-25 2017-00-26 2017-09-06 2017-09-07 2017-09-08 Figure 5 : Number of users on the respective days of the in- vestigation period for Google Search , after data cleansing . 3.2 Geographic distribution of data donors The distribution of users on the map of Germany in Figure 7 shows that we managed to acquire data donors Germany-wide and that Krafft , Gamer and Zweig Anzahl Nutzer Google News , Mittelwert = 480.1 2017-08-21 2017-08-22 ] 2017-08-23 ] 2017-09-11 2017-09-12 ] 2017-0 2017-0 2017-09-15 } 2017-09-13 ] 2017-09-24 ) Anzahl Nutzer Google News Eingelogat , Mittelwert : 338.9 os Nicht eingeloggt . Mitelwert : 141.3 , 2017-00-14 2017-00-19 2017-00-24 2017-09-23 Figure 6 : Number of users on the respective days of the in- vestigation period for Google News , after data cleansing . our data preparation ( see Section 2.3 ) does not suggest regional effects : Locations that are not included after our data preparation are displayed as reds dots . Those are spread all over Germany ; overall , the West of Germany is represented more strongly . 3.3 Distribution of internet and media offerings in the search results For the remaining data set we first calculated which top-level do- mains managed to get onto the first search result page most often for every search term . Figure 8 shows the results for the politi- cal parties and Figure 9 those for the politicians . For all parties except for Die Linke the respective party ’ s own top-level domain ranks first , for Die Linke it ranks 4th , while the parliamentary group ’ s website ranks second . Likewise , the respective Facebook account is always the second to fourth most common link , Twitter manages an entry into the top 10 for four parties ; for all parties except for the AfD , this is accompanied by the German Wikipedia entry . For the AfD there is a German Wikipedia entry as well , but it does not appear as often as the aggregate topic pages of Focus , Zeit , Merkur , Spiegel , FAZ and Tagesspiegel . A regular appear- ance for parties except for Die Griinen is the top-level domain www.bundestagswah ! -bw.de , which offers an overview of all par- ties . * bundestageswahl-2017.com ” , which appears for Die Griinen What did you see ? Personalization , regionalization and the question of the filter bubble in Google ’ s search efiginference ’ 17 , July 2017 , Washington , DC , USA Figure 7 : Distribution of data donors in Germany , where the respective positions were determined on the basis of the IP address and are therefore only an approximation of the po- sition of the individual users . The red dots are coordinates that are no longer included in the database after data cleans- ing . and the SPD , is a private collection of information relating to the parties and their platforms . It stands out that both Biindnis 90/Die Griinen and Die Linke predominantly have their own websites in the top 10 results , or those that could be altered by them with some degree of effort , e.g . in case of false coverage . This includes Face- book and Twitter as well as Wikipedia in general . For politicians , the personal website is always in the top 10 as well , for Alexander Gauland and Alice Weidel those are subpages of the top-level domain www.afd.de and thus not specifically visible . The corresponding German Wikipedia entry appears for all of them as well , besides a changing number of social media accounts , which are completely absent for Alexander Gauland . As a matter of fact , we could not find any personal social media account of Alexander Gauland , his website refers to the respective accounts of the AfD . Most big German online news magazines have topic pages , which collect news relating to a person or institution and often display an introductory , general text about the topic . Such person-related topic pages can be found for politicians among the top 10 of the top-level domains , but news from those and other sources as well . AfD Biindnis9 @ /Die Griinen cou wow.afd.de Wwe www . gruene .. com ~ore gruene . Wa . Wa Tom ww . gruene-nrw . er Com Gesamtanzahl an URLS : 169114 www . Faz . Gesamtanzahl an URLS : 164374 Www : Gesamtanzahl an URLS : 164980 csu Die Linke FDP www . csu.de 21.427 er . com = Cont wwii WW wil va wa WwW . WoW Wai Tom Gesamtanzahl an URLS : 152339 Gesamtanzahl an URLS : 152862 wid Gesamtanzahl an URLS : 152764 SPD Ww Www . www . www . wwe , . Gesamtanzahl an URLS : 178017 Figure 8 : Most common top-level domains for the organic Google search for the parties . Examining the top-level domains for the top stories , a less uni- form picture emerges ( see Figure 10 ) : While AfD , CDU , CSU , SPD and FDP receive most top stories from far-reaching media compa- nies , the top 10 sources for Die Griinen and Die Linke are lesser- known in some instances . For the searched persons , there are other sources to be found besides the most far-reaching , like the Gen- eralanzeiger Bonn ( for Cem Ozdemir ) or www.epochtimes.de ( for Alexander Gauland and Katrin Giring-Eckhardt ) ( see Figure 11 ) . For the sake of completeness , Figure 12 and 13 also show the top 10 of top-level domains for the respective searches on Google News . A media studies classification of the respective sources can not be provided here — the data however is available for future analysis ! ! . Overall , the first result page both for Google News and Google ’ s organic search are dominated by renowned media companies , es- pecially from the printing sector . Exceptions to this are the on- line newspaper Huffington Post and Freemail service provider t- online.de , which often appear as news sources . When searching for the terms ” Christian Lindner ” and ” FDP ” , Google provides a website as a news result which is being managed by the party ’ s federal branch . 3.4 Owned Content , Social Media and media offerings The search result lists contain different result categories , as Figure 14 shows for an example of a search for > Cem Ozdemir ” . An inter- esting question when assessing the diversity of results delivered by '' https : //datenspende.algorithmwatch.org/data.html Conference ’ 17 , July 2017 , Washington , DC , USA Krafft , Gamer and Zweig Alexander Gauland Alice Weidel Angela Merkel Alexander Gauland Alice Weidel Angela Merkel wow . faz-net 21231 de wa . : Wil , WH whl www . faz . net wii www . bild . wn , : wow waz wa . z Gesamtanzahl an URLS : 179070 Gesamtanzahl an URLS : 176493 Gesamtanzahl an URLS : 159040 Gesamtanzahl an URLS : 366262 Gesamtanzahl an URLS : 374593 Gesamtanzahl an URLS : 363632 Cem Ozdemir Christian Lindner Dietmar Bartsch Cem Ozdemir Christian Lindner Dietmar Bartsch web.de er.com www . christian Lindner . de [ 23785 ww . dietmar—bartsch.de [ 19992 Wl wid Ww de [ 23854 Wu Wu Wu Wil vw WH WW WNW . SP ! Wa Wat . . Walls Gesamtanzahl an URLS : 178748 WwW Wuw.ShZ , Gesamtanzahl an URLS : 367973 Gesamtanzahl an URLS : 174977 Gesamtanzahl an URLS : 184959 Gesamtanzahl an URLS : 372799 Gesamtanzahl an URLS : 383192 Katrin Géring-Eckardt Martin Schulz Sahra Wagenknecht Katrin Géring-Eckardt Martin Schulz Sahra Wagenknecht « de [ 20933 www . spi de 28.642 www , Faz . net 59881 wa , WH www.stern . 22451 ai9aa Wa zi wa Wu wn WwW-PP WwW . wa Wo Was : Gesamtanzahl an URLS : 381740 Gesamtanzahl an URLS : 183340 Gesamtanzahl an URLS : 168050 Gesamtanzahl an URLS : 176105 Was : Gesamtanzahl an URLS : 384376 Gesamtanzahl an URLS : 364193 Figure 9 : Most common top-level domains for the organic Figure 11 : Most common top-level domains for the Google Google search for the persons . News person searches . AFD Biindnis90/Die Grinen cou Alexander Gauland Alice Weidel Angela Merkel t. 12164 www welt .de 11543 = 74 ) Www . mz . . 3036 net 1715 wow bild . Gesamtanzahl an URLS : 55622 com Gesamtanzahl an URLS : 56290 Gesamtanzahl an URLS : 52983 com WW . Gesamtanzahl an URLS : 54122 Gesamtanzahl an URLS : 47700 Cem Ozdemir Christian Lindner Dietmar Bartsch ww . bild . de +de [ 3120 cSU Die Linke www . WWW WW Www won wu . wu zi WoW . SVZ + Gesamtanzahl an URLS : 55211 Gesamtanzahl an URLS : 54296 Gesamtanzahl an URLS : 45251 Katrin Géring-Eckardt Martin Schulz Sahra Wagenknecht ww WuN SP : WW wu . Gesamtanzahl an URLS : 51113 | Gesamtanzahl an URLS : 53523 | Gesamtanzahl an URLS : 52535 SPD www.welt . WW Wi : www . zeit . wane , 7 WH www . Spiegel . Gesamtanzahl an URLS : 49993 Gesamtanzahl an URLS : 55865 Gesamtanzahl an URLS : 52970 WWW . Figure 12 : Most common top-level domains for the top sto- ries of the Google search for the persons . Gesamtanzahl an URLS : 59658 Figure 10 : Most common top-level domains for the top sto- end , each individual URL was manually assigned to the database ries of the Google search for the parties . and one of 7 different categories , according to its top-level domain ; URLs of the Media category were categorized in a more nuanced way ' . A detailed description of those individual categories can be search engines is to look at their distribution on different offering found in Appendix A. categories and especially in asking the question of the extent to which persons or parties are able to edit their contents . Websites We thank the Bavarian Regulatory Authority for Commercial Broadcasting ( Bay- of candidates and parties evidently belong to the latter . To that erische Landeszentrale fiir Neue Medien , BLM ) for this difficult work . What did you see ? Personalization , regionalization and the question of the filter bubble in Google ’ s search efiginference ’ 17 , July 2017 , Washington , DC , USA Biindnis9 @ /Die Griinen cpu online.de [ 36789 wuw.t online.de 1287 wo . wa : wu won : Wale Ww 7 Www WwW z wan wt 7 Wa WwW 7 wo wo . . wats ww ww nd . wun zi Gesamtanzahl an URLS : 23185 Gesamtanzahl an URLS : 359399 wai , 7 Gesamtanzahl an URLS : 363612 csu Die Linke FDP www.rp online.de [ 39548 Wa wal WwW . www walt Wa wi wun . 7 zi www i 18403 Wai wiv ~com Gesamtanzahl an URLS : 368838 Gesamtanzahl an URLS : 363838 Gesamtanzahl an URLS : 359884 SPD www . faz.net 44276 WwW . SP . www . stern . Gesamtanzahl an URLS : 361836 Figure 13 : Most common top-level domains for the Google News party searches . Personliche Editierbare Nachrichten Webseiten Webseiten Cem Ozdemir Ozdemirs Bundestagsrede zur AfD : rs hw osrcenr ce © Ws hntapespentse Pm Miser une UND wi tor Busta a Evi WIRTSCHAFT GEHORT KEIN Cem Ozdemir — Wikipedia yergangene Woche viel Boachiung erzie hitps : //de.wikipedia.org'wiki/Cem_Ozdemir ¥ et Schwabe - Krokodile und c ? Kontakt - Cem Ozdemir https : / ; Wwww o @ 7demir de/kontakt/ + Kontakt . Cem Ozdemir , Migled des O cem.oezdemir @ bundestag.de . Bunde : Wegen Bundestagsrede : AfD kandiatt ipsa. » Paik » Dochiond sti Bad Urach Tscherkesson in der Turket -Sakularis wgon - Die AID will die Bundestagsrede des G ‘ Thema im Allestenat machen , Die Part wehrt sich Owned Content 3947 Media 406 Publicly funded 303 Others 71 Social Media 12 Wikipedia 10 Freemail portals 5 Table 3 : Distribution of all top-level domains of the Google search over the offering categories . websites of parties and persons and the approximately 400 media domains , the relatively high number of publicly funded domains stands out ( about 300 domains ) . Those primarily represent cities and municipalities ; however , the website of the Federal Agency for Civic Education and the Bundestag are included here as well . Party Number of top-level domains as- signable to a party SPD 1043 CDU 944 FDP 687 Biindnis90/Die Griinen 675 Die Linke 465 CSU 96 AfD 6 F : ( 030 ) 22776069 , € : cem oezdemirg ( 0711 ) 65832900 . F : ( 0711 ) kommen dagegen Griine : AfD kiindigt Beschwerde gegen Bundes https : /www.welt.de » Newsticker » News1 ( AFP - Journal ) * vor 2 Tagen - Die AMD wil offziall Beschwerde gegen die Bundest Gzdemir einlegen , in der er de AID-Adgeordheten als Rassisten Parlamentsgeschaistutrer der AfD-Bundestagstakton , Bemd Be die AID werde Ozdemirs Cem Ozdemir ( @ cem_oezdemir ) | Twitter hits /twitter.con/cem_oezdemir ? lang=de ¥ 107 tweets « 515 photosvideos « 96K folwers “ Der Kreg weitere unvosselbar rausame Dimensionen ereicht . Die # unsere Hie jetzt ! Heute Abend Mahnmarsch um 18 Ur -c kommen mitt AfD kundigt Beschwerde gegen Bundestagsrede von Cem Ozdemir ... s/o err de ef ven besctwerde goer bundestaystede- von co » + Tag - Die AFD will ffziell Beschwerde gegen die Bundestagsrede des Grunen-Poliikers Cem Seem eninge , n rer die AM ? -Abgoorneton a Rasen boosh hata Cem Ozdemir - Startseite | Facebook https /de-de facebook comiCem/ ¥ ‘ Com Ozdemir , Berlin . Gefallt 155 201 Mal , wwwoez Figure 14 : Division of organic search results for the search term `` Cem Ozdemir ” into three possible categories : per- sonal websites , which can be further divided into `` Owned Content ” and ” Social Media ” , editable websites such as Wikipedia and news . Besides , aggregate news services such as Freemail portals appear frequently ( t-online , web.de ) , but were not among the results of this search . It is more than astonishing that of the 4754 top-level domains of the Google search that were delivered during the investigation period a predominant portion of 83 % are subject to editability by parties or persons ( ? Owned Content ” ) . The vast majority of Owned Content consists of pages of local branches belonging to the re- spective parties ( see Table 4 ) . Some parties are significantly more active than others : While the sum of search results for the AfD provides a mere 6 clearly discernible individual top-level domains , it is more than 1000 for the SPD and nearly 950 for the CDU . Besides Table 4 : Number of top-level domains which can be assigned to a party . They usually represent a local branch , the party itself or individual party members . Figure 15 shows the distribution of organic search results ( with- out top stories ) over the entire investigation period . Here , distinct differences can be found regarding the share of URLs in the cate- gories Owned Content and Media between individuals and parties . The amount of links referencing a Wikipedia page lies above 10 % , which means slightly above one link , as there are users who re- ceived both the German and English Wikipedia entry . Due to this categorization it is now possible to differentiate between the entire proportion editable by a party or individual and the proportion that can not be edited ( media , Freemail portals , publicly funded and others ) . Summarizing the proportion of the respective categories for the particular parties ( see Table 5 ) , further evidence of a varying media presence in the digital space presents itself . While Biindnis 90/Die Griinen with 60 % and Die Linke as well as the FDP with about 50 % have achieved a very high proportion of Owned Content ( i. e. links to own domains of parties , local branches or politicians ) , the CDU and SPD manage a mere 30 % . A chicken-and-egg problem arises : A Conference ’ 17 , July 2017 , Washington , DC , USA 0.13 @ Owned Content @ Social Media @ Wikipedia 0.00 @ Medien 0.06 a Freemail Portale @ Offentlich finanziert B Sonstige 0.06 Krafft , Gamer and Zweig Owned Content Social Media Wikipedia Medien Freemail Portale Offentlich finanziert Sonstige Figure 15 : Distribution of organic search results among different categories in % , left for individuals , right for parties . The 9-10 organic search results a user receives when searching for a person thus contained e. g. on average two URLs from the category ’ Social Media ” and 4-5 links from the category ” media ” . well-working search engine optimization ( SEO ) provides good visi- bility of contents for all search engines , but good visibility in search engines can also lead to high popularity of contents in all search engines , which in turn results in good visibility in search engines . Therefore , the reason for some parties ’ own content being more vis- ible to themselves does not seem assessable . After all the conducted investigations we consider it most likely that those parties are most visible that provide a sufficient amount of timely content both on the regionalization as well as the news level . Table 5 shows the same analysis for search results that represent individuals . Here it is noticeable that especially for Gauland , who does not own social media accounts , less directly or in principle editable domains are delivered in total - for most other persons approximately two social media accounts are delivered . Frequently a publicly funded domain is shown for those with a seat in the German Parliament ( e. g. www.bundestag.de , www.bundeskanzlerin.de ) , which are missing for Gauland , Weidel , Schulz and Lindner . Finally Figure 16 shows the distribution of categories for the delivered top stories in the Google search . No significant differences both on the search term level as well as aggregated by parties or persons could be observed . The majority of 85 % always comes from the print media sector with an online presence . Media offerings with the internet as their sole path of distribution are displayed in the top stories with 9 % , while only 3 % represent public service channels and online branches of classic German private television service providers . 4 SCOPE FOR PERSONALIZATION/ REGIONALIZATION The # Datenspende project is a proof-of-concept to demonstrate that black-box analysis enables society to investigate algorithmic decision-making systems such as search engines - but in principle others such as product recommendation systems or social media as well - for dangerous spots . A much-debated dangerous spot 0.85 @ Print @ Online Only 0.00 GB ORR 0.03 O TV 0.03 & Sonstige 0.09 Figure 16 : Share of media delivered by Google in the top sto- ries during the investigation period for Google search of all search terms . in recent years has been the algorithm-based formation and re- inforcement of filter bubbles based on personalized search and recommendation filters . The question of whether and to what ex- tent search engine users receive different news and information about important political institutions and persons was therefore the focus of the analysis . The fact that we inspected a search engine and not the much more vulnerable social media such as Facebook was above all a matter of easier access to the results . Personalization of search results , as stated previously , is understood to describe a customized preparation or selection of search results that the user has not yet clicked . Suggestions are made based on profiles and click behavior of other users perceived as being similar . What did you see ? Personalization , regionalization and the question of the filter bubble in Google ’ s search efiginference ’ 17 , July 2017 , Washington , DC , USA AFD Buncnis9O/ | py csu Die Linke FDP SPD Die Grunen Owned Content 0,12 0,59 0,32 0,20 0,46 0,41 0,30 Social Media 0,11 0,16 0,19 0,20 0,21 0,21 0,10 Wikipedia 0,04 0,11 0,12 0,12 0,15 0,13 0,12 Media 0,60 0,01 0,25 0,42 0,07 0,19 0,29 Freemail portals 0,03 0,00 0,02 0,01 0,00 0,01 0,02 Publicly funded 0,09 0,05 0,09 0,04 0,07 0,06 0,10 Others 0,01 0,08 0,00 0,00 0,04 0,00 0,07 Share of ( in principle ) editable websites ~z a q Aa ( red ) /without such ac- cess ( blue ) Table 5 : Distribution of the organic search results on the different categories , for the searches for the parties . The circular diagrams represent the proportion of all websites that are ( in principle ) editable by the person or party in red ( Owned Content , Social Media and Wikipedia ) and the proportion of websites on which such an intervention is not possible ( Freemail portals , media , publicly funded and others ) , in blue . Alexander = Alice AngelaMer- Cem Christian Gauland Weidel kel Ozdemir Lindner Owned Content 0,08 0,11 0,11 0,16 0,14 Social Media 0,01 0,22 0,15 0,23 0,23 Wikipedia 0,12 0,12 0,14 0,12 0,12 Media 0,71 0,52 0,46 0,27 0,47 Freemail portals 0,08 0,03 0,04 0,13 0,02 Publicly funded 0,00 0,00 0,13 0,09 0,01 Others 0,00 0,00 0,00 0,00 0,01 Share of ( in principle ) > » editable websites ( red ) /without such ac- Ce oO @ oOo o cess ( blue ) Katrin Sahra Dietmar Goring- Martin Wagen- Bartsch Eckardt Schulz knecht Owned Content 0,16 0,12 0,11 0,16 Social Media 0,22 0,20 0,22 0,17 Wikipedia 0,12 0,12 0,12 0,12 Media 0,29 0,37 0,50 0,46 Freemail portals 0,10 0,08 0,04 0,03 Publicly funded 0,11 0,10 0,00 0,06 Others 0,00 0,01 0,00 0,00 Share of ( in principle ) editable websites = '' = @ @ o @ cess ( blue ) Table 6 : Distribution of the organic search results on the different categories , for the searches for the parties . The circular diagrams represent the proportion of all websites that are ( in principle ) editable by the person or party in red ( Owned Content , social media and Wikipedia ) and the pro- portion of websites on which such an intervention is not pos- sible ( Freemail portals , media , publicly funded and others ) , in blue . The personalization itself can be conveyed in the chosen selection , but also in a different order in the presentation of the found results . In the explanations for the use of the Google service it says : other features tailored to how you use our ser- vices . And we analyze your content to help us detect abuse such as spam , malware and illegal content ? So how significant was this personalization for the data donors before the 2017 federal election ? 4.1 Proportion of similar search results The book by Eli Pariser noted the many potential dangers of filter bubbles and expressed the concern that every person is trapped inside their own filter bubble ( `` being isolated in a web of one ” ' 4 ) , which likely contains * information desserts ” rather than nutritious information '° ( `` information vegetables ” ) . Therefore , a first inter- esting question is which share of data donor pairs will be shown exactly the same links and in addition , what percentage of them will get these links in exactly the same order . For the results of the Google search ( without top stories ) , the results summarized in Table 7 show the percentage of identical result lists and identical result lists in the same order . In fact , these percentages are essentially in the low single-digit percentage range - apart from the AfD , where 16 % of data donor pairs contain the same results . It is important to emphasize that this does not mean that 16 % of the result lists are exactly identical . An example : if out of 100 people two groups of people with 5 and 6 members each get exactly the same results and everyone else does not share the exact same links with anyone , then there are 10 pairs of users and 15 pairs of users , each seeing the same links , from a total of 4,950 pairs . This corre- sponds to 0.51 % of all pairs and thus almost to the result for the CDU . Truly remarkable is the enormously high share of pairs with sim- ilar search results for the persons , which is - except for Alexander Gauland - on average at least a quarter and for some almost 50 % . Shttps : //policies.google.com/privacy ? g|=de # infouse , ( 2018 , August 12 ) “ Prom Eli Pariser ’ s TED Talk : https : //www.ted.com/talks/eli_pariser_beware_online-filter_bubbles , minute 8 . 15 From Eli Pariser ’ s TED Talk : https : //www.ted.com/talks/eli pariser_-beware_online_filter_bubbles , minute 5-6 . * We use automated systems that analyze your content to provide you with things like cus- tomized search results , personalized ads , or Conference ’ 17 , July 2017 , Washington , DC , USA partei Anteil gleicher Anteil gleicher Ergebnisse artel Ergebnisse mit Sortierung ATD 16.5001 1.83138 Biindnis90/Die Griinen 0.57114 6.214303 0.570018 @ .149749 CSU 1,70591 0.353519 Die Linke 3.46704 1.24836 FDP 1.34052 0.343161 SPD 2.88426 ®.599181 Anteil gleicher Anteil gleicher Ergebnisse Person Ergebnisse mit Sortierung Alexander Gauland 8.83055 3.22469 Alice Weidel 29.6601 8.45194 Angela Merkel 26.6007 9.05307 Cem Ozdemir 32.0659 6.76066 Christian Lindner 31.0667 11.2727 Dietmar Bartsch 34,5123 3.50788 Katrin Géring-Eckardt 45.0472 10.4351 Martin Schulz 26.6496 5.50891 Sahra Wagenknecht 44.7985 21.1722 Table 7 : Share ( in percent ) of identical search results without consideration of sorting , separated by keywords for parties and persons ( 2nd column ) . In column 3 , the proportion ( in percent ) of identical search results can be found in the exact same order . In other words , had we asked any two data donors to do a search for one of the persons at the same time , the same links would have been delivered to a quarter to almost half of those pairs - and for about 5-10 % in the same order as well . If there were filter bubbles here , at least some of them would be quite spacious and would affect larger groups of people at the same time . A manual inspection of the result lists of Alexander Gauland sug- gests that notably the missing social media accounts lead to this result : These are replaced by messages which apparently are de- livered in a more diverse way . Reviewing Figure 9 supports this hypothesis . The illustration shows that politicians have different numbers of Owned Content and Editable domains among their top 10 top-level domains . Table 8 compares the percentage of similar search result lists to the number of Owned Content and Social Media top-level domains in the top 10 of search result top-level domains . It becomes apparent that more of these top-level domains among the top 10 correlate with a higher conformity of search result lists . Search term Number of “ Owned Content ” + | Percentage of identical result “ Social Media ” among top 10 lists top-level domains in the or- ganic search Alexander Gauland 3 9 % Angela Merkel 27 % Martin Schulz 27 % Alice Weidel 29 % Christian Lindner 31 % Cem Ozdemir 32 % Dietmar Bartsch 35 % ufalalajulalas Sahra Wagenknecht 45 % Katrin Goring-Eckardt 4 45 % Table 8 : Comparison of the type of top-level domains of politicians among their top 10 top-level domains ( Figure 9 ) and the percentage of identical result lists . In any case , it should be noted that even for people receiving the sare links , the order is likely to be different since the proportion Krafft , Gamer and Zweig of those with exactly the same order of those with the same results is in most cases below 50 % . 4.2 Average number of common links Just because two people do not get exactly the same links does not mean that they get completely different links . Therefore , Table 9 and Table 10 each show the average number of common links for all pairs of data donors that look up the same search term at the same search time . For persons , the number ranges between 7.2 and 8.1 common links . This also has to be correlated to the average length of the search result lists . Since this is just over 9 , on average only 1 to almost 2 links per randomly drawn pair of data donors are different . This is the * scope for personalization ” , which means the number of search results that could now be filled with links of various political content . In any case , the informational situation regarding the persons is - on average ! — essentially the same . Therefore , on average we observe a very high overlap of the received news and information . Person gemeinsame Links |mittlere Lange Raum fir der Suchergebnisliste | Personalisierung Alexander Gauland 7.21006 9.06237 1.8523 Alice Weidel 7.5889 9.06172 1.47282 Angela Merkel 7.88147 9.02418 1.1427 Cem Ozdemir 7.76558 9.08891 1.32333 Christian Lindner 7.49458 9.08401 1.58943 Dietmar Bartsch 8.1262 9.24993 1.12373 Katrin G6ring-Eckardt | 8.11471 9.18402 1.0693 Martin Schulz 7.49725 9.82739 1.53014 Sahra Wagenknecht 7.96757 9.11063 1.14307 Table 9 : The mean result list length without top stories ( 3rd column ) for the persons compared to the average number of URLs , which share a result list with all other result lists at the same search time ( 2nd column ) . From this , the average scope for personalization can be calculated by subtraction ( 4th column ) . For the parties , the result looks a bit different . Here , any two data donors searching for `` Die Linke ” at the same time have only 4.7 common links on average , for the AfD ” up to 7 links . Comparing this with the average lengths of the search result lists again , which fluctuate ! ® between 8 and 9 , for the parties an average of 2 ( AfD ) , 3 ( Biindnis90/Die Griinen , Die Linke , FDP ) and almost 4 ( CDU , CSU ) of non-shared links remain . Figure 17 and Figure 18 show that the averages essentially origi- nate from distributions that are skewed to the left . This is because each pair can share a maximum of 8 or 9 links , depending on the average length of the lists . Therefore , to the right this limit is closer than to the left . Only the AfD shows a bimodal distribution , e. g. 10 % of pairs of data donors sharing only 2 links . This finding will be further considered below ( Section 5 ) . 16The short organic search result lists are an effect of displayed top stories ( the or- ganic search result list usually contains 9 entries then ) and can be further reduced by displaying deletion hints or the like . Especially with `` Die Linke ” , such effects seem to have shortened the search result lists . Since the corresponding information was not saved on the search results page , we can not make a final assessment here . What did you see ? Personalization , regionalization and the question of the filter bubble in Google ’ s search efiginference ’ 17 , July 2017 , Washington , DC , USA Partei meinsame Links |mittlere Lange Raum fii : . : arees genes ans ymeserere range ae We also conducted the same investigation on the Google News der Suchergebnisliste | Personalisierung . . . . . aD 6.09774 9.03863 764089 search result lists , the outcome of which we will discuss in the next Biindnis9 @ /Die Griinen | 6.03871 9.15723 3.11852 section . cou 5.39071 8.94959 3.55888 csu 5.31047 8.99783 3.68736 Die Linke 4.76699 8.00472 3.29773 4.3 Scope for personalization on Google News FDP . 5.1696 8.35014 3.18054 SPD 6.28109 9.03634 2.75524 The search result lists on Google News almost always contain 20 Table 10 : The mean result list length without top stories ( 3rd column ) for the parties compared to the average number of URLs that share a result list with all other result lists at the same search time ( 2nd column ) . From this , the average scope for personalization can be calculated by subtraction ( 4th col- entries , therefore the average rounded lengths are 20 for almost all of the search terms . Of these , for persons on average 17.3 to 18.3 are shared . The percentage of shared links is thus even higher than for the Google Search , leaving 2 to 3 links with possibly personalized messages . umn ) . Person durchschnittliche mittlere Lange — | durchschnittlicher Raum Anzahl gemeinsamer Links |der Ergebnislisten | fir Personalisierung we Bananesoie Sranen coe Alexander Gauland 18.0928 19.9667 1.87385 Alice Weidel 17.2749 19.8514 2.57648 Angela Merkel 18,3288 19,991 1.66218 Cem Ozdemir 18.1502 19.9789 1.82867 Christian Lindner 18.078 19.9387 1.86071 . Dietmar Bartsch 18.0043 19.8279 1.82363 , Katrin Giring Eckardt | 17.2947 19.7863 2.49161 Martin Schulz 17.8846 19.9697 2.08504 ve a : Sahra Wagenknecht 18.2229 19.944 1.7211 cu Die Linke FOP Figure 19 : The mean result list length on Google News ( 3rd column ) for the persons compared to the average number ly of URLs that share a result list with all other result lists at LL the same search time ( 2nd column ) . From this , the average scope for personalization can be calculated by subtraction ( 4th column ) . For the parties , the scope for personalized messages ( on av- erage ) is also rather small and ranges from 1.3 to 2.1 for all but * Bundnis90/Die Grinen ” , where up to 3 links from 18 could be personalized . It is important to note that only pairs of people are considered here . That which A and B do not share , B could share Figure 17 : Distribution of the number of identical URLs in pairwise comparison of the organic search results for the parties . : : : with C. Thus , these non-shared links do not necessarily have to suevandesGnutan vance wae nga nt be displayed to only one person , but may again affect smaller sub- groups . Partei durchschnittliche mittlere Lange durchschnittlicher Raum Anzahl gemeinsamer Links |der Ergebnislisten | fiir Personalisierung AfD 18.3519 19.9802 1.62838 Ohara : [ | oo = Biindnis9 @ /Die Griinen | 14.6315 17.7313 3.69981 Cem Gzdemir Christian Lindner Dietmar Bartsch , cDU 18.3747 19.7574 1.38266 csU 18.6942 19.9999 1.30568 | ” Die Linke 17.4219 19.5355 2.1136 FDP 18.1947 19.7516 1.55692 . SPD 18.4332 19.8903 1.45712 : Figure 20 : The mean result list length on Google News ( 3rd Se sre - a column ) for the parties compared to the average number of URLs that share a result list with all other result lists at the same search time ( 2nd column ) . From this , the average space for personalization can be calculated by subtraction ( 4th col- : ‘ umn ) . elles | alle , ITE | EEL Figure 18 : Distribution of the number of identical URLs in 5 REGIONALIZATION pairwise comparison of the organic search results for the persons . Due to the large amount of Owned Content , which can mainly be attributed to the many websites of regional branches or the web- sites of local politicians , regionalization of search results inevitably leads to many non-shared links . Therefore , we have once again Conference ’ 17 , July 2017 , Washington , DC , USA categorized each party ’ s Owned Content as regional/non-regional . We were rather conservative in our approach and have only marked those domains as regional which clearly referenced a city in the URL . For each pair of party search result lists , we first removed those regional URLs and then calculated the average number of non-shared links . Therefore , this represents a closer approximation to the possible number of personalized links , because the regional links are explicitly excluded . Table 11 shows the result of this re- finement : While the data donors differ on average by 3 links for Die Griinen , only one of these is non-regional ( and could be person- alized ) . This is similar for the SPD , FDP , CDU , and Die Linke , each falling from ( about ) 3 non-shared links to below 2 non-regional links . Non-shared links Non-shared links ( without regionalized links ) BUndnis90/Die Griinen 3.11852 1.02717 SPD 2.75524 1.572 FDP 3.18054 1.70385 CcDU 3.55888 1.84831 Die Linken 3.29773 1.8818 AfD 2.04089 2.0244 CSU 3.68736 3.36667 Table 11 : Refining the average number of non-shared links while taking into account regionalization . The left-hand column shows the average number of non-shared links for the entire search result list , and the right-hand one for the search result list after deleting the clearly regionalized web- sites ( the respective local branches or individual local politi- cians ) . There is essentially no effect for the AfD to be seen - yet that is not surprising , as only six top-level domains are displayed at all and no websites belonging to local branches were found . Of the six domains , four are of a regional nature ( afd.berlin , afd.nrw , afd-bw.de , afd-fraktion-brandenburg.de ) . Interestingly , little change occurs for the CSU , too . However , a look at the map of Germany showing the approximate locations of our data donors shows that Bavaria has fewer data donors who were still in the summer holidays during the first four weeks of the investigation period . Since most of the local branches are located in Bavaria , hardly any regionalized search results were delivered . A manual inspection of the search result lists shows that relatively many messages are delivered that overlap less strongly . Here , a more in-depth , content-related inspection appears sensible . Nonetheless , on average the search result lists clearly overlap more than half , so that here , too , a common information base is laid out . 6 DYNAMICS An important subquestion of the project concerns the dynamic in which search results in the ordinary Google search change . One pos- sible hypothesis here is that towards election day , Google ’ s search results change in their similarity or the share of different media . In the sequence of the previous analysis , we first considered the Krafft , Gamer and Zweig dynamics of the respective share of top stories as the most promi- nently placed results ( see Section 6.1 ) . The second is an analysis of the number of delivered top-level domains per search time ( see Section 6.2 ) , followed by a look at the respective shares of editable URLs in the search queries , i. e. Owned Content , Social Media and ( with some limitations ) Wikipedia ( see Section 6.3 ) . 6.1 Dynamics of the occurrence of top stories A first interesting point in the question of whether the search re- sults have changed towards the election was whether and when top stories are displayed and whether the proportion of search re- sults with top stories has increased towards the end of the election campaign , for example . In this case , effects such as a higher news density could lead , as an example , to Google delivering more search result lists with top stories shortly before the election than five weeks before that . However , the analysis of the occurrence of top stories has shown that across all search terms and search times , the proportion hardly fluctuates . Percentages always range in a corridor around 90 % with up and down swings of no more than 10 % ( see Figure 21 ) . Only when looking at the individual search terms stronger deviations have been found . 08 0.6 4 Anteil der Ergebnislisten mit Schlagzeile 0 20 40 60 80 Suchzeitpunkte Figure 21 : Proportion of all result lists for a search time , where at least one top story was delivered . There are clear outliers for Katrin Giring-Eckardt and Dietmar Bartsch ( see Figure 22 ) . In contrast , the shares of search result lists with top stories for the search terms CSU , SPD , Angela Merkel , Martin Schulz and AfD are very stable , although at the beginning of the investigation period their proportion of top stories ( search time 6 to 22 ) is still subject to fluctuations ( see Figure 23 ) . The isolated , complete absence of top stories ( see Figure 22 ) may indi- cate that it is decided by Google whether or not to deliver a top story according to the latest news — but these deviations can not be fully explained from the outside . Without further information it is particularly inexplicable why , for the same search time and search request , Google delivers top stories for some participants and does not do so for others . Especially the very stable values of some search terms ( CSU , SPD , Angela Merkel and Martin Schulz ) contradict a browser setting of these users which would suppress What did you see ? Personalization , regionalization and the question of the filter bubble in Google ’ s search efiginference ’ 17 , July 2017 , Washington , DC , USA such a top story in any form , because then these users would not have received top stories for other search terms ( such as CSU , SPD , Angela Merkel ) . However , these search terms show many search times where all users received top stories . Dietmar Bartsch Katrin Géring-Eckardt Time : 00:01 Time : 04:01 http : //www.stimme.de/themen/wah- len/btw17/wahichecks/WahIcheck-mit-Katrin- Goering-Eckardt ; art140707,3901145 , http : /www.rp-online.de/politik/deutsch- land/katrin-goering-eckardt-sieht-tiefe-kluft- zwischen-gruenen-und-fdp-aid-1.7027881 http : //www.stimme.de/themen/wah- len/btw17/wahichecks/Ohne-Klimaschutz- ohne-die-Gruenen ; art140707,3901145 ~hitp : /iwww.goering-eckardt.de/ https : //de.wikipedia.org/wiki/Kat- tin G % C3 % BG6ring-Eckardt hitp : /Awww.goering-eckardt.del https : //de.wikipedia.org/wiki/Kat- tin G % C3 % B6ring-Eckardt a o https : //de-de.facebook.comiGoe- g g _https : //de-de.facebook.com/GoeringEckardt ’ _| ringEckardt 2 08 z 08 http : //www.spiegel.de/thema/katrin_goe- http : //www.spiegel.de/thema/katrin_goe- 3 8 ting_eckardt/ ting_eckardt/ Fos Eos https : //www.bundestag.de/abgeord- 3 B https : //www.bundestag.de/abgeordnete18/bi- | nete18/biografien/G/goering_eckardt_kat- 2 os ¢ os ografien/G/goering_eckardt_katrin/258372 rin/268372 & a http : //www . focus.de/politik/deutsch- http : //www . focus.de/politik/deutsch- 3 : land/gruene-spitzenkandidatin-goering- land/gruene-spitzenkandidatin-goering- B02 B02 eckardt-hat-sich-von-ihrem-mann-getrennt- eckardt-hat-sich-von-ihrem-mann-getrennt- 2 2 und-spricht-ueber-ihre-neue- und-spricht-ueber-ihre-neue- oo 7 liebe id 6967147.html liebe id_6967147.html 0 20 40 60 30 20 40 60 0 Suchzeitpunkte Suchzaitpunkte Figure 22 : Proportion of result lists with top stories for the search terms “ Dietmar Bartsch ” and ” Katrin Goéring- Eckardt ” show clear deviations from all others . This inconsistency also becomes clear when looking at individual users . For example , with the same user and search term sometimes top stories appear and sometimes they do not ( see Figure 24 ) . Over- all , however , the proportion of search result lists with top stories is relatively stable and shows no particular temporal patterns with regard to the federal election . ° Suchzoitpunkte Angela Merkel Martin Schulz 9 , Figure 23 : Proportion of all result lists that contain top sto- ries , for the search terms CSU , SPD , Angela Merkel , Martin Schulz and AfD . Figure 24 : Search results of a user from August 28th 2017 for the mentioned times and the search term ” Katrin Géring- Eckardt ” . Top stories were once displayed to the same user at different , consecutive search times ( highlighted in gray ) and then they were not . 6.2 . Dynamics of the number of different top-level domains In processing of the number of different top-level domains that were delivered to at least one data donor at a search time , on the one hand already recorded trends ( see Figure 25 , 26 ) confirm that search result lists for parties generally have more top-level domains than results lists for persons . On the other hand , this number fluctuates quite strongly from party to party : While only about 22 top-level domains characterize the results on the AfD at most search times , the number is around 180 for Die Griinen ( with large deviations ) . Essentially , the number of top-level domains of the parties is re- flected here again , and the fluctuating extent of regionalization is thus visible . For the persons the number is between 17 and 18 , which also shows that the number of shared links ( including top-level domains ) is very high for the persons . Although the fluctuations over the search period are sometimes very pronounced , there are no striking temporal patterns in the number of different top-level domains . 6.3 Dynamics of proportions of editable contents Over time , does the proportion of URLs that are on top-level do- mains and that are editable by the parties or persons ( in principle ) change over time ? We also examined this question for all search times during the investigation period . There is a slight drop for all parties ( except Die Griinen ) for the search times right before the election . It should be noted that the last 6 search times are from the election weekend . Presumably this is caused by an increased share of news , although this only takes effect in the last days before the election . For most persons , too , this short-term decline in editable websites can be seen among the search results , which in some cases already Conference ’ 17 , July 2017 , Washington , DC , USA Krafft , Gamer and Zweig “ hh Vi h wi i Mt \\ AFD ; Bindnis90/Die Grinen Alexander Gauland Alice Weidel N } \\ I | | ii | iM he A Wat | \\ MAN oA Wal nee MA Tg RCN Ha pay Hh \\ \\h “ at ua iy Wana AWN \\ Y \\ y | a `` | N ) hank h I MA =| | Iya ‘ y Ww vv NY [ Nut 4 I , \\ MN | | n Vea Al As Kh WAlh aT ipwoe\\ linn ! Whe i \\ { | || 3 TAN ) Wi oA aN yy | iY `` h 1 | MI if TANT VW I pee VS | Die Linke - FDP Christian Lindner Dietmar Bartsch \\ \\ i An A il ; L , l|\\ Ne pa why PAY I a N AN AI “ h | NV \\ W \\ | | nu WV | | | | iF ia l f iH M ft | \\ H | | \\f | |\\ Nn wl U i i I ‘ * H '' | ! “ OY | yt ty '' yt Ny Figure 25 : Number of different top-level domains over the 81 search times for the Google search of parties . starts one week before the election ( Gauland , Lindner , Ozdemir and Wagenknecht ) . The result was not pursued further , because this report deals with the key issues of personalization , regionalization and filter bubbles . However , for media scientists it could prove to be an interesting initial observation that can be followed up on by means of the publicly available data from the data donation . 7 SEARCH RESULT LISTS WITH LOW SIMILARITY TO ALL OTHERS Even though most of the search result lists are very similar on av- erage , some pairs of search result lists beyond the average showed almost no overlap . As previously mentioned in the first interim report , a manual inspection of search result lists showed the occa- sional result list that differs greatly from all of the others ! ’ . It was determined that these lists often contained links to websites in other languages ( mostly English ) . It is difficult to conclusively cluster and identify these links automatically , partly because the link itself does not necessarily give any insight on the language of the website it links to , e. g. some websites end in ” .com ” and still refer to a German website like * handelsblatt.com ” . Most social media pages also end in * .com ” ( twitter.com , facebook.com ) and the language displayed depends on the user being logged in . On Wikipedia pages the language is encoded into the first two letters of the URL , so * de.wikipedia.org ” refers to the German , and ” en.wikipedia.org ” to 17Section 4 of the first interim report ( Krafft et al. , 2017 ) Tahra Wagenknecht Figure 26 : Number of different top-level domains over the 81 search times for the Google search of persons . the English version of that page . Furthermore it is unclear if all deviant clusters have to contain at least one website in a foreign language . We also followed a second approach , that also requires manual preparation of the data : First links were removed that were seen by least 70 % of all users for each search term and time , since their popularity suggests a lack of personalization . In the next step , we clustered the lists with the remaining links , so that the lists within these clusters are similar once more . The original lists of these groups were then compared to every user outside of the group , to find the number of common links . For example : We find 5 users , who retained only 4 entries in their lists , after the popular links for the search term “ Die Linke ” were removed , but still shared at least 3 links with each other - they form a cluster . For these 5 users , we compared their original result lists with every other user outside of the cluster to find the average number of common links . If this average falls below 3.5 the cluster is considered to be a very distinct group . During a manual inspection of the identified dis- tinct clusters we found that , especially for the search terms `` Die What did you see ? Personalization , regionalization and the question of the filter bubble in Google ’ s search efiginference ’ 17 , July 2017 , Washington , DC , USA AID B90/Die Grinen a acon ¥ acadoemmnanel AAA han bu csu Pat ering Die Linke FOP SE NLNIN ASI , Theos hw a SPD tnt Figure 27 : Proportion of ( in principle ) editable websites for the respective party of all result links of the respective party . Here , the proportion for each of the 81 search times is ap- plied and the mean value is drawn in in gray . Linke ” and * Biindnis90/Die Griinen ” , most of these clusters were regional groupings , whose search result lists differed only in the large selection of local branches of the party . In summary we can say that automatically identifying groups of users that receive different content according to the filter bubble theory ( not originating from regionalization ) , has proven to be quite a complex task . A third approach showed a clear pattern that does indicate a stable filter bubble , which would have to be subject to further studies : Based on the time of publication that accompanies every top story , it is possible to detect the main language Google assigns to a user . Our data set contains publication times in Norwegian , English , German and French . This made it possible to partition the search result lists . In all examined cases , we saw a separation of users by Google into * presumably German ” with high similarity of re- sults per search term and time , and ” presumably foreigners ” who shared unusual results which were then mixed with results of the suspected , preferred language . This was done via manual inspection , since there was no possibil- ity to automatically separate users into those that are considered German-speaking by Google and those that are not ( primarily ) German-speaking . Some users received German publication times once and only English publication times after that , and many of the users manually flagged as having partially non-German search avander Gauland Tea Werder Aj po Np yer Na ~ noe Angela Ware ta , Len ee aa at Nl —/ Chvatan Linde Dietmar eI A 7a 7 aA a h ee NH ne Taha Wagenknecht ALY AWM La PICK Figure 28 : Proportion of ( in principle ) editable websites for the respective persons of all result links for the respective person . Here , the proportion for each of the 81 search times is applied and the mean value is drawn in in gray . result lists did not receive any top stories and therefore did not receive publication times . This pattern will be demonstrated with some selected examples below . 7.1 Example : Search result lists from a French IP Figure 29 shows the search results of a user in France . For the result lists containing top stories one can clearly see that Google suspects a French person , since the publication times that Google adds to every news entry are French ( e.g . “ Il y a 2 heurs ” ) . The top stories themselves link to French websites , which discuss the German election . It is interesting to see that some lists contain German results . The results for the search term Angela Merkel ” overall look like a sensible selection of websites — at least for a person living in France . For the search term ” AfD ” the same person receives - along with re- sults concerning the German political party - websites from French initiatives with the same acronym , mainly L ’ Agence francaise de développement , a French organization fighting diabetes and sup- porting people with autism and their families . Following the same Conference ’ 17 , July 2017 , Washington , DC , USA hitps : /ferwe.tolesta.t/people/angpla- meskel qui est le mari de la chonceliere-allemande- photos 156102 nttps : /furrw.bundeskonzierin.def Figure 29 : Search results for the search term ” Angela Merkel ” of a user with an IP address in France , close to Paris . The results are divided into three top stories and the organic search results below . method of looking for international institutions or organizations with the same acronym as the political parties we found the French Cultures et Societés Urbaines and the American universities Charles Sturt University and Colorado State University while searching for “ CSU ” . The Google search for the German politicians is for the most part without error , meaning that the user almost always receives infor- mation about the persons searched for : The results contain mostly the social media profiles and - depending on the prominence of the politician - their French Wikipedia entry and French news outlets ; this is especially the case with Angela Merkel and Martin Schulz . Apart from that , the user receives German news websites and social media pages . An exception to this is Cem Ozdemir : One Twitter profile received belongs to another person with the same name ! ® and results concerning a football player on the transfer market ! ? , both of which are not members of `` Die Griinen ” . The occurrence of links in the ( suspected ) native language of users outside of Germany is without question useful and the amount of German-speaking websites received by the examined user probably originates in the lack of French-speaking websites for these partic- ular search terms . It is not possible to further determine how the choice was made whether and when a user in a foreign country receives links to German websites . It is a lucky coincidence that we received data from multiple data donors , all with an IP address originating in Kaiserslautern , but in different languages , namely English , Russian and German . This allows us to eliminate the influence of regionalization based on the IP address . 18h ttps : //twitter.com/esekherif_ 1 https : //www-transfermarkt.fr/cem-ozdemir/profil/spieler/170442 Krafft , Gamer and Zweig In the next step we examine the search results of a user receiv- ing links to Russian websites from Google while searching from a German IP address from Kaiserslautern . 7.2 Example 2 : Google search from Germany with partially Russian results Our manual inspection showed a person located in Kaiserslautern according to their IP address , who often received Russian Wikipedia pages while searching for politicians and political parties . Our browser plug-in recorded the IP address as well as the keyboard language used , which was set to Russian for this person . Table 12 shows a typical search result list for this user when searching for * Angela Merkel ” . https : //de.wikipedia.org/wiki/Angela_Merkel https : //ru.wikipe- dia.org/wiki/ % DO0 % 9C % DO % B5 % D 1 % 80 % DO % BA % DO % BS % DO % BB % D1 % 8C , _ % D0 % 90 % DO % BD % D0 % B3 % D0 % B5 % D0 % BB % DO % BO https : //en.wikipedia.org/wiki/Angela_Merkel https : //ru-ru.facebook.com/angelamerkel https : /Avww.angela-merkel.de/ http : //www.spiegel.de/thema/angela_merkel/ https : /Avww.bundeskanzlerin.de/ https : /Avww.forbes.com/profile/angela-merkel/ http : //www.focus.de/personen/angela-merkel/ http : //www.stern.de/politik/deutschland/themen/angela-merkel-4540550.html Table 12 : Typical search result list for the search term ” An- gela Merkel ” for a user who donated around 40 result lists , sometimes containing Russian results . The second link of this result list refers to a Russian Wikipedia page of Angela Merkel , the third link to the English version . The fourth refers to the Facebook page of Angela Merkel , which is pre- dominantly German content-wise . If someone were to open that page while logged into Facebook and with his or her preferred language set to Russian , the text supplied by Facebook would be in Russian ( e.g . the user display , etc. ) . Thus , this would not change the content of the politician . Lastly a second English-speaking website ( forbes.com ) appears near the end of the result list . Therefore the user did not receive any Russian websites , but Google seems to regard the Russian Wikipedia pages as appropriate . It is unclear why this is the case . We observed that for a lot of users English keyboard settings do not necessarily imply English results , which is why we do not think the Russian keyboard settings are the ( only ) reason for these results . It is noteworthy that this person was always logged into Google , which could be the source of the information . After that we compared the results received by the person from Kaiserslautern , who received some Russian results , to other users from Kaiserslautern and another user outside of Germany , namely the person mentioned before from France ( Figure 30 ) . It is noteworthy that users who received non-German results from Google did not receive any top stories . The user from Kaiser- slautern with a link to the Russian Wikipedia website of Sahra Wagenknecht also received a link to her Twitter profile . The last What did you see ? Personalization , regionalization and the question of the filter bubble in Google ’ s search efiginference ’ 17 , July 2017 , Washington , DC , USA KL Paris FR Zeit- Ss KL Paris DE1 DE2 RU FR Zeit- Zeit- Zeit- Zeit- Suchergebnisse Suchergebnisse Suchergebnisse Suchergebnisse angabe 8 angabe 8 angabe e angabe 8 angabe ‘ wagenknecht 47797052 : ntml 5.de ed ALD htips/ffrewkapedaorg/enke/sotra aps /fen wiignalia mph Sau Waye tes funwwt- layswahlfid 8151608/sat 2 hup : vera bhitpy/fwwrw-bunie.defpanorama/politikysa_tagswshl/id_81516044/sahre-wegerknecht- ba tpestanndnis-sie-hartie suegerre kanler-gehab hind Figure 30 : Search result lists for the search term ” Sahra Wa- genknecht ” on August 22 , 2017 from users with IP addresses in Paris ( rightmost column ) and Kaiserslautern . Identical results are represented by the same color . The first two columns show users whose result lists are constantly Ger- man . The third column shows the search results of a person who sometimes received Russian results . The fourth column shows the results of a user from Paris , France according to their IP address . part of this link * lang=ru ’ only affects the content supplied by Twit- ter ( e.g . translations of the navigational buttons like ” Messages ” , * Follow/ Unfollow ” ) - the tweets themselves are in German . The user also receives links to an overview page from the Tagesspiegel and an article from Bunte , both concerning Sahra Wagenknecht . The user from France received an article about `` Sahra la Rouge ” and the English Wikipedia entry . Interestingly the user from Kaiserslautern does not receive a Rus- sian Wikipedia entry for every person that is present there : Except for Dietmar Bartsch and Katrin Giring-Eckardt , every politician included in our set of search terms is represented on the Russian Wikipedia website , but not always displayed to the user . Figure 31 shows the search results of 4 users for the search term ” Cem Ozdemir ” and for the same search time . The user from Kaiser- slautern receives the German and English Wikipedia entry , the French user gets the German and French entry . Apart from the links that they share with the users receiving constantly German Tap Stories vor 9 Standen 155/2/1.Hem Figure 31 : Search result lists for the search term `` Cem Ozdemir ” on August 22 , 2017 from users with IP addresses in Paris ( rightmost column ) and Kaiserslautern . Identical results are represented by the same color . The first two columns show users whose result lists are constantly Ger- man . The third column shows the search results of a person who sometimes received Russian results . The fourth column shows the results of a user from Paris , France according to their IP address . result lists , they also share the Twitter profile of another person with the name `` Cem Ozdemir ” who is not the German politician . The same is true for their respective last entry , a link to a sub-page of the top-level domain > www.gruene.de ” that is rarely seen else- where . In summary both of the users who received non-German results from Google share 6 links . The French user also received two French websites along with the reference to the football player and the correct Twitter profile of Cem Ozdemir . The result list of the user from Kaiserslautern , who also received Russian results , contained a news article from ” Zeit ” which was not received by the other three users . He or she shares 7 and 6 links respectively with the other users from Kaiserslautern . A lot more frequent than a person who receives Russian Wikipedia websites are users with IP addresses in Germany and other coun- tries , who receive mixed language results , consisting of English and German websites . Among these is a user with an IP address from Kaiserslautern . We therefore looked at four result lists of users with an IP address based in Kaiserslautern for all political parties at the same search time . Two of those users received only German results ( DE1 and DE2 ) , the user with partially Russian results ( RU ) and a Conference ’ 17 , July 2017 , Washington , DC , USA user with partially English websites originating in the USA ( USA ) . Figure 32 shows the number of common results for each party . USA | 12 usa |_10 RU | 6 | 10 RU | 10 | 10 pe1| 4 | 4 | 12 be1| 8 | 38 | 12 pez| 4 | 4 [ 12 | 12 pe2| 7 | 7 [ 11 | 12 usa | RU | DE1 | DEZ usa | RU | DE1 | DE2 AfD Biindnis90/Die Grinen USA | 10 usA |_10 ru | 6 | 10 RU | 4 | 10 pe1| 5 | 5 | 12 ve1| 2 [ 4 | 12 pez ] 5 | 5 | 12 | 12 pez ] 2 | 4 | 12 ] 12 UsA | RU | DE1 | DEZ USA | RU | DEI | DE2 cpu csu usA | 10 usa | 10 ru | 7 | 10 RU | 6 | 10 pe1| 4 | 4 | 41 pe1| 4 [ 4 | 41 pez| 4 | 4 | 12 | 41 pez| 4 [ | 4 [ | 10 | 11 usa | RU | DE1 | DEZ USA | RU | DE1 | DE2 Die Linke FDP usA | 12 ru | 3 | 10 pe1| 6 | 4 | 12 pez| 6 | 4 | 12 | 12 | Usa | RU | DE1 | DE2 | SPD Figure 32 : The result lists of four users with IP addresses based in Kaiserslautern for all parties on September 5 , 2017 were compared to find the number of common links . Two users only received German results ( DE1 and DE2 ) , one user also received Russian and English websites ( RU ) and one user websites with American origin ( USA ) . Displayed are the number of identical links for each pair — the diagonal fields ( gray ) show the total number of links contained in the per- son ’ s search results . It is noticeable that the two users with purely German results almost always have identical search result lists . A manual inspec- tion shows that even the order of the results is mostly identical . Surprisingly , the remaining users have more links in common for five of the parties and the same amount of links in common for two parties as the purely German users , even though they searched from the same location based on IP addresses . To further enhance this pattern we did a last comparison to look at all search result lists from Kaiserslautern and all result lists outside of Germany based on IP locations for one search term and time ( September 22 , 2017 , `` Angela Merkel ” ) . For every person except one top stories were included , so we could determine whether Google supplied them with English or German publication times ( °1 hour ago ” vs. ’ Vor 1 Stunde ” ) ; other languages were not represented in this sample . The astonishing result is shown in Figure 33 : The simi- larity between the search results is highly dependent on whether Google German-speaking or an English-speaking Person . Even though the patterns in the deviant clusters remain com- plex and also due to the relatively low number of users with con- stantly German websites , a distinction between `` German ” and ” non- German ” users is clearly visible . It is unclear which aspects factor Krafft , Gamer and Zweig into Google ’ s decision whether a person is German-speaking and should only receive German results . Users who also received Eng- lish results showed very similar result lists , regardless of their location ( in this case Austria , Belgium , Great Britain and Denmark ) . One exception to this is a person from Norway , who did not receive any top stories - therefore it is unclear which language Google has assigned to them . It is however noteworthy that this user received two Norwegian websites and has received top stories for another search term ( `` Alexander Gauland ” ) at the same search time , which had Norwegian publication times . Another exception is one of the Swiss users , who received a lot of results not present in the others ’ result lists . This results in a not completely isolated , but noticeably different media space for the users receiving English ( or other foreign ) re- sults while living in Germany ( or at least using a router located there ) . 7.3 Possible explanations In the end the simplest explanation is probably the correct one : The type of deviant search result lists for German IP locations can easily be recreated by logging into one ’ s Google account and changing the search language settings . To accomplish that , one must go to the search settings on the Google website and change the language settings to the desired language , e.g . French . Another visit to the Google website shows that the navigational buttons are now dis- played in the selected language . If the term searched for results in the display of top stories , these will be accompanied by the pub- lications times in the selected language . Additionally the organic results contain some deviant links identical to the one we found when searching for the search terms used in this project : Links to English Wikipedia pages , confusing CSU , CDU , AfD and SPD with identical acronyms , more common in the selected language ( e.g . * Colorado State University ” , `` Charles Darwin University ” , `` Agence Francaise de Développement ” , ’ symphysis pubis dysfunction ” ) , and also German websites that indeed belong to the German political party or their respective social media profiles . The similarities to the deviant results found within our data set are strong - but this does not necessarily proof that the search language settings are the only factor resulting in these deviant result lists . We follow the principle of `` Occam ’ s razor ” , which states that the simplest solution tends to be the right one . We therefore conclude that the deviant result lists originate in the personal settings of the respective data donor . The result is a combination of language filter , regionalization ( most likely depending on the IP location ) and the most relevant websites for the given search term . It is important to note that the cases shown here did not contain news about different political perspectives on the politicians or the political parties . According to Eli Pariser ’ s dreaded content-specific filter bubble , wherein some users receive a drastically different polit- ical perspective than others could not be found in our manually in- spected cases . English news came from The Guardian , French news from Le Figaro , the Russian websites were Wikipedia or Wikimedia pages . In a lot of cases the search results of a “ foreign ” user differed from specific aggregate topic pages , like http : //www-.faz.net/aktuell/ politik/thema/martin-schulz compared to the result lists of more regionalized `` German-speaking ” users . What did you see ? Personalization , regionalization and the question of the filter bubble in Google ’ s search efiginference ’ 17 , July 2017 , Washington , DC , USA IP im Ausland Zeitangabe auf| ? Englisch Zeitangabe auf Deutsch Eng IP in Deutschland Zeitangabe auf Deutsch Figure 33 : Search result lists on September 22 , 2017 at 4pm for the search term ” Angela Merkel ” . They are sorted into result lists from users with an IP address outside of Germany ( 6x Switzerland , 3x Austria , 2x Belgium , 2x USA , 2x France , 2x Great Britain , Denmark , Norway ) separated into columns . The last 6 columns contain users with an IP address based in Kaiserslautern . If top stories were present , the publication time ( `` vor 4 Stunden ’ 0 1 hour ago ” ) indicated which language was assigned to the user by Google . The deviant clusters were accompanied by English publication times , even with the user from Kaiserslautern . The result lists in the cluster themselves are very similar to each other . It still brings up the question what kind of information people belonging to one of the minorities of a country , like the first and second generation of migrants , should receive and from which source , so that these discussion forums overlap as far as possible . 8 SUMMARY We come to the conclusion that , since almost all of the search result lists show sufficient overlap - regardless of content - the algorith- mically based creation and reinforcement of isolated filter bubbles is not present . It is noteworthy that even though users who received foreign websites from Google ( probably due to different search lan- guage settings of these users ) showed some overlap in their results , their deviant clusters can be a sign of a filter bubble . Though this is unavoidable due to the difference in languages , this means that , based on the four mechanisms that have to be working together to create these dangerous filter bubbles , one must still inspect the contents . Manual inspection and a number of received top-level domains mostly display mainstream media , but there are also stray top-level domains and URLs that are harder to classify . This would require interdisciplinary analysis of the data and preferably further research . But what about the question whether the algorithm provides all of us with one-sided content ? Firstly the large amount of received top-level domains contradicts this , but that does not answer the question if there could have been other top-level domains that should have been displayed , or if some top-level domains appeared more or less frequently . What could be used to make such a com- parison ? One possible dimension would be to use the popularity of the top-level domains according to all internet users , as is contin- uously measured by the Nielsen-Online-Panel . The Nielsen-Panel is based on a representative user group , whose internet behavior is measured in great detail . For every top-level domain there is a score called the “ active reach ” based on the measurements of the panel that shows the percentage of users that visited that top-level domain at least once in a given time period ” ® . This leads to another chicken-and-egg problem , since Google is definitely the most prominent search engine in Germany and a great number of visits to a website are done via referral by Google . This means that there is an unknown proportion of visits that only occurred because of Google and hence the numbers do not repre- sent a popularity measure independent of Google ’ s search engine algorithm . Therefore , the following findings are more indicative of further research questions than the results of the # Datenspende project . Figure 34 shows the application of the active reach ” of a domain against the URLs of the top stories ( not the organic searches ) of this domain supplied by Google to the data donors in the same period . Since the differences per axis are very large ( from 0.01 to 100 % or from 1 to 1,000,000 URLs displayed ) , a double logarithmic application was chosen . The pattern of the data allows to create a linear regression by this application . The formula y = 1,373 * active reach ? essentially means that the number of URLs delivered correlates almost linearly with the range , with a small damper for longer ranges . This score is not very meaningful for extremely low scores , e.g . less than a hand full of people visited this website . This will be noted in the Nielsen Report . Conference ’ 17 , July 2017 , Washington , DC , USA Celleheute.de : meedia.de welt.de 0 % active reach epochtimes uebermedien deutsche-wirtschafts- ~ oe é swr gala.de nachrichten correctiv.org freenet.de ardmediathek.de . Moz.de medienmagazin.de Ln-online . ae und aktiencheck.de Figure 34 : The diagram shows the ” active reach ” ( percentage of users that visited the top-level domain at least once ) for the different top-level domains according to the August edi- tion of the Nielsen Report and the total number of search results from August 2017 of our data set . It is a double loga- rithmic application , where some sources with strong devia- tion from the trend line have been marked . In the Figure , some points are picked out which deviate from this pattern by a factor of approximately 5 upwards or downwards . This means that they are delivered at least 5 times more or 5 times less than expected according to the formula . On the one hand , this in- cludes media that report on media such as correctiv.org , meedia.de and uebermedien . Correctiv.org is a correction website that takes up and corrects incorrect messages . While this top-level domain in the Nielsen Panel has no reach in August , one of its URLs will be delivered to 245 people in the data donation project , almost five times more than expected . Nevertheless , this is less remarkable than first thought , as it concerns exactly one top story , which is delivered to all donors at this search time ( August 24 , 2017 , 12pm , search term “ Alexander Gauland ” ) . Since we have already found that the search result pages are very uniform overall , such a de- cision always affects everyone at the time of the search . This is a one-time event that suddenly raises the number of URLs delivered above the expected value . Articles by meedia and uebermedien are delivered 10 and 16 times more than expected . It is important to emphasize once again that the comparison with the Nielsen reach is methodologically difficult : neither does the ’ active reach ” represent a popularity measure independent of Google ’ s search engine , nor can popularity be regarded without restriction as a direct measure of the content quality of the contributions of the top-level domains . It may still be an interesting observation that the following 10 sources are the most overrepresented ( regarding the expected value from the regression ) : ( 1 ) Epochtimes ( with 240.004 links in all search result lists , expected were 840 ) ( 2 ) Chiemgau24.de ( 1.905 links , expected 22 ) ( 3 ) Jungewelt.de ( 1.595 links , expected 81 ) ( 4 ) Stimme.de ( 5.259 links , expected 274 ) ( 5 ) Ka-news.de ( 4.047 links , expected 218 ) ( 6 ) Tichyseinblick.de ( 4302 links , expected 235 ) ( 7 ) Welt.de ( 131.793 links , expected 8120 ) — Krafft , Gamer and Zweig ( 8 ) Ubermedien.de ( 2102 links , expected 131 ) ( 9 ) Cicero.de ( 2785 links , expected 174 ) ( 10 ) Butenunbinnen.de ( 2058 links , expected 131 ) As with all relative scores , the most outliers are sources that did not appear often in the search results . The media with the highest reach are however still represented within the top stories delivered by Google . The combination of the websites of persons and politi- cal parties , the Wikipedia entries and news websites , all found in the organic search results , shows a broad view of politicians and parties , which on the whole allows for comprehensive information and opinion-forming . It should also be mentioned that further com- bining the search terms used in this project would allow for a more detailed search , in the case of an unsatisfactory first search result list . 8.1 Generalization of the results : possibilities and boundaries The results shown in this report can not be applied to all Google users in Germany , since the data donors are not a representative sample ( caused by their own decision to participate ) . Interestingly , the donors who seem to have used a different search language could invalidate the argument that the set of users was so homogeneous that this alone explains the low degree of personalization observed . It appears improbable that all English-speaking users from different countries are homogeneous in personalization , yet Figure 33 shows remarkable similarities between their search result lists . Here too , we follow the principle of Occam ’ s razor and assume that the search result lists are mainly determined by search language settings , the location ( e.g . based on the IP address ) and the general relevance of the website , followed by previously visited websites to a lesser extent and possibly some personalized links . Therefore it would surprise us if further studies show highly deviant degrees of per- sonalization . In every case , our observations are only valid for the time period and search terms used in this project . We can not preclude the possibility of the degree of personalization changing over time , but this study shows how this can be monitored simply , cost-efficiently , flexibly ( regarding the search terms ) and automatically . This holds true for every search engine . 8.2 Demand for suitable interfaces to examine the filter bubble theory in social networks and other intermediaries This does not apply to social networks like Facebook , other social media like Twitter , Instagram or YouTube . At the moment it would only be possible with great effort to filter out and centrally collect all of a user ’ s political content in the news feed of a Facebook account , for example . ProPublica has tried such a project during the federal election of 2017 . An API that allows for selective access to these contents does not exist , so the only choice would be to require the users to allow complete access ( privacy concerns ) or to ask them to submit screenshots of political content . The latter is neither easy , nor can the data be analyzed automatically , since the content would have to be described manually to allow for searching and summarizing the data . Hence a demand for the necessary interfaces arises , to investigate all What did you see ? Personalization , regionalization and the question of the filter bubble in Google ’ s search efiginference ’ 17 , July 2017 , Washington , DC , USA social media and social networks , whose degree of personalization could lead to algorithmic creation or reinforcement of filter bubbles . A suitable control of the degree of personalization relieves the respective companies - as long as the degree remains low - of the demands of the society to gain further insight into their software code . If a high degree of personalization ( of relevant content ) and a certain degree of isolation of the filter bubbles becomes evident , further investigations are required to determine to what extent the content has extremely different perspectives and makes social discourse more difficult . Such a staggered model of the depth of insight through black box analysis depending on the measured degree of personalization would thus help both sides . 9 ACKNOWLEDGMENT We would like to take this opportunity to thank Landesmedien- anstalten Bayern ( BLM ) , Berlin-Brandenburg ( mabb ) , Hessen ( LPR Hessen ) , Rheinland-Pfalz ( LMK ) , Saarland ( LMS ) and Sachsen ( SLM ) who supported the project , as well as Spiegel Online as our media partner . We would also like to express our gratitude towards Uwe Conradt , director of the LMS , who suggested this project to us . We also thank Dr. Anja Zimmer , director of the mabb , and Siegfried Schneider , president of the BLM , who - together with Uwe Conradt - were particularly committed to the project . Our special thanks go to Adrian Gerlitsch ( BLM ) who supervised the project and has always and tirelessly found constructive solutions to all problems . 10 APPENDIX A ) Category System The category system is used to assign domains that were displayed as part of the data donation . It was developed by the Bayerische Landeszentrale fiir neue Medien ( BLM ) who also carried it out . 10.1 Main categories Every domain is assigned to one of the main categories . In cases of conflict the most concise assignment is chosen . a Owned Content : The category Owned Content contains all channels that allow the parties an unfiltered display of opinion , either through a personal website of a member of the party , a local branch , or the party itself . Social media channels also belong to this category , but will be assigned to their own category in this categorization scheme . b Social Media : Social Media describes all channels that focus on the social interactions between provider and users . The domains allow for networking , ie . to exchange ideas with each other and to create and relay media content for individuals , specific groups , or the public . Examples for networks that belong to this category are Facebook , Twitter or Instagram . c Wikipedia : All Wikipedia domains are assigned to this category . d Media : Domains that are operated by a media provider are assigned to this category . A website is considered a media provider if it provides journalistic content and acts as the online offshoot of classic print media , a private television or radio provider , or a public-service broadcaster . Foreign journalistic content as well as online-only providers also belong to this category ( see sub-categories ) . Examples are : www.schwarzwaelder-bote.de , news.sky.com , www.news.de . Freemail portals : Freemail portals offer free email ad- dresses and a mailbox to send and receive emails . Most of these websites also contain news columns . The most common Freemail portals belonging to this category are web.de , yahoo.com and gmx.net . Freemail domains that appear in the results of Google News will not be assigned to any sub-categories , only the main category . Publicly funded : The category ’ publicly funded ” con- tains all domains financed by public funds , e.g . the Federal Agency for Civic Education ( Bundeszentrale fir politis- che Bildung ( bpb ) ) and the online presence of cities and municipalities . g Other : Every domain that does not explicitly belong to any of the before-mentioned categories will the assigned to the this category . oO — 10.2 Sub-categories Sub-categories contain domains that were previously assigned to the * Media ” category . The other main categories are not specialized any further . Every domain can only be assigned to one sub-category . a Print : The category contains all online offerings from clas- sic German print media ( newspapers and magazines ) . Do- mains are included if they originate in Germany and pub- lish German content . Example include : spiegel.de , faz.net , welt.de . b TV : All online offerings of approved German private tele- vision providers are assigned to this category . Both origin and published language of the content is German . Example include : rtl.de , pro-sieben.de Public service providers ( ORR ) : This category contains all online offerings of German public-service broadcasters , like their online branches for radio and television channels . This category can contain daserste.de , ndr.de , zdf.de . d Online Only : Media offerings who publish their content exclusively on the internet are assigned to this category . Examples include : 02elf : net , www.promiflash.de . ° 1612.06551v1 [ cs.SI ] 20 Dec 2016 arXiv The Impact of the Filter Bubble—A Simulation Based Framework for Measuring Personalisation Macro Effects in Online Communities Thomas Gottron Institute for Web Science and Technologies , University of Koblenz-Landau , Germany gottron @ uni-koblenz.de ABSTRACT The term filter bubble has been coined to describe the situation of online users which—due to filtering algorithms—live in a person- alised information universe biased towards their own interests . In this paper we use an agent-based simulation framework to measure the actual risk and impact of filter bubble effects occurring in online communities due to content or author based personalisation algo- rithms . Observing the strength of filter bubble effects allows for opposing the benefits to the risks of personalisation . In our simu- lation we observed , that filter bubble effects occur as soon as users indicate preferences towards certain topics . We also saw , that well connected users are affected much stronger than average or poorly connected users . Finally , our experimental setting indicated that the employed personalisation algorithm based on content features seems to bear a lower risk of filter bubble effects than one perform- ing personalisation based on authors . 1 . INTRODUCTION Eli Pariser coined the term filter bubble in [ 8 ] . The filter bubble represents the personal , unique universe of online information a user lives in . The boundaries of this universe , what gets in and what remains outside the reach of the user , says Pariser , depends on the personalisation algorithms in social networks and search en- gines . The personalisation algorithms consider a user ’ s interaction with information to predict which information she most likely con- siders relevant . As a consequence the algorithms will show such information at higher ranks in a result list more likely or , in the most extreme case , even exclusively , ic . blocking other informa- tion from the sight of the user . Thus , the personalisation algorithms effectively operate as filters on the information the users perceive . The genuine aim of the personalisation algorithms is to get an idea of the topics the users are actually interested in and to improve their user experience by preferably showing them contents that match their interests . On the downside , this leads to a situation , where the user might be confronted with information that is so highly per- sonalised , that she will not see any content that does not match her interests or represents opinions and facts apart from her own point Felix Schwagereit Institute for Web Science and Technologies , University of Koblenz-Landau , Germany schwagereit @ uni-koblenz.de of view . For an individual user this might lead to a skewed and biased perception of the world . The risks and problems of the filter bubble effect have been dis- cussed widely and in different contexts . Several approaches aim at ensuring diversified results in search scenarios or for particular information needs [ 5 ] . The actual risk of observing filter bubble effects as well as their strength , instead , has hardly been analysed . In this paper we use an agent-based simulation to measure the im- pact of personalisation algorithms on the perception of users in so- cial networks . Here , we are not interested in the effects on the level of individual users , but rather on the macro level of an entire com- munity . To this end , we combine an established generative network model [ 1 ] and a state of the art topic modelling approach [ 3 ] to sim- ulate a social network structure and the messages the users create and consume in this network . The resulting model consists of a set of agents , each of which with her individual range of topics she is interested in . The agents have their individual network context of friends . They send messages to and receive messages from these friends . By involving algorithms for personalisation the simula- tion allows to observe the development of appropriate macro-level metrics which measure the benefit and risk of personalised filters . The metrics to measure the benefits include classical information retrieval metrics , such as precision and recall . The negative impact is measured by analysing the reduction of the active social context to only a few friends or a reduced used of vocabulary . Finally , the number of perceived messages that fall into the core field of in- terest of the users can be read in both ways : positive as the users are not bothered with off-topic messages and negative because their perception of other topics of peripheral interest is reduced or even filtered out entirely . We considered two possible algorithms for personalisation : one based on the content of messages and one based on the author of messages . In our simulation we observed , that both personalisa- tion approaches lead to filter bubble effects w.rt . the focus of the perceived messages being shifted towards the core interests of the users . However , we also observed that the personalisation algo- rithm based on content lead to the same benefits , but with a lower impact on the downsides , e.g . the active social network does not become as thin , neither the used vocabulary as sparse . The contributions we make in this paper are the following : e We describe a model for simulating the generation , dissem- ination and rating of messages based on established genera- tive models for social network construction and topic models . We investigate the strength of filter bubble effects on a macro level when introducing personalisation filters in the content dissemination of a social network . e We analyse which user groups of an online community are affected most by filter bubble effects . e We compare two prototypical filtering methods under the as- pect of risks and benefits of filter bubble effects . We proceed as follows . In Section 2 we will review related work in the field of community simulation as well as the analysis of effects of personalisation and diversification in information provision . Af- terwards we present the general framework of our simulation . Its implementation and the choice of model parameters is presented in 4 . In Section 5 we describe the two personalisation algorithms we have analysed and in Section 6 the metrics we use to measure filter bubble effects . The actual experiments in the form of simula- tion runs are discussed in Section 7 . We present our results in 8 and discuss them in detail in 9 . We end in Section 10 with a summary of our findings and a look at future work . 2 . RELATED WORK The importance and the effects of information propagation and per- ception in social networks and information portals has been anal- ysed in various contexts . Serendipity discovery of non-relevant items in digital libraries [ 12 ] shows a general benefit of being in- spiring for seeking information and thinking out of the box . The impact on political processes and democracy was discussed in [ 2 ] . A psychological study addressed the effects of information presen- tation and forgetting processes in social networks [ 4 ] . Simulation and probabilistic models as tools for the analysis of on- line communities has been established in recent years . Schwagereit et al . use simulations to support policy modelling and strategic decisions [ 11 ] . The dynamics of popularity among news stories was investigated and described by Hogg and Lerman [ 6 , 7 ] . Self- enforcing content generation mechanisms and their representation as stochastic processes were investigated in [ 14 ] . In our simulation , we use the preferential attachment model of Barabasi and Alberts [ 1 ] to construct a social network . Preferen- tial attachment is a probabilistic model to generate graph struc- tures which exhibit typical features of social networks . We use topic models to represent the interests of agents . Latent-Dirichlet- Allocation ( LDA ) [ 3 ] can be considered a state of the art topic modelling approach . LDA is a generative , probabilistic model to describe the topic composition of text documents . To this end each document is represented as distribution over k global topics . This distribution is independent from the distribution of other documents but follows the same parameters . The topics themselves are mod- elled as distributions over terms . Various extensions have shown , that LDA is also suitable to model sentiments and opinions as well as authors . To the best of our knowledge there is no systematic large scale anal- ysis of filter bubble effects , neither based on real world data nor based on simulations . Figure 1 : High level iterative process of the agent-based simu- lation . 3 . THE SIMULATION MODEL For our analysis we make use of an agent-based simulation . The initial step prior to starting the actual simulation consists of the setup of the network with a fixed number of agents , each of which has a profile of her individual interests . The network structure re- flects the friendship relations between agents and will provide the basis for how messages are disseminated among the agents . We do not consider changes in the network structure during the simula- tion of the communities interaction . An agent ’ s profile of interest will serve to describe the messages she will write as well as for the decision whether or not a message lies within her core field of interests . The idea of the simulation is focussing on an iterative creation , dis- semination , filtering and rating of messages published in a social network plus a step of learning for updating the filters based on the user feedback . The overall process is depicted in Figure 1 and we illustrate the high level steps before going into the technical details of the implementation in the next section . Creation Each agent creates messages . The number of messages an agent creates depends on how verbose she is . The content of the messages themselves depends on an agent ’ s interests . Dissemination The messages are disseminated along the edges of the social network . This means that for each agent the set of incoming messages is determined by the messages created by her friends . Filtering The personalisation algorithms operate on this set of in- coming messages . The messages are ranked according to the predicted relevance and the result list is cut off at a given threshold . Each agent has an individual instance of the per- sonalisation algorithm which is specifically trained on the ba- sis of her behaviour . Rating The agents are presented with the messages the personali- sation algorithms deemed interesting for them . At this point the agents interact with the messages of other agents , i.e . they rate them as relevant or as irrelevant . This decision also depends on whether or not the message is in the core field of interest of a agent . Learning The personalisation algorithms receive the information which of the messages were rated as relevant . This feedback of the agents is used by the personalisation algorithms to up- date their individual relevance model for the agents . Iterating this cycle many times allows the personalisation algo- rithms to learn from the agent ’ s feedback . In this way they can adapt to the agent ’ s interests . At some point in time we would ex- pect to see filter bubble effects , such as a high ratio of messages in the core field of interest , the active social network of the agents being reduced to a few contacts or a reduction of the perceived vo- cabulary . 4 . IMPLEMENTATION The general process of the simulation is given as pseudo code in Algorithm 1 . The phase of the initial setup and the iteration phase with the steps of content generation , dissemination , filtering , rating and the learning phase are outlined . The next sections illustrate the relevant parts of this process , i.e . the concrete implementation of the methods in this algorithms . \\Algorithm 1 : Simulation put : Number of agents VV , personalisation algorithm F ’ , Number J of iterations // Agent Setup forn=1 ... Ndo // Create an agent and her instance of the personalisation algorithm a ¢ INITIALISEAGENT ( ) ; PF , © F.AINSTANCE ( ) ; At AU { a } ; // Network Setup etwork < — CONSTRUCTNETWORK ( ) ; fori=1 ... I do // Content creation foreach a € A do L Olt , < — @ .GENERATEMESSAGES ( ) ; // Dissemination foreach a € A do foreach b € Network.FRIENDSOF ( a ) do L. ita © ita Uouty ; // Filtering foreach a € Ado | filtered , — F , .FILTER ( ina ) ; // Rating foreach a € A do foreach c € filtered , do | if a.ISRELEVANT ( c ) then | relevant , < filtered , U { c } ; // Learning foreach a ¢ Ado | . Fa-LEARNINTERESTS ( filtered , , relevant , ) ; 4.1 Initialising an Agent and her Interests When initialising an agent with the method INITIALISEAGENT , the interests of the agents are modelled in a probabilistic manner by randomly assigning a distribution over topics . The more probable topics in this distribution represent the core field of interest of the agent . This distribution will be used in both the generative process when an agent writes messages as well as in the perception phase when an agent decides whether or not a message lies within her core field of interests . To implement the topic models of the agents we employ Latent Dirichlet Allocation ( LDA ) [ 3 ] . To this end , each agent is assigned a random distribution over k global topics which is drawn from a Dirichlet distribution with prior a . The entries in the prior vector a influence how the distribution over the topics looks like . High entries in a generate distributions in which more topics are cov- ered equally likely . Low values in a generate topic distributions in which only few topics have a high probability of occurring . The global topics themselves are randomly initialised as well . They also follow a Dirichlet distribution . Here the prior 2 influences how the distributions of terms within each topic look like . Thus , the topic distribution of an agent is independent from the distribution of the other agents but follows the same parameters . The same is true for the topic distributions . As we are not interested in the actual contents , we use an artificial vocabulary and artificial topics , which have the same probabilistic characteristics as real world topics . We chose the values of a and ( from literature to model focussed top- ics and a not too wide coverage of too many topics by an individual agent . The concrete settings for the Dirichlet priors , as well as the number of agents and vocabulary terms we used in our simulation runs are summarised in Table 1 . Additionally we model the verbosity of each agent individually . To this end , we provide each agent @ with the number A , of messages we expect her to produce on average . The value of Aq is chosen randomly when setting up the agent and follows a x distribution with mean e. To have realistic values for how many messages we can expect the user to write we estimated the value of e from statis- tics on how many tweets people write per day ' . 4.2 Social Network Setup We construct the social network of the agents randomly in CON- STRUCTNETWORK using the preferential attachment model [ 1 ] . In this generative model a social network graph is constructed starting from a nucleus of very few completely connected nodes . Iteratively the graph is extended with new nodes , each of which establishing the same amount of edges to existing nodes . The probability of con- necting to an existing edge is proportional to the number of edges it already has . In our settings , we started with a nucleus of ten nodes and had each newly created node connect to five other nodes . 4.3 Content Creation The first step in the method GENERATEMESSAGES is that the agent randomly decides how many messages she is going to write in this iteration . The number of generated messages follows a Laplace distribution with parameter \\ , , which has been assigned to each agent a during initialization . Once it is decided how many messages will be generated , the agents write each individual message c based on their profile of interests . For the sake of simplicity , in our simulation each message has an equal length of 10 words . To determine the actual words we used the generative process behind the LDA model . This means that for each word of the messages , the model randomly chooses first a topic ( according to the agent ’ s topic distribution ) and in a second ‘ http : //edudemic.com/2012/12/ 14-twitter-statistics-you-may-not-—know/ step randomly selects a word from this topic ( according to the term distribution of the corresponding topic ) . 44 Rating The agents need to be able to interact with the messages in the so- cial network in order to give feedback on what is relevant to them . To this end , in the method ISRELEVANT each message the agent perceives is first classified into either falling into her field of core interests or into the category of peripheral interest . The core inter- est of an agent is defined by the set of LDA topics which covers a high fraction of her individual topic distribution . The other topics describe her peripheral interests . The decision if a message is in the field of core interests is based on the odds of the agent to have con- structed such a message solely from her core interests topics versus solely from her peripheral interests . If these odds are higher than a given threshold @ , a message is considered to be of core interest to an agent , otherwise it belongs to her peripheral interests . For our simulation we set the value cov of core topic coverage to 80 % and the odds threshold @ to 2 . In preliminary experiments we found that with these settings an agent assigns more than 90 % of her own messages and about 5-20 % of the messages of any random other agent to be in her core interest . However , as long as the decision on what is part of the core interest is consistent the overall model will behave very similar . The actual act of rating a message as relevant then depends on two probabilities Deore and Pperipherai- Not all messages of core interest will be considered relevant . Neither will all messages of peripheral interest be considered irrelevant . As we have no empirical data on which to base these probabilities will we keep them variable and explore the behaviour of the entire simulated community depending on these two probabilities . 5 . PERSONALISATION ALGORITHMS The personalisation algorithms need to implement the two methods FILTER and LEARNINTERESTS to work in the context of our sim- ulation framework . This essentially complies with the operation modes of these algorithm . On the one hand , the algorithm needs to rank a set of messages in decreasing order of predicted interest for a user . It operates as a filter if the resulting ranking is cut off at a cer- tain position b and all entries below that position are discarded and hidden from the user . On the other hand it needs to interpret the in- teractions of the users with the messages which indicate relevance in order to derive the user ’ s interests . We implemented two prototypical , orthogonal personalisation al- gorithms . One algorithm is based on the content and one on the authors of a message . Both are based on established methods to predict if a given message with a specific content or from a specific author will be rated as relevant by a user . 5.1 Content Based Personalisation A message is characterised by its individual words . This assump- tion underlies many information retrieval models . The terms are signals that either contribute or oppose the probability of the mes- sage to be relevant . The information provided by the user via her interaction with the contents can help to understand which kind of signal is emitted by which term . This assumption underlies the concept of relevance feedback in search systems . We implemented our content based personalisation algorithm fol- lowing the principles of relevance feedback in the binary indepen- dence model of probabilistic retrieval [ 9 ] . This means , that for each document the user has seen , we keep track of whether or not she has rated it to be relevant . This relevance is directly mapped onto the single terms . And for each term ¢ ; we can estimate the probability of being relevant ( using a random variable R ) by : er ( t ) + Cy PURI ) = ST en + OCy ( 1 ) In this case cry ( t ; ) is the number of times a user has rated a mes- sage containing term t ; € V as relevant . Likewise , cny ( t ; ) counts how often a message with this term has not been rated as relevant . The constant C ' y is a smoothing parameter to overcome zero prob- abilities for unseen events . Using these estimates allows to formulate a probability of relevance for a new incoming message . To this end the message c is broken up into its individual terms . The probability of relevance is given by the product of the probabilities of relevance over the single terms : p ( R\\e ) = T ] PCR|ts ) Q ) t , €e This probability can be computed for each incoming message . The messages are then sorted in decreasing order of probability follow- ing the probability ranking principle [ 10 ] . 5.2 Author Based Personalisation Instead of focussing in the contents , an alternative paradigm is to consider the authors of a message as indicative signal for relevance . This is mainly motivated by the strong social component of online communities : it makes sense to consider that it is rather the news of specific people than specific contents the users want to see . Again we can model this in a probabilistic way . Depending on how many times messages of one specific author a have been seen and rated as relevant allows for estimating the probability of messages of this author to be relevant . Given that the author is the only signal con- sidered we can then rank all incoming messages according to the probabilities : cra ( a ) + C4 p ( Rla ) = cra ( a ) +ena ( a ) + 2Ca G3 ) Here , cr4 ( a @ ) counts the number of times a user has rated a mes- sage of author a € A as relevant , while cn 4 ( a ) counts how often the messages with this author were not relevant . Again we use a smoothing constant C ' 4 . 6 . MEASURING FILTER BUBBLE EFFECTS To measure the impact of personalisation we have to consider two kinds of effects . On the one hand we have to measure the bene- fits of the personalisation on incoming content items , on the other hand we have to measure the filter bubble effect . The improvement in the ranking of incoming items can be measured relatively easy by considering classical information retrieval metrics . Precision measures the ratio of relevant items among the retrieved , ic . here among the seen messages . IR systems and also their personalisa- tion components strive to improve precision . Thus , an increase in Table 1 : Parameters and their values in our simulation . |\\V| Size of vocabulary , i.e . number of words 10,000 a4 Parameter vector entries in Dirichlet prior for the topic distributions of the agents 0.01 Bi Parameter vector entries in Dirichlet prior for the term distributions of the topics 0.001 N Network size , i.e . number of users 10,000 m Minimum number of friends per user 5 k Number of topics 100 t Message length 10 € Prior for the expected value of the number of messages a user creates 2.42 Peore Probability to rate a message of core interest as relevant variable Pperipherat Probability to rate a message of peripheral interest as relevant variable cov Core topic coverage 0.8 g Threshold odds for core topic 2.0 b Cut off rank position in the filters 20 precision at the individual level of single agents due to the use of a personalisation filter is sign for the benefits of the personalisation algorithms . To observe this behaviour on the macro-level we use average precision over all agents . To answer our questions of the strength of the filter bubble we need different metrics . To the best of our knowledge , metrics for filter bubble effects have not been developed so far . However , there are clear signals for users being in a filter bubble : ( 1 ) a reduction of the active social context , ( 2 ) a reduction of the vocabulary a user perceives and ( 3 ) users perceives messages mainly or only from the fields of her core interests . To measure the active social context it is sufficient to count the number of distinct friends from which an agent perceives mes- sages . If we denote the set of authors for a set of messages by A ( filtered , ) = { b € Network : dc € filtered , : c.AUTHOR = } } , then we can define the active social context of any given agent a by : _ |A ( filtered , ) | ASC ( a ) = |Network.FRIENDS ( a ) | @ ) This value measures the active social context for one agent only . To observe macro effects , we aggregate and average the values over all agents in the simulation : ASC = a - $ 5 ASC ( a ) ( 5 ) acA However , even a low value of this metric does not necessarily indi- cate a poorer social context . After all it is possible , that the context is small at each time step , but constantly changing with every itera- tion . Figuratively speaking , a user might received messages always just from a small circle of her friends , but this circle is composed of different friends in each iteration . Thus , we need to take the change rate of the social context over a longer time into consideration . This can be achieved by extend- ing ASC to operate on the authors seen over a longer time period ( e.g . the last 10 iterations ) . We will refer to this values as ASC ) . Comparing ASC ’ to ASC ) , we can estimate the change rate . The reduction of active vocabulary can be measured in an equiva- lent way . We defined the according functions as AV and AV ) . The ratio CR of core messages in the perceived messages finally can be computed similar to average precision . If we define cores as the set of all messages in filtered , which are in the core interest of an agent , then we get : CR |corea | = |filtered , ,| 6 ) As we interested in which parts of the online community are af- fected stronger by filter bubble effects we stratified the agents de- pending on their node degree . We divided the agents in five strata . The first stratum consisted of the agents with the highest node de- gree which covered 20 % of all network edges . The next stratum contained all agents providing the next 20 % of the edges and so on . 7 . SIMULATION EXPERIMENTS As stated above we could estimate most parameters in our model from public statistics of online communities or by using values which have been reported in related work . One parameter we could not estimate are the probabilities Prore and Pperipherat With which the users rate messages of their core or peripheral interest as relevant . Thus , we kept these parameters variable and observed how this user behaviour influences the filter bubble effect . This lead to a setup where we ran for each personalisation algo- rithm independent simulations over 441 parameter settings to cover the parameter space of the probabilities peore aNd Pperipherai- We it- erated over these probabilities from 0 to 1 in steps of 0.05 . Each simulation run was initiated with a new random network and ran- dom assignment of topic distributions to the users . Then we ran the simulation for 100 iterations—a value which in preliminary exper- iments had shown that at this point the values become stable . 8 . RESULTS Given that we iterate in small steps over a 2-dimensional parameter space we will present the result as three dimensional surface plots . This allows to get a very good visual impression of the impact of the user behaviour ( i.e . how likely they rate messages of core and peripheral interest as relevant ) on the filter bubble effect . GR Global Average ( a ) Global Average GR Stratum 1 ( b ) Top Stratum Figure 2 : C ’ R values for content based personalisation . GR Global Average ( a ) Global Average GR Stratum 1 ( b ) Top Stratum Figure 3 : C ’ R values for author based personalisation . The first question we want to address is the impact on the ratio of messages of core interest the agents receive . Figure 2 shows the value of the C ' R metric over the range of different settings for peore and Pperipheral When operating with a content based personalisation . The left Figure 2 ( a ) shows the average C ’ R for the entire online community . We can see very clearly the diagonal ridge where the two probabilities are about the same value . Above and below this ridge the CR values form a plateau . This means that the ratio of messages in the core interest field of an agent is higher if the prob- ability for rating messages as relevant is higher in the class of core interest than in the category of peripheral messages . This behaviour is somewhat expected as the personalisation filters learn what are the core interests of the users . The plateau , however , indicates that the ratio of core interest messages does not grow arbitrarily high . On the entire community , the values of C ' R reach an average of at most 73 % if the users rate more core interest messages as rel- evant and at least 13 % if the users mainly rate peripheral interest messages as relevant . The right plot in Figure 2 ( b ) shows the val- ues for the top stratum of highly connected agents in the social network . While the general behaviour is the same , the effects are much stronger . The values in the lower plateau are set around 4 % and the high plateau values about 87 % . This means that especially the well connected users are affected strongest by the filtering ef- fects . They hardly get to see messages from outside their core field of interest . Figure 3 shows the same plots for the personalisation algorithm based on message authors . Again the general behaviour is very similar . The effect , however , is slightly less strong . The C ’ R values in the top stratum reaches only 80 % . Let us look at the impact on the social network next . In Figure 4 we compare the active social network ( ASC ; , ) of the top stratum for content based ( Figure 4 ( a ) ) and author based personalisation ( Figure 4 ( b ) ) . Now we can see a clear difference between the two methods . While the author based personalisation immediately re- stricts the number of people from which messages are received as soon as the agents give any feedback , the content based personali- sation is not that extreme . The ASC ) , values are higher in general and the decline is much slower , when users give feedback . Further- more , as long as they do not excessively rate messages as relevant ( with a probability of more than 60 % ) the active social context re- mains relatively broad . This is also reflected in the change rate of the perceived authors . ASG , Stratum 1 ASG , Stratum 1 ( a ) Content base personalisation ( b ) Author base personalisation Figure 4 : Active social network ASC ’ , for the top stratum . A similar behaviour can be observed on the side of the vocabulary in Figure 5 . This is intriguing , as content based personalisation in the end relies on single terms . However , filtering messages based on the preferred terms restricts the overall perceived terms less than when filtering messages based on their author . The positive aspects of the personalisation can be seen when look- ing at average precision in Figure 6 . We can see that precision improves with the probability of the users giving feedback on what they consider relevant . This is valid for both , the content and the au- thor based personalisation . However , the shape of these plots par- tially depends directly also on the probabilities Deore and Pperipheral- If those probabilities are close to zero , the agents rate no or hardly any message as relevant . Accordingly precision is low by defini- tion . However , if they tend to consider messages relevant at a high probability they will rate nearly everything as relevant and , thus , precision will automatically be very high . The most interesting as- pect of the plot are the regions where Peore and Pperipherat have very different values . In these cases the algorithms really need to bring the right category of messages ( core interest or peripheral interest ) to the agent ’ s attention such that they have the right basis of mes- sages to rate with a higher probability as relevant . Given the high values in these regions and the observations made for the CR val- ues , this is achieved by both approaches 9 . DISCUSSION Our simulation model allowed us to make some quite interesting observations on the macro level of online communities : 1 . Filter bubble effects occur when using personalisation algo- rithms . We observed for both types of personalisation the effect , that users have a biased perception based on their own interests . This happens as soon as they indicate a prefer- ence of their core interest by rating messages in this field as relevant with a different probability than all other messages . However , this after all is the aim of the personalisation al- gorithms . So this can be considered the central trade off be- tween using personalisation for improving the user experi- Note the changed scale for the values . Given the size of the vo- cabulary , the few messages an agent receives after filtering can only cover a small fraction of the vocabulary anyway . ence and not using personalisation for the sake of unbiased message perception . Furthermore , on average the filter bubble effect is not that strong that a user can not get out of the filter bubble any more . Users still receive messages from outside their core field of interest which technically allows them re-adjust the person- alisation algorithms to potentially new interests . 2 . Better connected users tend to be more prone to filter bubble effects than the average user . This can be easily explained with these users receiving far more messages . Accordingly they are also likely to receive more relevant messages falling into field of their core interest and from which the personali- sation algorithms can chose . The algorithms are simply less under pressure to also suggest less relevant messages . However , this bears a certain risk as well : the well connected users represent hubs and are typically considered influential users . If their perception of the world is biased , this bias may affect also their social context and be propagated through the online community . 3 . Author based personalisation causes a stronger filter bubble effect than content based personalisation under the aspects of active social context and active vocabulary . Our experiments showed a much stronger restriction of the active social net- work and perceived vocabulary when using the author based filtering algorithm . This is partially interesting as it might influence the potential to actually get out of the filter bubble . Given that both approaches behave similar under the aspect of fo- cusing on the users interests and achieving comparable precision values , the content based personalisation approach seems to have a lower impact on the filtering of the social network and vocabulary . Thus , one conclusion might be that content based personalisation seems the better option as it causes a less strong filter bubble effect . However , this observation needs to be checked and confirmed with other personalisation algorithms . 10 . SUMMARY AND FUTURE WORK In this paper we proposed a model to measure the macro effects of personalisation in online communities with respect to filter bub- ble effects . We combined established topic and network models to AV , Stratum 1 O14 012 O41 0.08 0.08 0.08 0.02 oREREIRE ( a ) Content base personalisation AY , Stratum 1 O14 012 O41 0.08 0.08 0.08 0.02 oREREINE ( b ) Author base personalisation Figure 5 : Active vocabulary AV ) , for the top stratum . Precision Stratum 1 Precision Stratum 1 ( a ) Content base personalisation ( b ) Author base personalisation Figure 6 : Average precision for the top stratum . build an agent-based simulation of an online community and in- vestigated the impact of different personalisation algorithms on the diversity of topics , people and vocabulary the users perceive . We observed that filter bubble effects occur as soon as the users give some indications about the topics they are interested in . However beyond the filtering of topics we also observed that in our setting author based personalisation lead to stronger restrictions and thus stronger filtering effect on the social network and vocabulary . In future work we will investigate other personalisation algorithms and consider flexible network structures . Also networks formed on the basis of common interests of the agents will be considered . One suitable candidate might be the social-circles model [ 13 ] . 11 . REFERENCES [ 1 ] Albert-L4szl6 Barabasi and Réka Albert . Emergence of scaling in random networks . Science , 286:509-512 , 1999 . [ 2 ] Solon Barocas . The price of precision : voter microtargeting and its potential harms to the democratic process . In Proceedings of the first edition workshop on Politics , elections and data , PLEAD °12 , pages 31-36 , New York , NY , USA , 2012 . ACM . [ 3 ] David M. Blei , Andrew Y. Ng , and Michael I. Jordan . Latent dirichlet allocation . Journal of Machine Learning Research , 3:993-1022 , 2003 . [ 4 ] A. Coman and W. Hirst . Cognition through a social network : The propagation of induced forgetting and practice effects . Journal of Experimental Psychology : General , 141 ( 2 ) :321 , 2012 . [ 5 ] M. Drosou and E. Pitoura . Search result diversification . ACM SIGMOD Record , 39 ( 1 ) :41-47 , 2010 . [ 6 ] Tad Hogg and Kristina Lerman . Social dynamics of digg . In Proceedings of the Fourth International Conference on Weblogs and Social Media , ICWSM 2010 , Washington , DC , USA , May 23-26 , 2010 . The AAAT Press , 2010 . [ 7 ] Kristina Lerman and Tad Hogg . Using stochastic models to describe and predict social dynamics of web users . ACM TIST , 3 ( 4 ) :62 , 2012 . [ 8 ] E. Pariser . The filter bubble : What the Internet is hiding from you . Penguin Press HC , 2011 . [ 9 ] S.E . Robertson and K. Spirck Jones . Relevance weighting of search terms . Journal of the American Society for information Science , 27 ( 3 ) :129-146 , 1976 . [ 10 ] [ 11 ] [ 12 ] Stephen Robertson . The Probability Ranking Principle in IR . The Journal of documentation , 33 ( 4 ) :294-304 , 1977 . Felix Schwagereit , Sergej Sizov , and Steffen Staab . Finding optimal policies for online communities with cosimo . In Proceedings of the WebScil0 : Extending the Frontiers of Society On-Line , April 26-27th , 2010 , Raleigh , NC : US , 2010 . Elaine G. Toms and Lori McCay-Peet . Chance encounters in the digital library . In Proceedings of the 13th European conference on Research and advanced technology for digital [ 13 ] [ 14 ] libraries , ECDL ’ 09 , pages 192-202 , Berlin , Heidelberg , 2009 . Springer-Verlag . Douglas R. White , NataS8a Kejzar , Constantino Tsallis , Doyne Farmer , and Scott White . Generative model for feedback networks . Phys . Rev . E , 73 ( 1 ) :016119 , Jan 2006 . Dennis M. Wilkinson . Strong regularities in online peer production . In Proceedings of the 9th ACM conference on Electronic commerce , EC °08 , pages 302-309 , New York , NY , USA , 2008 . ACM . Journal of Science Policy & Governance Policy Analysis : Public Discourse in Age of Personalization Public Discourse in the Age of Personalization : Psychological Explanations and Political Implications of Search Engine Bias and the Filter Bubble Audrey B. Carson Corresponding author : audreycarson @ college.harvard.edu EXECUTIVE SUMMARY : This policy proposal recommends that Google engineer and implement a new web application , to be embedded directly into the company ’ s trademark search engine , that will allow users to manually toggle between results returned through Google ’ s new personalization algorithms and results returned through Google ’ s original PageRank algorithms . The intent of this policy is to provide users with an interactive visualization of Google ’ s various content filters that will increase their awareness , understanding , and control of these same filters and thus impact how users appreciate and act upon the information delivered to them by Google ’ s search engine. ! This policy proposal is motivated by recent research on the effects of online personalization algorithms , especially their tendency to trap users in “ filter bubbles ” - information streams uniquely tailored to the interests and biases of individual users - without their knowledge or consent . Drawing upon relevant literature in rational choice theory and social psychology , this policy proposal examines how filter bubbles threaten meaningful public discourse and effective democratic governance , and presents the aforementioned policy as a solution . Concerns regarding the policy ’ s feasibility and functionality are also addressed . This policy proposal is targeted for Google ’ s Public Policy and Governmental Affairs team . This team ’ s primary responsibility is to convene with government and elected officials to clarify Google products and promote the growth of the web . The team also works to ensure that Google ’ s Code of Conduct - guided by the mantra , don ’ t be evil - is upheld . The Public Policy and Governmental Affairs team identifies “ ... following the law , acting honorably , and treating each other with respect ” as important ways in which Google prioritizes “ doing the right thing. ” 3 1 Sayooran Nagulendra and Julita Vassileva , `` Understanding and Controlling the Filter Bubble through Interactive Visualization : A User Study , ” Hypertext and Social Media : Proceedings of the 25th ACM Conference ( Santiago , Chile : The Association for Computing Machinery Digital Library , 2014 ) . 2 Eli Pariser , The Filter Bubble : What the Internet Is Hiding from You ( New York : Penguin , 2011 ) , 9 . 3 `` Transparency , '' Google U.S. Public Policy , http : //www.google.com/publicpolicy/transparency.html . www : sciencepolicyjournal.org JSPG. , Vol . 7 , Issue 1 , August 2015 Journal of Science Policy & Governance Policy Analysis : Public Discourse in Age of Personalization I . PUBLIC DISCOURSE AND ONLINE MEDIA The roots of democratic theory on the necessity of a free press and public discourse can be traced back to Thomas Jefferson , who believed that an educated citizenry was requisite for the proper functioning of a free and enlightened nation . Because a free press is “ the best instrument for enlightening the mind of man and improving him as a rational , moral , and social being , ” Jefferson explained , the freedom and quality of the press are important indicators of the health of the nation as a whole . * Jefferson ’ s argument continues to influence how political scientists understand the democratic function of the news media in modern America . While the most basic purpose of the media is to inform the public , it is also responsible for establishing the “ foundation of shared experience and shared knowledge upon which democracy is built. ” 5 The news puts people on the same page - literally and figuratively - by providing a shared vocabulary and set of facts with which to debate and reach a consensus on how to work together to solve common problems . By writing , reading , and discussing the news , citizens engage in a dialogue that allows them to “ democratically create their culture and to calibrate their ideas in the world. ” ¢ Indeed , as reporter Walter Lippmann intoned , it might even be that “ all that the sharpest critics of democracy have alleged is true , if there is no steady supply of trustworthy and relevant news. ” 7 Given the indispensability and responsibility of a free press to democracy , the media is a fundamentally political and ethical enterprise . In recent decades , distributive and curatorial power over the news has shifted 4 Thomas Jefferson , and Henry Augustine Washington . The Writings of Thomas Jefferson : Being His Autobiography , Correspondence , Reports , Messages , Addresses , and Other Writings , Official and Private . Published by the Order of the Joint Committee of Congress on the Library , from the Original Manuscripts , Deposited in the Department of State ( Washington , D.C. : Taylor & Maury , 1854 ) . 5 Pariser , The Filter Bubble , 50 . 6 Ibid , 163 . 7 Ibid , 50. from print journalism to online content suppliers . Cyberphiles in the early days of the Information Age - like John Perry Barlow , author of the 1996 treatise “ A Declaration of the Independence of Cyberspace ” - regarded this shift with optimism. ? In large part , they believed the nation ’ s well-established newspapers had failed their democratic mission , using their exclusive ownership of expensive printing presses to guard the gates of public opinion , protect elite interests , and decide what “ the people ” should think . The Internet , these “ techno-optimists ” argued , would disintermediate and redemocratize public discourse by allowing individuals to autonomously plug into a public sphere that directly supplied more and “ better information , and the power to act on it. ” ? While the Internet has not brought about a digital democratic utopia , recent technological innovations have dramatically reduced the cost to produce , distribute , and access diverse information and perspectives.10 As Internet activist Eli Pariser so powerfully puts it , “ whereas once only those who could buy ink by the barrel could reach an audience of millions , now anyone with a laptop and a fresh idea can. ” ! ! As the cost of producing media plummeted at the end of the 20 century , the number of blogs and online news websites grew exponentially ; the chore of filtering through vast swaths of cluttered , obscure information on the Internet for relevant content became unmanageable . ! 2 Google - which now holds nearly 70 % of U.S. search engine market share - emerged at the turn of the 21s century to fill the pressing demand for a tool that would allow users to effectively search 8 Jack L. Goldsmith and Tim Wu , Who Controls the Internet ? : Hlusions of a Borderless World ( New York : Oxford UP , 2006 ) , 18 . 9 Thid , 3 . 10 Seth R. Flaxman , Sharad Goel , and Justin M. Rao , `` Ideological Segregation and the Effects of Social Media on News Consumption , ” Social Science Research Network . ( 2014 ) : 2 . 11 Pariser , The Filter Bubble , 51 . 12 Siva Vaidhyanathan , . The Googlization of Everything : ( and Why We Should Worry ) ( Berkeley : U of California , 2011 ) , 1. www : sciencepolicyjournal.org JSPG. , Vol . 7 , Issue 1 , August 2015 Journal of Science Policy & Governance Policy Analysis : Public Discourse in Age of Personalization 3 and organize the web.13 Since then , the company has become a lens through which millions of people view the world and process knowledge , and one of the single most important arbiters of “ what is important , relevant , and true on the web and in the world , ” 14 It is key to note that Internet search engines and traditional media broadcasters - like newspapers and television - draw upon two very different paradigms of content distribution . Newspapers and television are “ push technologies ” that specialize in “ pushing ” generic content at a passive general audience . Search engines , on the other hand , are “ pull technologies ” that specialize in “ pulling ” information from various online servers to answer the specific queries of their users.15 Google ’ s original search algorithm , PageRank , “ pulled ” information in a relatively objective and democratic manner . PageRank assumed that “ if one site was referred to more than another , it was ... more relevant to users. ” ! 6 As a young company , Google listed websites linked to by many other websites higher up on the pages of results it returned to users . Google founder Larry Page believed this process “ utilized the uniquely democratic structure of the web , ” in that it essentially rewarded those websites with the greatest number of “ votes. ” ! 7 With PageRank , identical searches returned identical results ranked according to popularity , regardless of who made the search or from where the search originated . It would be fair to say that Google did not resemble a traditional news source in 1998 when the company ’ s founders , Larry Page and Sergey Brin , operated their startup out of a garage near the Stanford University campus before moving to a small office on 13 Ashley Zeckman , . `` Google Search Engine Market Share Nears 68 % , '' Search Engine Watch , http : //searchenginewatch.com/sew/study/2345837/google- search-engine-market-share-nears-68 . 14 Vaidhyanathan , The Googlization of Everything , xi . 15 Pariser , The Filter Bubble , 67 . 16 Vaidhyanathan , The Googlization of Everything , 2 . 17 Pariser , The Filter Bubble , 31 . University Avenue in Palo Alto . 18 Unlike traditional news sources , Google did not carefully curate a single “ front page ” that featured important - and _ potentially unpopular - stories to be distributed indiscriminately to all of its users . It did not put all of its users on the “ same page. ” But the fledgling company did do what may have been the only feasible option in an information ecosystem overflowing with new content : it routed its users to many pages that were all the same . Every unique Google search returned a corresponding and consistent “ front page ” on the topic implied by the search ’ s keywords . A user employing Google ’ s search engine to learn more about the Iraq War , for instance , would see the same results , in the same order , as other users who searched the topic . Thus , while Google did not generate “ shared experience and shared knowledge ” in the same way that traditional news sources had done , the company did generate and organize a body of common information that was equally visible and accessible to all Internet users.19 Because Google ’ s search results reflected a democratic consensus about which news topics were most important , the public had the potential to develop a shared vocabulary and engage in a common conversation about current events . A few years after its founding , Google adopted the slogan , “ Democracy on the Web works ” as a guiding principle.20 By that time , the company was well on its way to becoming one of the world ’ s most important sources of news . On December 4 , 2009 , Google announced that it had replaced PageRank with algorithms that “ personalized search [ es ] for everyone. ” 21 Google executives publically explained that the change was an attempt to 18 '' Qur History in Depth , ” Google , http : //www.google.com/about/company/history/ . 19 Pariser , The Filter Bubble , 50 . 20 Pamela Jones Harbour , `` The Emperor of All Identities , ” The New York Times , 20 May 2015 , http : //www.nytimes.com/2012/12/19/opinion/why-google- has-too-much-power-over-your-private-life.html ? _r=0 . 21 Pariser , The Filter Bubble , 1. www : sciencepolicyjournal.org JSPG. , Vol . 7 , Issue 1 , August 2015 Journal of Science Policy & Governance Policy Analysis : Public Discourse in Age of Personalization 4 improve the user experience . By installing “ cookies ” that recorded online “ click signals , ” the search engine could learn users ’ specific needs , goals , interests , and preferences , thus adapting to provide more personally relevant content . 22 It was a small step towards perfecting “ the ultimate search engine , ” Google founder Larry Page proclaimed - a machine that “ would understand exactly what you mean and give back exactly what you want , ” 23 But personalization was _ also motivated by profit . Google monetized its operations by selling advertising space on its search engine . Google could sell more advertisements at higher prices if its personalization algorithms ensured that increasingly targeted audiences would see - and ultimately click on - increasingly relevant advertisements.2 * Moreover , the growth of personal data-aggregation companies willing to pay to accumulate “ click signals ” in vast commercial databases on users ’ interests and identities provided Google with another incentive to personalize . Such personalization algorithms increased the likelihood that a given Google search would return relevant results and trigger sellable clicks . While Google does not publish confidential company reports on_ the _ statistical characteristics of its search results , academic and industry researchers believe that at least 11.7 % of searches conducted with Google ’ s personalized search engine - and frequently , a far larger proportion of such searches - return individual users with significantly different results as a result of algorithmically programed personalization . 25 Google ’ s publicly available annual investor relations 22 Engin Bozdag and Job Timmermans , `` Values in the Filter Bubble Ethics of Personalization Algorithms in Cloud Computing , ” 1st International Workshop on Values in Design - Building Bridges between RE , HCI and Ethics ( Lisbon , Portugal : Delft University of Technology , 6 September 2011 ) . 23 Pariser , The Filter Bubble , 33 . 25 Aniko Hannak , Balachander Krishnamurthy , Piotr Sapiezynski , David Lazer , Christo Wilson , Arash Molavi Kakhki , and Alan Mislove , `` Measuring Personalization of Web Search , ” World Wide Web Conference , 13 May 2013. reports do shed some light on the effects of personalization on the company ’ s bottom line . Since 2008 - the year before announced it would be personalizing search - Google ’ s advertising revenues have nearly tripled , jumping from $ 21 billion in 2008 to just shy of $ 60 billion in 2014.26 The realization that Google ’ s users are in fact its products , rather than its customers , is indeed troubling . This paper , however , addresses what may be an even more worrying and _ pervasive outcome of personalization algorithms : their tendency to trap users in filter bubbles - information streams uniquely tailored to the interests and biases of individual users , often without their knowledge or consent . Unlike PageRank , Google ’ s new algorithms return personalized results to individual users by noting their geographic location and documenting their “ click signals. ” These filters screen which results its user sees and dictate in what order the user sees them , effectively straining out content deemed inconsistent with interests and perspectives that the user has encountered and endorsed in the past . As citizens become increasingly dependent on Google for their view of the world , writer Paul Boutin notes that the “ would-be information superhighway risks becoming a land of cul- de-sacs , with each user living in an individualized bubble created by automated filters. ” 27 Thus , Google ’ s personalization algorithms are concerning precisely because they tend to erode the shared public sphere that the news media once built and occupied and instead provide users with “ their own custom versions of the Internet. ” 28 The damage done to democratic processes by personalization , Pariser asserts , 26 `` Google 's Annual Advertising Revenue 2001-2014 , ” Statista , 24 June 2015 , http : //www statista.com/statistics/266249/advertising- revenue-of-google/ . 27 Paul Boutin , `` Your Results May Vary , ” Wall Street Journal [ New York ] 20 May 2011 , Eastern ed . : A13 , ProQuest Business Collection . 28 Thid . www : sciencepolicyjournal.org JSPG. , Vol . 7 , Issue 1 , August 2015 Journal of Science Policy & Governance Policy Analysis : Public Discourse in Age of Personalization 5 could be severe . After all , democracy requires that citizens see the world from one another ’ s point of view - a task made easier by a common collection of shared facts - but users are now more and more “ enclosed in their own bubbles , ” living in “ parallel but separate universes. ” 29In the pages that follow , this paper draws upon two interpretations of human attention , judgment , and decision- making to explain why the filter bubbles created by personalization algorithms are socially and politically harmful , and proposes a possible solution . Il . BIAS AND RATIONALITY : TWO COMPETING THEORIES OF HUMAN INFORMATION-PROCESSING AND DECISION-MAKING Modern social science theories that have their basis in the ways in how human beings process information and make decisions have generally demonstrated a preference for one of two competing interpretations : information-processing and decision-making as a manifestation either of economic rationality or of psychological bias . These approaches are introduced below and discussed in relation to the filter bubble in the following section . The economic principle of rational choice theory posits that all individuals seek complete information in order to make well- reasoned decisions that will maximize their total utility according to their own stable , predetermined preferences.3° Adam Smith , commonly referred to as the “ father of modern economics , ” held that individuals contribute to society ’ s general opulence by pursuing their own self-interest through markets of trade and exchange.3 ! Applying this same logic to the political realm , 29 Pariser , The Filter Bubble , 5 . 30 Jonathan Levin and Paul Milgrom , Introduction to Choice Theory , Stanford University , 2004 , http : //web.stanford.edu/~jdlevin/Econ % 20202/Choice % 20T heory.pdf . 1 . 31 Adam . Smith , The Wealth of Nations [ 1776 ] ( New York : Penguin Books , 1982 ) , http : //nrs.harvard.edu/urn- 3 : HUL.FIG:003625441 , 13. economist Anthony Downs argued that individuals promote the health of the polity when they amass complete information about their voting options and cast their votes for the party whose platform promises them the greatest personal utility . In order to evaluate the optimal course of action , a citizen “ depends ultimately on the information he has about policies. ” 32 To political scientist Joseph Schumpeter , rational decision-making similarly entailed “ sift [ ing ] critically ” through information in order to gather “ the ultimate data of the democratic process. ” 33 Exclusive exposure to “ adulterated or _ selective ” information , he argued , impinges upon a citizen ’ s ability to rationally “ make up his mind ” and leads him to “ exalt certain propositions into axioms and put others out of court. ” 3+ Schumpeter believed that this type of “ associative and affective ” thinking would ultimately detriment the political community as a whole by allowing “ the people to be ‘ fooled ’ step by step into something they do not really want. ” 35 Rational choice theory thus posits that individuals pursue their own self-interest through well-informed and well-reasoned decision-making that , in the end , tends to benefit the larger polity . A more recent iteration of rational choice theory , “ bounded rationality , ” asserts that while individuals are not perfectly rational , they do act rationally given certain restrictions . 36 Proponents of bounded rationality , like Herbert A. Simon and Gary Becker , criticized Smith and Downs ’ models of rationality because these models assumed the existence of an impossibly perfect “ economic man , ” blessed with access to 32 Anthony Downs , An Economic Theory of Democracy ( New York : Harper , 1957 ) , 46 . 33 Joseph Schumpeter , Capitalism , Socialism , and Democracy ( New York : Harper Perennial , 1976 ) , “ The Classical Doctrine of Democracy , ” 254 . 34 Thid , 264 . 35 Thid . 3¢ Herbert A. Simon , “ A Behavioral Model of Rational Choice , ” The Quarterly Journal of Economics 69 , no . 1 ( 1959 ) . www : sciencepolicyjournal.org JSPG. , Vol . 7 , Issue 1 , August 2015 Journal of Science Policy & Governance Policy Analysis : Public Discourse in Age of Personalization 6 complete information and limitless “ computational capacity. ” 3 ? While Simon and Becker believe that rational decision-making occurs when individuals “ weigh the advantages and disadvantages of alternative actions , ” they also believed that rational decision-making is often constrained by logistical and cognitive limitations.38 Because “ the information-gathering process is not costless ” and because people suffer from deficiencies in “ income , time , memory and calculating capacities , ” they explained , perfectly rational decision-making is at times neither practical nor attainable3 ? To Simon and Becker , the fact that individuals frequently choose to satisfy rather than maximize their utility preferences does not prove that humans are irrational . Rather , decisions of this type indicate the functioning of rational decision-making under certain logistical and cognitive constraints . While academics and researchers who believe that human information-processing and decision-making are primarily governed by certain psychological biases do not deny the existence of rational thought and action , they do claim that conscious , intentional , and systematic cognitive processing plays a far more limited role in the day-to-day workings of human behavior than the _ rational approach would suggest . In the 1970s , psychologist Daniel Kahneman proposed that the human cognition occurs through the collaboration two different psychological systems . The operations of System 1 , Kahneman wrote , are “ fast , automatic , effortless , associative , implicit ... and often emotionally charged ; they are also governed by habit. ’ 40 The operations of System 2 , on the other hand , “ are slower , serial , effortful , 37 bid , 99 . 38 Gary Becker , “ The Economic Way of Looking at Life ” Nobel Lecture , 9 December 1992 , http : //www.nobelprize.org/nobel_prizes/economic- sciences/laureates/1992/becker-lecture.pdf , 51 . 39 Simon , Rational Choice , 106 . 40 Daniel Kahneman , “ A Perspective on Judgment and Choice : Mapping Bounded Rationality , ” The American Psychologist 58 , no , 9 ( September 2003 ) : 697-720 , http : //www . ncbinim . nih . gov/pubmed/14584987 , 698. more likely to be consciously monitored or deliberately controlled. ” 41 Because the processing capacity of System 2 is easily expended - in other words , because the cognitive resources necessary for rational decision-making are in short supply - the intuitive and automatic functions of System 1 manage “ most of moment-to-moment psychological life. ” 42 Indeed , “ much of a person ’ s everyday life , ” Bargh and Chartrand explained , is determined “ by mental processes that are put into motion by features of the environment and that operate outside of conscious awareness and guidance. ” 48 Rather than endangering free will and self- determination , automatic mental processes silently carry much of the brain ’ s cognitive load so that resources remain for rational decision-making during the most deserving and deliberative of circumstances . * 4 Unfortunately , precisely because System 1 ’ s operations are effortless , they also frequently remain unexamined . * * Thus , while System 1 ’ s mental shortcuts effectively simplify and sublimate the complex task of gathering and processing information , they can also lead to severe and systematic errors that would not occur if individuals were fully aware of what they were doing . * 6 In 2002 , Daniel Kahneman was awarded a Nobel Prize in Economic Sciences for challenging the prevailing assumption of human rationality with his empirical and _ theoretical findings on psychological biases and heuristics . His best- selling book , Thinking , Fast and Slow , was published in 2011 and summarizes a body of work that has revolutionized our understanding of the ways in which human 41 Thid . 42 ] . A Bargh and T L Chartrand , “ The Unbearable Automaticity of Being , ” American Psychologist 54 , no . 7 ( 1999 ) : 462 . 43 Thid . 44 Tid , 464 . 45 Kahneman , Judgment and Choice , 699 . 46 Robert Jervis , “ The Drunkard ’ s Search , ” Political Psychology , edited by John T Jost and Jim Sidanius ( New York : Psychology Press , 2004 ) , 259. www : sciencepolicyjournal.org JSPG. , Vol . 7 , Issue 1 , August 2015 Journal of Science Policy & Governance Policy Analysis : Public Discourse in Age of Personalization 7 begins process information and make decisions . I ] . APPLICATION : THE FILTER BUBBLE Before any thorough investigation of the detriments of personalized filter bubbles , it is important to note that some filtering , both online and in person , is necessary for effective functioning . As discussed above , the human brain can not constantly engage in purposeful , systematic reasoning - the type of rational decision-making venerated by Adam Smith and Anthony Downs - because the mind ’ s effortful resources are limited . The human brain lacks the capacity to consciously and deliberately process all of the physical and social information presented by the surrounding environment . Thus , most moment-to-moment cognition occurs automatically , with conscious awareness only roused when “ there are real options and choices of which path to take. ” 47 Importantly , the basic psychological theory that humans have limited information processing capacity may explain a large part of Google ’ s success . As the Internet expanded , it became clear to many cybertheorists that the anarchic cyber utopia extolled by “ techno- optimists ” at the dawn of the Information Age was becomingly mind-numbingly vast ; in this “ interlinked yet unindexed ” web of networks in which “ clutter and confusion reigned , ” the sheer amount of data thrust in the faces of intrepid Internet users threatened to render the system unnavigable.48 The human brain was not up to the task of consciously and deliberately filtering through hundreds of thousands of websites to find a single piece of useful information . A direct , disintermediated web guaranteed an attention crash . The invaluable insight of Google ’ s founders was that in order to be useful , the Internet required a sorting mechanism that would reduce the amount of energy and time required to extract useful information from 47 Bargh and Chartrand , Automaticity of Being , 473 . 48 Vaidhyanathan , The Googlization of Everything , 1. the web . In many ways , Google ’ s search engine can be thought of as a virtual extension of the System 1 processing operations of the human brain . Because there was far too much data on the Internet for users to consciously sift through in search of a few pieces of truly important information - and because Google initially offered to sift through and prioritize this data using seemingly “ neutral and democratic ” methods -users came to trust Google ’ s search engine to quickly filter through the Web for them and alert them of any key findings. * ? While users lack the cognitive resources to deliberately assess every page on the web , they do have sufficient cognitive capacity to evaluate the limited number of results returned to them by a Google search , especially when these results are ranked ina meaningful and fair way . This is why “ when personalized filters offer a hand , ” Pariser explains , users “ are inclined to take it . Personalized filters can help users find the information they need to know and see and hear , the stuff that really matters. ” 5° Given the indispensability of some means of filtering through the vast amount of information on the web , this paper does not criticize online personalization outright . Rather , it suggests that Google ’ s information filtering algorithms may have become “ too good. ” 51 One of the primary functions of System 2 is to reconcile uncertainty and consciously decide how to settle the doubt that arises when one is confronted by incompatible thoughts or perceptions . % 2 System 1 recognizes that uncertainty and doubt are strategically important to human- decision making and accordingly draws the attention of System 2 to their existence so that deliberative reasoning can occur . In his book , The Sentimental Citizen , George Marcus argues that emotional anxiety provoked by perceptions of conflict is the only means of 49 Ibid , 2 . 50 Pariser , The Filter Bubble , 11 . 51 Nagulendra and Vassileva , Interactive Visualization , 107 . 52 Kahneman , judgment and Choice , 702. www : sciencepolicyjournal.org JSPG. , Vol . 7 , Issue 1 , August 2015 Journal of Science Policy & Governance Policy Analysis : Public Discourse in Age of Personalization 8 forcing a rational reevaluation of one ’ s currents beliefs and habits . Anxiety is unpleasant , Marcus acknowledges , but “ it frees us from being just stimulus-response creatures ” by recruiting “ reason and the attentive state of mind. ” 53 While Google ’ s personalization algorithms are extraordinarily good at filtering through the billions of gigabytes of data stored on the web and bringing items relevant to users ’ search queries to their attention , it is less clear whether the items they bring to users ’ attention actually foster the doubt , uncertainty , and anxiety required to trigger deliberate and conscious evaluation . Because personalized filters are programmed to predict users ’ interests , habits , and desires by learning from past online behavior , these filters become increasingly biased to share users ’ own views . * 4 Rather than returning results that might throw a user ’ s current beliefs into question and prompt him or her to reevaluate his or her perceptions and rationally decide on a new course of action , personalized algorithms return results that “ encapsulate users in a bubble of their comfort ” - a friendly world - where they see “ only content related to their interests ” and are “ spared of anything else. ” 55 While Google ’ s filtering algorithms excel at returning relevant results to users , they omit those that are in fact most strategically important : results that threaten a user ’ s unexamined assumptions and habits . Thus , Google ’ s current search engine approximates the psychological operations of System 1 while neglecting one of its most vital functions . By metaphorically “ severing the synapses in the brain , ” Pariser warns , Google ’ s personalized filters are effectively performing a “ global lobotomy. ” 56 Google ’ s original PageRank algorithms , on the other hand , did expose 53 George E. Marcus , The Sentimental Citizen ( Pennsylvania State University Press , 2002 ) , http : //nrs.harvard.edu/urn- 3 : hul.ebookbatch.PMUSE_batch : muse978027 1052731 54 Pariser , The Filter Bubble , 3 . 55 Nagulendra and Vassileva , Interactive Visualization , 107 . 56 Pariser , The Filter Bubble , 19. users to online media that had the potential to jeopardize their current worldviews and thus instigate critical assessment of previously unexamined beliefs . A staunch social conservative who Googled “ homosexual ” in 2006 , for instance , might have received as his or her top search result a popular article advocating for civil unions ; in 2011 , this same person would have much more likely been directed to sources consistent with his or her ideological opposition to homosexuality . Because PageRank ranked its results according to relevant websites ’ popularity , the algorithm plunged users into a common media stream of “ shared knowledge and_— shared experience. ” There , users were forced to confront social and political positions that either commanded general democratic consensus or demanded attention due to the discussion and debate they instigated . To the extent these results challenged rather than affirmed a _ user ’ s . preexisting _ beliefs , PageRank prompted the same uncertainty , anxiety , and doubt necessary for rational reevaluation and eventual working consensus . In other words , PageRank carried out the democratic mission of a free press . While PageRank filtered out much of the web , it continued to point users ’ attention to strategically important information that , by threatening users ’ automatic and unexamined points of view , would eventually allow users to end on the same page . Conversely , Google ’ s new personalization algorithms presage far less promising political outcomes . Personalized search results turn computer monitors into one-way mirrors that reflect and exaggerate users ’ own biases and interests . Rather than pushing users towards some sort of shared dialogue and common consensus on social and political issues , personalization algorithms tend to exacerbate individual users ’ particular predilections by showing them content and perspectives that echo and amplify their own beliefs . Because Google ’ s personalized filters fail to activate System 2- www : sciencepolicyjournal.org JSPG. , Vol . 7 , Issue 1 , August 2015 Journal of Science Policy & Governance Policy Analysis : Public Discourse in Age of Personalization 9 type judgments among users , they increase the likelihood that users will suffer from some of the same severe and systematic biases that an unquestioned reliance on System 1 ’ s automatic assumptions tends to generate . In 2014 , an interdisciplinary team of computer and social scientists from the University of Minnesota empirically affirmed that “ recommender systems ” like Google ’ s personalized search engine have an outsized effect on user ’ s choices - larger even than that of peers and experts - and that over time , these systems “ strongly push users towards narrow consumption ” of online content.5 ” The researchers suggested that recommender systems display diversity metrics or summary statistics to alert users of the declining variety of their returned results , a recommendation very much aligned with the one proposed in this paper . A second study , commissioned by Microsoft Research , produced similar findings and found that individuals exhibit “ substantially higher ” ideological segregation when they rely on personalized search engines to deliver their news.°8 Cumulatively , personalization tends to nurture biases that fracture of the public sphere into narrow and inflexible interests that struggle to participate effectively in the rational , deliberative decision-making of collective public discourse . IV . POLICY PROPOSAL AND EVALUATION Currently , a Google search will return users with only one set of search results . These results are determined by Google ’ s personalization algorithms , which rely on users ’ “ click signals ” and other personal data to refine their predictions and provide individual users with personally relevant results . Prior to December 4 , 2009 , PageRank - Google ’ s original search algorithm - indexed 57 Tien T. Nguyen , Pik-Mai Hui , F. Maxwell Harper , Loren Terveen , and Joseph A. Constan , `` Exploring the Filter Bubble : The Effect of Using Recommender Systems on Content Diversity , ” International World Wide Web Conference,7 April 2014 , 685 58 Seth R. Flaxman , Shared Goel , and Justin M. Rao , Ideological Segregation . search results for all of Google ’ s users using a rough approximation of relative website popularity . This approach to search was democratic because it rewarded websites for receiving “ votes ” of confidence from other websites . Because personalized filters prioritize relevance and PageRank filters prioritize popularity , a side-by-side search conducted by the two algorithms using identical keywords would return different results . This policy proposal recommends a simple solution to the filter bubble problem : Google should engineer and implement a new web application that will allow users to easily toggle between results returned through Google ’ s new personalization algorithms and results returned through Google ’ s original PageRank algorithms . At a functional level , the toggle feature should be an easy-to-use interactive tool . It should be easily accessed through an icon embedded in Google ’ s search bar , directly adjacent to the microphone ( “ Search by voice ” ) and magnifying glass ( “ Search ” ) icons . A light switch icon may bea helpful illustration of the toggle feature ’ s main function . When flipped to “ Personal , ” the toggle feature should prompt the Google search engine to display and arrange highly relevant results that reflect Google ’ s perceptions of the individual user . When flipped to “ Popular , ” the toggle feature should prompt the Google search engine to display and arrange highly popular results ranked using Google ’ s original PageRank algorithms . As the name suggests , a single click of the mouse on the toggle icon should allow the user to flip back and forth between results returned using the “ Personal ” and “ Popular ” filters . While the launch of the toggle feature should prompt the creation and distribution of some explanatory user materials - including an informative text bubble that should instruct a user on how to use the feature when he or she hovers his or her mouse over the toggle icon - because Google developed its PageRank algorithm a decade ago , the implementation of the toggle feature www : sciencepolicyjournal.org JSPG. , Vol . 7 , Issue 1 , August 2015 Journal of Science Policy & Governance Policy Analysis : Public Discourse in Age of Personalization 10 should not require the costly and time- consuming development of an entirely new search algorithm . Rather , it simply demands the reintroduction of the PageRank algorithm alongside the personalized algorithms already in place , and the creation of a simple and intuitive toggle mechanism that will direct the search engine which algorithm to use in which situation . The toggle feature will help users visualize and understand how their search results change depending on what type of filter Google applies , and give users the opportunity to explore content they would not have discovered if they only had access to personalized search results . Thus , the toggle feature will both educate and empower users . By allowing users to engage in a side-by-side comparison of PageRank search results and personalized search results , the toggle feature will educate users on how Google ’ s filters function and expose them to informative content they would not have seen had they only referenced their personalized search results . The toggle feature will give users the opportunity to choose which filter - popular or personalized - they wish to apply when they use Google search , and thus will empower them to decide for themselves what type of results they would like to receive . Because the toggle feature increases the likelihood that users will be exposed to results deemed important by Google ’ s PageRank algorithms , it increases also the likelihood that users will confront challenging information that is highly relevant to the democratic community as a whole and thus instrumental to generating democratic consensus . Additionally , by drawing users ’ attention to the disparity between the results returned by the “ Personal ” and “ Popular ” filters , the toggle feature will alert users of their own biases , as they are reflected by their search engine ’ s learned biases . As a result , this policy will reduce the negative effects of filter bubbles while providing users with continued access to the highly relevant search terms returned by Google ’ s personalization algorithms . V. RESPONSE TO POSSIBLE CRITICISMS The policy proposed is vulnerable to two major criticisms . First , why would Google , a company beholden to _ its stockholders and motivated by profit , expend precious resources to implement a web application that , in the end , may harm its bottom line ? Some users may never explore or utilize the toggle feature . Many will likely use the feature occasionally to assess how the results returned differ depending on the filter they use . Still , others may use the toggle feature to opt out of Google ’ s personalization algorithms altogether , metaphorically leaving the switch “ off ? whenever they use Google ’ s search engine . Less personalization theoretically means less relevance , which ultimately translates into fewer clicks , fewer data points to sell to data-aggregation companies , and fewer advertisers willing to pay for prime real estate in Google ’ s search results . So what reason does Google have to engineer and implement this policy ? It should be noted that the policy proposed does not completely eliminate personalization . Rather , the toggle feature allows users to switch between results returned using Google ’ s new personalization algorithms and results returned using Google ’ s original PageRank algorithms . Google will therefore still continue to profit from personalization , though it is true that - in the short term - profits may fall due to user defection from Google “ Personal ” to Google “ Popular , ” where advertisements command lower prices and fewer click signals are generated for sale to date-aggregation companies . In the long run , however , implementing this policy may actually increase Google ’ s profits in three different ways . First , by increasing the transparency of its personalization algorithms , Google will foster trust from its users . Google currently refrains from explaining or demonstrating www : sciencepolicyjournal.org JSPG. , Vol . 7 , Issue 1 , August 2015 Journal of Science Policy & Governance Policy Analysis : Public Discourse in Age of Personalization 11 exactly how its personalization algorithms function , and the company offers users little to no control over these settings . By providing users with knowledge about these filters and granting them some control over their functioning , Google will strengthen the loyalty of its existing users and attract new users , thus increasing the quantity of personal data it can collect and the value of the advertisements it can sell . Second , this policy will placate political interests that are currently calling for legislation to more strictly regulate the personal data market. * ? If legal limitations are placed on what kind of personal data Google can collect and how it can be collected , Google ’ s future inventory of “ click signals ” will plummet , and a potential source of profit will be eliminated . Thus , this policy functions as a proactive concession to politicians who seek to regulate the personal data market ; by increasing the transparency of its personalization algorithms , Google may be able to convince these interests that further regulation is not required . Finally , asa corporation headquartered in the United States of America , Google will benefit from this policy because it indirectly enhances the quality of public debate and democratic decision-making . By reducing the deleterious effects of filter bubbles , this policy will contribute to effective democratic governance in the United States , which in will improve the laws passed by federal and state governments contribute to favorable business conditions . The second criticism of this proposal logically follows the first : even if Google did choose to implement this policy , would Internet users actually use toggle feature ? After all , personalization increases relevance , and relevance is akin to convenience . In the short term , users benefit from personalized search results because they route users websites tailored to their location , interests , and values . As such , this policy may overestimate the extent to which users will actually assess the differences between their 59 Harbour , The Emperor of All Identities . “ Personal ” and “ Popular ” search results . If confronting opinions that disagree with our own is inherently anxiety provoking , as George Marcus claimed , is it reasonable to assume that Internet users will willfully seek out opinions that challenge their own ? First , it must be acknowledged that not all Google users will explore and utilize the toggle feature proposed in this policy recommendation . The criticism advanced above is valid : personalization is a useful tool , and many users appreciate the relevancy of the search results it returns . This policy does not propose eliminating personalization , but rather tempering it . It recommends that users be given the option to explore how search personalization works and opt out if they so choose . Two powerful psychological tendencies grounded in Daniel Kahneman ’ s empirical work on psychological biases and heuristics predict that users will indeed experiment with the toggle feature . The first is that “ information gaps ” tend to spur curiosity . If users are notified that they are operating ina filtered environment , they may feel a sense of deprivation and seek to learn what is being hidden from them . This same tendency explains why individuals pursue additional information even if this information is noninstrumental to their decision-making. * ! Thus , if a clearly visible icon reminds users their results are being filtered , they will be tempted to explore how personalization changes their search results . A second explanation for why a user may take advantage of the toggle feature is that , once he or she has tried it , his or her attentional capacity is altered and amplified from a feeling of empowerment . The tool proposed here is indeed a powerful one ; it gives users have the ability to manipulate the algorithms of the world ’ s largest Internet company and control their own view of the world . 60 Pariser , The Filter Bubble , 90 . 61 A. Bastardi and E. Shafir , “ On the Pursuit and Misuse of Useless Information , ” Journal of Personality and Social Psychology 75 , no . 1 ( July 1998 ) . www : sciencepolicyjournal.org JSPG. , Vol . 7 , Issue 1 , August 2015 Journal of Science Policy & Governance Policy Analysis : Public Discourse in Age of Personalization 12 Psychological research shows that the sensation of power allows individuals to attend to information more selectively and to exhibit greater attentional flexibility.s ? These findings suggest that individuals who feel empowered by the toggle feature will want to continue using it , thus enhancing its greater impact . VI . SUMMARY This policy proposal began by examining the roots of democratic theory on the necessity of free speech and public discourse . It traces the development of the news media to the present day , with particular attention paid to the birth and expansion of online content distributors , especially Google . It describes Google ’ s gradual transition from PageRank algorithms to personalized algorithms , noting how personalization increases the company ’ s profits . After briefly outlining the rational and psychological approaches to human behavior , it applies these approaches to the filter bubble problem . This policy proposal recommends that Google implement a toggle feature to combat the deleterious effects of filter bubbles . This feature , to be embedded directly into Google ’ s central search bar , will allows users to switch back and forth between results returned using Google ’ s personalization algorithms and _ results returned using Google ’ s PageRank algorithms . Although this policy will not completely solve the filter bubble problem and may , in the short run , diminish Google ’ s profits , it is still defended as a necessary step to ensure the longevity of effective public discourse in America . References Bargh , John A. and Tanya L. Chartrand . “ The Unbearable Automaticity of Being. ” American Psychologist 54 , No . 7 ( 1999 ) : 462-479 . 62 Ana Guinote , “ Power Affects Basic Cognition : Increased Attentional Inhibition and Flexibility , ” Journal of Experimental Social Psychology 43 , no . 5 ( September 2007 ) : 685 . Bastardi , Anthony , and Eldar Shafir . “ On the Pursuit and Misuse of Useless Information. ” Journal of Personality and Social Psychology 75 , No . 1 ( 1998 ) : 19-32 . Becker , Gary . “ The Economic Way of Looking at Life ” Nobel Lecture , December 9 , 1992 . Boutin , Paul . `` Your Results May Very . '' Wall Street Journal [ New York ] 20 May 2011 , Eastern ed . : A13 . ProQuest Business Collection . Web . 7 Dec. 2014 . Bozdag , Engin , and Job Timmermans . `` Values in the Filter Bubble Ethics of Personalization Algorithms in Cloud Computing . '' ist International Workshop on Values in Design - Building Bridges between RE , HCI and Ethics . Lisbon , Portugal . Delft University of Technology , 6 Sept. 2011 . Web . 24 Nov. 2014 . Downs , Anthony . An Economic Theory of Democracy . New York : Harper , 1957 . Flaxman , Seth R. , Sharad Goel , and Justin M. Rao . `` Ideological Segregation and the Effects of Social Media on News Consumption . '' Social Science Research Network . 6 Dec. 2014 . Web . 9 Oct. 2014 . Goldsmith , Jack L. , and Tim Wu . Who Controls the Internet ? : Illusions of a Borderless World . New York : Oxford UP , 2006 . Print . `` Google 's Annual Advertising Revenue 2001- 2014 . '' Statista . Accessed June 24 , 2015. http : //www : statista.com/statistics/2662 49 /advertising-revenue-of-google/ . Guinote , Ana . “ Power Affects Basic Cognition : Increased Attentional Inhibition and Flexibility. ” Journal of Experimental Social Psychology 43 , No . 5 ( September 2007 ) : 685-697 . Harbour , Pamela Jones . `` The Emperor of All Identities . '' The New York Times . N.p. , 20 May 2015 . Web . 22 June 2015. http : //www.nytimes.com/2012/12/19/opinion/ why-google- has-too-much-power-over-your- private-life.html ? _r=0 . Hannak , Aniko , Balachander Krishnamurthy , Piotr Sapiezynski , David Lazer , Christo Wilson , Arash Molavi Kakhki , and Alan Mislove . `` Measuring Personalization of Web Search . '' World Wide Web Conference , May 13 , 2013 . Accessed June 23 , 2015 . Introna , Lucas D. , and Helen Nisenbaum . `` Shaping the Web : Why the Politics of Search Engines Matters . '' The Information Society 16 ( 2000 ) : 169-85 . Accessed June 23 , 2015 . Taylor & Francis . www : sciencepolicyjournal.org JSPG. , Vol . 7 , Issue 1 , August 2015 Journal of Science Policy & Governance Policy Analysis : Public Discourse in Age of Personalization 13 Jefferson , Thomas , and Henry Augustine Washington . The Writings of Thomas Jefferson : Being His Autobiography , Correspondence , Reports , Messages , Addresses , and Other Writings , Official and Private . Published by the Order of the Joint Committee of Congress on the Library , from the Original Manuscripts , Deposited in the Department of State . Washington , D.C. : Taylor & Maury , 1854 . Print . Jervis , Robert . “ The Drunkard ’ s Search. ” In Political Psychology , edited by John T Jost and Jim Sidanius , 259-270 . New York : Psychology Press , 2004 . Kahneman , Daniel . “ A Perspective on Judgment and Choice : Mapping Bounded Rationality. ” The American Psychologist 58 , No . 9 ( September 2003 ) : 697-720 . Levin , Jonathan , and Paul Milgrom . Introduction to Choice Theory . Stanford University . 2004 . Accessed June 23 , 2015. http : //web.stanford.edu/~jdlevin/Econ % 20202 /Choice % 20Theory.pdf . Liao , Q. Vera , and Wai-Tat Fu . `` Beyond the Filter Bubble : Interactive Effects of Perceived Threat and Topic Involvement on Selective Exposure to Information . '' Proc . of | Conference on Human Factors in Computing Systems , Paris . Association forComputing Machinery and SIGCHI , 2013 . Web . 7 Dec. 2014 . Marcus , George E. The Sentimental Citizen , Pennsylvania State University Press , 2002 . Nagulendra , Sayooran , and Julita Vassileva . `` Understanding and Controlling the Filter Bubble through Interactive Visualization : A User Study. ” — Hypertext and Social Media : Proceedings of the 25th ACM Conference . Santiago , Chile . The Association for Computing Machinery Digital Library , 2014 . Web . 24 Nov. 2014 . Nguyen , Tien T. , Pik-Mai Hui , F. Maxwell Harper , Loren Terveen , and Joseph A. Constan . `` Exploring the Filter Bubble : The Effect of Using Recommender Systems on _ Content Diversity . '' International World Wide Web Conference , April 7 , 2014 , 677-86 . `` Our History in Depth . '' Company . Google . Web . 23 June 2015. http : //www.google.com/about/company /history/ Pariser , Eli . The Filter Bubble : What the Internet Is Hiding from You . New York : Penguin , 2011 . Print . Schumpeter , Joseph . Capitalism , Socialism , and Democracy . New York : Harper Perennial , 1976 ) . “ The Classical Doctrine of Democracy. ” Print . Simon , Herbert A . “ A Behavioral Model of Rational Choice. ” The Quarterly Journal of Economics 69 , No . 1 ( 1955 ) : 99-118 Smith , Adam . The Wealth of Nations [ 1776 ] , New York : Penguin Books , 1982 . “ Transparency. ” U.S. Public Policy . Google . Web . 8 Dec. 2014. http : //www.google.com/publicpolicy/tra nsparency.html . Vaidhyanathan , Siva . The Googlization of Everything : ( and Why We Should Worry ) . Berkeley : U of California , 2011 . Print . Zeckman , Ashley . `` Google Search Engine Market Share Nears 68 % . '' Search Engine Watch . 20 May 2014 . Web . 22 June 2015. http : //searchenginewatch.com/sew/stud y/2345837 /google-search-engine-market-share- Audrey Carson is an undergraduate at Harvard University concentrating in Government and pursuing a secondary field in History . She grew up in Oakland , California and is preparing to write a senior honors thesis on cyberpolitics . Ms. Carson 's two primary research interests are the politics of technology and international development . www : sciencepolicyjournal.org JSPG. , Vol . 7 , Issue 1 , August 2015 Pop the Feed Filter Bubble : Making Reddit Social Media a VR Cityscape Rhema Linder * Alexandria M. Stacy ? Texas A & M University ABSTRACT On Reddit , users from tens of thousands of communities create and promote internet content , including pictures , videos , news , memes , and creative writing . However , like most social media feeds , sub- scribing to a very small subset of available content creates filter bubbles . These bubbles , while created unintentionally , skew percep- tions of reality . This phenomena provides an impetus for researchers to design techniques breaking out of filter bubbles . Virtual real- ity provides opportunities for new environments that contextualize social media among multiple perspectives . We present one solu- tion to the filter bubble problem : Blue Link City , which enables contextualized exploration of Reddit . 1 . INTRODUCTION AND RELATED WORK On Reddit , users from tens of thousands of communities create and promote internet content , including pictures , videos , news , memes , and creative writing . As consumers of content , users can sub- scribe to specific communities that match their tastes . However , this potentially creates a “ filter bubble ” , where the targeted con- tent users enjoy fosters skewed perceptions of what most people believe . Like most social media , Reddit uses subscription-based feeds that present content in linear lists , ordered based on upvotes and recency . Researchers have previously identified filter bubbles on Twitter [ 6 ] , which provides similar feeds . The filter bubble problem also contributes to larger concerns about machine learn- ing algorithms and their potential to unwittingly reinforce social inequality [ 11 ] . This project seeks to call attention to the filter bub- ble problem and presents our approach for mitigation . We discuss and demonstrate an alternative to linear feeds for consuming social media . Blue Link City is a virtual reality environment that maps communities from Reddit into a virtual cityscape . 1.1 . Presence in VR and Casual Browsing In Virtual Reality research , presence [ 2 ] is the subjective feeling of being lost in the moment or the reality of the system . Casual web browsing creates a similar sense of presence . Elsweiler et al . describes Casual-Leisure contexts as having separate goals than stan- dard Information Behavior Models [ 5 ] . They found that people seek out mood boosters in everyday situations , accepting many informa- tional outcomes rather than having a particular goal or informational need . We emphasize the exploring for the experience use case from Elsweiler et al. , which typically refers to exploring novel physical spaces where the goal is to learn about the space . In this leisurely context context , the focus is about the experience itself instead of an informational goal . 1.2 Reddit and Other Social Media Feeds Reddit is a link and text sharing social media site where individual posts are constantly shifting in importance and prominence based on votes from users [ 13 ] . One of the key aspects of Reddit is that it is organized into hundreds of thousands of topic specific subreddit groups . Each post is voted on by users to impact its “ hot ” * e-mail : { rhema , nic , andruid } @ ecologylab.net te-mail : alstacy2323 @ gmail.com * e-mail : ragan @ tamu.edu Nic Lupfer * Interface Ecology Lab , Computer Science Department Andruid Kerne * Eric D. Ragan ? Department of Visualization Texas A & M University score and current placement [ 14 ] . One thing Facebook , Twitter , Pinterest , and Reddit have in common is that they all use a feed- based subscription model . Content is prioritized with algorithms and be scrolled through . While displaying content in lists has advantages , non-linear spatial arrangements better support finding emergent and creative connections among content [ 8 , 15 ] and conceptualization through visual thinking [ 10 ] . In 3D environments , meaningfully spatialized information is ideal for learning activities [ 12 ] . This spatialization helps people remember and learn automatically , which we find to be better than linear feeds . Social media exploration is a personally meaningful form of creativity where more diverse experiences can be considered more creative [ 7 ] . We suggest that helping contextualize content mitigates filter bubble effects . 2 BLUE LINK CITY To create the cityscape structure , we start with data from Reddit , construct a graph that connects related subreddits in a force-directed graph , use an interactive application to create the city , and finally export the structure into the virtual environment . For data from Reddit , we used data from Woolf [ 16 ] . In this scheme , all subreddits are represented as nodes , with edges between them representing co-occurring comments from users . When a user comments at least five times in two subreddits , a score of 1 is added . For example , there are 621 users who commented five times in both /r/guns //firearm , making an edge with a weight of 337 between nodes /r/guns and /r/firearms . Using this data , we construct a graph in an interactive web application that uses a D3.js visualization ( Figure 1 a ) to author a cityscape . We mapped each node to a subreddit , and represented it as a building . Once we were satisfied with our organization of the city , we snapped the nodes in position to city blocks . We included relatively large spacing between buildings to create a grid where the virtual user can navigable through the city , and the overall effect results in city blocks with a mix of larger and smaller subreddits . We import the building structures into Unity to generate a cityscape ( Figure 1 ) . The city structure takes advantage of net- works [ 1 ] to support serendipity , while enabling non-linearity [ 8 ] in the arrangement of curated subreddits . Each building represents a subreddit . For each building , we place text titles of the name of its subreddit at the top . Buildings display new content when looked at ( via head tracking ) for more than three seconds . New posts appear from the top of the building towards the ground . Each post wraps around the building and shows a title and thumbnail image or “ self ” text . The size of building are mapped to the number of the subred- dit ’ s subscribers . Subreddits with few subscribers are narrow and short , while those with many subscribers are wide and tall . 2.1 Interaction and Exploration For hardware , we have used both a Leap Motion controller connected to an Oculus Rift ( see Figure 1 b ) and the Oculus Touch controllers . We developed a bimanual gesture technique for navigation in 3D environments , which we describe very briefly in this work . To translate , users clasp the fingers in each hand together and pull their hands toward or away from the HMD . Spreading hands wider makes the translation fast , while putting hands closer together makes it slow . The accuracy of the Oculus Touch was much better than the Leap motion . Overall , we found this to be an effective and natural-feeling ga k Et i ( < ) , Figure 1 : In ( a ) , the top shows initial force direct graph with the bottom showing a top down . For ( b ) , we show the Leap Motion navigation . In ( c ) , we show a portion of Blue Link City , with a spatialized Reddit as a social media cityscape . In the VR application , users can fly around and browse content up close , or from a distance . Demos and videos of the Blue Link City authoring tool and environment are available at bluelinkcity . com . technique for exploration . It is “ hyper-natural [ 3 ] in the sensation of accelerated swimming beyond natural speeds . In Blue Link City , a user can view subreddit buildings to see fresh content appear . Often , this reveals interesting juxtapositions in the structure of the city and posts . For example , one view shows a subreddit about a popular show on Reddit ( Rick and Morty ) , is jux- taposed with /r/shittyaskscience and /r/talesfromtechsupport . This indicates that , in this region of the city , people who comment about the popular show also have a tendency to joke about science and describe horror stories about supporting technology . Another prox- imal juxtaposition shows that /r/SandersForPresident resides near /cfsocialism , which are close but not as close to /r/polotics and /cfthe_donald . In this virtual environment , browsing political posts in nearby buildings juxtaposes content from posts that day from multiple and conflicting perspectives . 3 DISCUSSION AND CONCLUSION Virtual Reality feeds should be spatial . Linear feeds dominate social media experiences on desktop and mobile platforms , but they also strengthen filter bubbles . In positive instances , feeds expose people to options they might not have otherwise found [ 9 ] . However , feeds can lead people to feel that everyone agrees with their own ideas . Cialdini ’ s work on social proof shows people change their expec- tations based on how they see others behave [ 4 ] . Algorithms [ 11 ] and individuals ’ choices to subscribe to narrowly-sourced feeds are both to blame . In order to help people overcome filter bubbles , it is important offer multiple perspectives . In Blue Link City , different re- gions of the spatialized community are shown simultaneously . Users can move across these communities in any path while maintaining a general sense of their orientation . In this way , we argue spatial techniques are needed for VR for casual-leisure [ 5 ] browsing . Use big data techniques to populate VR contextualized social media environments . In our VR application , we used a combination of force-directed layout and interaction to arrange the structure of the city . We did not create the content manually , but relied on big data methods to populate its content . We believe that linear feeds of social media produce filter bubbles . VR environments can mitigate this problem by contextualizing posts among multiple perspectives . By design , the structure of Blue Link City juxtaposes content to help encourage more creative [ 7 ] and contextualized exploration . REFERENCES [ 1 ] P. André , J. Teevan , S. T. Dumais , et al . Discovery is never by chance : designing for ( un ) serendipity . In Proceedings of the seventh ACM conference on Creativity and cognition , pp . 305-314 . ACM , 2009 . [ 2 ] [ 3 ] [ 4 ] [ 5 ] [ 6 7 ] [ 8 ] [ 9 [ 10 ] Qi [ 12 ] [ 13 ] [ 14 ] [ 15 ] [ 16 ] D. A . Bowman and R. P. McMahan . Virtual reality : how much immer- sion is enough ? Computer , 40 ( 7 ) :36-43 , 2007 . D. A . Bowman , R. P. McMahan , and E. D. Ragan . Questioning natural- ism in 3d user interfaces . Communications of the ACM , 55 ( 9 ) :78-88 , 2012 . R. Cialdini . Influence . HarperCollins , 2009 . D. Elsweiler , M. L. Wilson , and B. Kirkegaard Lunn . Chapter 9 understanding casualleisure information behaviour . New Directions in Information Behaviour , Emerald Group Publishing , Bingley , pp . 211-241 , 2011 . I. Himelboim , S. McCreery , and M. Smith . Birds of a feather tweet together : Integrating network and content analyses to examine cross- ideology exposure on twitter . Journal of Computer-Mediated Commu- nication , 18 ( 2 ) :40-60 , 2013 . A. Jain , N. Lupfer , Y. Qu , R. Linder , A. Kerne , and S. M. Smith . Evaluating tweetbubble with ideation metrics of exploratory browsing . In Proceedings of the 2015 ACM SIGCHI Conference on Creativity and Cognition , pp . 53-62 . ACM , 2015 . A. Kerne , A. M. Webb , S. M. Smith , R. Linder , N. Lupfer , Y. Qu , J. Moeller , and S. Damaraju . Using metrics of curation to evaluate information-based ideation . ACM Transactions on Computer-Human Interaction ( TOCHD ) , 21 ( 3 ) :14 , 2014 . R. Linder , C. Snodgrass , and A. Kerne . Everyday ideation : all of my ideas are on pinterest . In Proc CHI , 2014 . N. Lupfer , A. Kerne , A. M. Webb , and R. Linder . Patterns of free-form curation : Visual thinking with web content . In Proceedings of the 2016 ACM on Multimedia Conference , pp . 12-21 . ACM , 2016 . C. O'Neil . Weapons of math destruction : How big data increases inequality and threatens democracy . Crown Publishing Group ( NY ) , 2016 . E. D. Ragan , D. A . Bowman , and K. J. Huber . Supporting cognitive pro- cessing with spatial information presentations in virtual environments . Virtual Reality , 16 ( 4 ) :301-314 , 2012 . P. Singer , F. Flock , C. Meinhart , E. Zeitfogel , and M. Strohmaier . Evo- lution of reddit : from the front page of the internet to a self-referential community ? In Proceedings of the 23rd International Conference on World Wide Web , pp . 517-522 . ACM , 2014 . P. Van Mieghem . Human psychology of common appraisal : The reddit score . Multimedia , IEEE Transactions on , 13 ( 6 ) :1404—1406 , 2011 . A. M. Webb , A. Kerne , R. Linder , N. Lupfer , Y. Qu , K. Keith , M. Car- rasco , and Y. Chen . A free-form medium for curating the digital . In Curating the Digital , pp . 73-87 . Springer , 2016 . M. Woolf . Jupyter notebook + code for reproducing reddit subreddit graphs . https : //github . com/minimaxir/reddit- graph , 2015 . IOP Conference Series : Materials Science and Engineering PAPER « OPEN ACCESS You may also like : soe : cf - The Learning of Religious Tolerance Filter bubble effect and religiosity : filter bubble mong Students in Indonesia from th . . . . . . Pers ive of Critical effect implication in the formation of subjects and E Firdaus . wt . - ( 1 ) The Triumph of Evoluti h views of religiosity Faure of Creationism ( 2 ) The Fath of Biol nd the Biol f Faith : Order Meaning , and Free Will in Modern Medical To cite this article : T Zakaria ef ai 2018 JOP Conf . Ser . : Mater . Sci . Eng . 434 012280 Science ( 1 ) Niles Eldredge ( 2 ) Robert Pollack - Environmental en ment . religion ani Spirituality in the context of secularization Marie Briguglio , Teresa Garcia-Mufoz and View the article online for updates and enhancements . Shoshana Neuman The Electrochemical Society Advancing solid stat chemical sc Blair ) olen 243rd ECS Meeting with SOFC-XVIII More than 50 symposia are available ! Present your research and accelerate science Boston , MA e May 28 - June 2 , 2023 RF Tice e-em alia This content was downloaded from IP address 79.179.8.212 on 12/11/2022 at 08:14 3rd Annual Applied Science and Engineering Conference ( AASEC 2018 ) IOP Publishing IOP Conf . Series : Materials Science and Engineering 434 ( 2018 ) 012280 doi:10.1088/1757-899X/434/1/012280 Filter bubble effect and religiosity : filter bubble effect implication in the formation of subjects and views of religiosity T Zakaria ’ , B Busro and S Furgon Faculty of Ushuluddin , UIN Sunan Gunung Djati Bandung , Jalan A H Nasution 105 Bandung 40614 , Indonesia * zakariatatang @ yahoo.co.id Abstract . The Internet presents a space called cyberspace . He changed the various aspects of human life , among them religion . The internet is closely related to the Lebenswelt ( world-life ) where humans live . There are religious impacts on internet media on the one hand , and the internet also forms religious individuals in life . In the perspective of religious phenomenology , technology is not neutral but human formation , as well as allowing the gap it can affect humans . This research will refer to the paradigm of constructivism as far as can be elaborated in the sitting of religious phenomenology . As a result , a follower of religion , as he is in contact with the internet media , he will be exposed . The negative effect of the filter is the strengthening of a person 's pretension to be reductive which leads to a radical attitude.The bubble effect filter , on the other hand , it is a necessary logarithmic system . There are two findings on this , firstly , the system it self is given . Secondly , even if undoubtedly , it is vulnerable to cracks , and can be rearranged . That is , it is optionally user-dependent , and simply , the information appears to match the availability of keywords . 1 . Introduction Cyberspace is a space occupied by netters or netizens , spaces or where we are when we navigate the global interactive information world called the internet . John Suler considers cyberspace to be a psychological space and as a psychological space of its existence does not depend on conventional boundaries on tangible objects [ 1 ] . Cyberspace , the term first introduced by Howard Reingold , displays reality , but not the real reality as we see but virtual reality , the infinite world . The netters who inhabit the cyberspace are called virtual communities [ 2 ] . However , although the scope of reality of cyberspace is so wide , we will specify this research on certain issues . First , in connection with the formation of consciousness . Today 's Internet is similar to our premise , it determines one 's consciousness . There is a process of forming a real subject that is not simply virtual , which in turn determines how it behaves . Especially after getting justified that in the digital age , a number of security protocols emerged that were conditioned . The impact of this began in 2011 when Eli Pariser released The Filter Bubble : What the Internet Is Hiding From You . [ 3 ] . Pariser 's main argument is that this constriction creates a filter bubble , which is not visible to the user but still has a big impact on the information available to the individual . When performing a Content from this work may be used under the terms of the Creative Commons Attribution 3.0 licence . Any further distribution Cu of this work must maintain attribution to the author ( s ) and the title of the work , journal citation and DOI . Published under licence by IOP Publishing Ltd 1 3rd Annual Applied Science and Engineering Conference ( AASEC 2018 ) IOP Publishing IOP Conf . Series : Materials Science and Engineering 434 ( 2018 ) 012280 doi:10.1088/1757-899X/434/1/012280 Google search , personal information is used in addition to search terms to find and prioritise the most likely search results . At some point , the effect of this filter will produce a separate environment . Especially concerning the way people think and especially in Indonesia , as one of the world 's largest religious country will create a separate community order . It is therefore of interest to examine the extent to which these increasingly complex habits of reality in individual life and religious life ; especially socially . This becomes important given that the effects of the sensor always have a negative impact . The significance of this study to show how the effect of a filter bubble impacts on the formation of religious attitudes . Specifically radical attitudes in religion-the opposite of media pluralism . Its urgency in order to restore the consciousness of human relations with technology and the religious impact of man , especially theoretically . Research that affirms some similar problems among others by , Heidi Campbell [ 4 ] , Karine Barzilia-Nahon & Gad Barzilia [ 5 ] , in addition , see Ozlem Hesapci Sanaktekin [ 6 ] . Thus , it is hypothesized that the filter bubble effect results in epistemological isolation and reduction for religious subjects leading to radicalism . 2 . Research methods This research refers to the paradigm of postphenomenology constructivism according to Don Ihde to understand and explain the relation of subject with technology [ 7 ] . For the next will be analyzed by using flow model of analysis as far as it can be described phenomenologically [ 8 ] . The primary data was taken hypothetically as far as referring to the Pariser variable filter bubble effect . Then directed to the findings that already exist about the pattern of internet users that lead to the strengthening of radicalism . This research is theoretical msofar as it refers to the assumption of the use of technology in the field of human religious experience . 3 . Technology and fragmentation of reality Through technology , humans can objectify time . The discovery of time-measuring devices and the determination of time units since the modern era has changed the way people view the time . Human perception is shortened , say in seconds , from old perceptions with daily duration systems ( morning , afternoon , evening , night ) . This change leads people to the acceleration of time . In almost the same time , with the development of transportation technology allows humans to travel very quickly . Distance moved from time to time using different counting units . Starting from monthly , daily , until now the distance duration often uses the clock : one hour , then one minute , then one second . The transformation of human experience from direct to indirect by the use of technology from time to time , resulting in a dichotomy . We can refer to Descartes in the Western philosophical literature that divides humanity as a cognitive individual ( res cogitan ) with individuals who are objectivating ( extensal res ) . This difference is in line with its adage cogito ergo sum : I think that I 'm there [ 9 ] . The foundation of this modern worldview places the human position as a central postulate . Human centrality in the modern world makes it easier to objectify reality . But of course , we have understood that there is a lack of argument in the modern world . Modern man deals with himself while at the same time-through technology-his perceptions are changing [ 10 ] . The use of technological instruments on this day is becoming more difficult to sort out . The use of electronic devices is no longer easy not to use . It means there is a thickening of the mutually layered reality between reality and humans . Determinism technology lies in its limits when used by humans [ 11 ] . Using a single device , such as a smartphone can improve the field of human experience . The negative side is the reality of being reduced . The reality in this realm is translated in such a way into the inter-face dish . Users , at the most opium level even merge themselves into cyberspace . The epistemological implications of this stage lead to absurdity [ 9 ] . This reality is first made possible by the data set that exists in cyberspace , and when the individual , through his appliance enters the dimension , it enters into the reality of the image . The reality of the imagery of the real reality . It becomes a reality as far as it represents it virtually and text . The branch 3rd Annual Applied Science and Engineering Conference ( AASEC 2018 ) IOP Publishing IOP Conf . Series : Materials Science and Engineering 434 ( 2018 ) 012280 doi:10.1088/1757-899X/434/1/012280 of this development starts from the internet , extends to AI ( artificial intelligence ) and then VR ( virtual reality ) [ 12 ] . The human position with the instrument is no longer dichotomous and black and white , but fragmentary and absurd . The end of the use of disaggregated instruments began in the early 20th century where advanced machines were invented , including computers and the Internet . The changes that these scientific discoveries allege change the three major ways in human life . These changes include the order of socio-anthropological , science , philosophy and religion [ 13 ] . 4 . Impact of bubble effect filter on religious attitude 4.1 . Virtual religion Along with the development of the era , David Nash reveals one thing , which the face of the changes that occur in the acceleration of technology that has been developed by humans has changed the face of communication . Language , as its pragmatic function is a tool for communicating . But as time passes , especially after what many people say as a communications revolution , language has been radically transformed into a new form [ 13 ] . This form is very numerous , covering all the shifts of developed communication media . In America , in religious studies , the media of information in such a way has changed public opinion and identity . Religious opinion no longer refers to the authority of the church , but the media [ 13 ] . In Indonesia , council such as MUI ( Indonesian Ulama Council ) and religious authority centres in the internet media portal can be said to have a wide-ranging significance . In Europe the most significant dichotomy occurs between free and Christian thinkers . This is why freethinkers have gained legitimacy , especially after the digital communications revolution : in this case the Internet [ 13 ] . Within this portal , freethinkers are very free to explore the possibilities of spreading their ideology . Anyhow , man can now choose his way of life by freely choosing what information he wants to consume .. There are exciting things after the digital information has emerged and received massively , the dichotomy is no longer between Christians / Muslims and atheists or free thinkers . Moreover , the dichotomy has taken place in such a way and has made man fragmented in such a way . This also leads to inequality regarding religious identity . In virtual portals , religious identity 1s no longer based on for example a car bumper , or a keychain- but becomes blurred . Indeed , in the real social level , this identity appears in the way of dressing and perhaps also the choice of eating as it did with Islam . As a result , the face of religion in the internet portal into something that just can be interfered and interpreted by many people . On the website , the identity of the website can indeed be emphasized to capture the public : for example specifically for religious or otherwise . But this kind of censorship does not always work in cyberspace . This means that the synchronization of information is always dominant . Someone with another belief can go in and become a member there . In the end , there is no guarantee whether the media is the media of religious fundamentalists , pluralists and or free thinkers , in the end , they must be willing to one reality : public freedom [ 14 ] . Freedom of will also gets its legitimacy on the internet . If we review history , freedom of speech , identity , thinking , race , religion , have been hegemonized by tyrants who want monoculture regarding identity , thinking , race , religion and voicing . Now that era is no longer applicable in the virtual portal , or the Internet . Similarly , in the case of Religion , the internet has an ever-changing and unpredictable face . For as it is revealed , the level of subjectivity and the will of choice becomes so 'T ' , so any authority in this portal must face that reality . The authority deconstructs and turns into something else . If established religions do not or do not become human models of how they live , dialogue and become civilized ( nonviolent ) societies , then this becomes a gap for the promotion of religious decentralization . The emphasis is on the mentality , way of thinking and religious worldview widely [ 15 ] . 3rd Annual Applied Science and Engineering Conference ( AASEC 2018 ) IOP Publishing IOP Conf . Series : Materials Science and Engineering 434 ( 2018 ) 012280 doi:10.1088/1757-899X/434/1/012280 The impact of internet usage , in addition to influencing the ethical aspect , also affects the individual attitude in Lebenswelt . In advance , we have assumed that there is a tendency to negate the plurality of individuals in an established dogma and tradition . The negation in question is that it is getting increasingly exclusive due to the internet . This exclusiveness takes place as happens in other cultural aspects that have been exacerbated by economic capitalization . In the consumption consumptive habitus model , one tends , or even entirely , to the plurality of the Internet . He will explore various aspects of diversity that exist as far as possible by the internet . Though of course there are divisions , the basic premise of this attitude is the openness of information-as individuals are open to any information . Someone in this mode will not negate the plurality of information from the internet [ 16 ] . Another case when someone enters on the set of information that is doctrinal as religion . As Yasraf disclosed that information technology had provided an easy path for the distribution of religion [ 17 ] . However , when subjects enter the realm of religion , there is an exclusiveness generated from the theological system . The long-term implications of the internet 's exclusivity attitude m this domain are due to doctrinal traits . There are always those who enter through into the cyberspace space when religion is converted : the theological question and the impact of religiosity . Theological issues still deal with the faith field [ 18 ] . Religious attitudes-or exclusively religious attitudes-on the one hand are still the same when religion is attached to the identity of car and clothing stickers ( as we pointed out before ) -as at the same time as a result of Internet expansion or virtual reality-based cyberspace , exclusivity is still inherent - to be plural and open . Of course , this is something that is contrary to the plural nature of the Internet and demanding open . Although economic and political power always plays a role in religious schemes , the result is purely ambivalent when dealing with radical and exclusive attitudes of believers . Any skepticism , just as opposed to the nature of science . The religious dimension , always known as the ethical dimension , always requires that man direct his intentionality not merely to ‘ use ’ , but to moral implications . Moral Hazard , in the economic field , is always wary of . Similarly , the moral dangers posed by the realm of science . Karlina Supelli alludes to this moral danger because-along with our phenomenological experience as an Indonesian man from year to year there is always a consistent tone of religious radicalism triggered by the spread of information flow : in a nutshell , triggered by technology [ 19 ] . The technological properties that dichotomize after becoming plural in the realm of cyberspace return to their dichotomous nature . There is a hyperloop to this effect . We identify it as a technological deterministic inevitability . This nature is always inherent because there is always a feature of anthropology in technology . Not to mention the technology becomes void without me ontologically accompanying it . Of course , human participation as an anthropological feature and the feature of ontology in its interaction with technology 1s always inseparable . 4.2 . Filter bubble effect The premise of the internet stems from the availability of information , the information disclosure , then interconnectivity . Data stacking leads to diversity or plurality . This plurality extends to which the internet can maintain its authentic character . The expectation of the alignment of information , because of the simultaneity conceived by the internet , vis-a-vis with real reality . For m the real-world world , humans no less require this plurality of qualities . This scepticism began to strengthen after Edward Snowden 's case in the United States [ 3 ] . Also , the impact of the Internet on the isolation of the subject increasingly felt . We call this narrowing point of view which is the result of cyber fanaticism . This closed attitude marks a new era of Internet use-the era of subject smelting . The inability of the subject to identify itself as a user or user , as I am transcendent and ontological , causes this fusion . The significant impact of it is that the subject is not aware first of all what happens mechanically on the internet it uses . That on the internet itself changes the basic mechanisms that respond to individual users . The suggestive implications of this Internet mechanism response result in the crystallization of the subject . 3rd Annual Applied Science and Engineering Conference ( AASEC 2018 ) IOP Publishing IOP Conf . Series : Materials Science and Engineering 434 ( 2018 ) 012280 doi:10.1088/1757-899X/434/1/012280 The narrowing point of view in the embodiment of the dichotomy of cyber reality that has had the most significant impact since December 2009 . Eli Pariser , in his critical treatise on the internet The Bubble Filter : What the Internet Is Hiding From You , he outlines some possible schemes of how the internet will be formed and form the user unnoticed [ 3 ] . 4.3 . Implications of religious attitudes Of course , there are some variables and procedures for sorting out the portion and composition to what extent the effect of an internet bubble filter . In the review given by Eli Pariser , at least we find one argument about the fact that democracy is surely the main thrust-especially in America-that supports transparent and plural life . Modern society of the 20th century is well aware of this . However , as we pointed out , in the Internet space , there is a tendency towards narrowing attitudes and perspectives on diversity . In America alone , channels of media dissemination to sensitive issues , especially the 20th century to the 9/11 incident , centre on TV [ 3 ] . Meanwhile , in the next development of the Internet increasingly shifting the position of media distribution channels . In today 's era , we call it the era of media openness . There are nuances of transparency and therefore plural . On the other side , however , the developers of the Internet , with filter protocol narrow the plural idea in the spread of media [ 3 ] . Instead of eradicating the crisis on a global scale , the internet , in turn , became a common threat . At least this becomes one of the things that must be reviewed . Because the threat in the world always interspersed with the matter of justice and intolerant attitude [ 20 ] . Indonesia , as well as America , is based on democracy . But the process of Indonesian democracy does not have the same rhythm as America-even much different . Significant differences that we mention especially when intersecting with religious issues . Post 9/11 , Americans begin to suffer from Islamophobia . To arrive at the terror is certainly needed a strong issue , political power and repeated propaganda . So there is an idea of the personality of the media-there is the terror , there 1s an object , there is an outline . Later , Islamophobia that has been embedded in the minds of some Americans , allegedly become a modality of winning Donal Trump [ 21 ] . Indonesia , of course , has issues of terrorism and religious fundamentalism [ 18 ] , but not until Islamophobia . In a country with an Islamic majority , Islamophobia is not very visible . The issue that dominates Indonesia 's internal friction is a matter of extreme moderate attitudes . As a democratic country , religious extremism is considered an anomaly . Because from the beginning , the basic philosophy of the state is a diversity with a variety of religions by the will and role model respectively . Therefore , pluralism , for Indonesia , an essential modality for the realization of democracy [ 19 ] . Radical ideas in religious attitudes have no place in the space of democracy . But in the reality of the internet-where , everyone now has a smart mobile device-coupled with a possible filter effect , indicates the possibility of a gap for a growing radical attitude [ 3 ] . Eli Pariser explains that there is a substantive difference between Google 's filter code as the largest Internet search engine , with Facebook , as the largest social media channel . We know that the internet records our behaviour in it . It 's just that , in general , if unfiltered , the information will appear to us simultaneously . Filters not only identify who we are but also play a role-not to determinate-as we should [ 22 ] Google installs users with the frequency of clicks as well as the history of any number of pages ever visited . The goal is to make it easier to identify who we are , what we want , and what ads are worth showing to us . While Facebook , identifying our personality is not from the frequency of clicks as google . Rather than the frequency of dividing , `` share '' by an account . Both the filter system used facebook and google implicates the narrowing of perceptions . Religiosity , as it is important in Indonesia , with such filter models is vulnerable to controlled issues . Radical content , hate speech , fanaticism have the potential to break the flow of democracy and erode moderation in religion . The Islamic religion in Indonesia , which is the majority religion of the people , along with the spread of media and radical ideology increases the attitude of fanaticism and radical . It is at this point 3rd Annual Applied Science and Engineering Conference ( AASEC 2018 ) IOP Publishing IOP Conf . Series : Materials Science and Engineering 434 ( 2018 ) 012280 doi:10.1088/1757-899X/434/1/012280 that the significance of media users ' awareness of the dangers of media flows on the one hand and the effect of filter bubbles caused by our behaviour as users . Someone who spread content made in Facebook 's social media channel , for example , will only consume news from the same stream and reproduce it . There are circles of habitus created by the behaviour of account users on their social media pages . This circle is called a bubble . Reality is no longer plural , especially the reality of cyberspace , but singular . This is exactly what internet developers want for their ease , putting aside the bad impact on users . Google users will be directed to the content they once clicked on , regardless of whether the content is valid or not , false or lying [ 3 ] . The internet implications of religious attitudes have a huge gap to improve radical attitudes and intolerant behavior . Because the subject when entering on cyber-space , he will only identify the reality he created himself for his own consumption . This reality is called a bubble . These realities co-exist between one subject and another . In this way plurality is lost in the internet . So our imagery of the stages of internet reality before and after the filter can be seen in figure 1 . @ ' 9- @ a a 2 S- @ ms Figure 1 . A simple overview of the heterogeneity of the subject in the unfiltered internet . In it , There is an impression of plurality . 3rd Annual Applied Science and Engineering Conference ( AASEC 2018 ) IOP Publishing IOP Conf . Series : Materials Science and Engineering 434 ( 2018 ) 012280 doi:10.1088/1757-899X/434/1/012280 Figure 2 . Reality built by filters . Figure 3 . The reality felt by the subject . Despite the possibility of narrowing this perception and the radicalization of religious attitudes on Internet portals , we can still seek solutions . The most fundamental way is to hold a distance-attitude attitude delaying distance with technology . Phenomenologically we can epoche from attachment to technology [ 23 ] [ 3 ] . The next solution that is to restore the user 's awareness position in front of cyber reality . Technically , besides , filters are just protocols that are intended to suit their interests . This means that it has been originally disseminated by code and its purpose-as Google with Facebook . In addition , because of the way filter operations are in the background , it makes it difficult to detect the extent to which we have established self-problem on the internet as well as the extent to which those behaviours shift backwards to form our habitus [ 24 ] . This shift and the simplest of its simplest workings are realized . 3rd Annual Applied Science and Engineering Conference ( AASEC 2018 ) IOP Publishing IOP Conf . Series : Materials Science and Engineering 434 ( 2018 ) 012280 doi:10.1088/1757-899X/434/1/012280 5 . Conclusion The internet impact for users on religious attitudes in Indonesia at least leads to three things : First : the technology in itself is hollow , it 1s always the intermediate voltage as positive or negative with the human subject . Similarly , the fragmentation of reality originated from the subject . Second : human handling of problems in cyberspace is possible as far as technology is always ethically involved in human life . Also , the traditionalism left in Indonesia reduces the ethical impact of media usage . Third : filters and their effects ( bubble effect filters ) increase homogeneous , individual , intolerant tendencies . In relation to religious attitudes , it carries a single , dogmatic tendency-the opposite attitude of plural and tolerant . Acknowledgement We say many thanks to Research and Publication Center of UIN Sunan Gunung Dyati Bandung Indonesia for supporting publication of our research . References [ 1 ] Suler JR 2000 The psychology of cyberspace ( New Jersey : Rider University ) [ 2 ] Piliang Y A 1998 Sebuah Dunia yang Dilipat ( Bandung : Mizan ) [ 3 ] Pariser E The Filter Bubble : What the Internet Is Hiding From You ( New York : the Penguin Press ) [ 4 ] Bakker A and Zubair A C 1990 Metodologi Penelitian Filsafat ( Yogyakarta : Kanisius ) [ 5 ] Barzilai-Nahon K and Barzila1 G 2005 Cultured Technology : The Internet and Religious Fundamentalism /nf ’ Soc . 21 1 p 25-40 [ 6 ] Hesapci Sanaktekin O , Aslanbay Y and Gorgulu V 2013 The Effects of Religiosity on Internet Consumption : A Study on A Muslim Country Information , Commun . Soc . 16 10 p 1553- 1573 [ 7 ] MilesM B and Huberman A M 1992 Analisis Data Kualitatif ( Jakarta : UI Press ) [ 8 ] Descartes R 2000 Diskursus Metode ( Yogyakarta : Ircisod ) [ 9 ] Lin F 2018 Filsafat Teknologi : Don Ihde Tentang Dunia , Manusia dan Alat ( Yogyakarta : Kanisius ) [ 10 ] Ihde D 1990 Technology and the Lifeworld : From Garden to Earth ( Bloomington : Indiana University Press ) [ 11 ] Myerson G 2003 Heidegger , Habermas and the Mobile Phone : Postmodern Encounters ( London : Icon Books Ltd. ) [ 12 ] Champbell H 2006 Religion and The Internet Commun . Res . Trends 25 1 p 1-43 [ 13 ] Nash D 2002 Religious Sensibilites In The Age Of The Internet : Freethought Culture And The Historical Context Of Communication Media in Practicing Religion in The Age of Media : Explorations in Media , Religion and Culture Hoover 8 M and Clark L S Eds ( New York : Columbia University Press ) [ 14 ] Hesapci Sanaktekin O , Aslanbay Y and Gorgulu V 2013 The Effects of Religiosity on Internet Consumption , ” Information , Commun . Soc . 16 10 p 1553-1573 [ 15 ] Flaxman $ 8 , Goel S and Rao J M 2016 Filter Bubbles , Echo Chambers , and Online News Consumption , ” Public Opin . QO . 8081 p 298-320 [ 16 ] Puiliang Y A 2011 Bayang-Bayang Tuhan : Agama dan Imajinasi ( Bandung : Mizan ) [ 17 ] Supelli K 2011 Dari Kosmos Ke Dialog : Mengenal Batas Pengetahuan , Menentang Fanatisme ( Bandung : Mizan ) [ 18 ] Lundby K 2011 Patterns of Belonging In Online/Offline Interfaces of Religion Information , Commun . Soc . 14 8 p 1219-1235 [ 19 ] Greenwald G 2013 NSA collecting phone records of millions of Verizon customers daily The Guardian [ Online ] Available : https : /Awww.theguardian.com/world/2013/jun/06/nsa-phone- records-verizon-court-order . [ Accessed : 02-Apr-2018 ] . [ 20 ] Cadwalladr C and Graham-Harrison E 2018 Revealed : 50 million Facebook profiles harvested 3rd Annual Applied Science and Engineering Conference ( AASEC 2018 ) IOP Publishing IOP Conf . Series : Materials Science and Engineering 434 ( 2018 ) 012280 doi:10.1088/1757-899X/434/1/012280 for Cambridge Analytica in major data breach The Guardian [ Online ] . Available : https : /Awww.theguardian.com/news/2018/mar/17/cambridge-analytica-facebook-influence- us-election [ Accessed : 05-Apr-2018 ] [ 21 ] Ma ’ mun S 2013 Pluralisme Agama dan Toleransi dalam Islam Perspektif Yusuf Al-Qaradhawi Humaniora 4 2 p 1220-1228 [ 22 ] Haim M , Graefe A and Brosius H B 2018 Burst of the Filter Bubble ? Digit . Journal . 6 3 p 330- 343 [ 23 ] Liberati N 2016 Technology , Phenomenology and the Everyday World : A Phenomenological Analysis on How Technologies Mould Our World Hum . Stud . 39 2 p 189-216 [ 24 ] Campbell H 2005 Spiritualising the Internet . Uncovering Discourses and Narratives of Religious Internet Usage Heidelb . J. Relig . Internet 11 p 1-26 Social Communication| 45 Volume 2 ( 2019 ) , pp . 45-52 $ sciendo DOI : 10.2478/sc-2019-0008 HOW FACEBOOK POLARIZES PUBLIC DEBATE IN POLAND - POLISH FILTER BUBBLE Zofia Sawicka ! Abstract The dissemination of the media has led to the phenomenon of the mediatization of social re- ality , which in the era of new media has become dominant , because the new media have infiltrated almost every aspect of human functioning . The surprising paradox of the new media is the fact that on the one hand they give access to almost unlimited information , on the other hand they narrow it down extremely . The modern media user , often without realizing it , “ uses ” only the information that is offered to him by specially selected internet algorithms . Created in this way the so-called “ informa- tion/filter bubble ” condemns him to the only vision of reality - and in the absence of the possibility of verifying his observations what results from the way the new media works - in his opinion the only true one . This is particularly important in creating the vision of social order and the functioning of the state . The mediatisation of Polish social reality - especially in the context of social media - led to the emergence of polarized groups isolated from each other and caused a lack of rational political debate on a number of important social issues . Keywords : Facebook , filter bubble , narcissism , public debate , Polish public opinion INTRODUCTION Both the new and the traditional media are nowadays an extremely important el- ement of human life and an integral part of culture . As a means of communication , as well as a source of behavioral patterns , they have significantly changed the functioning of societies . The number of data in the world is growing very fast . Every year , we produce more data than during the past few years of our history . The access to information is nowadays no longer a problem , the more difficult issue , in the current information over- load , the more its skillful finding . Walter Lipmann already argued in his theory from 1921 that people are unable to the perception of surrounding them extremely complex and complicated reality , which is why in their minds simplified models of the external world are created . Lipmann called it “ images in heads ” , and argued that the dominant role in their creation belongs to the press [ Pyzikowska , 2001 , p. 75 ] . According to Lipmann , information media create cognitive maps of the world , to which the recipients react , cutting off from the reality that is too complicated for the human mind . In this way the mediatization of social reality is created , which , according to Walery Pisarek , is a process 1 Zofla Sawicka- PhD in College of Media and Social Cornmunication at University of |n- formation Technology and Management in Rzeszéw , contact zsawicka @ wsiz.rzeszow.pl , ORCID : 0000-0001-7679-5303 46 of media mediation in exploring the world , influencing the media perception of phenom- ena inaccessible to direct experience , shaping the image of the entire social reality , and even comprehensive social experiences under the influence of media structures [ Pis- arek , 2006 , p. 116 ] . The influence of the media on shaping public opinion is investigated by the theory of agenda setting , which , despite being created over 40 years ago , has not lost its rele- vance . According to this theory , media messages have a huge impact on public opinion , because they determine the information order of the day , deciding about the existence of selected messages in the consciousness of their recipients [ McCombes & Shaw & Weaver , 2014 ] . What is more , the media , through the framing function , give their own interpretation to the presented content . In this way , the media not only tell their users what to think about , but also how to interpret the provided information [ Nowak , Reidel , 2008 , p.180 ] . In the era of the new media , the phenomenon of mediatization has become even more visible , because the new media have penetrated almost every aspect of human life . In the light of conducted research on the impact of the media ( both traditional and new ) on public opinion , it seems that thanks to online media and social media , the agenda-set- ting power of the media has been strengthened . The new media give more possibilities to identify and associate issues and their attributes corresponding to the preferences of the recipient [ Nowak , 2016 ] . In this way , the surprising paradox of the new media starts to be visible . The new media on the one hand give access to almost unlimited informa- tion , on the other they extremely narrow it . The modern media user , often without real- izing it , “ uses ” only the information that is offered to him by specially selected internet algorithms . This phenomenon is clearly visible on one of the most popular social media , i.e . on Facebook . The following article aims to explain how Facebook polarizes public debate in Po- land . The presented conclusions are based on the critical analysis of the discourse of Polish media including social media , mainly Facebook , observations and interviews with Polish students who belong to the generation of digital natives and on the assumptions of intercultural psychology and communication . DIGITAL NATIVES AND FACEBOOK Today ’ s social media have become an undoubted rival of the press or other tradi- tional media in fulfilling the informational function about the world events . This compe- tition is definitely won among the generation of digital natives , for whom social media become the basic source of knowledge about the world . At the end of 2018 , over 2 billion users used Facebook worldwide . Among them , the largest group were people aged 18 to 34 [ Kuchta , 2019 ] . Digital natives are- generally speaking- people who were born in the times of widespread use in the everyday and professional life of the Internet , computers and other devices , treating the Internet as an ordinary element of the world around them . Growing up in the world of new technologies has significantly changed their patterns of communication , processing and consumption of information [ Prensky , 2001 ] . One of the distinguishing features of this generation is narcissism , which in this case is not only about focusing on the physical image ( e.g . placing countless selfies on the web ) , but also on the media consumption model . According to research conducted by Pew Re- search Center , Facebook users ( the vast majority of whom belong to the digital natives ’ generation , about 70 % of them have accounts on this social network [ Statista , 2019 ] ) are looking for information that confirms the validity and the importance of their views . Moreover , they are not willing to speak in the discussion if they are convinced that others do not share their opinions [ Anderson , Camount , 2014 ] . This is how the phenomenon of the egocasting is created , which consists in focusing only on content identical to indi- vidual interests , and omitting information with which he disagrees [ Rosen , 2004/2005 , pp . 51-72 ] . This leads to a situation in which the individual begins to live in a world of their own beliefs without the possibility of their confrontation or verification . The rules of Facebook functioning significantly strengthen this mechanism . FACEBOOK AND FILTER BUBBLE Although Facebook is the most popular social medium , according to Pew Research Center research , as many as % of all users do not know how it works . In this way , the mechanism of personalization the content escapes the attention of users and without their knowledge encloses them in an information bubble [ Hiltin , Rainie , 2019 ] . Every Facebook user , after logging in to the website , notices the so-called newsfeed or wall on which he can see the latest activities of his friends . Their activity is so-called edge . According to the simulation , with having several hundred friends on an account on Facebook , with every login in to the site should appear about 1,500 new edges . In this way the user would be overwhelmed with the number of new information . To facilitate his task , Facebook has created content filtering algorithms that are designed to predict what will interest a given user . The algorithm calculates possible interests based on the user ’ s previous behavior on the website and decides which content will be displayed and which is not , in this way the new phenomenon occurs , in which the information finds the user and not vice versa [ Malinowski , 2016 ] . The first person paying attention to this mechanism was Eli Pariser , an American In- ternet activist . During his speech at the TED conference in 2011 , he used for the first time the term filter bubble , which he defined as “ a personal and unique information universe in which we all live online. ” He reached this conclusion by observing his own Facebook wall , when after clicking on links shared by liberal views friends , he stopped noticing content posted by his more conservative friends . The algorithm of Facebook based on his activity on the portal limited the content that Pariser would consider to be polarizing with his views [ Pariser , 2011 ] . Pariser ’ s remarks were confirmed by Matt Honan from the “ Wired ” magazine , who liked every activity of his friends that appeared on his wall . “ Bemused ” in this way the algorithm stopped displaying content shared by other users , showing only information from brands , which also showed to his friends [ Honan , 2014 ] . Pariser ’ s observations on the principles of Facebook 's operation show the power of this medium in creating and strengthening the narcissistic attitudes of its users who locked in their own filter bubbles , have access to information in accordance with their preferences and likings . In this way , they are cut off from everything that the algorithm deems “ unworthy ” of their interests and freed from the content confronting their views on reality . Thanks to this mechanism , they gain the belief that their point of view is cor- rect and all those who think differently must be wrong . It is worth noting that the algorithms activity does not only cover the interests of Facebook users , although it also in this case deprives them of the possibility of changes . Based on their previous choices , the algorithms offer them similar content , not consider- ing that the taste of each can change . Algorithms also personalize the news that reaches users closing each of them in a separate bubble . Access to other users is conditioned by the convergence of opinions , views or needs . In this way , public discourse is disturbed . FACEBOOK AND PUBLIC OPINION In the world of the new media , the role of a gatekeeper , so far performed by media broadcasters or opinion leaders , has been taken over by algorithms what significantly influenced the shape of modern public opinion . The selection of information , devoid of a human factor , sorts them only according to the rules of importance for the user , not con- sidering what is really important and what is less important for the general public . That leads to the situation where the user sees only the content with which he agrees and comes to the conviction that everyone thinks in the same way . If he meets a person with 47 48 different views , he is convinced that this person must be wrong . Isolating users from content that collides with their points of view leads to the creation of “ digital ghettos ” whose “ residents ” reinforce each other 's beliefs in the validity and importance of their views and consume only information that confirms their opinions [ Szpunar , 2018 ] . At the same time , they are still convinced about choosing independently the content to which they have access . This illusion is further amplified by the confirmation bias our brain is subject to , i.e . the tendency to choose and prefer sources consistent with our worldview [ Kahneman , Tversky , 1979 ] . Thanks to this , we protect ourselves and the conviction that we are right . These opinions and views are strengthened by spreading them through repeated and continuous communication between users who share the same type of thoughts in a closed system , i.e . on social networks . In this way , the echo chamber is created , which in turn leads to the rejection of alternative views and , consequently , to the strengthening of one ’ s own [ Jamieson , Apella , 2010 ] . This situation is extremely conve- nient for the individual , because he is not forced to confront the content with which he does not agree . What is more , his belief that the world is homogeneous grows , because any form of difference is not allowed to his consciousness , which results in the radical- ization of his views . This attitude leads to a state in which users close themselves to an alternative vision of the world , and any confrontation remains only in the declarative sphere [ Szpunar 2018 ] . This situation has a huge impact on public opinion , because it significantly limits public debate , favoring the radicalization and polarization of opposing views . If we add the phenomenon of narcissism to this , then a debate with people with different views than ours will not be possible at all . This way of shaping public opinion is of particular importance in the generation of digital natives , because mainly among them the role of the information medium has been taken over by Facebook . It is also important for those who do not belong to this generation , but who also use social me- dia . Since people are looking for information consistent with their beliefs , they will use those traditional media that share their opinion , Facebook ’ s algorithms will additionally confirm it . In this way , by using various sources of information , they will “ concrete ” in their own views . What was one of the promises of the Internet- the creation of a public sphere that would foster debate and create a consensus , turned out to be not entirely true . The sur- prising paradox of the new media is the fact that on the one hand they give access to almost unlimited information , on the other hand they narrow it down extremely . The modern media user , often without realizing it , “ uses ” only the information that is offered to him by specially selected internet algorithms . Created in this way filter bubble con- demns him to the only vision of reality - and in the absence of the possibility of verifying his observations what results from the way the new media works - in his opinion the only true one . This is particularly important in creating the vision of social order and the functioning of the state which is well illustrated by the example of Polish society and its division into “ two ” functioning parallel Poland . The mediatization of Polish social reality has led to the emergence of isolated groups , whose members - mainly through media activities - have limited opportunities to make choices and make independent decisions . It also caused a lack of rational political debate on a number of important social issues . POLISH FILTER BUBBLE Facebook in Poland is one of the most popular social networking sites . At the end of 2018 , 16,840,000 Poles used it , which accounted for 44.3 % of the total population . Their age range was as follows : 7.6 % between the ages of 13 and 17 years 22 % between the ages of 18 and 24 years 29,1 % between the ages of 25 and 34 years 20,8 % between the ages of 35 and 44 years 10,2 % between the ages of 45 and 54 years 6,4 % between the ages 55 and 64 years [ Gérska , 2018 ] So , itis clearly seen that the generation of digital natives most often uses Facebook , this is particularly important in the face of the fact that for 61 % of all users of this me- dium Facebook is the basic source of news about the events in Poland and in the world [ Statista , 2019 ] . If we compare these data with another survey , it turns out that for older Poles ( 60 years and older ) the main source of knowledge is television ( 90 % ) , while Face- book in the 18-29 age group is a source of information for 58 % of them . The press as a source of the news is in this group in the reverse [ Kolanko , 2019 ] . The situation that emerges from the results of the research presented above has a significant impact on the shape of public debate in Poland . Since Facebook encloses its users in filter bubbles , it means that over 60 % of Poles using this medium do not have reliable knowledge about events in Poland and in the world . They are receiving person- alized information , which on the one hand is very convenient for them , but on the other , from the point of view of social communication and building a public debate , this fact has disastrous consequences . Each of them lives closed in their information bubble and according to it assesses reality . If we assume ( and this is confirmed by the author's observations ) that the Internet , or more precisely Facebook is the only source of infor- mation for young Poles , they have no way of verifying their views , which in turn leads to radicalization of their opinions . Also , those who use television as the main source of in- formation are not free from the filter bubble effect . With the current polarization of news sites in Poland , viewers of individual TV stations or readers of specific titles of weekly opinions will not get a chance to confront their views on the web . The algorithm will pre- pare information for them that will only confirm their views . In this way , there is a huge polarization and radicalization of public debate in Poland , in which there are no rational arguments on important social issues . Politicians also are not free from the filter bubble effect . This is significant because they have a decisive influence on the shape of the public debate and what issues are raised in it . Since politicians have specific views and use social media , it can be assumed that information that does not coincide with their beliefs never reaches them . It can be seen from specific examples , such as during the interview of Rafat Trzaskowski , who was the minister of foreign affairs in the shadow cabinet of Civic Platform . Asked by Konrad Piasecki , the journalist of Radio Zet , he could not answer the question related to the dispute about the Smolensk Monument in New Jersey , despite the fact that this topic was dominant in social media for three days , his filter bubble did not contain this message [ Piasecki , 2018 ] . Probably the algorithm treated this information as related with Law and Justice party what was automatically classified as not corresponding with Trzaskowski ’ s opinion . Another example is the Polish migration policy project , which addresses issues related to refugees or Muslim migrants . This problem was discussed very strongly in public debate . The word “ Islam ” appears 47 times in the document and always in the context of security threats , terrorism and fundamentalism . Almost the en- tire subsection entitled “ Ensuring security in the migration process ” ( over 12 pages ) is devoted to the alleged threat from Islam . No other religious group is singled out in the policy draft in such a way . All Muslims are racialized and portrayed as non-integrated radicals , and if not present , future terrorists . There is no mention of the diversity of Islam and Muslim societies . The authors cite an article from the Catholic far-right website / bimonthly Polonia Christian , which was at the forefront of racism and stigmatization of Muslims in Poland , as well as information from the TVP Info news portal , which present- ed information in a similar tone about Muslims and refugees [ Pedziwiatr , 2019 ] . The au- thors of the document ( they were not undisclosed to the public opinion ) connected with the ruling party , when created this draft , used sources of information available to them , limited by their own filter bubbles . They presented their image of Muslims , convinced of the correctness of their own views . In this way , the debate about such an important 49 50 problem for Poland as the problem of migration is polarized and extremely radicalized . The filter bubble effect in the Polish public debate seems to be strengthened by the Polish national character , which , according to the author , perfectly fits into the activities of social media algorithms . Pawet Boski , a precursor of intercultural psychology , distin- guishes among characteristics of Poles : the lack of social discipline , low level of social trust and sarmatism , which is inseparably connected with the conviction of being unique and always right [ Boski , 2009 ] . Moreover , the tradition of the Polish public debate are the parliaments and councils , which were often dominated by excessive talkativeness , quar- rels and disputes that resulted from the noble pettifogging characteristic for Poles also nowadays . Julian Ochorowicz , a nineteenth-century Polish philosopher , psychologist and publicist , also attributed to the Polish nation partisanship saying that when three Germans gather , they form a union , and three Poles form four parties [ Lewandowski , 2007 ] . All of the above-mentioned features are easily reinforced by the nature of social media . Filter bubble divides the Polish Internet community into groups that can not talk to each other . Social media are conducive to “ excessive talkativeness ” and , as has al- ready been shown in the article , are a great tool for confirming your own uniqueness and infallibility , especially on the assumption that others can not be trusted . While the filter bubble mechanism works similarly around the world , it seems that it can be assumed that its effects may depend on the cultural characteristics of network users . Although digitized reality may have its own culture and rules , then traditions and customs of reality still seem to be the leading force in determining and arranging relationships in virtual environments [ Laurenson , 2014 ] . In this way , according to the author , the polarization and radicalization of the Polish public debate has been strengthened to the maximum . SUMMARY One of the main hopes associated with the emergence and spread of the Internet was its ability to create a public sphere and strengthen democratic debate that will fos- ter consensus . The subsequent stages of the development of this medium showed the deceptiveness of the expectations placed on it . In the era of the dominance of social media , such as Facebook , there is an increasing fear that the Internet actually strength- ens opinion polarization processes , because users interact with like-minded people , and the tendency to personalize information on the web is growing . This technological bias divides the online debate into virtual echo chambers in which the user hears only the in- formation with which he agrees . In this way , the possibility of public debate is extremely limited . The phenomenon of polarization of views is observed all over the world . Never before has it been so easy to conflict entire societies . According to Philip Zimbardo , polarization of the community to such an extent is a new phenomenon that will deepen . Zimbardo argues it is because of the loss of true communication skills , which occurred as a result of the development of new technologies [ Suchan , 2019 ] . The impact of the filter bubble on the polarization of public debate is particularly evident in Poland . Algorithms of social media “ strengthened ” by the national nature of Poles divided Polish society into at least “ two ” functioning parallel Poland . To remedy this , media education is needed in Poland . Hopefully , thanks to it Poles will be able to leave their information bubbles and , on the basis of diverse information , conduct a ra- tional public debate . Awareness of filter bubbles is the first step to leave them . It is hard to disagree with Goethe , who said : “ None are more hopelessly enslaved than those who falsely believe they are free ” . The time will show , what the future will bring . References ANDERSON M. , CAUMONT A . ( 2014 ) , How social media is reshaping the news , Pew Research Center , [ online : September 10 , 2019 ] , httos : //www.pewresearch.org/fact-tank/2014/09/24/how-social-media-is-reshaping- news/ BOSKI P , , ( 2009 ) , Kulturowe ramy zachowah spotecznych , Warszawa , PWN . GORSKA Z. , ( 2019 ) , Polscy uzytkownicy social media na koniec 2018 : Messenger i Instagram rosty szybciej niz Facebook , [ online : 20 September , 2019 ] , https : //napoleancat.com/pl/blog/polscy-uzytkownicy-social-me- dia-na-koniec-2018-messenger-i-instagram-rosna-szybciej-niz-facebook/ HILTIN P. , RAINIE L. , ( 2019 ) , Facebook Algorithms and Personal Data , Pew Research Center , [ online : 10 Octo- ber 2019 ] , https : //www.pewresearch . org/internet/2019/01/16/facebook-algorithms-and-personal-data/ HONAN M. ( 2014 ) , | liked everything | saw on Facebook for two days . Here ’ s what it did to me , , WIRED ” , [ online : 10 September 2019 ] , htto : //www.wired.com/2014/08/i-liked-everything-i-saw-on-facebook-for-two-daysheres- what-it-did-to-me JAMIESON K.H. , CAPPELLA J.N . ( 2010 ) , Echo Chamber : Rush Limbaugh and the Conservative Media Estab- lishment , Oxford , Oxford University Press . KAHNEMAN D. , TVERSKY A . ( 1979 ) , Prospect Theory : An Analysis of Decision under Risk , , Econometrica ’ , XLVII ( 1979 ) , p. 263-291 . KOLANKO M. , ( 2019 ) , Sondaz : Glownym Zrddtem wiedzy cla Polakow jest telewizja , , Rzeczpospolita ’ , [ online : 15 Septeber , 2019 ] , https : //www.rp . pl/Mecia/190429917-Sondaz-Glownym-zrodlem-wiedzy-dla-Polakow-jest- telewizja.html KUCHTA M. , ( 2019 ) , Ilu uzytkownikow korzysta z sieci i social media w 2019 roku ? , SocialPress , [ online : 4 Sep- tember 2019 ] , https : //socialpress.pl/2019/02/ilu-uzytkownikow-korzysta-z-sieci-i-sacial-media-w-201 9-roku LAURENSON L. , ( 2014 ) , Culture ’ s impact on social media adoption , [ online:20 September 2019 ] , https : //www . oreilly.com/ideas/cultures-impact-on-social-media-adoption LEWANDOWSKI E. , ( 2007 ) , Co wiemy o charakterze Polakdw ? , , Polityka ’ , [ online : 10 October 2019 ] , https : // www . polityka.pl/tygodnikpolityka/spoleczenstwo/216105,2 , co-wiemy-o-charakterze-polakow . read ? page=528- moduleld=4686 MALINOWSKI B. , ( 2016 ) , Jak Facebook zamyka nas w barice informacyjnej . Algorytm filtrujacy newsfeed a zjawisko filter bubble , , Zarzadzanie mediami ’ ” , Tom 4 ( 1 ) 2016 , pp . 15-22 . MCCOMBES M.E. , SHAW D.L , WEAVER D.H. , ( 2014 ) , New directions in agenda-setting theory and research , “ Mass Communication and Society ’ , Vol . 17 , nr 6 . NOWAK E. , RIEDEL R. , ( 2008 ) , Agenda setting , priming , news framing . Analiza pordwnawoza telewizyjnych audycji informacyjnych TVN i TVP1 w okresie kampanii przedwyborczych w Polsce 2005 i 2007 r. , , Zeszyty Prasoznaweze ’ , nr 1-2 . NOWAK E. , ( 2016 ) , Teoria agenda-setting a nowe media , , Studia Medioznawcze ’ , 3 ( 66 ) , pp . 11-24 . PARISER E. , ( 2011 ) , Beware online “ filter bubbles ” , , TED ” , [ online : 10 September 2019 ] , http : //www.ted.com/ talks/eli_pariser_beware_online_filter_oubbles PEDZIWIATR K. , ( 2019 ) , The new Polish migration policy — false start , openDemocracy , [ online : 1 September 2019 ] , httos : //www.opendemocracy.net/en/can-europe-make-it/the-new-polish-migration-policy-false-start/ ? f- dclid=lwAR1nc-4PTgaBCl-ow660PnNKjuqiBQbahH_SWLOrjaz3imKWDEIAu_dCHw PIASECKI K. , ( 2018 ) , Gosé Radia Zet : Rafat Trzaskowski , [ online ; 3 September 2019 ] , httos : //www.radiozet . ol/Radio/Programy/Gosc-Radia-ZET/Rafal-Trzaskowski-Jezeli-PK W-powie-ze-nie-wolno-czegos-robic-zastosu- je-sie PISAREK W . ( ed . ) , ( 2006 ) , Stownik terminologii mecialnej , Krakow , Universitas . PRENSKY M. , ( 2001 ) , Digital Natives , Digital Immigrants , [ online : 4 July 2019 ] , httos : //www.marcprensky.com/ writing/Prensky % 20 % 20Digital % 20Natives , % 20Digital % 20|mmigrants % 20- % 20Part1 .pdf PYZIKOWSKA A. , ( 2001 ) , Teoria agenda-setting i jej zastosowanie , [ in : ] Dobek-Ostrowska B . ( ed . ) , Nauka o komunikowaniu . Podstawowe orientacje teoretyczne , Wroctaw , Wydawnictwo Uniwersytetu Wroctawskiego . ROSEN CH . ( 2004/2005 ) . The Age of Egocasting , “ The New Atlantis ’ , vol.7 , 9.51-72 , [ online : 10 September 2019 ] , https : //www.thenewatlantis.com/publications/the-age-of-egacasting Statista , ( 2019 ) , Distribution of Facebook users worldwide as of October 2019 , by age and gender , [ online : 2 November 2019 ] , https : //www.statista.com/statistics/376128/facebook-global-user-age-cistribution/ Statista , ( 2019 ) , Main sources of news content in Poland in 2016 and 2018 , [ online : 2 November 2019 ] , https : // 51 52 www . statista.com/statistics/980473/poland-news-sources/ SUCHAN M. , ( 2019 ) , Philip Zimbardo : Stworzenia spoteczne mile widziane-wywiad , [ online : 22 November 2019 ] , https : //fakty.interia.pl/wywiady/news-philip-zimbardo-stworzenia-spoleczne-mile-widziane , nlc,3349089 SZPUNAR M. , ( 2018 ) , Kancepcja banki filtrujacej a hipernarcyzm nowych medidw , , Zeszyty Prasoznawcze ’ , T.61 , nr 2 ( 234 ) , pp . 191-200 . Purdue University Purdue e-Pubs Charleston Library Conference Relevancy Redacted : Web-Scale Discovery and the “ Filter Bubble ” Corey Davis Royal Roads University , corey.4davis @ royalroads.ca Follow this and additional works at : https : //docs . lib.purdue.edu/charleston An indexed , print copy of the Proceedings is also available for purchase at : http : //www.thepress.purdue.edu/series/charleston . You may also be interested in the new series , Charleston Insights in Library , Archival , and Information Sciences . Find out more at : http : //www.thepress . purdue.edu/series/charleston-insights-library-archival- and-information-sciences . Corey Davis , `` Relevancy Redacted : Web-Scale Discovery and the “ Filter Bubble ” ( 2011 ) . Proceedings of the Charleston Library Conference . http : //dx.doi.org/10.5703/1288284314965 This document has been made available through Purdue e-Pubs , a service of the Purdue University Libraries . Please contact epubs @ purdue.edu for additional information . Relevancy Redacted : Web-Scale Discovery and the “ Filter Bubble ” Corey Davis , Technical Services Librarian , Royal Roads University Library Abstract : Web-scale discovery has arrived . With products like Summon and WorldCat Local , hundreds of millions of articles and books are accessible at lightning speed from a single search box via the library . But there 's a catch . As the size of the index grows , so too does the challenge of relevancy . When Google launched in 1998 with an index of only 25 million pages , its patented PageRank algorithm was powerful enough to provide outstanding results . But the web has grown to well over a trillion pages , and Google now employs over 200 different signals to determine what search results you see . According to Eli Pariser , author of `` The filter bubble : what the internet is hiding from you '' ( Penguin , 2011 ) , a growing number of these signals are based on what Google knows about you , especially your web history ; and , according to Pariser , serving up information that 's `` pleasant and familiar and confirms your be- liefs '' is becoming increasingly synonymous with relevancy . This session will critique Pariser 's concept of the ‘ filter bubble ’ in terms of collection development and the possible evolutions of discovery layers like Summon and WorldCat Local , and the challenge of providing relevant academic research results in a web-scale world where stu- dents increasingly expect the kind of personalization sometimes at odds with academia 's adherence to privacy and intellectual freedom . The following is a critique of Eli Pariser ’ s The filter bubble : What the Internet is hiding from you ( 2011 ) , and attempts to capture the conversational nature of the presentation as given at the Charles- ton Conference in 2011 . Not that long ago , when different people searched Google , if they used the same search terms , they got the exact same search results . Not anymore . When you search Google ( “ Technology overview ” , n.d. ) , over 200 signals determine relevancy , includ- ing location , and—if you ’ re logged into your Google account , or you allow your browser to accept cook- ies from Google—previous search history . Two people can get two totally different results sets based on the same key words , and increasingly , these results are determined—at least in part—on what you ’ ve searched for and clicked on before . The rewards for this kind of personalization are bet- ter relevancy , but the challenges are that we will increasingly see results based on what we ’ ve looked at before , creating a kind of ‘ filter bubble ’ that iso- lates us from resources we might not otherwise see . The concept of a filter bubble is fairly straightfor- ward as presented by Eli Pariser in his TED talk Be- ware online ‘ filter bubbles ’ , which has received around a million views on the TED talks website . As web companies strive to tailor their services { including news and search results ) to our per- sonal tastes , there 's a dangerous unintended 556 Charleston Conference Proceedings 2011 consequence : We get trapped in a `` filter bub- ble '' and do n't get exposed to information that could challenge or broaden our worldview . ( TED , 2011 ) In 2009 , Google started tailoring search results for all users—whether signed into their Google Accounts or not—based on their previous activities on the web . A wide range of websites increasingly use similar algo- rithms to guess what information a user wants based on what they know about that user , such as their location , previous click behavior , and search history . This kind of personalization is fairly obvious at web- sites like Amazon and Netflix , but it can be much more subtle on sites like Google and Facebook . The net result , however , is the same . Websites present only the information which is , in a way , similar to information previously consumed by a user . Accord- ing to Pariser , people in the filter bubble are not as exposed to contradictory perspectives and can , as a result , become intellectually isolated in ways that threaten their ability to meaningfully take part ina society full of uncomfortable truths . But what does this all have to do with Libraries and their collections ? | work at Royal Roads University ( RRU ) in Victoria , British Columbia . We have about 2000 full-time equivalent ( FTE ) students but we ’ re pursuing growth aggressively , particularly in the realm of international undergraduate students , and we expect our numbers to rise significantly in Copyright of this contribution remains in the name of the author ( s ) . DOI : http : //dx.doi.org/10.5703/1288284314965 the coming years . Right now we focus mostly on graduate programs at the Master ’ s level , delivered mostly online via Moodle . RRU was established by the provincial government in 1995 , and took up quarters in an old military college . We have a rela- tively small print collection , with the focus being on our collection of ebooks and article databases . So while we have more and more students spend- ing time with us on campus , people mostly access our collections online . The Internet Archive ’ s Wayback Machine http : //www.archive.org/web/web.php is a wonder- ful resource . | can use it to see what our library website http : //library.royalroads.ca looked like over a decade ago . | can see that we linked to our local catalog and an alphabetical list of article and re- search databases , with a rudimentary attempt to classify them by program or subject . By 2006 we started organizing things a little differently and placed a catalog search box on the homepage , but we still were experiencing the basic problem of in- formation silos , where that multiple databases con- taining high-quality and highly sought-after content dispersed across dozens and dozens of different systems and platforms , with no way to effectively search across them all . For books and video , a user had to search the catalogue . For articles , they needed to choose one of many article databases . To help with this , we started creating subject guides . We also did our part during information literacy instruction to help make sense of this complex in- formation environment . We were suffering from three main issues , as iden- tified by Burke ( 2010 ) : 1 . Noclear and compelling place to start re- search . 2 . No easy way to identify appropriate library resources . 3 . A lack of awareness of library resources . Try using the Wayback Machine to look at Google ’ s homepage in 1998 , the year the company was founded . There are no lists . The interface is easy and intuitive to use . These are the same qualities that draw us to Google today . While our library has gone through three or four major website revamps in an attempt to help our users navigate and use our resources , Google ’ s main search site has re- mained remarkably stable . In 1998 Google co-founders Larry Page and Sergey Brin published an article called The anatomy of a large-scale hypertextual web search engine ( Brin & Page , 1998 ) . At this time , ‘ human curation ’ was a major way that companies like Yahoo ! helped peo- ple access information on the web , through the creation of directories and other lists . Page and Brin recognized that the web was growing too fast for this kind of organization to continue in a sustainable manor . Human editors simply couldn ’ t keep up . In 1999 , according to Danny Sullivan ( 2008 ) at Search Engine Land , a majority of major search engines were still presenting human-powered results . But these lists were expensive to create and they didn ’ t scale to what the web was becoming . Lists and di- rectories also didn ’ t deal well with obscure topics : “ Human maintained lists cover popular topics effec- tively but are subjective , expensive to build and maintain , slow to improve , and can not cover all esoteric topics ” ( Brin & Page , 1998 , p. 107 ) . Google ’ s creators knew humans could not organize the web effectively as it scaled , and that this organi- zation had to be automated . One of the biggest challenges they faced was the unstructured nature of web documents , in contrast to the kind of data libraries were dealing with , such as MARC records . The web was a jumble of different shapes and sizes , not a structured catalog of information based on well-established metadata standards . “ The web is a vast collection of completely uncontrolled hetero- geneous documents ” ( Brin & Page , 1998 , p. 111 ) . At this point in the history of the web , Google ’ s basic key to its rapid success was the PageRank al- gorithm , which was powered by the nature of hy- perlinks , rather that primarily by the occurrence of keywords in a particular document . PageRank relies on the uniquely democratic na- ture of the web by using its vast link structure as an indicator of an individual page ’ s value . In essence , Google interprets a link from page A to page B as a vote , by page A , for page B . But , Google looks at considerably more than the sheer volume of votes , or links a page receives ; for example , it also analyzes the page that casts the vote . Votes cast by pages that are them- End Users/Usage Statistics 557 selves “ important ” weigh more heavily and help to make other pages “ important. ” Using these and other factors , Google provides its views on pages ’ relative importance . ( Sullivan , 2007 ) Using the relationship between documents to drive relevancy was the key to Google ’ s success . Relevan- cy was about relationships . Editors couldn ’ t build directories fast enough to meaningfully provide ac- cess to the whole of the web . We have built a large-scale search engine which addresses many of the problems of existing sys- tems . It makes especially heavy use of the addi- tional structure present in hypertext to provide much higher quality search results . ( Brin & Page , 1998 , p. 108 ) Although many of our individual systems at aca- demic libraries have robust search capabilities , we couldn ’ t until very recently bring these systems to- gether in a meaningful and easy-to-use way . Search has come a long way since 1998 . Google now in- dexes over a trillion pages , all accessible from a sin- gle search box . User expectations are very different now that they were in the late 1990s and early 2000s . When people search , they expect Google , not Yahoo ! circa 1998 , which is how many academic library websites are still organized . And because many libraries still have websites that arguably ha- ven ’ t in essence changed that much since the early 2000s , academic librarians rightly intuit that people are not finding our content and services as easily as they might : In a 2009 survey of 66 academic libraries , ProQuest found that 86 percent of libraries feel that faculty and students do not understand the breadth of their collections , and 94 percent think the collections are not explored to their fullest . ( Burke , 2010 ) . Now , we actually have the tools to take us there . At RRU , we are using the web-scale discovery service called Summon from Serials Solutions . According to Serials Solutions : Through one simple search to a single unified index , the Summon service provides instant ac- cess to the breadth of authoritative content 558 Charleston Conference Proceedings 2011 that 's the hallmark of great libraries . No need to broadcast searches to other databases —it provides one search box for a researcher to en- ter any terms they want and quickly get credi- ble results in one relevancy ranked-list . ( ProQuest , 2011 ) This is not federated or broadcast searching , where queries are sent live to disparate systems and tech- nology such as screen scraping is used to collocate results . This is different . Summon is a pre-built index , just like Google . It searches ebooks , books , videos , theses , articles , and more , and in most cases , it searches the full-text . It is lightning-quick and really big , with a current index of over 500 million items . And it ’ s that “ really big ” that brings us back to the filter bubble . Pariser starts his book out mentioning a post on the official Google blog from the 4th of December , 2009 : Today we 're helping people get better search results by extending Personalized Search to signed-out users worldwide , and in more than forty languages . Now when you search using Google , we will be able to better provide you with the most relevant results possible . For ex- ample , since | always search for [ recipes ] and often click on results from epicurious.com , Google might rank epicurious.com higher on the results page the next time | look for recipes . Other times , when I 'm looking for news about Cornell University 's sports teams , | search for [ big red ] . Because | frequently click on www.cornellbigred.com , Google might show me this result first , instead of the Big Red soda company or others . ( Horling & Kulick , 2009 ) Google states that : “ By personalizing your results , we hope to deliver you the most useful , relevant information on the Internet. ” ( Horling & Kulick , 2009 ) Everybody understands that search engines are a big deal . They 've changed the way we think about information . They bring the world to us . But this change was big , even in terms of Google . Danny Sullivan ( 2009 ) of Search Engine Land called it “ ... the biggest change that has ever happened in search engines ... ” According to Sullivan ( 2009 ) , “ until now , search engines have largely delivered the same re- sults to everyone . Two different people could search for Barack Obama and get back the same set of results. ” The days of “ normal ” search results that every- one sees are now over . Personalized results are the “ new normal , ” and the change is going to shift the search world and society in general in unpredictable ways . ( Sullivan , 2009 ) This post very well could have formed the genesis for the filter bubble idea . According to Pariser ( 2011 ) : “ with little notice or fanfare , the digital world is fundamentally changing. ” ( p. 6 ) . Once an anonymous medium where anyone could be any- one , the web has become a tool for soliciting and analyzing our personal data . For example , diction- ary.com , according to Pariser , places over 200 track- ing cookies and beacons on your computer when you first visit the site . Search for the word “ depres- sion ” on this website , and you could see ads for anti-depressants on another . “ The race to know as much as possible about you has become the central battle of the era for Internet giants like Google , Fa- cebook , Apple , and Microsoft. ” ( Pariser , p. 6 ) The more personally relevant their information offerings are , the more ads they can sell , and the more likely you are to buy the products they are offering . And it works ! Amazon was a pioneer of personalization . The company recorded revenues of $ 24.5 billion during 2009 , an increase of 27.9 % over 2008 . ( Datamonitor , “ Amazon , Inc. ” , 2011 ) . It makes bil- lions by , in great part , predicting what you ’ re going to buy . And for Google , the more relevant the re- sults , the better they can target ads , the more money they make . Advertising is , to understate it , a big deal for Google . Google made almost $ 30 billion in 2010 , up 24 % from 2009 ( Datamonitor , “ Google , Inc. ” , 2011 ) . 96 % of that revenue comes from ads . According to Pariser , if personalization was all about advertising , that wouldn ’ t be so bad , but it ’ s effecting how in- formation flows on the web . If you get your news from Facebook ( and , according to Pariser , 36 % of Americans under 30 get their news from social net- working sites ) , you may only see the things that your friends like . This is Pariser ’ s central critique . .. these engines create a unique universe of in- formation for each of us—what | call the filter bubble—which fundamentally alters the way we encounter ideas and information . ( Pariser , p. 9 ) But why do we personalize ? Too much information leads to what blogger Steve Rubel ( 2007 ) calls “ at- tention crash ” . Personalization helps search provid- ers filter through truly massive amounts of infor- mation need to get to what the user wants . If search results are not personalized , it ’ s much more difficult for a search engine to determine what a particular user wants . And the signals users send are pretty pathetic . “ A number of studies have shown that a vast majority of queries to search en- gines are short and under-specified and users may have completely different intentions for the same query. ” ( Qiu & Cho , 2006 , p. 1 ) According to Jansen , Spink , and Saracevic ( 2000 ) , who analyzed over one million Web queries by users of the Excite search engine : “ we found that most people use few search terms , few modified queries , view few Web pages , and rarely use advanced search features. ” ( p. 233 ) The mean number of words per query was 2.21 . 31 % of all queries used only a single word . Most users searched for only one query and did not fol- low with successive searches . Silverstein , Marais , Henzinger , and Moricz ( 1999 ) analyzed an AltaVista Search Engine query log consisting of approximately 1 billion entries for search requests over a period of six weeks . This represents almost 285 million user sessions . They found that the average number of terms in a query was 2.35 . For 85 % of the queries only the first result screen is viewed . 77 % of the sessions contain only one query . Another project ( Wang , Berry , & Yang , 2003 ) analyzed 541,920 user queries submitted to and executed in an academic website during a four-year period , and found that 38 % of all queries contained only one term , with a mean query length of two words . And analysis of Elsevier ’ s ScienceDirect platform ( Ke , Kwakkelaar , Tai , & Chen , 2002 ) revealed that “ approximately 85.2 % of queries contained one , two , or three terms , although the average query length was 2.27 terms. ” ( p. 275 ) Personalization can make search more relevant when queries are generally short and ambiguous . According to Qiu and Cho ( 2006 ) , “ ... a user 's general preference may help the search engine disambigu- ate the true intention of a query. ” ( p. 727 ) Matthijs and Radlinski ( 2011 ) examined personalizing web End Users/Usage Statistics 559 search using long term browsing history and found that “ ... personalization techniques significantly outperform both default Google ranking and the best previous personalization methods. ” ( p. 34 ) So , when Google personalizes , they are interested in increasing the relevance of search results , and this is based on sound evidence . Personalization truly does increase relevancy . When you search using Google , you get more relevant , useful search results , recommenda- tions , and other personalized features . By per- sonalizing your results , we hope to deliver you the most useful , relevant information on the In- ternet . ( Google , 2011 ) Google looks primarily at search history . If you ’ re signed in to a Google account , Web History is used , and if you are signed out , Google ’ s servers link to an anonymous browser cookie that tracks your click history for up to 180 days ( Google , 2011 ) . This is a big problem for Pariser : “ what you ’ ve clicked on in the past determines what you see next. ” ( Pariser , p. 16 ) This can lead to something he calls informational determinism : “ in the filter bub- ble , there ’ s less room for the chance encounters that bring insight and learning. ” ( p. 11 ) Pariser spends a good deal of time on the importance of serendipity . He argues quite convincingly that crea- tivity and new ideas and the solutions to our most intractable problems come from chance encounters with new or challenging people and ideas . The filter bubble threatens this . It ’ s something that librarians and many scholars recognize the importance of too . There is a certain irony here . Before PageRank , search results could be humorously irrelevant , and the balance between locating relevant resources and discovery through serendipity was skewed to the side of chance encounters . Google has worked hard since 1998 to lessen these kinds of chance en- counters , as mentioned in Brin and Page ’ s 1998 pa- per : “ While the results are often amusing and ex- pand users ‘ horizons , they are often frustrating and consume precious time. ” ( Brin & Page , 1998 , p. 116 ) The need for more relevant results in order to in- crease advertising revenue in great part drove Google ’ s move to personalization . Danny Sullivan from Search Engine Land , when writing about this 560 Charleston Conference Proceedings 2011 move , used a Library metaphor to describe how it could work , and hinted at how informational per- sonalization was done at libraries in a time before Google and other search engines : Imagine you ’ re in a library—the classic meta- phor for a search engine and how it interacts with a searcher , from when WebCrawler ’ s Brian Pinkerton used to explain how they worked back in the 1990s . Someone walks in and says “ travel. ” In a library , the librarian would ask more questions , to try and understand what they want . Early search engines didn ’ t do this . They couldn ’ t do this ! Over time , search engines tried to do the li- brary-style conversation by offering related searches , as a way to get searchers to refine their queries . Then Google took a huge leap last year by making use of your previous query to refine your results . That makes sense and doesn ’ t seem to require any particular reason to ask for user opt-in . Again , imagine the librar- ian . It would be unreasonable to expect them to forget the last thing you said in a conversa- tion you were having , as they tried to help you . Unreasonable and unhelpful . But would you expect the librarian to help you by remembering everything you ’ d asked over a half-year period ? That might be helpful , sure , but it might also be eerie . But this is what Google is doing now . It remembers everything you ’ ve searched for over 180 days , and it uses that in- formation to customize your results . To alert you about this huge change , it made a blog post on Friday afternoon . That ’ s it . ( Sullivan , 2009 ) So , in some ways , Sullivan is making a connection here . Google is attempting to automate what librari- ans have always done , which is to use human judg- ment and experience to mediate access to scholarly works and other kinds of information . According to Jane Burke ( 2010 ) , Vice-president of ProQuest : Increasingly , libraries are viewed as irrelevant to the research process , leaving them vulnerable to being cut , both financially and from the mind of the end user . However , new ways of discovering content in library collections holds the promise of returning the researcher to the library . For this reason , tools like Summon hold great prom- ise : “ web scale discovery efforts aim squarely at Google as the competitor and mimic that search engine ’ s characteristics of simple , easy , fast. ” ( Burke , 2010 ) It has taken a while to settle in with Summon , but for the most part , our users at RRU are happy with this new and important tool . Initially , relevance was a bigger problem than it is now . Could Summon search results be personalized using cookie technology similar to that employed by Google to track users ’ past click history ? Should we employ this kind of technology ? In a 2002 thought- peice , Surprenant and Perry wrote : Being able to see the student allows the Cybrar- ian , with the aid of a diagnostic algorithm which has access to their infoprofiles , to help gauge how comfortable/secure the student is with the current skill set and to gain some insight into the level of his/her developing abili- ties/capabilities . Does the future really hold a spot for a human be- ing—a librarian—to access an ‘ infoprofile ’ of a par- ticular individual in order to help them find the best information available ? Does this kind of mediation of experience have a place in a world where com- plex personalization algorithms could hypothetically determine relevant without our help ? What is the benefit to our users in having to interact with us , rather than an online search tool ? Surprenant and Perry ( 2002 ) also envision a high- level of personalization in the future : “ Communi- cating through Virtual Reality helmets and V-mail , and utilizing diagnostic tools to customize resources to individual profiles , cybrarians will provide effective support for problem solving and discovery groups. ” These are important concepts to ponder . They strike at the tension within academic libraries that disintermediation represents , where systems be- come usable enough—even in the face of increasing complexity—that reference and instruction are seen as less and less important . Pariser ends his book with a call to ‘ algorithmic lit- eracy ’ , which means understanding the basic oper- ating principles of the systems you rely on for in- formation . Librarians can and should play a greater role in explaining not only the information land- scape for scholarly and other resources relevant to students and faculty , but how the systems most commonly used to gather information actually work , both in terms of benefits and risks . References Brin , S. , & Page , L. ( 1998 ) . The anatomy of a large- scale hypertextual web search engine . Computer Networks and ISDN Systems , 30 ( 1-7 ) , 107-117 . Burke , J . ( 2010 ) . Discovery versus disintermediation : The new reality driven by today ’ s end-user . Paper presented at the VALA2010 : Connec- tions , Content , Conversations , 15th Biennial Conference and Exhibition , Melbourne , 9- 11 . Retrieved from http : //www.vala.org.au/vala2010/papers2 010/VALA2010 57 Burke Final.paf . Datamonitor . ( 2011 ) . Amazon , inc. Datamonitor Report . Retrieved from http : //search.ebscohost.com.ezproxy.royal roads.ca/login.aspx ? direct=true & db=dmhc o & AN=2B52E1D8-E964-4D7F-8B1B- C48DBC97815F & site=bsi-live Datamonitor . ( 2011 ) . Google , Inc. Datamonitor Re- port . Retrieved from http : //search.ebscohost.com/login.aspx ? di rect=true & db=dmhco & AN=5B199F61- 608D-4923-B4A3-FS5EE15285ADE & site=bsi- live Google . ( n.d. ) . Technology overview . Retrieved from http : //www.google.com/about/corporate/ company/tech.html . Google . ( 2011 ) . Personalized search basics . Re- trieved from http : //support.google.com/accounts/bin/a nswer.pyPhl=en & answer=54041 , Hoeber , O. , & Massie , C. ( 2010 ) . Automatic topic learning for personalized re-ordering of web search results . Advances in Intelligent Web Mastering-2 , 105-116 . Retrieved from End Users/Usage Statistics 561 http : //www.cs.mun.ca/~hoeber/download { 2009 awic_misearch.pdf . Horling , B. , & Kulick , M. ( 2009 ) . Personalized search for everyone . Retrieved from http : //googleblog.blogspot.com/2009/12/p ersonalized-search-for-everyone.html Jansen , B. J. , Spink , A. , & Saracevic , T. ( 2000 ) . Searching the web : The public and their queries . Journal of the American Society for Information Science and Technology 52 ( 3 ) , 226-234 . Ke , H. , Kwakkelaar , R. , Tai , Y. , & Chen , L. ( 2002 ) . Exploring behavior of e-journal users in sci- ence and technology : Transaction log anal- ysis of Elsevier 's ScienceDirect OnSite in Taiwan . Library & Information Science Re- search , 24 ( 3 ) , 265-291 . Matthijs , N. , & Radlinski , F. ( 2011 ) . Personalizing web search using long term browsing histo- ry . Paper presented at the Proceedings of the Fourth ACM International Conference on Web Search and Data Mining , 25-34 . Re- trieved from http : //research.microsoft.com/pubs/13993 3/MatthijsRadlinski_WSDM2011.pdf . Pariser , E. ( 2011 ) . Filter bubble : What the internet is hiding from you . New York : Penguin Press . ProQuest . ( 2011 ) . The Summon™ Service . Retrieved from http : //www.serialssolutions.com/discovery /summon/ Qiu , F. , & Cho , J . ( 2006 ) . Automatic identification of user interest for personalized search . Paper presented at the Proceedings of the 15th International Conference on World Wide Web , 727-736 . Retrieved from http : //oak.cs.ucla.edu/~cho/papers/qiu- ui.pdf . 562 Charleston Conference Proceedings 2011 Rubel , S. ( 2007 ) . The attention crash : A new kind of Dot-Com bust . Retreived from http : //adage.com/article/steve- rubel/attention-crash-a-kind-dot- bust/117325/ . Silverstein , C. , Marais , H. , Henzinger , M. , & Moricz , M. ( 1999 ) . Analysis of a very large web search engine query log . Paper presented at the ACM SIGIR Forum , 33 ( 1 ) 6-12 . Sullivan , D. ( 2008 ) . Search 4.0 : Social search engines & putting humans back in search . Retrieved from http : //searchengineland.com/search- 40-putting-humans-back-in-search-14086 Sullivan , D. ( 2007 ) .What is Google PageRank ? A guide for searchers & webmasters . Re- trieved from http : //searchengineland.com/what-is- google-pagerank-a-guide-for-searchers- webmasters-11068 . Sullivan , D. ( 2009 ) . Google ’ s personalized results : The “ new normal ” that deserves extraordi- nary attention . Retrieved from http : //searchengineland.com/googles- personalized-results-the-new-normal- 31290 . Surprenant , T. T. , & Perry , C. A . ( 2002 ) . The Aca- demic Cybrarian in 2012 : A Futuristic Essay . Retrieved from http : //www.docstoc.com/docs/15482044/ Full-Text -- -Alphafduedu . TED . ( 2011 ) . Eli Pariser : Beware online `` filter bub- bles '' . Retrieved from http : //www.ted.com/talks/eli_pariser_bew are_online filter _bubbles.html . Wang , P. , Berry , M. W. , & Yang , Y . ( 2003 ) . Mining longitudinal web queries : Trends and pat- terns . Journal of the American Society for Information Science and Technology , 54 { 8 ) , 743-758 . Association for Information Systems AIS Electronic Library ( AlSeL ) : Al and Semantic Technologies for Intelligent AMCIS 2020 Proceedings Information Systems ( SIGODIS ) Aug 10th , 12:00 AM Leveraging Cross Domain Recommendation Models to Alleviate Filter Bubble Problems Jianshan Sun Hefei University of Technology , sunjs9413 @ hfut.edu.cn Jian Song Hefei University of Technology , 775301251 @ qq.com Yuanchun Jiang School of Management , Hefei University of Technology , ycjiang @ hfut.edu.cn Yezheng Liu School of Management , Hefei University of Technology , liuyezheng @ hfut.edu.cn Mingyue Zhu Hefei University of Technology , 3238689883 @ qq.com Follow this and additional works at : https : //aisel.aisnet.org/amcis2020 Recommended Citation Sun , Jianshan ; Song , Jian ; Jiang , Yuanchun ; Liu , Yezheng ; and Zhu , Mingyue , `` Leveraging Cross Domain Recommendation Models to Alleviate Filter Bubble Problems '' ( 2020 ) . AMCIS 2020 Proceedings . 11. https : //aisel.aisnet.org/amcis2020/ai_semantic_for_intelligent_info_systems/ ai_semantic_for_intelligent_info_systems/11 This material is brought to you by the Americas Conference on Information Systems ( AMCIS ) at AIS Electronic Library ( AlSeL ) . It has been accepted for inclusion in AMCIS 2020 Proceedings by an authorized administrator of AIS Electronic Library ( AlSeL ) . For more information , please contact elibrary @ aisnet.org . Cross Domain Recommendation Models to Alleviate Filter Bubble Leveraging Cross Domain Recommendation Models to Alleviate Filter Bubble Problems Completed Research Jianshan Sun Jian Song School of management , Hefei University of School of management , Hefei University of Technology , Hefei , China Technology , Hefei , China sunjs9413 @ hfut.edu.cn 775301251 @ qq.com Yuanchun Jiang Yezheng Liu School of management , Hefei University of School of management , Hefei University of Technology , Hefei , China Technology , Hefei , China ycjiang @ hfut.edu.cn liuyezheng @ hfut.edu.cn Mingyue Zhu School of management , Hefei University of Technology , Hefei , China 22328689883 @ qq.com Abstract With the development of Web-based social networks , reeommender systems have become prevalent and integral to how users are interacting with the Internet . They filter out redundant information and personalize relevant and interesting items to online users . However , the positive reinforcement effect of recommender systems narrows users ’ information experiences and cause filter bubble problems . How to provide relevant and diversified items for online users are becoming a challenging issue . In this study , we develop a novel cross domain matrix factorization model with adaptive diversity regularization to tackle the above challenges . We leverage the social tags and adaptive diversity regularization to improve recommendation performance . We conducted a comprehensive experiment on a real social media site to verify the effectiveness of the proposed method . The results show that the proposed method is able to achieve a decent balance between the accuracy and diversity of recommendation . Keywords Filter bubbles , cross-domain recommender system , matrix factorization , diversity . Introduction With the development of web-based social networks , online users have access to a large number of products and services . However , this large number of items can quickly become unmanageable and cause ‘ information overload ’ problems for users . Against this background , recommender systems are developed to filter out redundant information and personalize relevant and interesting items to each user ’ s taste ( Adomavicius and Kwon 2011 ) . Nowadays , recommender systems have become ubiquitous and integral to how users are interacting with the Internet . Recommender systems have provided a personalized web experience and deliver relevant content according to users ’ perceived interests and the interests of similar people to whom a user is connected . Certainly , they can accurately find preferred items for users . At the same time , they also polarize information perspectives and reduce novelty and diversity , which have an important influence on user satisfaction . With the positive reinforcement effect of recommender systems , online users are becoming to obtain narrowed information or content and are trapping in information cocoons . These effects of biased information experiences are often called echo chambers in the media communication community ( Karlsen et al . 2017 ) . However , Americas Conference on Information Systems 1 Cross Domain Recommendation Models to Alleviate Filter Bubble information retrieval researchers often refer them to filter bubbles , which are serf-reinforcing systems of narrowing information experiences that isolate people from diversified viewpoints , beliefs or content ( Pariser 2011 ) . Existing recommendation algorithms focus more on how to improve the accuracy of recommendations but pay less attention to the diversity of the reeommendation results . In order to solve the above problems , some researchers have explored a lot of algorithms to improve the diversity of recommendations . For example , some basic recommendation models were employed to generation recommendation lists and some strategies are designed to reorder the list to improve diversity ( Cheng et al . 2017 ; Wu et al . 2018 ) . Furthermore , diversity was considered into the unified recommendation models , such as adding diversity constraints ( Gogna and Majumdar 2017 ) and using Determinantal Point Processes ( DPP ) ( Borodin 2009 ) . However , existing diverse strategies are not personal but universal to all users who often have different needs on diversity . Some people prefer more novel items , while others hope to be recommended with content conforming to their personal preferences ( Barraza-Urbina et al . 2015 ) . Furthermore , most recommendation algorithms only employ single domain knowledge to improve diversity . Recently , cross-domain recommendations have begun to emerge rapidly . Since people are often interested in many items and participate in many domains , cross-domain recommender systems can transfer knowledge from the source domain to the target domain to alleviate data sparsity problems ( Hu et al . 2018 ) and to improve the accuracy of recommendations ( Shevade and Murty 2019 ) . However , existing cross- domain recommendation methods focus more on recommendation accuracy than diversity . How to employ cross-domain knowledge to balance accuracy and diversity to alleviate filter bubble problems remains a very important issue . In this paper , we develop a cross domain matrix factorization model with adaptive diversity regularization , called AD-CDMF , to address the key challenges highlighted above . Firstly , we joint the rating matrices of different domains for decomposition to migrate the rating patterns of the source domain . Secondly , we leverage social tags to calculate inter-domain similarity to strengthen the inter-domain knowledge transfer and ensure the accuracy of recommendations . Finally , we import the user 's need for diversity from the source domain and use the designed adaptive diversity regulation to promote diversity adaptively . The proposed methods and models are evaluated through comprehensive experiments using the real dataset . The results show that the proposed AD-CDMF model outperforms the baseline methods based on a variety of recommendation metrics . Related Work With the rise of social media , people can share information with others at any time and they have more channels to obtain all kinds of information . Although this can enhance the communication between users to a certain extent , the possible negative impact has also attracted more and more attention of scholars . In recent years , some scholars have proved that social networks may cause problems such as echo chambers and filtering bubbles ( Chitra and Musco 2020 ; Su et al . 2016 ) . The recommendation algorithm , as a widely used technology in social media , is also being discussed fiercely by scholars . There is a debate whether recommender systems cause filter bubble problems . Some scholars believe that recommendation algorithms can expose users to more diverse and unbiased information ( Nguyen et al . 2014 ) . However , most scholars believe that the use of recommendation systems may produce filter bubbles . The term ‘ filter bubble ’ was coined by ( Pariser 2011 ) and he believed that the recommendation systems would connect users with information that was very similar to their existing views , thereby trapping users in a constant environment , which would reduce users ’ learning ability , creativity , and form filter bubbles . And when a filtering algorithm is used , the polarization phenomenon became more serious . Through the analysis and modeling of the recommendation system , ( Fleder and Hosanagar 2009 ) proved that some well-known recommendation algorithms would lead to a decrease in sales diversity , while making popular products more popular . This actually reflects that the recommendation system may cause filter bubbles , and users are trapped in a lack of diversity . At present , to alleviate the ‘ filter bubble ’ dilemma , some researchers aim to increase the recommended diversity . ( Wu et al . 2018 ) proposed a greedy re-ranking method based on personality traits to improve the diversity of recommendations . The method mainly includes two steps . The first step is to generate a candidate item set based on the user 's preferences . The second step is to integrate personality into a greedy re-ranking process to generate the final diverse recommendation list . ( Di Noia et al . 2017 ) also proposed a Americas Conference on Information Systems 2 Cross Domain Recommendation Models to Alleviate Filter Bubble recommendation method based on re-ranking . They first generated the recommendation list based on the existing recommendation algorithms , and then used the newly proposed re-ranking method to modify the recommendation list . Some other scholars make a diverse recommendation through a single-stage approach . ( Gogna and Majumdar 2017 ) proposed a single-stage optimization method by adding diversity enhancing constraints to the matrix factorization model . Different from the traditional matrix factorization method , they recovered the latent factor matrix of dense user and sparse item . Finally , the experimental results on real world dataset showed that the method has a high diversity of results . ( Wu et al . 2019 ) proposed a recommendation method based on generative adversarial networks . A generator based on the Determinantal Point Process ( DPP ) model was built to capture the diversity and relevance of items , while a discriminator is used to distinguish the recommended items from the real items obtained from user observation data . Although there have been many studies on the improvement of the diversity of reeommendation results , most of these studies have caused a slight loss in accuracy ( Gogna and Majumdar 2017 ; Man et al . 2017 ) , and the recommendation of diversity is not enhanced adaptively according to users ’ demand for diversity . Moreover , most of these studies are recommendation diversity algorithms in a single domain , without taking advantage of user interactions in other domains . In this paper , cross domain recommendation is used to solve the problem of data sparsity , which can not only obtain high accuracy , but also improve the diversity adaptively . Cross Domain Recommendation Model with Adaptive Diversity Regularization In the previous works , diversity-oriented recommended systems were often designed to improve recommendation diversity in a single domain . Compared with algorithms aiming to promoting diversity in a single domain , cross-domain recommendation algorithms have been proposed to improve the diversity of recommendations by providing better coverage of the range of user preferences ( Winoto and Tang 2008 ) . In this study , we propose a cross domain matrix factorization model with adaptive diversity regularization ( AD-CDMF ) , our method adds two regularization terms to the traditional collective matrix factorization model ( i.e . the similarity regularization between the domain of source and target domain , and the adaptive diversity regularization ) . We attempt to connect the learning process of matrix factorization both in the source domain and target domain by adding the two regularization terms , and then improve the recommendation diversity under the premise of not significantly reducing the recommendation accuracy . Our proposed cross-domain recommendation model includes three main modules : collective matrix factorization module , inter-domain similarity regularization module , and target domain adaptive diversity regularization module . Collective Matrix Factorization Module Collective matrix factorization module aims to enrich the knowledge from relational domains through collective matrix factorization of two correlation matrices ( Singh and Gordon 2008 ) . Given users are overlap in the two different domains but the items are not , the objective function of CMF can be expressed as : 2 2 LP , Qs @ r ) = > Y Ciy— < Pwd > ) + > , > , Giy < Pw dy > ) + AWCUPIP + QI ? +1 ? ) a ) ueu iEjs ueU jejT Where U = US U UT is the set of all users , which we assume overlaps between the domains , /S is the source domain items , JT is the target domain items , ||-|| is the Euclidean norm of a matrix , < - > represents dot product of two vectors , Q ; and Q ; are matrices containing the item latent vectors in the source and target domains respectively , P is the matrix containing the user latent vectors , R is the rating matrix , and 4 , is used to prevent model overfitting . CMF model is leveraged to learn a latent vector P , € R * for each user u € U and separately models source and target domain items q ; and q , , with i € JS , and j € JT , and it always imports additional user preference information from the source domain . Americas Conference on Information Systems 3 Cross Domain Recommendation Models to Alleviate Filter Bubble Inter-domain Similarity Regularization Module The second module of our model is based on that latent vectors of related items should explain the semantic similarities between them , in addition to the users ’ preferences 7 , ; ~ < p , , , q ; > . That is , we not only seek to predict the users ’ preferences , but also require that the item latent vectors of the target domain and the source domain satisfy the inter-domain similarity constraint . To link different domains by importing the inter-domain similarity regularization , we adopt the inter-domain similarity regularization proposed by ( Fernndez-Tobas et al . 2019 ) , which is showed as follows : mind , » . » . ( Sj- < ana ) > ) ( 2 ) ie js jejT Where , q ; and q ; are the latent factor of the item i and the item j respectively , A , > 0 is the cross-domain regularization parameter , controlling the contribution of the inter-domain similarity regularization , and S , ; is the inter-domain similarity matrix calculated by social tags of items from different domains , which is demonstrated as follows : < ViPVjT > * o TTX '' ( 3 ) Where ||-|| is the Euclidean norm of a matrix , < - > represents dot product of two vectors , V ; / * is the semantic vector of item i in the set of source domain items /S , v , / T is the semantic vector of the item j in the set of target domain items JT . V , / * and V ; ’ '' are calculated by using the co-occurrence relationship ( Wartena et al . 2009 ) between self-carrying tags and several common tags related to genres between two domains . The calculation process of V , / * and Vv , T is based on two assumptions , the first is that the more times two tags co- occur , the closer the relationship becomes , the second is that users may have similar preferences for item genres in different domains ( Fernndez-Tobas et al . 2019 ) , for example , people who like mystery novels may like science fiction movies . The inter-domain similarity regularization is used to regularize the item latent factors in the different domains to satisfy the similarities between them and to improve the accuracy of recommendations . In the following of the section , we propose an adaptive diversity regularization term to promote the recommendation diversity adaptively . Adaptive Diversity Regularization Module The third module of our model is based on the assumption that latent vectors of related items in the target domain should explain semantic distance between them and the strength of users ’ demand for diversity , in addition to the users ’ preferences and inter-domain similarity . That is , we not only seek to predict the preferences r , ; ~ < Dy , q ; > and S ; ; ~ < qi , q ; > , but also require that the item latent vectors of the target domain and the user latent vectors satisfy the adaptive diversity constraint . In this section , we introduce the target domain adaptive diversity regularization term designed by us , which is able to adjust the difference of users ’ ratings for different styles of items in the target domain according to the strength of users ' demand for diversity . Specifically , if the distance between two items is bigger ( i.e . d , , ; , is bigger ) , and the demand for diversity of useruis bigger ( i.e . N , ,is bigger ) , the user latent vector p , , and the item latent vectors q , , , q ; , will be regularized to decrease the difference of u ’ s ratings of these two items , as follows : 2 minds > Nu ) Aria , ~ Vi . ) ( a ) u JujoeJT Where p , , is the userulatent vector , q , , is the item j , latent vector , q , , is the item j , latent vector , and Ag > 0 is the target-domain adaptive diversity regularization parameter , controlling the contribution of the adaptive diversity regularization term , d ( j , , j . ) is the semantic distance between the item j , and the item j , in the target domain , which is defined as follows : Americas Conference on Information Systems 4 Cross Domain Recommendation Models to Alleviate Filter Bubble dU , J2 ) = |¥j,7 '' ~ yj,7 '' || ( 5 ) Where ||-|| is the Euclidean norm of a matrix , V ; , J¥and Vi , J ? are the semantic vector of the item j , and item jz in the target domain respectively , which calculated by social tags as descripted in ( Inter-domain similarity regularization module ) . And we adopt the idea of information entropy ( Shannon 1948 ) to measure the degree of user demand for diversity . N , , represents the demand for diversity of user u , which is shown as follows : Nee Ui Mu , M. MCD , Eri ? ° Where M , , is the semantic vector of user u , calculated by the co-occurrence relationship between self-tagged social tags and some common tags related to styles between two domains , which is similar to the calculation process of V , /°and V ; / '' . M , , , is the i element of vector M , , , and n , , is the number of common tags related to styles between different domains . The larger N , , is , the more dispersed of the u-tagged items in style are , indicating user u greater demand for diversity , and vice versa . Learning Process of Proposed Model The matrix factorization model with adaptive diversity regularization for cross-domain recommendation proposed by us integrates above three modules . Let U = US U UT be the set of all users , which we assume overlaps between the domains , and let ] = JS UJT be the set of all items , which we assume do not overlap . Our model learns a latent vector p , € R * for each user u € U and separately models the item latent vectors q ; and q ; , with i € JS , andj € JT . Our model ’ s loss function is as follows : L ( P , O5.0 , ) = > , = < PG > ) uel ie JS + ) Ss : 1 , — < Purdy sy uecUje JT +A , Ss : Ss : ( S , j- < 9 . ) > y ( 7 ) ie Bje JT tN , YD Mi hMP.G , - 9 , ue Ip ieJT +4 , ( IPI +|e , P +2 , Where all model parameters were explained as described above . As in standard matrix factorization , we train our model using Alternating Least Squares ( Bell and Koren 2007 ) . Firstly , we fix Q , ; and Q , , and solve analytically for each p , , by setting the gradient to zero : Du = ( 2QEQs + 2QFQr + AaNu QPL Qr + 2A , E ) `` ( ZOE + 2QFT uy ) ( 8 ) Where D is the semantic distance matrix between items in the target domain , Ly = D ’ — D is the Laplacian matrix of D , and D ’ is the diagonal matrix with i ‘ ” diagonal entry equal to ¥ ; , d ( i , / ) , the vector 7 , contains the ratings of user u for all items in the source domain , and the vector 7 , , , contains the ratings of user u for all items in the target domain . Secondly , we fix P and Q , , and compute the optimal values for q ; . Again , by setting the corresponding gradient to zero and solving analytically , we obtain : qi = ( PTD + AsQPQr + A , E ) + x ( PTH +A ; , QTSi ) ( 9 ) As previously , the vector r ; contains the ratings assigned to item i and s , is the i row of the inter-domain semantic similarity matrix S. Americas Conference on Information Systems 5 Cross Domain Recommendation Models to Alleviate Filter Bubble Finally , we fix P and Q , to compute and optimal values ordinally for q ; : nT Gj = ( PTD + AsQEQs + AYE + AgH Ly ( i ) `` ( PTH + ASQES ; — AH » . Ly , ) 4 ; ’ ) ( 10 ) fouy'si Where H = P'N ’ P and N ' € R @ * * is the diagonal matrix , where only the main diagonal has values and N ’ ; ; = N ; , Lp , ( k ) is the k ‘ * element of the k ' ” row of the matrix Lp , n ; is the number of items in the target domain , as previously , the vector 7 ; contains the ratings assigned to item j and s ; is the j * column of the inter-domain semantic similarity matrix S. Experimental Design Datasets In our work , we adopt a widely used dataset from Douban ( Zhong et al . 2014 ) - a Chinese online social networking platform , which includes 3191,620 ratings from 33,559 users in the book domain , 5115,162 ratings from 33,417 users in the movie domain , and 2528,925 ratings from 26,962 users in the music domain . It also includes rich metadata of items , such as abstract , language , and social tags on items . In order to train and validate our proposed cross-domain recommendation model , we choose the book domain and the movie domain with a large number of common users as the research objects . We consider the book domain with sparser ratings as the target domain and treat the movie domain with denser ratings as the source domain . We adopt the following preprocessing similar to the one done in ( Gao et al . 2013 ) . Statistics of the preprocessed datasets are given in Table 1 . Domain | # users | # items | # ratings | density | # social tags | role Movie ( M ) | 4212 13362 1825147 3.22 % 124250 source Book ( B ) 4212 8329 627963 1.79 % 117692 target Table 1 . Statistics of the Douban Dataset Evaluation Metrics In order to evaluate recommendation accuracy , we apply Mean Absolute Error ( MAE ) for performance analysis ( Cantador et al . 2015 ) . Its definition is shown below : 1 MAE = |arest| » . bray ~ | ( 11 ) ( ufeatest Where , 7 is the test set and smaller values of MAE indicate better recommendation performance . For item recommendation , we reckon it as a content retrieval system to recommend to users the most diverse and relevant top-K items . The evaluation metrics , CC @ K and a — NDCG , , @ K are applied to assess the recommendation diversity of different methods . The CC @ K is measured by the quantity of categories covered by top-K items divided by the total number of categories available in the dataset ( Ashkan et al . 2015 ) . A higher category coverage demonstrates the top-K items are more diverse in topic , as follows : CC @ K = ( 12 ) Where , C , , is the quantity of categories covered by top-K items , and C ; , ; is the total number of categories . The @ — NDCG , , @ K is a high-authority diversity evaluation approach , which is used to reward newly discovered themes and punish superfluous ones ( Chandar and Carterette 2013 ) : Americas Conference on Information Systems 6 Cross Domain Recommendation Models to Alleviate Filter Bubble K G , @ i a —NDCG , @ K =z , ) —— A log ( 1 +i ) ( 43 ) Where G , , @ k is the gain at the i “ position with respect to the given user u . In particular , G , , @ k is defined as follows : Cei-1 G @ k = ) ( =a ) ( 14 ) VteT Where c , , ; is the quantity of times that topic t has presented in the ranking of the recommendation list up to the i position . Experimental Procedure In order to reduce the impact of variations in the training set , we adopt the N-fold cross validation . The ratings of target domain are divided into three subsets with similar distributions and sizes . And then the union of two subsets is taken as the training set , while the remaining subset is reckoned as the test set . We performed the process three times and record the result of average test as the result of the 3-fold cross validation . Furthermore , for comparison , we tested eight methods : MF , PMF , CUNE-MF , SVD , SVD++ , CMF and two models proposed by us , one without adaptive diversity regularization and the other with adaptive diversity regularization . ( 1 ) MF : MF is the basic and popular model of recommender systems . ( 2 ) PMF ( Mnih and Salakhutdinov 2008 ) : PMF is the probabilistic version of MF and we user the standard probabilistic matrix factorization model . ( 3 ) CUNE_MF : The CUNE_MF model proposed by ( Zhao et al . 2011 ) extends MF by identifying the top-K semantic friends of each user by network embedding technology . ( 4 ) SVD ( Golub and Reinsch 1971 ) : SVD could make matrix decomposed into singular vectors and singular values and is one of the matrix factorization algorithms . ( 5 ) SVD++ : SVD+-+ is one of matrix factorization algorithms proposed by ( Koren 2008 ) that simultaneously considers user bias , item bias and user implicit feedback information . ( 6 ) CMF : CMF proposed by ( Singh and Gordon 2008 ) , couples rating matrices for all domains on the item or user dimension so as to transfer information through the common item-factor matrix or user-factor matrix . ( 7 ) CDMF : Cross-domain matrix factorization model without adaptive diversity regularization . ( 8 ) AD_CDMF : Cross-domain matrix factorization model without adaptive diversity regularization . Henceforth , concerning these eight approaches , the first five demonstrate single-domain recommended approaches while the remainder show cross-domain recommended approaches . Results and Discussions The recommender system techniques were implemented and the results were compared in the RecQ recommender system library Platform ( Tang et al . 2012 ) . We tuned properly the parameters of all methods , and the performance of the eight recommendation methods is reported in the following subsections . Recommendation Accuracy The recommendation accuracy of recommendation models is given in Table2 , and the performance of CDCF is better than any other comparison models . Since CDCF leverages social tags to transfer knowledge between domains , and utilizes inter-domain similarity regularization to control the intensity of knowledge transfer between domains , which may import considerable knowledge with consistency of user preferences . Americas Conference on Information Systems 7 Cross Domain Recommendation Models to Alleviate Filter Bubble Methods MAE MAE improvements over baseline MF Single-domain method MF 0.58927 __ PMF 0.57773 — CUNE_MF 0.57598 SVD 0.56984 SVD++ 0.58156 Cross-domain method CMF 0.59723 __ CDMF 0.55581 5.7 % AD_CDMF 0.58126 1.4 % Table 2 . Recommendation Accuracy of the Eight Methods * Furthermore , we note that SVD is the best performing algorithm between single-domain methods . Perhaps it ’ s because SVD factorize the matrix into singular vectors and singular values , and the target domain information could be better utilized than other methods . CMF 's recommendation accuracy is the worst , probably because jointing the matrices of the two domains for factorization increases the score sparsity . Besides , the performance of AD_CDMF in accuracy is moderate , but not far behind the best algorithms . It ’ s probably because the adaptive diversity regularization causes the loss of recommendation accuracy . And compared with other algorithms , AD_CDMF aims to enhance more coverage of user preferences instead of consistency of user preferences by importing the adaptive diversity regularization . In summary , the proposed CDCF model is able to improve recommendation accuracy effectively , while the proposed AD_CDMF model could promise certain recommendation accuracy . Recommendation Diversity To evaluate the recommended diversity of these methods , we consider the top-10 recommended scenario , where a list of top-10 rated items is recommended for each user . It is because that each book has almost 3 styles , but the total number of styles is less than 15 . If the recommendation list contains a large or a too small number of items , it is easy to make the diversity metric lose its significance ( Cheng et al . 2017 ) . Sy cc @ 10 Bes ) o-NDCG @ 10 wie ca i SS St Lor art™ OS ove Figure 1 . Diversity Performance of the Eight Recommendation Methods Figure 1 demonstrates the performance of all recommendation methods in diversity . We observe that the proposed AD_CDMF model is clearly the best performing approach , both in CC @ 10 and a — NDCG , , @ 10 . Since our approach leverages the underlying CMF framework to introduce additional user preference information , and further adjusts diversity with adaptive diversity regularization . What ’ s more , we notice CUNE_MF gets the worst diversity performance , since recommendation diversity suffers with the import of semantic friend information for users . CMF model has the worst performance of diversity between cross- * Best values for each single-domain and cross-domain methods are shown in bold , and overall best values are underlined . Americas Conference on Information Systems 8 Cross Domain Recommendation Models to Alleviate Filter Bubble domain methods , probably because the rating pattern introduced from the source domain is less conducive to the improvement of diversity than the social tags . Furthermore , by comparing these results with Table 2 , we observe that although it is commonly said that diversification by its nature results in deterioration in accuracy as a cost of introducing diversity ( Wasilewski and Hurley 2018 ) . The single-domain model SVD and the cross-domain model AD-CDMF are able to provide a good trade-off of decent diversity and the most accurate recommendations compared to other algorithms . Conclusion and Future Work Recommender systems bring benefits and convenience for our life and also may cause filter bubble issues . In this paper , we proposed a cross domain matrix factorization model with adaptive diversity regularization . The proposed model leveraged social tags as bridge to link the target and source domain to promise decent recommendation accuracy and utilized adaptive diversity regularization to improve recommendation diversity . Comprehensive experiments were conducted on a real social media website to evaluate the effectiveness of the proposed model . Through the analysis of the results , we draw the following conclusions . Firstly , the use of social tags is very effective in overcoming the low recommendation accuracy caused by the sparsity of the target domain . Secondly , the addition of adaptive regularization designed by us can effectively improve the individual diversity of reeommendations . Thirdly , our proposed model can achieve a good balance between the accuracy and diversity of recommendations . Several future research directions also exist for this study . Firstly , only one type of social media site ( the Douban dataset ) to validate the proposed approach in this paper . We will extend our approach to other sites ( such as Amazon ) to improve its applicability and generalizability . Secondly , we will explore user ’ s need for diversity in more advanced ways , such as leveraging more user history interaction data , or treating it as parameters that require implicit learning . Acknowledgement This work is supported by the National Natural Science Foundation of China ( 71872060 , 91846201 , 71490725 , 71722010 , 91546114 , and 91746302 ) , partially Sponsored by Zhejiang Lab ( No . 2019KEOABo4 ) . REFERENCES Adomavicius , G. , and Kwon , Y . 2011 . `` Improving aggregate recommendation diversity using ranking-based techniques , ” IEEE Transactions on Knowledge and Data Engineering ( 24:5 ) , pp 896-911 . Ashkan , A. , Kveton , B. , Berkovsky , S. , and Wen , Z . 2015 . `` Optimal greedy diversity for reeommendation , '' ” Twenty-Fourth International Joint Conference on Artificial Intelligence . Barraza-Urbina , A. , Heitmann , B. , Hayes , C. , and Carrillo-Ramos , A . 2015 . `` XPLODIV : An exploitation- exploration aware diversification approach for recommender systems , '' The Twenty-Eighth International Flairs Conference . Bell , R.M. , and Koren , Y . 2007 . `` Scalable collaborative filtering with jointly derived neighborhood interpolation weights , '' Seventh IEEE International Conference on Data Mining ( CDM 2007 ) , IEEE , Pp . 43-52 . Borodin , A . 2009 . `` Determinantal point processes , '' arXiv preprint arXiv:0911.1153 ) . Cantador , I. , Fernndez-Tobas , I. , Berkovsky , S. , and Cremonesi , P. `` Cross-domain recommender systems , '' in : Recommender systems handbook , Springer , 2015 , pp . 919-959 . Chandar , P. , and Carterette , B . 2013 . `` Preference based evaluation measures for novelty and diversity , ” Proceedings of the 36th international ACM SIGIR conference on Research and development in information retrieval , pp . 413-422 . Cheng , P. , Wang , S. , Ma , J. , Sun , J. , and Xiong , H. 2017 . `` Learning to recommend accurate and diverse items , ” Proceedings of the 26th international conference on World Wide Web , pp . 183-192 . Chitra , U. , and Musco , C. 2020 . `` Analyzing the Impact of Filter Bubbles on Social Network Polarization , '' Proceedings of the 13th International Conference on Web Search and Data Mining , pp . 115-123 . Di Noia , T. , Rosati , J .. Tomeo , P. , and Di Sciascio , E. 2017 . `` Adaptive multi-attribute diversity for recommender systems , ” Information Sciences ( 382 ) , pp 234-253 . Americas Conference on Information Systems 9 Cross Domain Recommendation Models to Alleviate Filter Bubble Fernndez-Tobas , I. , Cantador , I. , Tomeo , P. , Anelli , V.W. , and Di Noia , T. 2019 . `` Addressing the user cold start with cross-domain collaborative filtering : exploiting item metadata in matrix factorization , '' User Modeling and User-Adapted Interaction ( 29:2 ) , pp 443-486 . Fleder , D. , and Hosanagar , K. 2009 . `` Blockbuster culture 's next rise or fall : The impact of recommender systems on sales diversity , '' Management science ( 55:5 ) , pp 697-712 . Gao , S. , Luo , H. , Chen , D. , Li , S. , Gallinari , P. , and Guo , J . 2013 . `` Cross-domain recommendation via cluster-level latent factor model , ” Joint European conference on machine learning and knowledge discovery in databases , Springer , pp . 161-176 . Gogna , A. , and Majumdar , A . 2017 . `` DiABIlO : Optimization based design for improving diversity in recommender system , ” Information Sciences ( 378 ) , pp 59-74 . Golub , G.H. , and Reinsch , C. `` Singular value decomposition and least squares solutions , '' in : Linear Algebra , Springer , 1971 , pp . 134-151 . Hu , G. , Zhang , Y. , and Yang , Q . 2018 . `` Conet : Collaborative cross networks for cross-domain recommendation , ” Proceedings of the 27th ACM International Conference on Information and Knowledge Management , pp . 667-676 . Karlsen , R. , Steen-Johnsen , K. , Wollebk , D. , and Enjolras , B . 2017 . `` Echo chamber and trench warfare dynamics in online debates , ” European Journal of Communication ( 32:3 ) , pp 257-273 . Koren , Y . 2008 . `` Factorization meets the neighborhood : a multifaceted collaborative filtering model , ” Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining , pp . 426-434 . Man , T. , Shen , H. , Jin , X. , and Cheng , X . 2017 . `` Cross-Domain Recommendation : An Embedding and Mapping Approach. , ” IJCAI , pp . 2464-2470 . Mnih , A. , and Salakhutdinov , R.R . 2008 . `` Probabilistic matrix factorization , '' Advances in neural information processing systems , pp . 1257-1264 . Nguyen , T.T. , Hui , P. , Harper , F.M. , Terveen , L. , and Konstan , J.A . 2014 . `` Exploring the filter bubble : the effect of using recommender systems on content diversity , ” Proceedings of the 23rd international conference on World wide web , pp . 677-686 . Pariser , E. 2011 . The filter bubble : What the Internet is hiding from you Penguin UK . Shannon , C.E . 1948 . `` A mathematical theory of communication , '' Bell system technical journal ( 27:3 ) , pp 379-423 . Shevade , S. , and Murty , M.N . 2019 . `` Neural Cross-Domain Collaborative Filtering with Shared Entities , ” arXiv preprint arXiv:1907.08440 ) . Singh , A.P. , and Gordon , G.J . 2008 . `` Relational learning via collective matrix factorization , ” Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining , pp . 650- 658 . Su , J. , Sharma , A. , and Goel , S. 2016 . `` The effect of recommendations on network structure , '' Proceedings of the 25th international conference on World Wide Web , pp . 1157-1167 . Tang , J. , Gao , H. , and Liu , H. 2012 . `` mTrust : discerning multi-faceted trust in a connected world , ” Proceedings of the fifth ACM international conference on Web search and data mining , pp . 93-102 . Wartena , C. , Brussee , R. , and Wibbels , M. 2009 . `` Using tag co-occurrence for recommendation , ” 2009 Ninth International Conference on Intelligent Systems Design and Applications , IEEE , pp . 273-278 . Wasilewski , J. , and Hurley , N. 2018 . `` Intent-aware item-based collaborative filtering for personalised diversification , ” Proceedings of the 26th Conference on User Modeling , Adaptation and Personalization , pp . 81-89 . Winoto , P. , and Tang , T. 2008 . `` If you like the devil wears prada the book , will you also enjoy the devil wears prada the movie ? a study of cross-domain recommendations , ” New Generation Computing ( 26:3 ) , pp 209-225 . Wu , Q. , Liu , Y. , Miao , C. , Zhao , Y. , Guan , L. , and Tang , H. 2019 . `` Recent advances in diversified recommendation , ” arXiv preprint arXiv:1905.06589 ) . Wu , W. , Chen , L. , and Zhao , Y . 2018 . `` Personalizing recommendation diversity based on user personality , '' User Modeling and User-Adapted Interaction ( 28:3 ) , pp 237-270 . Zhao , J. , Lui , J.C. , Towsley , D. , Guan , X. , and Zhou , Y . 2011 . `` Empirical analysis of the evolution of follower network : A case study on Douban , ” 2011 IEEE Conference on Computer Communications Workshops ( INFOCOM WKSHPS ) , IEEE , pp . 924-929 . Zhong , E. , Fan , W. , and Yang , Q . 2014 . `` User behavior learning and transfer in composite social networks , '' ACM Transactions on Knowledge Discovery from Data ( TKDD ) ( 8:1 ) , pp 1-32 . Americas Conference on Information Systems 10 City Research Online CIT UNIVERSITY OF LONDON EST 1894 City , University of London Institutional Repository Citation : McKay , D. , Owyong , K. , Makri , S. & Gutierrez Lopez , M. ( 2022 ) . Turn and face the strange : Investigating filter bubble bursting information interactions . In : UNSPECIFIED ( pp . 233-242 ) . Association for Computing Machinery . ISBN 9781450391863 doi : 10.1145/3498366.3505822 This is the accepted version of the paper . This version of the publication may differ from the final published version . Permanent repository link : httos : //openaccess.city.ac . uk/id/eprint/28089/ Link to published version : https : //doi.org/10.1145/3498366.3505822 Copyright : City Research Online aims to make research outputs of City , University of London available to a wider audience . Copyright and Moral Rights remain with the author ( s ) and/or copyright holders . URLs from City Research Online may be freely distributed and linked to . Reuse : Copies of full iterns can be used for personal research or study , educational , or not-for-profit purposes without prior permission or charge . Provided that the authors , title and full bibliographic details are credited , a hyperlink and/or URL is given for the original metadata page and the content is not changed in any way . City Research Online : http : //openaccess.city.ac.uk/ publications @ city.ac.uk Turn and Face the Strange : Investigating Filter Bubble Bursting Information Interactions Turn and Face the Strange : Filter Bubble Bursting Behaviour Dana McKay School of Computing Technologies , RMIT University , dana mckay @ rmit.edu.au Kaipin Owyong iSchool , University of Melbourne , kaipin.owyong @ unimelb.edu.au Stephann Makri Centre for HCI Design , City , University of London , stephann @ city.ac.uk Marisela Gutierrez-Lopez Faculty of Social Science and Law , University of Bristol , Marisela.gutierrezlopez @ bristol.ac.uk It is a ‘ truth universally acknowledged ’ that people prefer to minimize encounters with information they disagree with and ignore it where they find it . Algorithms purportedly support this avoidance by creating filter bubbles filled only with agreeable information potentially increasing polarisation and undermining democracy . How accurate is this portrayal , though ? Recent research has begun to cast doubt . We challenge these assumptions and report atwo- phase analysis of filter bubble-bursting behavior . The first phase reports novel incidental findings from an interview study on the role of information interaction in view change . Participants demonstrated a clear interest ina diversity of information , including information specifically opposed to their own views . The second phase reports findings from a diary study specifically designed to investigate people ’ s interactions with information that reflected a different view to theirs . We examine how people found disagreeable information , how they responded to it and the factors affecting their responses . We find that people will sometimes actively seek and engage with disagreeable information , rather than avoid and ignore it . Our findings pave the way for future information interfaces that support this previously undiscussed information interaction . CCS CONCEPTS » * Information systems~Information retrieval~Users and interactive retrievaleHuman-centered computing~Human computer interaction ( HCI ) ~Empirical studies in HCI Additional Keywords and Phrases : Filter bubbles , echo chambers , social media , view change , information interaction ACM Reference Format : First Author ’ s Name , Initials , and Last Name , Second Author ’ s Name , Initials , and Last Name , and Third Author's Name , Initials , and Last Name . 2018 . The Title of the Paper : ACM Conference Proceedings Manuscript Submission Template : This is the subtitle of the paper , this document both explains and embodies the submission format for authors using Word . In Woodstock ‘ 18 : ACM Symposium on Neural Gaze Detection , June 03-05 , 2018 , Woodstock , NY . ACM , New York , NY , USA , 10 pages . NOTE : This block will be automatically generated when manuscripts are processed after acceptance . 1 Introduction How much do those around us influence what we think ? Can we be trapped into specific ways of thinking by algorithms feeding us what we want , rather than what we need ? These are the key questions posed by research on filter bubbles and echo chambers respectively . Echo chambers are the limited information ecologies created by surrounding ourselves with only those who are socially and ideologically similar to us , thus avoiding alternative viewpoints [ 45 ] . Filter bubbles are the algorithmic extension of this idea ; the personalisation of search engines ( or , more recently , social media feeds ) exposes us to news and ideas we are more likely to find agreeable [ 8 ; 36 ] . Some have even argued that these information structures nudge us further and further from the centre on issues , encouraging us to engage with only certain viewpoints and resulting in polarisation [ 8 ] . If these structures are as powerful as suggested , they present significant social challenges—having been blamed for increasing climate change denial [ 4 ] and COVID vaccine hesitancy [ 38 ] , and even influencing the outcome of the 2016 US election [ 47 ] . The ability to engage with a diversity of information has been described as a cornerstone of democracy [ 18 ] . Seeing views other than one ’ s own may promote either debate or consensus [ 18 ] . Diverse information also affords the opportunity to reconsider and possibly change one ’ s views [ 29 ] . Not getting this diversity of information , conversely , deprives people of these opportunities for developing new perspectives , and possibly reduces creativity and innovation as well [ 26 ; 28 ] . Popular discourse in this space suggests that people will avoid information diversity , preferring to stick within their filter bubbles and echo chambers [ 3 ; 42 ] . Recent research , however , has begun to question whether filter bubbles are as impermeable—or even as appealing—as this discourse suggests [ 8 ; 9 ; 21 ; 47 ] . Indeed , it is unlikely any algorithm can insulate people from all information they disagree with [ 9 ] , and unwillingness to engage with alternative views may not be as entrenched as previously thought [ 8 ] . Regardless of their permeability , to break out of a filter bubble , people must first see , and then engage with views different than their own . The core question then , is whether they see and engage with alternative viewpoints , and if so , how ? In this paper , we present empirical evidence from two qualitative studies on people ’ s interactions with information that reflected views different to their own . The first study identifies a propensity for deliberately engaging with information from alternative viewpoints among a highly specialized group : people who had recently changed their view on an important issue . Having both recently changed their view and being willing to discuss it , this group is unlikely to be representative of the general population . The second study therefore involved a broader group of social media users . It examines interactions with information reflecting alternative views on social media , exploring how people acquire and react to that information . We demonstrate that aversion to information reflecting alternative views , and avoidance of it where it is discovered , is far from universal . We identify engagement with information from alternative or opposing viewpoints as a new type of broad information need and identify factors that promote and inhibit this engagement . This paves the way for future novel information interfaces that facilitate finding and engaging with alternative views . The remainder of this paper is structured as follows : firstly , we discuss relevant background literature , focusing on studies of filter bubbles and echo chambers ( see Sec . 2 ) , In Section 3 , we report novel incidental findings from our study of information-facilitated view change that motivated our dedicated study of peoples ’ engagement with information they do not agree with . In Section 4 , we explain and justify the study method , presenting findings in Section 5 . We discuss both studies in the context of existing literature , offering suggestions for future information interfaces in Section 6 . Finally , in Section 7 , we draw conclusions and suggest avenues for future work , 2 Background In this section we discuss relevant background literature , focusing first on theoretical discussions around filter bubbles and echo chambers , then on empirical examinations of information interaction around these information structures . 2.10n the nature of filter bubbles and echo chambers In 2001 , Sunstein argued that despite the internet being a wellspring of information , it may have a deleterious effect on democracy by allowing people to increasingly engage only with likeminded others , avoiding news and opinion they find offensive or disagreeable—a concept he referred to as information cocoons or echo chambers [ 45 ] . Recently , Sunstein has extended this argument to social media , arguing it is exacerbating the problem described 20 years ago [ 44 ] . Ten years after Sunstein first mooted echo chambers , the idea of the filter bubble—algorithms that hide information they think we do n't want to see by personalising our search results—was popularized by Pariser [ 36 ] . While Pariser focused on search , other commentary on filter bubbles focuses on social media feeds [ 8 ] . Unlike search , these feeds are not constrained by keyword relevance , and thus social media algorithms select what we see based entirely on engagement and personalisation . This has been raised as a particular concern due to the increase in use of social media for news access [ 2 ; 6 ] . The suggestion that the internet may hide things from us , potentially allowing messages we agree with to become ‘ consistent and overwhelming ’ [ 35 ] ( like effective propaganda ) has attracted rapid and significant attention from ethico-legal scholars [ 17-19 ] . Democracy relies on an informed populace to make voting decisions , so information interfaces and systems that limit or bias information are viewed with great caution [ 17 ] . Based on concerns about the impact of limiting information to a single perspective , these same scholars have argued for policy measures to increase diversity in search results and social media recommendations [ 18 ] . One challenge they identify is how to measure diversity [ 19 ] ; this echoes similar discussions of the challenges of measuring bias in news media [ 41 ] . More recent discussions of filter bubbles and echo chambers have pointed out that homophily—choosing to associate predominantly with others like oneself—is both natural and potentially beneficial [ 9 ] . Benefits , if any , stem from the ability to tease out the nuances of an argument with like-minded people , and that this process is critical to advancing our thinking [ 17 ] . These recent discussions have questioned whether social media does result in echo chambers , pointing out that ‘ context collapse ’ ( where one ’ s social groups become a single audience [ 5 ] ) may mitigate against homophily . Similarly , they question whether algorithmic filter bubbles make a meaningful difference to information ecologies , noting that it is very hard to entirely avoid information we disagree with online [ 9 ] . This work also strongly questions the empirical evidence for filter bubbles ; a question we examine in section 2.2 . Anotable commonality of previous work is that it treats filter bubbles and echo chambers as though they are likely to be innately desirable to individuals interacting with information , albeit potentially harmful to society at large . In this paper , we question this assumption by focusing not just on peoples ’ ( putative ) attitudes , but also on their behaviour when they come across information they disagree with . 2.2 Information interactions with filter bubbles and echo chambers While there has been considerable theoretical concern about filter bubbles and echo chambers , there is less research on how these structures influence information interaction in practice , particularly in terms of people ’ s experience of information . Much of the evidence on the impact filter bubbles and echo chambers doesn ’ t interrogate which of these structure ( s ) are responsible for the putative effect on people ’ s engagement with information . In fact without significant knowledge of the underlying ( proprietary ) algorithms this would be difficult in practice ; it is difficult to determine what people might have seen ( or not seen ) without knowing how the algorithms work . Instead , research examines whether there are divisions between groups of people , and whether those people are willing to engage with information from the ‘ other ’ side , mostly focusing on news content . General studies of news engagement demonstrate that political polarity does not affect which news sources are engaged with : neither algorithmic nor social pressures push people away from the central news sources consumed by the majority [ 16 ; 47 ] . Looking specifically at social media , researchers have found clear social divides and strong evidence of homophily , but information is shared between groups [ 11 ] . Even when looking at politically partisan news readers , there is a willingness to read information from ‘ the other side ’ , and readers spend longer on this type of news than they do on news with which they are more familiar [ 21 ] . The authors of that work suggest this time is possibly spent looking for flaws or constructing counterarguments , however , rather than engaging with an open mind . In contrast , our own previous work demonstrates that some people do deliberately engage open-mindedly with information that reflects alternative views to theirs [ 29 ] . We thus aim to provide a clearer picture of cross-ideological engagement . While there is considerable evidence questioning the role of filter bubbles and echo chambers in view formation and change , some studies do suggest they may be influential . A large-scale survey found that 90 % of news readers stuck within their political polarity , and that search engines and social media reinforced polarity while aggregators reduced it [ 14 ] , In this study , < 5 % of already-polarised participants engaged with news from any source that was unlikely to reflect their own view , a finding supported by [ 6 ] . Another study similarly demonstrated a low level of news engagement across political polarity on social media , with < 20 % of users clicking on news they were likely to disagree with [ 3 ; 14 ] . While some of this was due to what algorithms showed them , much was due to their own preferences . This finding is supported by a qualitative study of the echo chamber effect ina single social network on Facebook which demonstrated that people were unwilling to engage with alternative views , preferring instead to mute or ignore them [ 42 ] . Like people , algorithms are not unbiased : a study of YouTube has demonstrated algorithms also facilitate a division of viewpoints [ 22 ] . However , algorithms can also increase engagement with alternative views , as demonstrated by [ 48 ] , which increased diversity and changed terminology on search results reflecting alternative views ultimately making them demonstrably more palatable to searchers . Significant effort has gone into developing information interfaces that support engagement with alternative views ; much of which has focused on presenting a diversity of viewpoints and highlighting where these views come from [ 6 ; 15 ; 24 ] . However , this research is based on a theoretical ( rather than empirical ) understanding of filter bubbles and echo chambers , Ultimately , the influence of filter bubbles and echo chambers on information interaction is unclear , but there are research gaps . Little work has investigated whether information consumers want to engage with alternative views ( rather than examining what they do ) and , if so , how best to design information interfaces to facilitate this engagement . Similarly , only [ 42 ] has specifically examined the experience of engaging with information that does not reflect one ’ s own view ( in contrast with [ 33 ] , which addresses reconciling opposing views ) , and only ina single social network ona single platform . While some interfaces have been designed to support ‘ filter bubble breaking ’ behaviour , they are not rooted in an understanding of that behaviour . In this paper we seek to understand whether the dominant narrative , of a protective , desirable filter bubble and carefully curated echo chamber , is what people really want . We examine how people come across information they disagree with , whether and how they seek it out , and what they do when they meet it . Do they turn away , or do they engage , and , if so , how and why ? 3 Motivating Study The genesis for the larger diary study reported in this paper was a new analysis of data from an interview study on the role of information interaction in view change ( see [ 29 ] ) . This analysis focused on the concepts of filter bubbles and echo chambers , and findings have not been previously reported . We present them here as motivation for the diary study described in the following sections . 3.1 Method for motivating study The motivating study focused not on finding information that does not reflect one ’ s view , but on the broader role of information interaction in view change . As more extensive details of the data collection approach have been previously reported [ 29 ] , we provide an overview to explain the novel analysis presented here . We interviewed 18 people recruited from a variety of sources about their experience of changing view on an issue that was important to them . We asked them to focus on the information interactions involved in the change , and collected information about the view change process . Changes they described included changes of political view , changing view on issues of personal importance ( such as health or education decisions ) , becoming vegetarian , changes of view on high profile criminal cases , and in one notable case , coming to believe the earth may be flat . Interviews were conducted in person or on Skype , and all but two were conducted by two researchers . They were transcribed professionally , and analysed using an inductive thematic analysis approach [ 7 ] . In this paper , we discuss the theme we identified on filter bubble breaking during view change . This theme surfaced without us mentioning filter bubbles , echo chambers , or related ideas ; it was entirely participant driven . 3.2 Filter bubble breaking during view change Arguably , to break out of a filter bubble or echo chamber , you first must recognise that you are engaging witha steady stream of similar information , and choose to change that . Participants expressed a high awareness of the potential for filter bubbles and echo chambers to limit what they saw . For example , P8 noted ‘ J have read about these things that are about echo chambers and things like that , and people wanting to reinforce their views and not willing to change it. ’ Similarly , P9 said of himself I ’ m from a working class , white , non-English background in a very rich country , so I ’ m sure that fits me into some kind of political bag and I ’ m sure some biases are inbuilt. ’ Echo chambers were seen as behaviourally-constructed , and something that participants could avoid if they so chose ; for example P11 stated ‘ this sounds like a negative behaviour I need to avoid . So what can I do to do that ? ’ . Other participants suggested they were not stuck in echo chambers , for example P16 stated ‘ I wouldn ’ t say my social media is an echo chamber ... 1 have journalistic instincts and values ... and I ’ m not one to get drawn into whatever. ’ In contrast , some participants , such as P14 , saw value in being in an echo chamber to ‘ discuss nuance ’ : ‘ Well , it is fan echo chamber ] in one respect , because it 's obviously a group of people who all share , at a more macro level , the same political views . But on a more micro level , it 's a safe place to discuss your thoughts ’ . Alongside a recognition of the social factors driving their information engagement , participants recognised algorithms were influencing some of what they saw . P10 said 7 have been following some people who talk about climate change and reducing CO2 emissions . And because I follow these people then whenever I go to the explore part of Instagram , | obviously see the suggestions for other pages on this ’ ; similarly , P16 noted ‘ there was some Twitter algorithm which was like , you ’ re going to like all this US stuff , because you ’ ve been liking that a lot recently ’ . This recognition of the limitations of their social circles and algorithmic feeds was a key driver for participants wanting information from outside their filter bubbles or echo chambers ; P11 noted there had ‘ been so many articles and other media about the echo chamber effect , and things like that ’ that had made him aware of these information constructs and their possible negative effects on view change . Of 18 participants , 10 described occasions where they had deliberately taken action to expose themselves to views other than their own , either regularly as part of their everyday information behaviour , or specifically on an issue that had come to their attention . Some actions were intended to ensure access to a diversity of information , others were specifically undertaken to ensure they saw positions they actively disagreed with . Some participants mentioned searching for information they disagreed with : P17 said 7 think I Googled it and talked to people as well , to try and understand why [ people voted for Brexit ] ' . This participant deliberately sought information diametrically opposed to her own view because she ‘ wanted to understand ’ the ‘ other side. ’ Other participants engaged with specific information sources they expected to contain views other than their own . For example , P8 regularly read The Economist , even though her views were broadly left wing : ‘ The Economist is ... very dogged religiously liberal free markets , and sometimes I think they skirt over the issues that have to do with capitalism and globalisation . But I still read it because I like to keep an eye on what they 're saying. ’ Similarly , P9 consulted newspapers that were further right than him on the political spectrum to chance upon information he knew he was likely to disagree with : ‘ my political views are generally slightly left of centre ... occasionally I go on the news and get an article from like The Sun or something that ’ s quite right wing and I ’ ll just read what ’ s there just out of sheer interest . While some participants specifically sought disagreeable information , others sought a plurality of views , such as P11 who said ‘ so at times it tends to be quite central . If | see a particular point of interest , I 'll go to The Guardian and The Times , and The Telegraph or The Mail just to see how differently those organisations interpret something , and P2 who said of the people she followed on Twitter 7 don ’ t agree with all of them ... but I don ’ t want to be in this bubble where I only listen to people that have the same ideas as I do ’ . While participants were open to alternative views , there were limitations to what they would engage with ; these limitations changed situationally . P14 noted that she would ‘ never ’ believe anything in the Daily Mail because ‘ they 've got a massive agenda ’ . In contrast P2 noted that while generally she was prepared to engage with alternative views to her own , ‘ sometimes you feel pretty passionate about something . You can not even think about the idea that someone might disagree with you. ’ In summary , participants reported a high level of awareness of the algorithmic and social limitations of information in personalised environments , particularly on social media . In response to these limitations , many took steps to ensure they engaged with information reflecting either a more diverse range of views , or views they explicitly disagreed with . However , there were limits to this engagement based on both information sources and participants ’ personal views . 3.3 Motivation for further study The narrative our participants expressed—awareness of being ina filter bubble or echo chamber—runs counter to descriptions of participants in much previous research ( for example [ 3 ; 14 ] ) . While the concept of the filter bubble has occasionally been challenged , the idea that people congregate in social echo chambers , and that there is a high personal cost for challenging these structures , is well supported by the literature [ 31 ; 42 ] . Furthermore , while heralded asa social and political benefit , deliberate engagement with a diversity of views , or with opposing views , has not been discussed in previous information interaction literature . While the behaviour of participants in our motivating study was interesting , it raised as many questions as answers . Firstly , our participants were relatively unusual : people who had both recognized a view change in themselves , and who were willing to discuss it . This is often not the case [ 37 ] . Perhaps this openness also extends to their information engagement . Secondly , self-reports of past behaviour may not be accurate [ 43 ] . Thirdly , participants engaged with information that reflected different views to their own because they had deliberately sought ( rather than passively encountered ) it , or at least created an information environment where encounters were likely to occur [ 26 ] . We thus had several questions about filter bubble breaking behaviour : does it occur outside the context of view change ? What kinds of behaviour do people who come across information they disagree with engage in when they are not looking for that information ? Do incidental encounters result in view change , or even engagement , or is the unwillingness to engage described elsewhere more typical ? To investigate these questions , we designed a diary study to capture encounters with information that reflects a different view to their own relatively contemporaneously . The diary study focused on how they found this information , whether they responded and how , the factors affecting their response and whether this prompted further interactions . We now describe the method for this study . 4 Diary Study Method Based on our previous study , where many encounters with view-changing information occurred on social media , we wanted to understand what happened when people encountered information at odds with their view ( ‘ disagreeable information ’ ) . Outside of the context of view change , we had little understanding of how frequent such encounters were , nor how they occurred , nor how people reacted to them . Diary studies have commonly been used to study information experiences that may be infrequent and hard to subsequently recall [ 1 ; 27 ; 30 ] ; we chose this approach . As with previous studies , we followed our diary studies up with semi-structured interviews to clarify elements of the diary and elicit further information about participant motivations and experiences [ 27 ] . Based on concerns about social media facilitating filter bubbles and echo chambers along with our earlier finding that much disagreeable information is found on social media [ 29 ] , we focused this study on social media platforms . We recruited 10 regular users of social media ( who used at least one social media platform several times a week ) through a combination of social media advertising , personal contacts and snowball sampling . This number , while small , is typical of other studies of information interaction ( for example [ 11 ; 20 ; 27 ] ) , and allowed us to form an initial impression of whether—and how—people engaged with disagreeable information . Nonetheless , the sample size is a limitation of this study , as is our sampling approach : we advertised on our own social media , and thus our participants may be ‘ people like us ’ who are more than usually willing to engage with disagreeable opinions . We asked participants to refer other participants , and our social media feeds to repost our advertisements . It , however , is unlikely that we reached very right-leaning people with deeply entrenched views , who are less likely to engage with views other than their own [ 47 ] . Participants were aged 18-30 ; 5 men and 5 women . They reported using social media platforms , including Reddit , TikTok , Facebook , Twitter , YouTube and Instagram . We refer to participants as P1-10 . 4.1 Diary study The diary period ran for one week in September 2020 , during which participants were asked to take screenshots of information they disagreed with on social media and describe their interactions with it . Diaries were recorded in Google Docs ; a new Google Doc was sent to participants at the end of each day , along with several prompts . The first prompt in each diary was ‘ did you see anything on social media that you disagreed with , or that changed your view today ? ’ This question was followed by a series of lightweight prompts intended to elicit details about participants ’ interactions with disagreeable information , for example ‘ what were you doing when you found this information ? ’ , ‘ how did you feel when you saw it ? ’ , ‘ did you interact with it in any way , for example by commenting or sharing ? ’ , ‘ what about this information didn ’ t align with your view ? ’ . Participants were encouraged to use the prompts as a starting point to provide a rich description of their information interactions . All but one participant provided at least one diary entry . Participants recorded 48 initial interactions in their diaries ; these could seed further interactions , such as reading comments ina discussion thread or seeking follow-up information . 7 participants reported 3-6 initial interactions each ; one reported 13 and one just a single interaction . The remaining participant reported no interactions with disagreeable information . While we analysed the diary entries in their entirety , we do not include the screenshots provided by our participants in our results ; complete anonymity is not possible due to photos , names and post searchability . Reporting social media data in a way that individuals—particularly non-participants—can be identified is poor ethical practice [ 40 ; 46 ] . 4.2 Follow-up interviews Semi-structured follow-up interviews were conducted over Zoom within a week of the diaries being completed . Interviews lasted between 7 and 69 minutes , most around 45 minutes . The 7 minute interview was with P8 , who didn ’ t record any diary entries ; we interviewed him briefly to confirm he had not seen any disagreeable information , and ask why he thought that was . Each participant 's interview focused on their diary entries , using them as memory aids to elicit further detail about their interactions with disagreeable information . Our questions focused on understanding ambiguities in the diaries , the nature and strength of participants ’ views , how participants found the information recorded in their diaries , how they responded to it and what influenced decisions around those responses . Examples of specific questions we asked included : ‘ had you gone to Reddit with any specific purpose in mind ? ” , ‘ did you interact with this information in any way ? ’ , ‘ why did you look at the comments underneath this tweet ? ’ and ‘ did you have any strong feelings about anything highlighted in this before you saw it ? ’ Interviews were transcribed automatically , then corrected by hand 4.3 Analysis Diaries and interview segments were combined to form a single narrative for each participant , and analysed using thematic analysis [ 7 ] . Analysis was done manually on paper by a single researcher ; a second researcher conducted an independent inductive analysis sensitised by the themes from our preliminary study . The resulting themes describe interactions with disagreeable information , and factors affecting the willingness to engage with disagreeable information . These themes are presented next . In line with Braun and Clarke ’ s assessment that the number of times a theme occurs does not reflect the importance of the theme , we deliberately do not give specifics of the number of instances of any theme or code [ 7 ] . In keeping with Braun and Clarke 's approach , we use quotations from participants to demonstrate each code , and codes are all bolded in their initial appearance . 5 Diary study findings This section describes how participants found disagreeable information , their responses and the factors driving and inhibiting these responses . Finally , we discuss participants ’ reflections on the information sources , platforms and algorithms they used when they found this information . 5.1 Finding disagreeable information None of the experiences of disagreeable information our participants described began with search ; instead , they involved purposeful browsing and passive information encounters . This is perhaps unsurprising , given most social media platforms incorporate feeds that promote information encounters [ 28 ] . Nevertheless , there were times where participants deliberately sought out information they knew they were likely to disagree with . Sometimes this was part of a regular routine , such as P3 reading a long Reddit thread about Melbourne each night , knowing it was likely to present a range of views about lockdown , or P1 who regularly read a Reddit thread ( r/ChangeMyView ) ‘ because there are really interesting posts on there . Very contentious topics as well , so it ’ s interesting to read what other people ’ s views are ’ . Participants also found disagreeable information when they deliberately engaged with contentious information , such as P1 seeking out a subreddit about COVID cases in Melbourne while watching a TV update ‘ to see how other people were reacting ’ , or P3 selecting ‘ very intensely downvoted or upvoted posts ’ to ‘ maybe just take a little look ... to see what content there is in those comments ’ . Passive information encounters with disagreeable information tended to happen where participants were just scrolling ’ through social media feeds , ‘ taking a break ’ ( P2 ) or ‘ before I go to sleep ’ ( P4 ) . Disagreeable information encountered under these circumstances included a ‘ slutshaming ’ TikTok video ( P4 ) and anti- lockdown commentary from friends and associates ( for example P3 and P9 ) . Some disagreeable information in these encounters was promoted by people outside participants ’ social networks , such as comments on a post by Australian politician Dan Andrews , which prompted P2 to state ‘ I don ’ t know how Facebook works ’ or a video P1 found ‘ just on my YouTube homepage ’ . More commonly , though , it was shared by people participants knew , either someone on the periphery of their lives ( for example the Instagram influencer on whom P5 did a ‘ deep stalk ’ ) or someone from their past . Referring to a disagreeable Facebook poster , P3 explained ‘ this guy was in primary school ... at the end of primary school you add everyone on Facebook ’ 5.2 Responses to disagreeable information One response to information participants did not agree with was disengagement—such as P3 who ‘ laughed a little bit and scrolled on ’ after seeing an offensive post on Grindr or P6 who Just left and continued scrolling ’ after seeing something she disagreed with on Twitter . We saw this response less often than we might expect , but this is likely because scrolling past disagreeable information on the internet is unlikely to be noteworthy or memorable . In two cases participants disengaged more actively , unfriending people who posted things they disagreed with . For example , P3 unfriended someone who posted anti-lockdown sentiment after seeing too much of it : ‘ I ’ d just had enough ’ . Some disengagement was more public , such as P9 who posted about anti-lockdown views ‘ if any of you guys do hold those views , just unfriend me now ’ . Another common response to disagreeable information was reading comments or replies . One example of this was P5 , who when someone started ‘ retweeting all the replies that agreed with her , ’ ‘ started looking at threads and reading replies ’ because ‘ I like to know what people are thinking ’ . Similarly , P2 ‘ read the replies ’ toa post ona state leader 's Facebook post to see ‘ what other people had to say . Four participants engaged in active information seeking after they encountered disagreeable information . This could be because they did not understand something about the view , for example P1 who didn ’ t know what sunk cost fallacy was , so I had to Google that ’ . Others needed more information to understand what was being expressed , such as P3 who when he saw Indian President Modi being compared to Trump and Bolsonaro ‘ wiki ’ d [ sic ] him a little bit ’ . Finally , some participants engaged in information seeking to test their own views , such as P10 who , when she saw a post favourably comparing the Swedish COVID response to lockdown , ‘ took a little bit of time to research and look at articles ’ . Another response our participants engaged in was ‘ liking/disliking ’ using social media mechanisms . P1 reported disliking ‘ to show the OP that people disagree with them ’ , whereas P3 wanted to let ‘ other people know the view is discouraged ’ . In contrast , P1 liked comments to ‘ [ show ] the commenter and people reading the comments “ hey , this is a good comment ” . Participants often liked or disliked in preference to commenting because it was easier ; P6 said : ‘ T would have had to make an account to comment ... otherwise you can just upvote or downvote ’ . While less common , some participants did report sharing their own views . Some did this by commenting on a post they disagreed with . For example , P9 replied directly to opposing posters to ‘ debunk their opinion ’ when discussing a COVID-related arrest in Melbourne . In contrast , when P7 came across an anti-China post ona friend ’ s WeChat , he did not want to confront the friend directly . However , he did post his views on his own feed , saying people can just ‘ pass it on [ sic , meaning pass by ] if they 're not interested . As well as sharing publicly , P9 reported he had shared his views on a group chat of likeminded friends because ‘ it felt like it was a safe place to rant ’ , whereas if he commented publicly he would ‘ have to form a more coherent and logical argument ’ . In contrast to these participants who shared their views , eight participants explicitly reported not sharing their views , such as P3 who described himself as ‘ a very passive consumer ’ and P4 who said ‘ in general I just lurk ’ . Finally , albeit rarely , participants reported changing their views in response to disagreeable information they encountered . One example came from P7 , who reported deciding to ‘ work harder on getting a job ’ after reading a post from an old school friend , where his original view was ‘ I got time , like , one more year to graduate ’ . P5 also reported changing her view , in this case about laws around payment for news content in Australia . At first , she was concerned : ‘ the way Google phrased it [ the laws ] were gon na change the way we search ’ , but then she talked to a friend who said ‘ nah nah , this is good , we need them to pay [ writers ] money , ’ so she went from being ‘ on Google ’ s side but then I changed to the government 's side ’ . 5.3 Factors affecting engagement Participants reported a variety of both intrinsic and extrinsic factors that affected their engagement with alternative views . Some of these factors affected their willingness to read or watch content with which they disagreed , others affected their willingness to express an opinion , and two factors affected both . 5.3.1 Motivations to read disagreeable information . One of the most common reasons for reading information participants knew they were likely to disagree with was seeking controversy . One example came from P10 , who decided to read the comments ona poll ‘ because I knew they 'd be spicy ’ . Similarly , P3 examined ‘ very intensely upvoted and downvoted ’ comments on a Reddit subforum . One reason participants gave for seeking controversy was understanding the spectrum of views on an issue . For example , P2 read the comments on Dan Andrews ’ s post because there were ‘ people hearting or whatever , some people were angry or laugh reacting ... so I really was curious as to what are people actually posting on his page ? How many people are actually mad at him ? ’ . Similarly , P10 ‘ wanted to understand how many people were actually against this ’ ina discussion of Melbourne ’ s lockdown and P6 wanted to ‘ get , like , a general idea of what Australia ’ s opinion was ’ . Another motivating factor for participants to engage with disagreeable information was to evaluate their own views . One approach was to compare their own views to those of others , such as P4 who said ‘ I kind of want to see what other people are thinking , the same as me or differently ’ and P1 who wanted ‘ to see where I sit compared with other people ’ . Similarly , P5 wanted to ‘ verify again , like if what I ’ m thinking is correct or just to like know what the other side is , just to become more aware of the situation ’ . In other cases , participants were seeking validation of their views , for example P6 who said ‘ even though it ’ s kind of a controversial opinion [ American racism being different from racism elsewhere ] , | would like to see other people like backing it up , and making me feel like my opinion is validated ’ . Similarly , P3 stated ‘ people having the same kind of feeling , makes my feelings more valid ’ . In line with wanting to validate their own views , two participants reported consuming disagreeable information so they could construct a counterargument . P9 stated ‘ so by getting like opposing information and seeing what they were arguing and the points they were making I was able to like , think of those points and then come up with counters , to their points ’ . This approach was supported by P10 who stated ‘ to make your own arguments , you need to know the other side ’ . Finally , participants were sometimes genuinely interested in understanding and empathizing with those who held a different view to them . P8 , who did not make any diary entries because he did not find any disagreeable information , described himself as someone who ‘ liked to understand both sides of an issue ’ , and when someone posted something he did not initially agree with , he tried to ‘ see things from their point of view ’ and question ‘ whether I need to broaden my own views ’ . Similarly , P10 said it was important to her to ‘ be empathetic that people ’ s opinions come from somewhere ’ , and P3 said he ‘ could probably empathise a bit with where that person was just coming from in terms of people wanting freedom ’ in response to a post criticizing Melbourne ’ s lockdown , even though he personally supported it . Even P9 , who read others ’ views to support constructing counterarguments , commented that doing so ‘ did open me up to , this whole other opinion and the arguments they were making ’ . 5.3.2 Willingness to express an opinion . Participants reported a variety of factors that influenced their motivation for sharing their own views , either in the form of liking or disliking comments , or posting a comment of their own . One of the major factors in whether participants sought to express their own views was their relationship with the people posting . P9 noted that personally knowing the people posting content ( rather than it being promoted by an algorithm ) made him more likely to read it . He stated if ] had just come across it normally while scrolling I probably would ’ ve scrolled past , but because it was shared by two of my friends , I was like wait , what is this ? ’ , 10 Relationships also influenced the way people reacted to posts . P7 , for example , reported liking a post by someone he wanted to reconnect with because ‘ / actually just want to draw some attention from him ’ . P8 noted that he avoided interacting with disagreeable information to preserve relationships ‘ I ’ d hate to destroy a relation [ sic ] over one silly argument ’ . Whether the people posting were friends was another factor affecting decisions to interact , for example , P2 said ‘ when it ’ s a stranger , does it really matter if one more anonymous person likes it ? ’ and ‘ T don ’ t care about arguing with someone who disagrees with me on the internet ... no-one ’ s mind gets changed ’ . P4 reflected this distinction , saying ‘ if it ’ s someone I know then I care more about sharing my opinion and hearing what they have to say . If it ’ s people on the internet , it ’ s kind of like , well , people think some stuff and I think some stuff . P9 enjoyed debating with strangers on the internet but noted that , with strangers , his arguments needed to be clearer and better formed . Disagreeable information that was perceived as serious , or which had a strong emotional impact was more likely to spur participants to engage or express their opinions . P2 , for example noted she swiped through a post about chihuahuas ‘ because it was lighthearted , and not as serious ’ , whereas after reading a post about COVID , she ‘ spent a bit more time reading the thread and googling [ sic ] ’ . Similarly , P9 who did not initially share his views ona planned lockdown protest because he thought ‘ oh , it ’ s just like a fad , it ’ ll pass ’ did share his opinion by the end of the week when it became apparent the protest was actually going to happen . The seriousness of the topic could lead to a strong emotional reaction , such as for P1 , who discussed a post about COVID support payments that made him ‘ more upset than some of the others. ’ in turn making him ‘ more inclined to react ’ . Similarly , when P9 saw a disagreeable article repeatedly , he became irritated and posted because ‘ I ’ ve had it up to here ’ . Participants wanted to see representation of their views in discussions , and this affected their engagement . If their opinion had not been represented , this could motivate them to post , such as self-described ‘ lurker ’ P4 , who described one of her reactions as ‘ what the hell ? And people were agreeing with it as well , and I was like someone has to say this [ to disagree ] ’ . Similarly , P9 said of anti-lockdown arguments ‘ 7 ’ ve had enough with those posts and arguments , | wan na say something and put forward a different opinion ’ . Conversely , if participants felt their views were well represented , they were less inclined to react to posts . P2 said ‘ when I see someone ’ s already commented it ’ s kind of like Oh , you know , they ’ ve already done it , so I don ’ t have to ’ . Similarly , P3 didn ’ t ‘ angry react ’ to a Grindr profile that had already received several angry reacts : ‘ the marginal benefit of me reacting additionally on top of that ’ s not really gon na ... have an impact or anything ’ . Participants sometimes expressed an opinion to try to influence others , such as P7 who posted in response to anti-China posts to ‘ influence [ the poster ] to think another way ’ . P2 thought it was important to challenge disagreeable information ‘ for the good of all of us , [ so ] things that I think are incorrect or disagreeable wo n't just go unchallenged ... other people will just accept them at face value ’ . Presentation of self was a key factor in decisions to express an opinion . P7 , for example , feared creating an enduring opinion profile that may have future consequences : ‘ I just wan na stop generating these traces . In the future , you know , something will happen and it will leave all these really bad histories for me ’ . Similarly , P2 said ‘ I don ’ t like connecting what goes on on the internet to myself , and P9 said I think because we have ... family and friends fon Facebook ] , we generally don ’ t want to share controversial opinions ’ . Sometimes though , self-presentation motivated people to act . P3 unfriended someone because ‘ don ’ t wan na be associated with it [ anti-lockdown sentiment ] ’ , and P8 ‘ didn ’ t want to be known as a social media drama queen ’ , so avoided posting . Related to presentation of self is the attention management some participants reported . Some avoided posting opinions to avoid ‘ get/ting ] attacked ’ ( P7 ) . P6 said she ‘ just would never like post anything publicly ... it really freaks me out ’ . Others did not share their opinion because they felt it would be drawing attention to the opposing view , such as P10 who said ‘ you guys would totally see me react , and nah I ’ m not interested in that ’ . Finally , and most prosaically , interface design motivated some decisions to express an opinion . P9 noted he did not comment on TikTok ‘ because it has a character restriction , and like , it ’ s very hard to get your opinion out ’ . Similarly , P4 did not comment on Reddit because she ‘ would ’ ve had to make an account to comment ’ . Similarly , P3 noted it was too much effort to react to a post he disagreed with ‘ / ’ m lazy—it ’ s an additional function that I would 11 have to do ’ . This suggests that it is possible for design to influence this behaviour , also reflected in participants ’ comments about the sources , platforms and algorithms they used when they found this information ( see 5.4 ) . 5.4Sources , platforms and algorithms Participants reflected not only on their interactions with information they disagreed with , but also on the information sources , platforms and algorithms they used when they found it . Participants routinely reported using different platforms for different purposes , for example P3 stated ‘ Instagram is a platform for me to connect and share ... not a platform for me to look at political content ’ . Platforms were not used in the same way by all participants , though . P6 , for example , used Facebook to keep up with people she knew personally , whereas on Twitter ( where she found most of her disagreeable information ) : ‘ 7 just follow like , random people who are fans of like the same artists that I am , or that sort of thing , so I tend to just get like completely random opinions of people like on the other side of the world ’ . In contrast , P9 used Facebook to ‘ follow , like , all those news articles a bit more , so I ’ ve got more exposure to those different opinions and views and more serious matters from Facebook ’ . Similarly , P4 described Reddit as ‘ probably the most predictable ... { for ] something on the front page , I 'll usually agree with the comments ’ . One common theme was bias . Three participants described certain news outlets as biased , such as P10 who described 9News in Australia as ‘ trash ... not informative journalism ’ and P3 , who did not want information filtered by some sort of journalist or something ’ . Participants also recognised communities as biased , for example , P4 who described the commenters on 7 News as ‘ do n't know , like 52 year old boomers on their iPad ’ and P6 who described people she followed on Twitter as outwardly ... feminist and that kind of thing . I think you call them Social Justice Warriors ’ . Finally , participants recognised the role of algorithms in what they were seeing , for example P4 who was annoyed that after she watched something she disagreed with , TikTok kept showing her more of the same because ‘ the algorithm sorts you into which posts you might like ’ . P10 said of Facebook that ‘ you may not subscribe to these people , or these pages , but according to maybe the algorithm of what you 've been looking at , what you ’ re spending most of your time with , what makes you react longer , so , | assume it has a timer on me interacting with these certain posts , so it will keep feeding me more of those posts , ‘ cause it keeps me on Facebook ’ . Even where participants were unsure of how algorithms worked , they hypothesised about their impact . P2 , for example stated ‘ T think it was a friend of mine liked it or commented on it which is why it got recommended ... I do n't know how Facebook works anymore ’ . 5.5Summary All but one of our ten participants interacted with information they disagreed with somewhere on social media over the course of a week . This information was predominantly passively encountered , though participants sometimes engaged in purposeful browsing to find it . Interactions with disagreeable information varied , but included reading the comments , sharing one ’ s own view , disengaging and looking for more information . Factors that affected participants interactions included relationships with the people posting information , the importance or emotional weight of the topic , wanting to understand and evaluate the opinions of others , and the interface limitations of various platforms . Finally , participants were acutely aware of many of the factors information researchers are concerned about , such as algorithmic influence and bias . 6 discussion One of the key contributions our work makes to the literature is on the permeability of filter bubbles . Previous studies have attempted to quantify this permeability [ 14 ; 47 ; 48 ] . For a filter bubble ( or echo chamber ) to be permeable , though , participants have to be willing to engage with information they find disagreeable , and participants ’ views on filter bubbles and echo chambers support this view . We have provided a qualitative 12 description of behaviour that—at least in the view of our participants—is designed to break filter bubbles . Participants in both studies reported in this paper contradicted popular narratives around filter bubbles and echo chambers . Not only were they theoretically willing to engage with alternative views , but their behaviour demonstrates that they do engage . It has been suggested that engagement across ideological lines occurs mostly to construct counterarguments , rather than to engage [ 21 ] ; our data belies this : only two participants mentioned constructing counterarguments . Many more participants wanted to understand alternative views , or empathise with the people who held them . Where our participants ’ experiences did align more with previous research , was on the issue of echo chambers . Our participants reported not wanting to engage with strangers , for fear they would be shouted at or called ‘ social media drama queens ’ ( P8 ) , but their relationships with posters also affected how they reacted . As in previous literature , old friends were discarded , but relationships with current friends were protected , and a site for open discussion [ 25 ; 42 ] . The echo chamber metaphor highlights a paradox in our results . Participants found the likes/dislikes and comments they read useful , but were often loath to engage themselves , particularly in the form of comments . While lurking is common [ 32 ] , it reinforces filter bubbles and thus encouraging comments and discussion could be considered positive . Participants themselves mentioned interface barriers to engagement ( such as lengthy sign-in processes ) and reducing these barriers while maintaining the accountability that reduces trolling [ 49 ] isa key challenge the future design of information interfaces . Participants were also ( rightly ) concerned about privacy and self-presentation , though , and understanding the relationship between views presented online and participants privacy concerns and self-concept is a complex challenge , ripe for further information interaction research , Where participants did post their own views , or react , they did so because they wanted to see their views represented and influence others , a finding that is similar to work on misinformation [ 10 ] . This finding supports theoretical work on filter bubbles , which posits diversity as a key defense against polarisation and division [ 18 ] . Similarly , posts disagreeing with misinformation have been shown to reduce trust in the misinformation [ 12 ] , so supporting opposing reactions may be an important protection against its spread . Some work on information interfaces to show a diversity of viewpoints has already begun [ 6 ] , but more work is needed on how best to present these views . Creative thinking is needed , because diversity can promote backlash instead of engagement [ 4 ; 23 ; 34 ] : how do we get the benefits without the backlash ? Interfaces that support diversity would also support one of the tasks our participants frequently engaged in : understanding the landscape of opinion and evaluating their own opinion in relationship to it . Assessing one ’ s own beliefs and opinions relative to others has been shown to reduce the spread of misinformation , and mitigate against polarisation [ 4 ] so supporting these tasks is important , but again how we might do this remains unclear . One final key lesson for information interaction in our data is the role of the passive information encounter . Participants in our motivating study had structured their information environments to contain diverse information ( ideal for serendipity [ 26 ] ) , and none of the initial interactions with information from alternative views described in this paper occurred through active search . This supports previous theoretical suggestions about the importance of the role of serendipity in limiting the impact of filter bubbles and echo chambers [ 39 ] . Non-search information behaviour , serendipity and interfaces to support them are significantly under-researched ( 13 ; 28 ] , and our work reinforces the importance of understanding and supporting these behaviours . 7 Conclusions and future work In this paper we report findings from two studies of information interaction with views different to , or disagreeable to , those held by participants . The first study is a motivating study , based on a new analysis of interview data collected to understand the role of information interaction in view change . This data demonstrated that seeking out alternative views , or structuring an information environment where one regularly comes across alternative views , are important , but previously unrecognized information tasks . 13 The participant group in the motivating study was inherently biased : people who had changed their views , and thus were likely to have interacted with information that they disagreed with . To better understand what ‘ normally ’ happens when people interact with information that they disagree with , we ran a one-week diary study with 10 participants , followed by interviews to clarify and expand on what participants had written in their diaries . This study demonstrated that interactions with disagreeable information were common ( all but two participants reported at least three interactions ) , but that view change as a result is relatively uncommon ( only 4 out of 47 interactions resulted in view change , each from a different participant ) . Participants typically passively encountered , rather than actively sought , disagreeable information . Once encountered , participants sometimes disengaged with disagreeable information . In contrast to the popular narrative , though , it was much more common to engage further : participants reported reading comments , engaging in active information seeking , evaluating their own views , expressing their own opinions , or—rarely—changing their view . Participants were motivated to engage by a range of factors , including issue importance , representation of their own view , wanting to empathise with ‘ the other side ’ , and emotional impact . This study has some limitations : participants were relatively young , the diary was for a short period ( onlya week ) , and the study focused on social media . Future work could address these gaps . The major contribution of this work , though , is a new and rich qualitative understanding of how social media users find information they disagree with , and how they react when they do : finding is less search driven , and reactions are less closed- minded than previous research would lead us to expect . Knowing that social media users actively engage with information different to their own views , and that this sometimes affects their views , opens the door to future work designing and evaluating information interfaces that support people who wish to engage with information even where it is disagreeable . This is a form of information interaction that is previously unaccounted for in information interface design . : Information interaction research is ideally placed to create new designs that support those who , like our participants , wish to turn and face the strange . Acknowledgements We thank Google News Initiative and The University of Melbourne for financial support for the motivating study . We also thank our participants , and George Buchanan for comments on a draft . References < bib id= '' bib1 '' > < number > [ 1 ] < /number > Adler , A , Gujar , A , Harrison , B.L , O'Hara , K , , and Sellen , A , 1998 . A diary study of work-related reading : design implications for digital reading devices . In Proc . CHI 98 ( Los Angeles , California , United States ) , ACM Press , 241-248 . DOI= http : //dx doiorg/10.1145/274644.274679 . < bib id= '' bib2 '' > < number > [ 2 ] < /number > Australian Competition and Consumer Commission , 2018 . Digital Platforms Inquiry : Preliminary Report . https : //www.accc gov.au/focus-areas /inquiries-finalised/digital-platforms-inquiry-0. < /bib > < bib id= '' bib3 '' > < number > [ 3 ] < /number > Bakshy , E. , Messing , S. , and Adamic , L.A , 2015 . Exposure to ideologically diverse news and opinion on Facebook . Science 348 , 6239 , 1130-1132 . DOI= http : //dx.doiorg/doi:10.1126/science.aaal160. < /bib > < bib id= '' bib4 '' > < number > [ 4 ] < /number > Benegal , S.D . and Scruggs , L.A , 2018 . Correcting misinformation about climate change : the impact of partisanship in an experimental setting . Climactic Change 148 , 1 , 61-80 . DOI= http : //dx.doiorg/10.1007 /s10584-018-2192-4. < /bib > < bib id= '' bib5 '' > < number > [ 5 ] < /number > Boyd , D. , 2014 . It 's complicated : The social lives of networked teens . Yale University Press. < /bib > < bib id= '' bib6 '' > < number > [ 6 ] < /number > Bozdag , E. and van den Hoven , J. , 2015 . Breaking the filter bubble : democracy and design . Ethics and Information Technology 17 , 4 , 249-265 . DOI= http : //dx.doiorg/10.1007 /s10676-015-9380-y. < /bib > < bib id= '' bib7 '' > < number > [ 7 ] < /number > Braun , V. and Clarke , V. , 2006 . Using thematic analysis in psychology . Qual Res Psych 3 , 2 , 77-101. < /bib > < bib id= '' bib8 '' > < number > [ 8 ] < /number > Bruns , A , 2019 . Filter bubble . /nternet Policy Review 8 , 4 . DOI= http : //dx doi.org/10.14763 /2019.4.1426. < /bib > < bib id= '' bib9 '' > < number > [ 9 ] < /number > Bruns , A , 2019 . It ’ s not the technology , stupid : How the ‘ Echo Chamber ’ and ‘ Filter Bubble ’ metaphors have failed us . In Prac . [ AMCR 19 ( Madrid , Spain ) , International Association for Media and Communication Research. < /bib > < bib id= '' bib10 '' > < number > [ 10 ] < /number > Chen , X , , Sin , S.-C.J. , Theng , Y.-L. and Lee , €.S. , 2015 . Why Do Social Media Users Share Misinformation ? In Proc . JCDL 15 ( Knoxville , Tennessee , USA ) , Association for Computing Machinery , 111-114 . DOI= http : //dx doiorg/10.1145 /2756406.2756941. < /bib > < bib id= '' bib11 '' > < number > [ 11 ] < /number > Colleoni , E. , Rozza , A. and Arvidsson , A , 2014 . Echo chamber or public sphere ? Predicting political orientation and measuring political homophily in Twitter using big data . ] Comm 64 , 2 , 317-332. < /bib > < bib id= '' bib12 '' > < number > [ 12 ] < /number > Colliander , J. , 2019 . “ This is fake news ” : Investigating the role of conformity to other users ’ views when commenting on and spreading disinformation in social media . Comp . Hum . Behav . 97 , 202-215 . DOI= http : //dx doi.org/10.1016/j.chb.2019.03.032. < /bib > 14 < bib id= '' bib13 '' > < number > [ 13 ] < /number > Fidel , R. , 2012 . Human information interaction : an ecological approach to information behavior . MIT Press. < /bib > < bib id= '' bib14 '' > < number > [ 14 ] < /number > Flaxman , S. , Goel , S. , and Rao , J.M. , 2016 . Filter Bubbles , Echo Chambers , and Online News Consumption . Public Opinion Q 80 , $ 1 , 298-320 . DOI= http : //dx.doiorg/10.1093 /pog /nfw006. < /bib > < bib id= '' bib15 '' > < number > [ 15 ] < /number > Foth , M , Tomitsch , M. , Forlano , L. , Haeusler , M.H. , and Satchell , C. , 2016 . Citizens breaking out of filter bubbles : urban screens as civic media . In Proc . PERDIS 16 ( Oulu , Finland ) , Association for Computing Machinery , 140-147 . DOI= http : //dx doiorg/10.1145/2914920,2915010. < /bib > < bib id= '' bib16 '' > < number > [ 16 ] < /number > Guess , A , Lyons , B. , Nyhan , B. , and Reifler , J . 2018 . Avoiding the echo chamber about echo chambers : Why selective exposure to like-minded political news is less prevalent than you think . Knight Foundation https : //kf-site- production.s3.amazonaws.com/media_elements/files/000/000/133 /original /Topos_KF_White-Paper_Nyhan_V1.pdf. < /bib > < bib id= '' bib17 '' > < number > [ 17 ] < /number > Helberger , N. , 2011 . Diversity by Design . | . Inf Policy 1 , 441-469 . DOI= http : //dx doi.org/10.5325/jinfopoli.1.2011.0441. < /bib > < bib id= '' bib18 '' > < number > [ 18 ] < /number > Helberger , N. , Karppinen , K , , and D ’ Acunto , L , 2018 . Exposure diversity as a design principle for recommender systems . Inf Comm & Soc . 21 , 2 , 191-207 . DOI= http : //dx.doi.org/10.1080/1369118X.2016 , .1271900. < /bib > < bib id= '' bib19 '' > < number > [ 19 ] < /number > Helberger , N. , Kleinen-von Konisgléw , K. , and van der Noll , R , 2015 . Regulating the new information intermediaries as gatekeepers of information diversity . Information and Media 17 , 6 , 50-71. < /bib > < bib id= '' bib20 '' > < number > [ 20 ] < /number > Kefalidou , G. and Sharples , S. , 2016 . Encouraging serendipity in research : Designing technologies to support connection-making . /JHCS 89 , 1-23 . DOI= http : //dx.doiorg/10.1016 /j.ijhes.2016.01.003. < /bib > < bib id= '' bib2 1 '' > < number > [ 2 1 ] < /number > Kelly , G.R , 2009 . Echo chambers online ? : Politically motivated selective exposure among Internet news users . ] Comp Mediated Comm 14 , 2 , 265-285 . DOI= http : //dx.doi.org/10.1111/j.1083-6101.2009.01440.x. < /bib > < bib id= '' bib22 '' > < number > [ 22 ] < /number > Ledwich , M. and Zaitsev , A , 2020 . Algorithmic extremism : Examining YouTube 's rabbit hole of radicalization . First Monday 25 , 3 . DOI= http : //dx.doi.org/10.5210/fm.v25i3.10419. < /bib > < bib id= '' bib23 '' > < number > [ 23 ] < /number > Lewandowsky , S. , Ecker , U.K.H. , Seifert , C.M , Schwarz , N. , and Cook , J. , 2012 . Misinformation and Its Correction : Continued Influence and Successful Debiasing . Psyc Sci in Public Interest 13 , 3 , 106-131 . DOI= http : //dx doi.org/10.1177/1529100612451018. < /bib > < bib id= '' bib24 '' > < number > [ 24 ] < /number > Liao , Q.V . and Fu , W.-T. , 2014 . Can you hear me now ? : mitigating the echo chamber effect by source position indicators . In Proc . CSCW 14 ( Baltimore , Maryland , USA ) , ACM , 2531711 , 184-196 . DOI= http : //dx doiorg/10.1145/2531602.2531711. < /bib > < bib id= '' bib25 '' > < number > [ 25 ] < /number > Lopez , M.G . and Ovaska , S. , 2013 . A look at unsociability on Facebook . In Proc . BCS HCI 13 ( London , UK ) , BCS Learning & Development Ltd , Article 13. < /bib > < bib id= '' bib26 '' > < number > [ 26 ] < /number > Makri , S. , Blandford , A. , Woods , M. , , Sharples , S. , and Maxwell , D. , 2014 . “ Making my own luck ’ : Serendipity strategies and how to support them in digital information environments . JASIST 65 , 11 , 2179-2194 , DOI= http : //dx doi.org/10.1002/asi.23200. < /bib > < bib id= '' bib27 '' > < number > [ 27 ] < /number > Makri , S. , Ravem , M. , and McKay , D. , 2017 . After serendipity strikes : Creating value from encountered information . ASIST Proceedings 54 , 1 , 279-288 , DOI= http : //dx doiorg/10.1002/pra2.2017.1450540103 1. < /bib > < bib id= '' bib28 '' > < number > [ 28 ] < /number > McKay , D. , Makri , S. , Chang , S. , and Buchanan , G. , 2020 . On Birthing Dancing Stars : The Need for Bounded Chaos in Information Interaction . In Proc . CHIIR 2020 ( Vancouver BC , Canada ) , Association for Computing Machinery , 292-302 . DOI= http : //dx doi.org/10.1145/3343413,3377983. < /bib > < bib id= '' bib29 '' > < number > [ 29 ] < /number > Mckay , D. , Makri , S. , Gutierrez-Lopez , M , MacFarlane , A. , Missaoui , S. , Porlezza , C. , and Cooper , G. , 2020 . We are the Change that we Seek : Information Interactions During a Change of Viewpoint . In Proc . CHIIR 20 ( Vancouver BC , Canada ) , Association for Computing Machinery , 173-182 . DOI= http : //dx.doiorg/10.1145 /3343413.3377975. < /bib > < bib id= '' bib30 '' > < number > [ 30 ] < /number > McKenzie , P.J. , 2003 . A model of information practices in accounts of everyday-life information seeking . J Doc 59 , 1 , 19-40 . DOI= http : //dx.doi.org/10.1108 /00220410310457993. < /bib > < bib id= '' bib3 1 '' > < number > [ 3 1 ] < /number > Metzl , J.M. , 2019 . Dying of whiteness : how the politics of racial resentment is killing America ’ s heartland . Hachette UK. < /bib > < bib id= '' bib3 2 '' > < number > [ 32 ] < /number > Nonnecke , B. and Preece , J. , 2000 . Lurker demographics : counting the silent . In Proc . CHI 00 ( The Hague , The Netherlands ) , Association for Computing Machinery , 73-80 . DOI= http : //dxdoiorg/10.1145/332040.332409. < /bib > < bib id= '' bib33 '' > < number > [ 33 ] < /number > Novin , A. and Meyers , E. , 2017 . Making Sense of Conflicting Science Information : Exploring Bias in the Search Engine Result Page . In Proc . CHIR 17 ( Oslo , Norway ) , ACM , 175-184 . DOI= http : //dx.doiorg/10.1145 /3020165.3020185. < /bib > < bib id= '' bib3 4 '' > < number > [ 34 ] < /number > Nyhan , B. and Reifler , J. , 2010 . When Corrections Fail : The Persistence of Political Misperceptions . Political Behaviour 32 , 2 , 303-330 . DOI= http : //dx.doi.org/10.1007 /s11109-010-9112-2. < /bib > < bib id= '' bib3 5 '' > < number > [ 35 ] < /number > 0'Donnell , V. and Jowett , G.S. , 1992 . Chapter 4 . In Propaganda and Persuasion Sage , 122-154. < /bib > < bib id= '' bib36 '' > < number > [ 36 ] < /number > Pariser , E. , 2011 . The filter bubble : What the Internet is hiding from you . Penguin UK. < /bib > < bib id= '' bib37 '' > < number > [ 37 ] < /number > Petty , E. , S.C. , W. , and Tormala , Z. , 2003 . Persuasion and Attitude Change . In Handbook of Psychology Wiley , 353-382 . DOI= http : //dx doi.org/10.1002/0471264385 , wei0515. < /bib > < bib id= '' bib38 '' > < number > [ 38 ] < /number > Puri , N. , Coomes , E.A , Haghbayan , H. , and Gunaratne , K. , 2020 . Social media and vaccine hesitancy : new updates for the era of COVID-19 and globalized infectious diseases . Hum Vaccin Immunother 16 , 11 , 2586-2593 . DOI= http : //dx doiorg/10.1080/21645515.2020.1780846. < /bib > < bib id= '' bib39 '' > < number > [ 39 ] < /number > Reviglio , U. , 2017 . Serendipity by design ? How to turn from diversity exposure to diversity experience to face filter bubbles in social media . In Proc . INSCI 17 ( Thessaloniki , Greece ) , Springer , Berlin , 281-300. < /bib > < bib id= '' bib40 '' > < number > [ 40 ] < /number > Rivers , C. and Lewis , B. , , 2014 . Ethical research standards in a world of big data F1000Research 3 , 38 . DOI= http : //dx.doiorg/10.12688 /f1000research.3-38.v2. < /bib > < bib id= '' bib4 1 '' > < number > [ 41 ] < /number > Robertson , RE , Jiang , S. , Joseph , K , , Friedland , L. , Lazer , D. , and Wilson , C. , 2018 . Auditing Partisan Audience Bias within Google Search . In Proc . CSCW 18 ( Austin , TX ) , New York NY , 1-22 . DOI= http : //dx.doi.org/10.1145/3274417. < /bib > < bib id= '' bib42 '' > < number > [ 42 ] < /number > Seargeant , P. and Tagg , C. , 2019 . Social media and the future of open debate : A user-oriented approach to Facebook ’ s filter bubble conundrum . Doiscourse Context and Media 27 , 41-48 . DOI= http : //dxdoiorg/10.1016/j.dcem.2018.03.005. < /bib > < bib id= '' bib43 '' > < number > [ 43 ] < /number > Sharp , H. , Preece , J. , and Rogers , Y. , 2019 . Interaction Design-Beyond Human-Computer Interaction Wiley , Trenton , NJ. < /bib > 15 < bib id= '' bib44 '' > < number > [ 44 ] < /number > Sunstein , C. , 2018 . # Republic : Divided Democracy in an Age of Social Media . Princeton University Press. < /bib > < bib id= '' bib45 '' > < number > [ 45 ] < /number > Sunstein , C.R. , , 2001 . Republic . com . Princeton University Press , Princeton , NJ. < /bib > < bib id= '' bib46 '' > < number > [ 46 ] < /number > Webb , H , , Jirotka , M , , Stahl , B.C. , Housley , W. , Edwards , A , Williams , M. , Procter , R , Rana , 0. , and Burnap , P. , 2017 . The Ethical Challenges of Publishing Twitter Data for Research Dissemination . In Proc . WebSci 17 ( Troy , New York , USA ) , ACM , New York , NY , 339-348 . DOI= http : //dx.doiorg/10.1145 /3091478,3091489 , < /bib > < bib id= '' bib47 '' > < number > [ 47 ] < /number > Weeks , B.E , , Ksiazek , T.B. , and Holbert , R.L , 2016 . Partisan Enclaves or Shared Media Experiences ? A Network Approach to Understanding Citizens ’ Political News Environments . J Broadcasting Elec Media 60 , 2 , 248-268 . DOI= http : //dx doi.org/10.1080/08838151.2016.1164170. < /bib > < bib id= '' bib48 '' > < number > [ 48 ] < /number > Yom-Tovy , E. , Dumais , S. , and Guo , Q. , 2013 . Promoting Civil Discourse Through Search Engine Diversity . Soc Sci Comp Rev 32 , 2 , 145-154 . DOI= http : //dx.doiorg/10.1177 /0894439313506838. < /bib > < bib id= '' bib49 '' > < number > [ 49 ] < /number > Zannettou , S. , Sirivianos , M. , Blackburn , J. , and Kourtellis , N. 2019 . The Web of False Information : Rumors , Fake News , Hoaxes , Clickbait , and Various Other Shenanigans . / , Data and Inf . Quality 11 , 3 , Article 10 . DOI= http : //dx doi.org/10.1145/3309699 , < /bib > 16 Journal Address Program Studi Ilmu Komunikasi Fakultas Ilmu Sosial dan Ilmu Politik UNIVERSITAS MUHAMMADIYAH TANGERANG JI . Mayjen Sutoyo No . 2 ( depan Lap . A. Yani ) Kota Tangerang , Banten , Indonesia Website : http : //jurnal.umt.ac.id/index.php/nyimak Email : journalnyimak @ fisipumt.ac.id NYIMAK Journal of Communication DAFTAR ISI ( TABLE OF CONTENT ) Multimodal Analysis of Photos in @ Sandiuno Instagram Account Before and After the 2019 Presidential Election —kKiemas Dita Anugrah Susetya and lis Kurnia Nurhayati— Representation of Black Feminism in Hidden Figures —Andre Ikhsano and Jakarudi— Understanding The Problem of Control and Ownership of Mojok.co : Is It Still Alternative ? —Muria Endah Sokowati and Fajar Junaedi— Analysis of The Filter Bubble Phenomenon in The Use of Online Media for Millennial Generation ( An Ethnography Virtual Study about The Filter Bubble Phenomenon ) —Sri Seti Indriani , Ditha Prasanti , and Rangga Saptya Mohammad Permana— Political Agonism for Indonesian Cyberpolitic : Critical Cyberculture to Political Campaign of 2019 Indonesian Presidential Election in Twitter —Henni Gusfa and Fransiskus Emilus D. Kadjuand— Discursive Intertextualities of RuangGuru due COVID-19 by the Governor of Central Java —Cosmas Gatot Haryono , Rustono Farady Marta , and Maichel Chinmi— Analysis of the Convergence Communication Model on Waste Bank Program Stakeholders in South Tangerang City , Indonesia —Mirza Shahreza , Sarwititi Sarwoprasodjo , Hadi Susilo Arifin , and Dwi Retno Hapsari— 157 — 168 169 — 180 181-198 199 — 209 211-232 233 — 247 249 — 265 Communication Patterns in the Development of Life Skills at the 267 —278 Darul Fallah Islamic Boarding School in Bogor Regency —Eko Purwanto , Sumardjo , Dwi Retno Hapsari , and Cahyono Tri Wibowo— Mediating the Lifestyle of Metrosexual on Instagram 279 —294 ( # priadewasa , # ganteng ) : Consumption and Identity —Rama Kertamukti— Nyimak Journal of Communication Vol . 4 , No . 2 , September 2020 , pp . 199-209 P-ISSN 2580-3808 , E-ISSN 2580-3832 Article Submitted 27 March 2020 @ Revised 21 August 2020 ™ @ Accepted 25 August 2020 Analysis of The Filter Bubble Phenomenon in The Use of Online Media for Millennial Generation ( An Ethnography Virtual Study about The Filter Bubble Phenomenon ) Sri Seti Indriani * , Ditha Prasanti ? , Rangga Saptya Mohammad Permana ? 123 Fakultas Ilmu Komunikasi Universitas Padjadjaran JI Raya Bandung — Sumedang KM.21 , Jatinangor Email : rahadianindri @ gmail.com ' , ditha.prasanti @ unpad.ac.id ? , rangga.saptya @ unpad.ac.id ? ABSTRACT This article describes about phenomenon of Filter Bubble for Millennial Generation in online media . Nowadays , we know that people in searching information are likely to be unaware that their search has been chosen . What is most interesting is how people which are aware on how a filter bubble works but seemed to forget when they search on some information . Researchers and critics are worried because these filters isolate people from getting the information on what they want not on what they need . People might not realize that they are led to partial information blindness . This research is acknowledge their awareness on the filter bubble phenomena especially on Y generation who are believed to be a group of people that adapt fast from the analogue era to the digital era . How they search information nowadays , how bubble filters add their self-value on things and how they prevent themselves from being in a bubble . The research was conducted using a qualitative method with an ethnography virtual approach through LINE group of millennial generation . This approach was to gain more information on the virtual culture , and this case the filter bubble phenomena . Results shows that most infor- mants were not aware on the term of ‘ Filter Bubble ’ , but have been assuming it for quite a while . When they were more informed of this term , they realized that they should be more critical on what they read , and being literated is a significant competence in this era . Whether or not this filter bubble could construct their identity , some denied that it didn ’ t have any relevation while others think that it did give some additional values on it . Keywords : Filter Bubble , Computer-mediated Communication , ethnography virtual , millennials , and self value ABSTRAK Penelitian ini menjelaskan tentang fenomena bubble filter untuk Generasi Milenial di media online . Sekarang ini , orang-orang dalam mencari informasi cenderung tidak menyadari bahwa pencarian mereka telah dipilih . Hal paling menarik ialah bagaimana orang-orang yang menyadari cara kerja bubble filter tetapi menjadi lupa ketika mereka mencari informasi . Para peneliti dan kritikus khawatir bubble filter ini mengisolasi orang dari memperoleh informasi tentang apa yang mereka inginkan , bukan tentang apa yang mereka butuhkan . Orang mungkin tidak menyadari bahwa mereka dituntun pada kebutaan informasi parsial . Penelitian ini bertujuan untuk mengetahui kesadaran generasi Y terhadap fenomena bubble filter : cara mereka mencari informasi saat ini , bagaimana bubble filter menambahkan harga diri mereka pada sesuatu , dan bagaimana mereka mencegah diri mereka dari berada dalam bubble . Penelitian ini menggunakan pendekatan kualitatif dan metode etnografi virtual untuk mendapatkan lebih banyak informasi mengenai budaya virtual , knususnya fenomena bubble filter . Hasil penelitian menunjukkan sebagian besar informan tak mengetahui istilah Filter Bubble , namun mereka sudah mengasumsikannya cukup lama . Ketika mereka menjadi lebih tahu mengenai istilah ini , mereka menyadari bahwa mereka harus lebih kritis terhadap apa yang mereka baca , dan menjadi literated adalah kompetensi yang signifikan di era sekarang ini . Selain apakah bubble filter dapat membentuk identitas mereka ataukah tidak , beberapa menyangkal bahwa bubble filter tidak memiliki relevansi apa pun , sementara yang lain tampaknya berpikir bahwa bubble filter memberikan beberapa nilai tambahan . Kata Kunci : Filter Bubble , computer-mediated communication , etnografi virtual , generasi milenial , nilai diri Citation : Indriani , Sri Seti , Ditha Prasanti & Rangga Saptya Mohammad Permana . ( 2020 ) . “ Analysis of The Filter Bubble Phenomenon in The Use of Online Media for Millennial Generation ( An Ethnography Vir- tual Study about The Filter Bubble Phenomenon ) ” . Nyimak Journal of Communication , 4 ( 2 ) : 199-209 . 199 Nyimak Journal of Communication , Vol . 4 , No . 2 , September 2020 INTRODUCTION Nowadays , filter bubble would be one of trending topic in using of online media . As we know that research about filter bubble has becoming increasingly high , most research about this phenomenon is about how it works and how it effects people . But , as the fact is not many researches focused on whether or not people are aware on it . What is more interest- ing is when people that are aware on how a filter bubble works in gaining information , but they still search information without realizing that they are in a bubble . People sometimes explicitly choose their filters , but most hardly even notice that they do ( Resnick et al. , 2013 ) . Researchers and critics are worried because these filters isolate people from getting the information on what they want not on what they need . People might not realize that they are led to partial information blindness ( Haim et al. , 2018 ) . People who are issolated with these filters may build their own believes and might stimulate frictions among other people . Researches also suggest that when people express themselves online , there is a signifi- cant effect and also play a key role in creating polarized opinions ( Abisheva et al. , 2016 ; Sagiyanto & Ardiyanti , 2018 ) . Another research found out that even though people were to see two different information , people would still preferentially select information that rein- forced their existing attitudes ( Liao & Fu , 2013 ) . In ths case , bubbles may shrink further if they retreat into like-minded safety ( Adee , 2016 ) . On the other hand , the Y generation is unique , because they are the one and only gen- eration that actually grow in the process from analogue era into the digital era . They seem to be the group of people that need to adapt the life style rapidly , especially in gaining information . When the internet was not common , people were to seek information through newspaper , magazines or news in the television . Generation X is a new group of workers which were born between 1977 and 1988 . They are likely labelled as Millennials or genera- tion Y . They have unique characteristics , some of them are that they are comfortable with change , more open and tolerant ( Jorgensen , 2003 ) . This generation was introduced with computer in their early ages and alo used them in their young age . However , the burst of communication using the internet emerged in the end of the 1990-ies . This research was intended to acknowledge about the awareness of informants which are millennials about the filter bubble phenomena , how they search information through the net , how this filter bubble phenomena construct their additional self-value and how they prevent themselves from this phenomena . This research was using ethnography virtual approach emerged quite high in the begin- ning of the digital era . It is an approach in understanding virtual communities . This study is to understand on how aware informants on the filter bubble phenomena are . This phenom- 200 Sri Seti Indriani , Ditha Prasanti , and Rangga Saptya Mohammad Permana P-ISSN 2580-3808 , E-ISSN 2580-3832 ena can also be described as how individuals are trapped in their own chosen information which were computer mediated . Computer Mediated Communication Human communicate , and the computer is one of the medium for people to communi- cate . Many researches about Computer-mediated communication have been conducted since the earliest stages in the 1970-ies when e-mails were the first to emerged in exchanging information ( Herring , 2002 ) . Computer-mediated communication ( CMC ) is a theory which involves sending messages through computer networks such as the Internet ( Liang & Walther , 2015 ) . It is a technological method for facilitating human communicative acts ( Walther , 1996 ) . From what Walther stated , these communication acts can be in verbal and nonverbal communication . Nowadays when people find information or exchange information through the internet , people find it easier and easier to understand , not only do people use text messages but audio-video messages are possible also . CMC system is changing how people communi- cate , it provides a system of human and computers , absorbs and then extends the advan- tages of all former formats of communication , embracing the instant interaction of oral communication , the abstract logics of printing dissemination , and the vivid images of movie and television ( Yu , 2011 ) . Why is CMC relevant with this study ? One of the reason is that Filter Bubble is one of the result in communicating through the internet . Filter Bubble Filter Bubble has also been an object of research many times , but most researches are more to how it works and how it . This study is to acknowledge people from the Y generation aware on the term of filter bubble and its consequences . Nadiya ( 2017 ) said that Hawkins and Mothersbaugh ( 2010 ) mentioned about the Y generation were people who were born in between 1977 to 1994 ( Nadiya , 2017 ) . Whether or not they know how to prevent themselves trapped in a bubble of contents . Bubble Filter has become a phenomenon from the earliest era when the new media emerged . However , not many people comprehend this term . Filter Bubble can be illustrated as a potential online personalisation that effectively isolates the person from other various perspectives and content . This online recommenda- tion system is built through algorithms that predict items on what users enjoy the most ( Nguyen et al. , 2014 ) . It is an algorithm curation and personalised system in a bubble which can decrease a person to find other news content cross ideology ( Spohr , 2017 ) . Analysis of The Filter Bubble Phenomenon in The Use of Online Media 201 for Millennial Generation ( An Ethnography Virtual Study about The Filter Bubble Phenomenon ) Nyimak Journal of Communication , Vol . 4 , No . 2 , September 2020 Finding information in the net can trap most users in a bubble which prevent them to see other various content . This bubble can create a constructed perspective . Personalized filters are sweeping the Web , creating individual universes of information for each of us ( Pariser , 2011 ) . This assumed that individual will have their own perspective about something and believe that it is right , which might be contradictive with other individuals . However , most research about these polarizing phenomena stated that if people were to be literated and skilful in searching information in the net , it is unlikely to be trapped in a bubble . Information research about politics , for example , people who are interested in poli- tics find social media as an outlet media to provide information . Those who are literate will not be cocooned in a political echo chamber ( Dutton et al. , 2019 ) . Though , in some cases , people that are literated can also be unaware . People at first , are unaware that there is a mechanical system that happens on the internet , which changes in responding to the users . The negative effect of the filter is the strengthening of a person ’ s pretension to be reductive which leads to a radical attitude . The bubble effect filter , on the other hand , it is a necessary logarithmic system ( Zakaria et al. , 2018 ) . METHOD This research is to acknowledge on how aware is the Y generation with the Filter Bubble phenomenon . The Y generation who are believed to be a group of people that adapt fast from the analogue era to the digital era . The research questions cover how they search information nowadays , how bubble filters add their self-value on things and how they pre- vent themselves from being in a bubble . The research was conducted using a qualitative method with an ethnography virtual approach . This approach was to gain more information on the virtual culture , and this case the filter bubble phenomena . Qualitative researchers seek to understand lived experiences in context and the meanings associated with these experiences , usually from the perspec- tive of participants . Qualitative data collection typically involves interviews , observations , and documents studies ( Maxwell & Reybold , 2015 ) . The ethnography approach was to gain a more comprehensive understanding on the phenomena in the virtual world , as the filter bubble phenomenon exsist more likely there . In the fact , researches has described data about virtual ethnography from Hine ( 2001 ) which consists of virtual ethnography questions assumptions , different with real-life and phenom- ena that arise from face-to-face interactions , and the internet changes the understanding of the ‘ location ’ of research ( Prasanti & Indriani , 2019 ) . Beside that , researchers also said the same method about from the oldest research before , that ethnography itself is a qualitative 202 Sri Seti Indriani , Ditha Prasanti , and Rangga Saptya Mohammad Permana P-ISSN 2580-3808 , E-ISSN 2580-3832 research design in which a researcher describes and interprets patterns that are exchanged and learned from cultural groups about values , habits , beliefs , and language ( Indriani & Prasanti , 2019 ) . RESULT AND DISCUSSION Using the ethnography virtual approach means that the research needs to begin in ex- plaining how a filter bubble works in the online media . Approaches using ethnographic study of the internet are diverse and various . The methodological approach has broadened and reformulated through the years such as digital ethnography , ethnography on/of/through the Internet , connective ethnography , networked ethnography , and cyberethnography ( Carter , 2018 ) . Filter bubble for short is a bubble of information that are collected through an allogaritm system in the net . It creates personalized filters which can be positive and negative for the users . The Internet create a persistent virtual space that transforms earlier notions of the imagined society ( Shumar & Madison , 2013 ) . This space is assumed to have become a bubble or a personalized space on which users believe in . There are some positive sides in this filter bubble phenomena . First , with this filter bubble , people are not lost in the amount of information . This situation can prevent people from excessive media exposure . Moreover , in this digital era , new information comes in seconds and it will be too much for someone to handle . Second , Filter bubbles facilitate our commu- nal instincts . Especially on social media , we will be more likely to look for similarities from thousands of friend/follower accounts . Third , filter bubble can actually become an assistant for people in seeking information because it filters other information that are not needed ( Lumakto , 2018 ) . On the other side , the negative sides of this filter bubble phenomenon on which why it has become a virtual problem is what Pariser ( 2011 ) wrote about in his book ‘ What the internet is hiding from you ’ . As mentioned before , filter bubbles are everywhere , especially on search engines and social media . This bubble shows information related to what we usually click on or search . Therefore , there are some negative sides . First , people can be stuck on what is called echo chamber effect . Where people seem to think they know every- thing . Second , people seem to see things in their own perspective , and the cause of the filter bubble strengthen their perspective . This reason can add more self-value which makes a person have a stronger attitude towards something . Third , in some cases it can benefit advertisements . When people click on an advertisement , then it will show again every time a person comes back to the internet and people tend to just click on what they see ( Pariser , 2011 ) . Analysis of The Filter Bubble Phenomenon in The Use of Online Media 203 for Millennial Generation ( An Ethnography Virtual Study about The Filter Bubble Phenomenon ) Nyimak Journal of Communication , Vol . 4 , No . 2 , September 2020 Information Research in Online Media Most informants in accessing information through the net , they go to google and look up to the first 1 until 3 pages , and click the title which are relevant to what they seek . They see the online media as a gate way to find resources of information . Google has become their first application to access information . After google gives out its list of answers , most infor- mants will choose the most reliable web address to seek information . Some said that they only stop in the first page of what Google offers without clicking the next page . Jerry said that he would go to google map to seek more detail information . Some others go to Facebook and Instagram , and just one informant who used another web address which is not quite familiar Duckduckgo.com . Informants seemed to have bigger interest in searching information through Google and Facebook . Galloway stated that there are four which are Amazon , Apple , Facebook , and Google to be the most influential companies on the planet ( Galloway , 2017 ) . Google seemed to be the best choice for people to seek information . Filter Bubble Phenomenon Awareness Some people might not be aware that Google had been customizing its search results since December 2009 . Google has been trying to predict what users most likely to click . These phenomena lessen people to get a broader popular result ( Pariser , 2011 ) . Four out of seven informants were not aware of the term filter buble , they were quite surprised and unaware of it . Rita stated that she didn ’ t even have any idea of what was happening . As she went through an article about the filter bubble , her first statement was that she was in shock and saw it as something cunning where a few people could get a lot of benefits from it which is unfair . Shirin was also unaware with the situation but she was questioning about it , like Rita , they were questioning why advertisements and news had almost the same traits . Shirin suspected it already and after she searched more about this ‘ filter bubble ’ term , her suspicious was right . “ At first , | did not know , but after searching , | finally found out . It is a logarithm that was “ intentionally ” created by a party to herd an opinion about a discourse ” ( Shirin , 2020 ) . Yo , another informants admitted that he was not aware before but found it as something very normal and ordinary because he could understand the principleThe other three infor- mants were aware of this term , but were more familiar with the term ‘ polarization ’ . After reading more information about the ‘ filter bubble ’ , he assumed that individuals in social environments , especially when communicating with social media , will not be separated from the filter bubble . Yo stated that even though an application is free , there will still be 204 Sri Seti Indriani , Ditha Prasanti , and Rangga Saptya Mohammad Permana P-ISSN 2580-3808 , E-ISSN 2580-3832 advertisements where it can gain profit . Advertising will be very personal when using a personal algorithm and algorithm can cross-platform . ‘ if you open lazada to look for par- ticular items . Then open FB and IG , then there will be several sponsors related to the searches we did previously on lazada or google ” . ( Yo , 2020 ) . This statement is relevant to what Pariser ( 2011 ) mentioned that a personalized world , people will be shown only news that is convenient and confirms what the people believe in ( Pariser , 2011 ) What people have clicked before will determine what the people will be exposed to in the future . Concerning the social environment in social media , at least people have filtered themselves when they feel uncomfortable with some posts sent . lan was one of the informants who was also unaware of this term , however he admitted to have a bit of knowledge on how the system worked . He seemed upset on the phenomena and sated that he felt that he was controlled by the system and disappointed that he wasn ’ t free to choose due to the unlimited information . The other three informants were aware on this term and were displore of it . Joko felt that in interacting on social media , he realized that it had a great potential to construct social media users into boxes . What he meant that , people had become persistant to what they believe which meant that what they believed was right . This was because they read what they saw in the media platform and unrealizing the alogaritm system in the net . This could be potential for conflicts . Jerry stated that he felt bored on what the media offered him . The news , games and music were similar . ‘ yes | know , like what | experienced on the homepage of youtube , the algorithmic effect displays film , vlog , music , and games that | have played or downloaded before , so it is annoying too , what comes out does not come out of the box. ’ ( Jerry , 2020 ) . Jerry also felt as he was a fool to read the same information all over again or listen to similar music . Some informants say that this phenomenon can have both positive and negative impact on one ’ s personalities . It can be harmful when people are not literate and critical in informa- tion exposure that they receive . They will believe in anything they read , without knowing whether the information could be fake news . This can increase the hoax spreading and cause wider negative effects . Additional Self-Value from Online Media Filter bubble can easily construct one ’ s identity or an additional self-value . However , these informants that are Y generation have self-prevented this situation . Though they say Analysis of The Filter Bubble Phenomenon in The Use of Online Media 205 for Millennial Generation ( An Ethnography Virtual Study about The Filter Bubble Phenomenon ) Nyimak Journal of Communication , Vol . 4 , No . 2 , September 2020 that the information that they get are likely more for adding knowledge but do not seem to have a big effect on the way they think about things . The filter bubble phenomena itself however add some self-values about the media itself . They are more sceptis on what the media provides and are more aware on things that they read . Though , they admitted that there has been a changing pattern on the way people choose and buys things . Prevention from Filter Bubble Yo determined that people must check every information so that they are not trapped in the polarization of ideas like frogs in a shell . Yo suggested that experts should use a new algorithm so that the polarization does not occur that could divide the community . A con- crete example is during the last presidential election ; the community was divided into ‘ shucks ’ and ‘ tadpoles ’ . Rita now is more aware on this phenomenon , she admitted that she should be more literated and also read a lot . And when she does read something , she needs to read from other sources to compare whether or not the information is true . Other suggestion she mentioned that people shouldn ’ t only read what are viral only but others which are not . So , results shows that there are 6 ways in preventing themselves from the bubble : The first , researchers has seen that informants suggest to click things that are unrelated to what people like , and what people usually click on , or click to some information that people might not agree on . This can enrich other perspectives beyond their knowledge . People should try different things and get out of their safe zone . The second , Informants suggest to filter themselves . They should develop a more critical way in thinking and not taking things for granted . They should find more resources that are credible and trustworthy . People can filter themselves by not clicking on to provocative titles or titles that can amused us . Then , the third , researchers also has funded that some suggested to reset back their username , start everything from the beginning . It would be so hardful for informant , when they have to start from the first step . The fifth , people should lessen the use of social media and not depend on it . In this case Joko admitted to erase his Facebook account and rarely use his Instagram account . If he does use social media , he uses an anonym account which he believes to be untraceable . The last , based on data of observation through online media , researchers has seem that informant try not to be controlled by suggestions that the media offers . 206 Sri Seti Indriani , Ditha Prasanti , and Rangga Saptya Mohammad Permana P-ISSN 2580-3808 , E-ISSN 2580-3832 CONCLUSIONS That filter bubble creates a world that is convenient for us alone because it shows and inform us on what we agree on or what we like about ; however , it makes our perspectives fragmented . The psychological language will emerge as a polarization of ideas among netizens . Results shows that most informants were not aware on the term of ‘ Filter Bubble ’ , but have been assumpting it for quite a while . When they were more informed of this term , they realized that they should be more critical on what they read , and being literated is a signifi- cant competence in this era . Though , in addition whether or not this filter bubble could construct their identity , some denied that it didn ’ t have any relevation while others seemed to think that it did give some additional values on it . The additional values stated on how people see informations nowadays , they might be in a filter bubble itself when they are discussing about the filter bubble phenomena . Researchers suggests that this phenomenon should be address highly in the media or in the help from institutions . This awareness may prevent frictions and miscommunication . There are assumptions from the informants that when individuals are trapped in their filter bubble , they will only see things in one perspective . ACKNOWLEDGEMENT For the publication of this article in the journal of Nyimak , the researcher would like to express his deepest gratitude for the opportunity given to the researcher . Researchers also want to thank the informants who have deigned to be informants in this study . REFERENCES Abisheva , A. , Garcia , D. , & Schweitzer , F. ( 2016 ) . When the filter bubble bursts . 307-308. https : //doi.org/10.1145/2908131.2908180 Adee , S. ( 2016 ) . Burst the filter bubble . New Scientist , 232 ( 3101 ) , 24-25. https : //doi.org/ 10.1016/s0262-4079 ( 16 ) 32182-0 Carter , P. ( 2018 ) . Virtual ethnography . In Social Memory and Heritage Tourism Methodolo- gies ( pp . 48-67 ) . https : //doi.org/10.4324/9781315797915-4 Dutton , W. H. , Reisdorf , B. C. , Blank , G. , Dubois , E. , & Fernandez , L. ( 2019 ) . The Internet and Access to Information about Politics : Searching through Filter Bubbles , Echo Chambers , and Disinformation . In Society and the Internet : How Networks of information and Com- munication are Changing Our Lives ( pp . 228-247 ) . https : //doi.org/10.1093/oso/ 9780198843498.003.0014 Analysis of The Filter Bubble Phenomenon in The Use of Online Media 207 for Millennial Generation ( An Ethnography Virtual Study about The Filter Bubble Phenomenon ) Nyimak Journal of Communication , Vol . 4 , No . 2 , September 2020 Galloway , S. ( 2017 ) . The Four : The Hidden DNA of Amazon , Apple , Facebook , and Google | Scott Galloway { | download . Portfolio . Haim , M. , Graefe , A. , & Brosius , H.-B . ( 2018 ) . Burst of the Filter Bubble ? Digital Journalism , 6 ( 3 ) , 330-343. https : //doi.org/10.1080/21670811.2017.1338145 Herring , S. C. ( 2002 ) . Computer-mediated communication on the Internet . Annual Review of Information Science and Technology , 36 , 109-168. https : //doi.org/10.1002/ aris.1440360104 Indriani , S. S. , & Prasanti , D. ( 2019 ) . Understanding Multiculturalism in a Family on Whatsapp Group in the Disruption Era | Indriani | Jurnal The Messenger . Jurnal The Messenger . Jorgensen , B . ( 2003 ) . Baby Boomers , Generation X and Generation Y ? Foresight , 5 ( 4 ) , 41-49. https : //doi.org/10.1108/14636680310494753 Liang , Y. J. , & Walther , J . B . ( 2015 ) . Computer Mediated Communication . In International Encyclopedia of the Social & Behavioral Sciences : Second Edition ( pp . 504-509 ) . https : / /doi.org/10.1016/B978-0-08-097086-8.95090-6 Liao , Q. V. , & Fu , W.-T. ( 2013 ) . Beyond the filter bubble . 2359. https : //doi.org/10.1145/ 2470654.2481326 Lumakto , G. ( 2018 ) . Mari Memahami Sisi Positif “ Filter Bubble ” Halaman all - Kompasiana.com . Kompasiana . Maxwell , J . A. , & Reybold , L. E. ( 2015 ) . Qualitative Research . In International Encyclopedia of the Social & Behavioral Sciences : Second Edition ( pp . 685-689 ) . https : //doi.org/10.1016/ B978-0-08-097086-8.10558-6 Nadiya , E. ( 2017 ) . STUDI PREFERENSI GENERASI Y DALAM MEMILIH HUNIAN DI JAKARTA BARAT . Jurnal Muara Ilmu Ekonomi Dan Bisnis , 1 ( 1 ) , 145. https : //doi.org/10.24912/ jmieb.v1i1.417 Nguyen , T. T. , Hui , P-M. , Harper , F. M. , Terveen , L. , & Konstan , J . A . ( 2014 ) . Exploring the filter bubble . 677-686. https : //doi.org/10.1145/2566486.2568012 Pariser , E. ( 2011 ) . Eff Pariser - The Filter Bubble_ What the Internet Is Hiding from You- Penguin Press HC , The ( 2011 ) . The Penguin Press . Prasanti , D. , & Indriani , S. S. ( 2019 ) . Analisis Etnografi Virtual Tentang Proses Komunikasi Kesehatan Ibu dan Anak dalam Whatsapp Group “ Tentang Anak ” | Prasanti | Mediator : Jurnal Komunikasi . Mediator . Resnick , P. , Garrett , R. K. , Kriplean , T. , Munson , S. A. , & Stroud , N. J . ( 2013 ) . Bursting your ( filter ) bubble . 95. https : //doi.org/10.1145/2441955.2441981 Sagiyanto , A. , & Ardiyanti , N. ( 2018 ) . SELF DISCLOSURE MELALUI MEDIA SOSIAL INSTAGRAM ( Studi Kasus Pada Anggota Galeri Quote ) . Nyimak : Journal of Communication , 2 ( 1 ) , 81- 94. https : //doi.org/10.31000/nyimak.v2i1.687 208 Sri Seti Indriani , Ditha Prasanti , and Rangga Saptya Mohammad Permana P-ISSN 2580-3808 , E-ISSN 2580-3832 Shumar , W. , & Madison , N. ( 2013 ) . Ethnography in a virtual world . Ethnography and Educa- tion , 8 ( 2 ) , 255-272. https : //doi.org/10.1080/17457823.2013.792513 Spohr , D. ( 2017 ) . Fake news and ideological polarization : Filter bubbles and selective expo- sure on social media . Business Information Review , 34 ( 3 ) , 150-160. https : //doi.org/ 10.1177/0266382117722446 WALTHER , J . B . ( 1996 ) . Computer-Mediated Communication . Communication Research , 23 ( 1 ) , 3-43. https : //doi.org/10.1177/009365096023001001 Yu , B . ( 2011 ) . Computer-mediated communication systems . TripleC , 9 ( 2 ) , 531-534. https : // doi.org/10.31269/vol9iss2pp531-534 Zakaria , T. , Furqon , S. , & Busro , B . ( 2018 ) . ( 25 ) ( PDF ) Filter bubble effect and religiosity : filter bubble effect implication in the formation of subjects and views of religiosity . |OP Pub- lishing Ltd . Copyright ( c ) 2020 Nyimak : Journal of Communication This work is licensed under aCreative Commons Attribution-ShareAlike 4.0 Analysis of The Filter Bubble Phenomenon in The Use of Online Media 209 for Millennial Generation ( An Ethnography Virtual Study about The Filter Bubble Phenomenon ) age = CYPrIUS Faculty of University of Communication and Technology Media Studies Bachelor ’ s Thesis Algorithmic culture and filter bubble : The case of YouTube ’ s recommendation system George Irakleous Limassol , May 2020 ii Copyrights Copyright® 2020 George Irakleous All rights reserved . The approval of the thesis by the Department of Communication and Internet Studies does not imply necessarily the approval by the Department of the views of the writer . lil Acknowledgements I could not have done this thesis without the help of many people . First of all , I would like to express my gratitude toward Dr. Dimitra L. Milioni for her guidance and support toward the whole process of the thesis . Also , I would like to thank Dr. Costas Djouvas for assisting me in both the technological and theoretical parts in order to fully complete the research . Finally , I would like to thank all my friends and family for the patience they showed every time I was talking about the thesis and for their advice and support . iv ABSTRACT Day by day , algorithms of all kinds are becoming part of our daily routines and help us to improve our daily lives . The recommendation systems of many platforms we daily use , are using different algorithms in order to function properly . A strand of the relevant research is currently exploring the impact of algorithms on the identity of users and culture more generally , which leads to the notion of “ algorithmic culture ” . Pariser ( 2011 ) first wrote about the phenomenon of the “ filter bubble ” and how they are being created , both by users and algorithms . Yet , it still remains controversial today if the phenomenon is real , and has split the academic community , as many tried to prove that such a phenomenon is not created by the algorithms . The YouTube platform has one of the most widely used recommendation systems and will be the focus of analysis for this thesis . The thesis examines the platform of YouTube for the existence of a commercial filter bubble in the case of music culture and ponders its impact on identity , or in this case , the music taste of users . Following the method of algorithm auditing , two fake accounts were created and loaded with two different types of music content in order to impersonate two different types of user with different music taste . By analyzing the recommended videos of the two accounts we show how different kinds of bubbles emerged through the recommendation of the platform , and how the platform of YouTube can faction as technology of the self . Keywords : YouTube , Recommendations , Algorithms , Culture , Filter Bubble TABLE OF CONTENTS ABSTRACT oo occcccccccccccscsecseeescseesesceseueeseseeseseesecseseceeseescseceesseseseesesesseseeseseeseeseseeseseeseseerens v TABLE OF CONTENTS ... 0 .... cccccccccccssesessesessesecseseeseseceesecseseeseseesesseseseeseseeseesesseresecseseeees vi LIST OF TABLES 20 ... ccc ceccccccecccecseseesesecseseceeseceeseceesseeescesessesessesscsesecseseesesecseeeseneeaes Viil LIST OF FIGURES oo ... cecccseccsessesecsesecsesecscsecacsecsesaesesaesesaesesacsecaesecaesecseecsenecaenaesenas ix Lo Vitro dtrctio eee cece cece ces ceceeceseu ees eesecsececeseesecaeeaeesesaeeeeesesaeseenseseeseeseeseeecaeeeeeaes 1 1.1 Problem — Necessity of Study ... ccccccccccectecrsessecnecssececssesseessessseeseeeseeseenss 3 1.2 Theoretical background 0.0.0 ... cece ce ccececesessecssessessecssecsecssesseeesessseeseesseeseeess 4 1.2.1 9 Filter bubble ... cece ceneeeeseeseaeeeeesesecseceeesensecaeesensenaeeneeeeeaes 4 1.2.2 Algorithmic Culture ... ccc ccc ccececnsesseesessececssececsseessessessseeseseseessenss 5 1.2.3 Recommender SystOMs 0.0.0.0 ... cece ccessecssessecsecssececeseessceseesseeseeeseessenss 5 1.2.4 Technologies of the self ... ccc ccc cccecsecssessecsecssecseceseessessessseeseeeseesseees 6 1.2.5 Algorithmic Culture ... ccc cece crsessecsessessecsseseessessscesecsseeseeeseessenss 7 1.2.6 The Frankfurt SCHOOL 2 ... eccececeeeceese cesses eseeseeesesecaeeeseseeaeeaeeeenaes 7 1.3 Literature ROVICW 2 ... cece cece ceteesececeseeseseeeceesesaeseeseesecaeeseesecaecaeeseeaeeaeerees 8 2 = Research Methodology .0 .... ccccccccccceccccsseessceseessceseeeseesseesecsseesecsseaeessessessesssesseees 10 3 Resullts/ Findings ... cece ecccccecccescesscescesseesecssecsecssessecssesecssessesssessecsseeseceseeseeeas 14 3.1 Artists appearance oo ... ccc ccc ceseessceseeescesceescesseesecsseesecssesaeessesseeseesiesseee 14 3.2 Recommended videos : views and popularity-age ......... cece cece ecteeteeneeee 15 3.3 The “ Recommended for you ” Videos 0.0.0 ... cceccecccesceseerseeseersesseensessessessseseee 16 3.4 Viewed vs Recommended videos ... 0 ... 0 .. 0.ccccececceceeeeeceseeseeeeeseeeseeeseeeecaeeseenes 19 3.5 The NOm-SONS 00 ... cc cece csecssecseceseessceseeescesecescesseeseesseeaeessesseessessessessieeseee 21 3.6 Non-songs & “ Recommended for you ” ........ ccccccecccccccceecrsessecrsensecseeseeeee 22 4 Discussion and CONCIUSION . ..... 0 ... cece ceeeeececeeseecseeeceseeeceeeseseseeeesseeeeseeeneceeaees 24 5 Limitations and suggestions for future research oo ... cece ceseeseceteeseeeseetseees 28 vi REFERENCES oo ... ccccccceccccccscnsescnseseceeseceeseceesecscnececnecscneescsvsenevsesvsecsesestsiessenessensesentetens 29 APPENDIX Doo eccccccecccceesseeeseeseseeseseeseceseecsseecseecnseseneesenesseneeseessseseteescsesesesenserens 32 vii LIST OF TABLES Table 1 : Recommended mainstream to alternative and alternative to mainstream ........ 15 Table 2 : Views of alternative Comtemt 2.0.00 ... ccc ccc cccceceseeeceeeeeeseeeeeeeseeeseeeseneceeaees 15 Table 3 : Views of mainstream Content 0.0.2.0 ... ccc ceccec cece ceteeeeeeeeeeseseeeeeseneeeeesenecseeaees 15 Table 4 : Popularity-age of mainstream songs in alternative music fan ............ 0 ... 0 16 Table 5 : Popularity-age of alternative songs in mainstream music fan ........ 0 .. 0 ... 16 Table 6 : “ Recommended for you ” tag frequency ... cece ceeeecrsetecnsesseeteeneeseees 17 Table 7 : Popularity-age of “ Recommended for you ” in alternative music fan .............. 17 Table 8 : Popularity-age of “ Recommended for you ” in mainstream music fan ............. 17 Table 9 : T-Test popularity of the “ Recommended for you ” Song ........ 0 .. 0 .. cccceeeeees 18 Table 10 : Popularity-age of alternative music fan ( Whole Set ) ... ccc ec eete tree 18 Table 11 : Popularity-age of mainstream music fan ( whole set ) 00.0.0. eect 18 Table 12 : T-Test popularity of all Songs ......... ccc cceccccccecsceseeseeseesecsseesecsessesnesseesiee 19 Table 13 : Views of loaded videos , Mainstream music fun ... cece cece cee eeeeee 20 Table 14 : Views of loaded videos , Alternative music fun ... eee cece ceeeeeeeee 20 Table 15 : Views of recommended videos , Mainstream music fum ....... 000 .. 00000cc ee 20 Table 16 : Views of recommended videos , alternative music fun ......... 0000. ee 20 Table 17 : T-Test alternative user : loaded vs recommended videos ........ 0 ..... 0. cece 21 Table 18 : T-Test mainstream user : loaded vs recommended videosS ............ 0 .. cece 21 Table 19 : Songs and non-songs with and without the tag ... ccc eeteeteeteees 23 Table 20 : Non-songs with and without the tag ...... 0.cccccccccecccsccsscesecrsesseensesseenessseeeees 23 vill LIST OF FIGURES Figure 1 : Depiction of the valuation cycle of users ’ choices ( based on the discussion by Karakayali et al. , 2018 ) oo ... ccccccccccccceccesccescesseeseessecsecssessecssessecsesssessecssessesssessesseeeseessenss 6 Figure 2 : Recommended videos from Homepage ............. 0ccccccccctecsesssessecsseeseesseenseees 12 Figure 3 : Recommendation in YouTube .0 ...... 0. cece eee ceeeceseeeeeeeeseeeeeeseneeeeeeeeneees 12 Figure 4 : “ Recommended for you ” tag ... ccccccccccecsecsseesecsscesecescesscessesseessesseessenaee 16 1x 1 Introduction It was the 13 '' to 14 of August 2019 , when a group of LGBTQs YouTubers joined a class action lawsuit suing YouTube for discrimination , deceptive business practices and unlawful restraint of speech . As reported by The Guardian , producers and independent film makers joined the lawsuit , suing YouTube for restricting their content and effectively trying to push them off the platform ( Kleeman , 2019 , Nov 22 ) . In the same article , The Guardian attempting to explain YouTube ’ s alleged practices , writes : “ Some think it is to appease advertisers wary of being associated with anything on YouTube that could be viewed as controversial ” . Taking this into consideration , can we really rely on algorithms and recommendation systems as a tool to help us find information , or should we have a more suspicious and critical attitude toward them ? Nowadays , we encounter the increase impact of datafication on our lives , which refers to “ the quantification of aspects of life previously experienced in qualitative , non- numeric form , such as communication , relationships , health and fitness , transport and mobility , democratic participation , leisure and consumption ” ( Kennedy , 2018 : 18 ) or “ the transformation of part , if not most , of our lives into computable data ” ( Cheney - Lippold , 2017 : 276-278 [ e-book ] ) . This data — which are often “ big ” data — are collected and used by commercial platforms such as Facebook , Twitter , YouTube , Skype , free e-mail services etc . To use this data , platforms routinely employ search , filtering and sorting algorithms , leading , as a result , to the algorithmic mediation of users ’ everyday life , in aspects such as friendships , interests , information searches , expressions of tastes and many more . All the above is the result of a pipeline of tools used for collecting and analyzing user-generated data . The sole purpose of these tools is the creation of models representing users ’ behaviors , that will then be used for feeding users with “ interesting ” content . This thesis focuses on the core element of this pipeline , the technology known as “ Recommender Systems ” . Recommender systems , using various information collected from various sources , and relating this information with a user ’ s behavior , suggests to a user content closer to his/her interests , called personalized content ( Ricci et al. , 2011 ) . Yet , by doing so , there is a high risk of reproducing and suggesting to a user very similar content creating “ echo chambers ” . “ Echo chambers ” , as employed by ( Dutton et al. , 2017 ) , suggest that users are exposed to the same kind of information with which they have already been exposed to and are familiar with . Pariser ( 2011 ) , based on the idea of the echo chamber , wrote about the creation of a “ filter bubble ” , a phenomenon that is encouraged by recommendation algorithms and in some cases by users , so that they come across information that is similar to their own interests . Recommendation algorithms map our preferences against other users ’ preferences , at times suggesting new or forgotten bits of culture for us to encounter . Music , as an aspect of users ’ culture , will play an important role in this study . This thesis will explore the existence of a filter bubble through the recommendation algorithms on the platform of YouTube in the case of mainstream and alternative music content . As argued by Cayari ( 2011 ) , the platform of YouTube has become a powerful space that affords new ways to consume , create and share music , while Allen et al . ( 2017 ) consider YouTube one of the three most popular means of discovering music , along with recommendations from friends and family , and the mainstream AM and FM radios . Taking into consideration the impact of algorithms on a daily basis , and the polarization that may occur by the filter bubble phenomenon , in different aspects of users ’ lives generally and in shaping users ’ music taste specifically , the research question that this thesis will attempt to answer is : In the case of music , does the recommendation system of the YouTube platform provide more mainstream content than alternative , creating as a result a commercial filter bubble ? YouTube is a platform that is famous for its user-generated videos . On the other hand , many commercial music companies are using the platform to share their music videos and songs with users all over the world . Separating music content into two different kinds will help us examine if the recommendation algorithms of the platform provide more content from those companies ( mainstream ) , than from other , not so famous companies or users ( alternative ) . Our hypothesis is that the algorithms , in order to increase the monetization of content and the platform ’ s profit , will provide more mainstream content and as a result the existence of a commercial filter bubble will be revealed . In the next chapters we will discuss why it was considered necessary to study this problem , the theoretical background that the research focused on , a literature review of similar studies , the methodology that was used to collect and analyse the data of the research , the results from the analysis of the data and how those results are linked to the existing literature and previous research work . At the end , further research ideas are suggested . 1.1 Problem — Necessity of study It is estimated that in each day that passes , 1 billion hours of videos are watched by users , on the platform of YouTube ( https : //www.youtube.com/about/press/ ) . As one of the biggest video platforms , if not the biggest , YouTube has often been the object of research with contradictory results , especially on the investigation about the existence of a filter bubble . Moreover , YouTube as a video sharing platform , with different themes and genres of videos , has been examined mostly for the existence of ideological filter bubbles , such as the extreme-right and the extreme-left filter bubble . Moreover , as internet users , we encounter everyday different kinds of algorithms . As we encounter social products with the mediation of algorithms , the result is the danger to be driven into more mainstream paths , limiting originality and creativity . Those algorithms are referred as cultural algorithms or algorithmic culture . On the one hand , there are several studies than confirm the existence of filter bubbles both on YouTube and other platforms using recommendation algorithms . On the other hand , there are a few studies proving that something like a filter bubble does not exist . This fact increases the importance for further study of the platforms ’ recommendation system and so does the relative gap in the literature regarding the impact of the recommendation algorithms of YouTube and the creation of filter bubbles in the case of using the platform to find music . Furthermore , a possible filter bubble that is created by the platform ’ s recommendation algorithms , as Allen et al . ( 2017 ) have argued , will reduce users ’ exposure to music that they are not familiar with . As a result of this practice there will be further polarization on users ’ tastes which can be considered a negative aspect , as it limits the possibilities for users to come across information , knowledge , ideologies and cultural content , different from what they are used to . 1.2 Theoretical background In this chapter we will focus on and discuss the main theoretical concept which is at the heart of this thesis , which is the “ filter bubble ” concept , as well as other important and broader theories which inform this study and are connected to the concept under study . 1.2.1 Filter bubble To begin with , the idea of filter bubbles was coined by Pariser ( 2011 ) in his book titled “ The filter bubble : What the Internet is hiding from you ” . As an idea is based on the theory of the echo chamber which , according to Dutton et al . ( 2017 ) , might restrict access to a more diverse array of views and other political information than one might otherwise come in contact with , either online or offline . In the case of the online environment we have an algorithmic filtering , while on the case of the offline social world , we have a social filtering . When social filtering is transferred to the online activities is referred to as “ confirmation bias ” , which attracts people to information that confirms rather than challenges their preexisting views . Pariser ( 2011 ) referred to the filter bubble as the preferential attention to viewpoints similar to those already held by an individual , which is explicitly encouraged by social media companies . Namely , to increase metrics like engagement and advertise revenue , recommendation systems tend to connect users with information already similar to their current beliefs . Pariser ( 2011 ) identifies the emergence of filter bubbles in two possible ways . First , the filter bubble can appear through the suggestions of recommendation algorithms , and second , through users ’ activities on the web and the choices of content s/he makes . Or , in most cases , as a combination of both , because if a user already has a diverse information or cultural “ diet ” , it is difficult for a filter bubble to emerge . 1.2.2 Algorithmic culture The concerns over the filter bubble ( s ) do not exist in a vacuum . They are situated in a broader critical discussion of what is called “ algorithmic governance ” , a term used to refer to “ a more evidence-based and data-driven than traditional governance ” ( Just & Latzer , 2017 : 245 ) . A key tool in this process is automated algorithmic selection , which “ governs a wide spectrum of individual action , and is heavily used for various societal functions ” , as algorithms co-govern or co-determine what can be found online , what is seen and found , is produced , is considered relevant , is anticipated and is consumed ( ibid : 247 ) . This transformed form of governance is based on proprietary big data that tends to strengthen selection criteria oriented on special interests concemed with profit maximization , thus weakening public interest goals and social responsibility in the construction of reality and eventually consolidating and creating new social inequalities ( Just & Latzer , 2017 ) . The filter bubble can appear as an effect of or can be used as a tool by the algorithmic governance in order to maximize profits , for example through advertisements , and to construct a reality . 1.2.3 Recommender systems Recommender systems are a significant part of algorithmic governance , as they use ( big ) data generated by users in order to create a set of suggestions for them ( Ricci et al. , 2011 ) . The most widely used form of recommender systems is known as Collaborating Filtering ( Breese et al. , 1998 ) . Collaborating filtering , based on the assumption that users with similar “ tastes ” ( interests , behaviors , etc . ) in the past will have similar “ tastes ” in the future , clusters users according to their “ tastes ” . Then , utilizing seen behaviors ( 1.¢. , clicking on a YouTube video ) from members of a cluster , suggests similar behaviors to other users of the cluster . The platform of YouTube heavily provides recommendation services and , as O'Callaghan et al . ( 2015 ) write , these recommendations are sets of videos that are presented to users , based on factors such as co-visitation and viewing history . Co- visitation is a factor based on machine learning algorithms , a type of algorithms that suggest to users videos that are based on what other users with similar characteristics tend to watch . The recommendation algorithms are an important factor in the creation of the filter bubble , both in the case of co-visitation and of a user ’ s viewing history . Also , as argued by Karakayali et al . ( 2018 ) , recommendation algorithms can function as “ technologies of control ” or as “ technologies of the self ” . 1.2.4 Technologies of the self Foucault , as discussed by Karakayali et al . ( 2018 ) , contended that in modernity there is shift from how subjects are produced in knowledge-power networks to how human beings turn themselves into subjects . To confirm this idea , Karakayali et al . describe a cycle that evaluates the choices of the user , as can be seen in Figure 1 . First , algorithms take into consideration the online and offline activities of a user and create a set of recommendations . Then , by the user ’ s choices on these recommendations the algorithms take a recursive feedback of the data and create a new set of recommendations resulting in the “ objectified ” aspect of the user . But taking into consideration that users can change or modify their activities any time , the algorithms must begin from the point that calculates the users ’ online and offline activities ; and so the circle begins again . Therefore , we need to consider how “ technologies of the self ” can impact users ’ behaviour and affect their point of view in subjects that are inseparable with cultural decisions . Figure 1 : Depiction of the valuation cycle of users ’ choices ( based on the discussion by Karakayali et al. , 2018 ) 1.2.5 Algorithmic culture Algorithmic governance in general and recommendation systems in particular also affect the realm of cultural production and consumption . Kroeber & Clyde Kluckhohn ( 1963 , cited in Hallinan & Striphas , 2016 : 3 ) wrote that the word “ culture ” is really hard to define and that there are more than 164 different definitions of it . Hallinan & Striphas ( 2016 : 3 ) , in their attempt to define it , refer to culture as “ particular modes of fostering human refinement and their underlying frameworks of valuation and authority , patterns of social difference , commonality and interactions ” . They also introduce the idea of “ algorithmic culture ” , as “ the use of computational processes to sort , classify and hierarchize people , places , objects and ideas and also the habits of thought , conduct and expression that arise in relationship to those processes ” ( ibid ) . Based on the case of Netflix , they discuss how the “ production of sophisticated recommendations produces greater customer satisfaction which produces more customer data which in turn produce more sophisticated recommendations , and so on , resulting — theoretically — in a closed commercial loop in which culture conforms to , more than it confronts , its users ” ( ibid : 122 ) . Hallinan & Striphas raise the question “ what happens when [ ... ] algorithms become important arbiters of culture ” . This issue is taken up by this thesis , which is empirically exploring this assumption in the case of music recommendations in YouTube . 1.2.6 The Frankfurt School It is true that we live in a capitalis system , where over-consumption does not refer only to money and products , but the free market has a major impact on the cultural consumption as well . In the Frankfurt School , culture is represented “ as the sum total of activities that possess the aura of intellectuality or spirituality , that is , the arts and sciences ” ( Piccone , 1978 ) . As part of the arts and culture , music was a subject of critical scrutiny under the critical theory of the Frankfurt School . Writing about music , the question that the philosophers of the Frankfurt School posed was the relation between music and the public . “ This question can not be explored independently of the matter of the function and influence of music society ” ( Tottoéia , 2015 , author ’ s translation ) . One philosopher that devoted a significant amount of time in his work to find an answer was Theodor W. Adorno . Some of his books that show the connection between consuming music and the impact on culture are “ Philosophy of new music ” ( 1949 ) and the “ Essays on music ” ( 2002 ) , which is a book comprised by 27 essays written by Adorno . Taking into consideration that the philosophers of the Frankfurt School were considered Marxist intellectuals , we could make a connection between music consumption and the role of algorithms . Adorno always shared the view that society takes anything that tries to criticize its power and makes it part of the mainstream culture ( in To1togia , 2015 ) , a process which is called “ appropriation ” . The question , then becomes , do recommendation algorithms play any part in this process ? 1.3 Literature Review The filter bubble phenomenon has become the subject of study in several research works . On the one hand , there are studies which reinforce the argument for the existence of the bubble in search engines and news recommendation ( Flaxman et al . 2016 ; Dylko et al . 2017 ; Beam , 2014 ) , while on the other hand there are several studies that refute the filter bubble effects , in cases like the search engines , music consumption and news consumption ( Nikolov et al . 2015 ; Hosanagar et al . 2013 ; Dutton et al . 2017 ) . In this part we will go deeper in three studies , two of which examine the existence of a filter bubble in the case of music on two different platforms with music recommendation algorithms , and one that examines the existence of ideological bubble in the platform of YouTube . O'Callaghan et al . ( 2013 ) , in their article “ The extreme right filter bubble ” , examined the recommendation system on the platform of YouTube asking whether it creates an extreme-right filter bubble . To do so , they first created a set of seed channels for extreme-right content from links propagated by extreme-right Twitter accounts and related channels , which were determined by using the results returned by YouTube ’ s related video services . To devise their method , they first generated an aggregated ranking of related channels for each seed channel . Next , they generated TF-IDF channel document vectors and then categorized the identified topics according to the set created . Lastly , they categorized the channels based on their topic weight and investigated whether an extreme-right filter bubble exists . Their main finding was that users who access an extreme-right video are highly likely to be recommended further extreme- right content , proving consequently the existence of an ideological filter bubble . Allen et al . ( 2017 ) , in their paper titled “ The Effects of Music Recommendation Engines on the Filter Bubble Phenomenon ’ , set out to examine the contribution of the music recommendation algorithm of “ Pandora ” to the filter bubble phenomenon , in comparison to more mainstream radio services . For their research they recruited 18 participants . All participants were given one temporary email address and by the use of a google chrome extension , the investigators tracked the participants ’ actions through the website of “ Pandora ” ( to collect information about the music recommendation algorithm ) and “ last.fm ” ( to collect information about the mainstream radio ) . In the latter case , participants had to listen to 10 to 12 hours of music from a pre-determined set of radio stations . After this process , each participant was interviewed on his/her experience with both services . The result of their study was that , through the comparison of “ Pandora ” and AM/FM radio listening habits , a cultural filter bubble effect does occur with “ Pandora ” as it was less likely for the participants to challenge their music preferences on the service . In this case the filter bubble was induced both from users and the algorithms . In their work titled “ Recommendation Systems as Technologies of the Self : Algorithmic Control and the Formation of Music Taste ” , Karakayali et al . ( 2018 ) aimed to show how music taste emerges as a significant aspect of the user ’ s self and how it becomes an object of care through his/her interactions with last.fm . The main object of their work was the role played by a recommender system in the care of music taste as an aspect of the self . To do that they delved into the experiences of the users of the music recommendation website “ last.fm ” . Their data sources were the comments of the users in several forums and ten in-depth interviews with users of the website . Their finding was that “ last.fm ” does not orient its users toward a definite “ music taste ” and its effects can be described more as disorientation for the users . From the results of this study , we conclude that , in the case of the music recommendation system “ last.fm ” , a filter bubble did not occur . Judging from the findings of previous studies similar to this thesis , it is confirmed there is contradictory evidence regarding the existence ( or not ) of the phenomenon of filter bubble in the cultural/music field . The first study discussed shows that the recommendation system of YouTube indeed creates an ideological filter bubble in the case of extreme-right content . The other two studies examine two different music recommendation algorithms with diverse results . 2 Research Methodology The method of this thesis is a relatively recent method called “ algorithm audit ” ( Sandvig et al. , 2014 ) , which is adapted from the classic audit study , a field experiment used in social sciences usually to detect discrimination ( ibid ) . More specifically , we will employ the subcategory of “ sock puppet audit ” ( ibid ) , which entails the impersonation of users by creating false user accounts . Thus , the proposed study is based on an experimental design , and , following the processes of the algorithm audits , it used a mixed method with both qualitative and quantitative analysis . Qualitative analysis was used to categorize the music content , as described below , whereas the quantitative component refers to the statistical analysis of the collected data . The first step of the research within the current thesis was the creation of the accounts that would be loaded with content . Since the YouTube platform belongs to the Google company , in order to login to the platform two different Google accounts were created . The first account was loaded with mainstream content in order to impersonate a user with mainstream or commercial music tastes and listening habits . The second account was loaded with alternative content following a similar rationale . The procedure to load the accounts with content entailed “ watching ” video content on YouTube for a period of one month ( to ensure that a user profile was consolidated ) and each account was loaded with one and half hour of content per day . The entire rationale of this approach was based on the assumption that YouTube personalizes its suggestions to users , according to their observed habits . The procedure began at the end of January 2020 and ended at the first days of March 2020 . Secondly , the categorization of the mainstream and alternative music content took place . As far as the mainstream content is concerned , the decision was made to identify mainstream content through YouTube channels , and more specifically the channel “ Universal Music Group ” ( UMG ) , which is “ the world ’ s leading music company ” , according to their website ( https : //www.universalmusic.com/company/ ) and 10 one of the three major players in the global music market ; in fact , in 2019 it reached 30 % of the total market share in the recorded music market and added more revenue than Warner Music and Sony Music combined ( Music Industry Blog , 2020 , March 5 ) . Additionally , based on research inside the YouTube platform , one more successful music provider was identified , the VEVO channel , which is a multinational video hosting service owned by Universal Music Group ( UMG ) and Sony Music Entertainment ( SME ) , along with other music companies ( Wikipedia , Vevo ) . Both channels host some of the most mainstream and popular music videos of the YouTube platform . In the case of the alternative music content , Wikipedia was used as a source of categorization . A Wikipedia page ( https : //en . wikipedia.org/wiki/Alternative_rock retrieved 05/05/2020 ) categorizes the alternative music content in two big genres , alternative rock and alternative metal . Each of these genres had a list of sub-genres . Based on this typology , a song was deemed alternative if it belonged to one of the genres or subgenres of those lists . An additional criterion was the popularity of the song or band . Namely , as specific songs or bands of alternative music become a huge success also among mainstream audiences , we worked with a narrow definition of alternative music , excluding songs or bands that are hugely popular within the YouTube platform from loading the account and thus “ training ” the algorithm . For example , the song “ Chop suey ” from the alternative metal band “ System of a down ” , was not used to load the alternative user , as the video today ( 10/05/2020 ) has almost 1 billion views . Also , a list was created with all the alternative artists that were found during the process , independently from their popularity , in order to be used for the categorization of the content that would be collected . As Davidson et al . ( 2010 ) write , recommendations on YouTube are featured in two primary locations : the “ Homepage ” and the “ Browse ” page . Based on the researcher ’ s engagement with the platform , in the Browse page there are recommendations that are related to the platform ; for example , a visit to the “ Browse ” page towards the end of the year ( visited in 2019 ) , the first recommended video is the “ YouTube Rewind video ” , a video that the company of YouTube creates at the end of each year summing up the platform ’ s activities . As can be seen in Figure 2 , in a random visit conducted by the researcher , the recommendations of the homepage are more relevant and personalized to the user compared to the “ Browse ” page . 11 Recommended + Most Epic Aggressive Modern Hybrid- Stewie stops Chris Orchestral Music | Hour Epic Massive ... TAmedia Premium Music HQ © 544K views » 1 week ago 3.6M views * 2 years ago Five Finger Death Punch - Wrong Side Ragnar Lothbrok || See What I've Of Heaven [ LEGENDADO ] become Eu Legendo David 7.7M views * 1 year ago 670K views + 2 years ago Figure 2 : Recommended videos from Homepage Based on these observations , the decision was made to begin the process of data collection following a path from the “ Homepage ” to recommended videos on the right side of the screen , as seen in Figure 3 . From the researcher ’ s experience and experimentation with the platform , the videos that appeared on the right side of the page are personalized and relevant to the user ’ s preferences and previous viewing history . Figure 3 : Recommendation in YouTube After the long process of loading the accounts with content , we logged in with each account , and from the “ Homepage ” we selected the first recommended song- related video , avoiding any other content irrelevant to this study , e.g . sports videos , video games videos , etc . Next , from the landing page , i.c. , the YouTube page of the 12 selected music video , the first recommended video was selected , i.e. , the first video that appeared on the right side of the page , where a list of recommended video appears . At this point , with the use of Python language , a program was created to automatically extract useful information from the recommended videos , which was the id of the videos , the title , the channel that uploaded the video , the views , the seconds since the publication of the video , the “ Recommended for you ” tag ( if it existed ) and the order in which the video appeared . For the programme to work , we had to save the html code of the YouTube page and then run the programme to save the information mentioned above in a csv file . Papadamou et al . ( 2019 ) found that through a 10-click rate , a toddler can come across disturbing video recommendations . Based on the same idea , we followed a 10-click path , which means that we clicked on the first video from the “ Homepage ” , the html of the page was saved and then clicked on the first recommended video . This procedure was repeated 10 times , and for 10 days straight for each account . As a result , a database of 2000 videos , along with their information , was created . The next step was the qualitative analysis of the videos and their categorization into mainstream and alternative ( or not song-related videos ) . Following Davidson et al . ( 2010 : 294 ) , we did not use metadata from the videos for this purpose , such as tags and description of the video , because “ video metadata can be non-existent , incomplete , outdated , or simply incorrect ” . Therefore , the categorization of the videos was completed manually by the researcher , drawing on the typology of the artists on Wikipedia , through the list that was created for the alternative artists and the two YouTube channels . Also when an artist was neither on the channels nor on the list , the researcher manually searched information about the artist ’ s genre . Finally , the analysis of the collected information was completed by statistical analysis and the results will be presented in the next chapter of the thesis . 13 3 Results/ Findings 3.1 Artists appearance Through the analysis that follows , the main purpose was to answer the research question of the thesis : In the case of music , does the recommendation system of the YouTube platform provide more mainstream content than alternative , creating as a result a commercial filter bubble ? In order to analyse our data , we performed a statistical analysis on the 2000 collected videos using SPSS . In order to investigate the existence of a filter bubble , we first explored the appearance of mainstream artists in the alternative music “ fan ” account ’ s recommended videos and the appearance of alternative artists in the mainstream music “ fan ” account ’ s recommended videos . If the recommendations corresponded to the accounts ’ registered tastes , we could speak about the existence of a filter bubble . Moreover , if mainstream content prevailed in both accounts , we could speak of commercial filter bubble , in the sense of YouTube promoting popular musical content irrespective of the users ’ preferences . The findings confirm the former assumption . As seen in Table 1 , the vast majority of the recommended songs recommended to the mainstream music “ fan ” were mainstream music songs ( 90 % , n=841 ) ; similarly , 96 % ( n=899 ) recommended to the alternative music “ fan ” fall into the alternative music genre . This difference is statistically significant [ x° ( 1 , n=1869 ) =1395 , p < .001 ) . Yet , quite unexpectedly , the number of alternative videos that appeared as recommended to the mainstream music fan ( 10 % ) was higher than the number of mainstream videos that appeared as recommended to the alternative music fan ( 4 % ) . The reason we consider the results of this analysis unexpected emerges from the assumption that more mainstream content would be recommended to both fans , in order to propel the profit of the platform , which as a result would be a clear creation of a commercial filter bubble . User Mainstream | Alternative Count Count The artist is categorized as = mainstream 841 33 mainstream or alternative alternative 96 899 14 Pearson Chi-Square Tests User The artistis categorized as Chi-square 1395.030 mainstream or alternative df 1 Sig . .000 '' Table 1 : Recommended mainstream to alternative and alternative to mainstream 3.2 . Recommended videos : views and popularity-age Because of this unexpected result , the analysis continued to examine the views of the recommended videos on both of the above cases . In the case of alternative content ( Table 2 ) , the mainstream music fan was recommended content with significantly more views ( M = 215137822.9 , SD = 369248343 ) , compared to the alternative music fan ( M = 5431534.4 , SD = 13327210 ) ( p < .001 ) . The same goes for the mainstream content ( Table 3 ) : again , the mainstream music fan was recommended content with significantly more views ( M = 345739592 , SD = 577670779 ) , compared to the alternative music fan ( M = 2162700 , SD = 6453661.5 ) ( p < .001 ) . N Mean Std . Deviation Std . Error user Mean mainstream “ fan ” 96 | 215137822.92 ] 369248343.047 ] 37686251.201 alternative “ fan ” 899 5431534.37 ] 13327210.238 444487.347 Table 2 : Views of alternative content N Mean Std . Deviation Std . Error user Mean mainstream “ fan ” 842 } 345739592.11 | 577670778.887 | 19907849.727 alternative “ fan ” 33 2162700.03 6453661.518 1123438.269 Table 3 : Views of mainstream content But those numbers are depended and can be affected by the time the video was uploaded on the platform of YouTube . If , for example , two videos had the same number of views but were uploaded three or four years apart , we consider that those two numbers of views are not entirely comparable . For this reason , a new variable was created named “ popularity - age ” . This variable was created by dividing the number of the views with the seconds that had passed since the upload of the video . Then , the 15 analysis was computed again but this time using the new variable of popularity-age of the videos instead of the views . In the case of the alternative music fan ( see Table 4 ) , the minimum value of popularity of the mainstream songs was 0.0003638020 and the maximum 0.5921270420 ( M = 0.04 , SD = 0.10 ) , while in the case of the mainstream music fan ( see Table 5 ) the minimum value of popularity of the alternative songs was 0.0093903710 and the maximum value was 15.69593706 ( M = 1.17 , SD = 2.73 ) . In the alternative music fan , the mainstream videos that were suggested had a lower value of popularity even compared to the value of popularity of the alternative suggested videos in the mainstream music fan . This can be considered as one step forward to the creation of a filter bubble but not of a commercial one , as the assumption , but a different filter bubble in cach fan , according to the popularity-age of it . N Valid 33 N Valid O68 Missing 0 Missing 0 Mean 0435538087 Mean 1.178638430 Std . Error of Mean 0182232008 Std . Error of Mean 2788885613 Median 0181307060 Median 4234102385 Mode 001068721 '' Mode .7943302160 Std . Deviation 1046843184 Std . Deviation 2.732538681 Variance 014 Variance 7.467 Range 5917632400 Range 15.68654669 Minimum 0003638020 Minimum 0093903710 Maximum 6921270420 Maximum 15.69593706 Table 5 : Popularity-age of mainstream Table 4 : Popularity-age of alternative songs in alternative music fan songs in mainstream music fan 3.3 . The “ Recommended for you ” videos The researcher noticed that some of the en eee OC ) ( Official Video ) recommended videos fell into a distinct category , identified by YouTube by the tag “ Recommended Nothing Left To Say / Rocks CS for you ” , as seen in Figure 4 . A recommendation system consists of a variety of algorithms . Could `` Figure 4 : “ Recommended for you ” that mean that the tag is used to signify tag information more intensely personalized for a certain user ? To answer this question , the first step was to analyze and compare the 16 frequency in which the tag appeared in the recommended videos of each fan . By running the analysis in song-related data ( see Table 6 ) , the results showed that in the alternative music fan 8 % of the videos that were recommended had the tag , while the mainstream music fan had 18 % . The analysis was significant at the 0.05 level with a significance of p < .000 . This difference is statistically significant [ x° ( 1 , n=1870 ) =39941 , p < .001 ) . Table 6 : “ Recommended for you ” tag frequency User Mainstream | Alternative Count Count “ Recommended for you ” tag Without the tag 769 856 With the tag 169 76 Pearson Chi-Square Tests User “ Recommended for you ” tag Chi-square 39.941 df 1 Sig . .000 '' Yet , the frequency of appearance alone can not help us understand how those tagged videos are related to the entire set of recommendations for each user . The next step was to compare the popularity-age of those videos to the popularity-age of the whole set of recommendations . In the alternative music fan ( see Table 7 ) , the minimum value of popularity-age was 0.0000145660 and the maximum was 1.166508029 ( M = 0.10 , SD = 0.24 ) . In the mainstream music fan ( see Table 8 ) , the minimum value of popularity-age was 0.0020529470 and the maximum was 2186.223529 ( M = 21.42 , SD = 167.91 ) . Then the two means were compared by T-Test to examine if their difference is statistically significant . As seen in Table 9 this difference , although large , is not statistically important ( p = .270 ) . N Valid Missing Mean Std . Error of Mean Std . Deviation Minimum Maximum 76 0 1028482925 0275728220 2403742891 0000145660 1.166508029 Table 7 : Popularity-age of “ Recommended for you ” in alternative music fan Mean Std . Error of Mean Std . Deviation Valid Missing Minimum Maximum 169 0 21.42739483 12.91650182 167.9145236 0020529470 2186.223529 Table 8 : Popularity-age of “ Recommended 17 for you ” in mainstream music fan N Mean Std . Deviation Std . Error user Mean mainstream “ fan ” 169 } 21.42739483 167.9145236 12.91650182 alternative “ fan ” 76 | .1028482925 .2403742891 0275728220 Table 9 : T-Test popularity of the “ Recommended for you ” songs But are those values mirrored in the entire set of the recommended videos or are they different ? So , the next step was to compare those values of popularity with the entire recommended datasets of each user ( including the tagged videos ) . In the mainstream music fan ( Table 10 ) , there was a mean of 6.41 ( SD = 71.74 ) . In the alternative music fan ( Table 11 ) , there was a difference in all the values of popularity of the videos . The minimum value was 0.0000008266 and the maximum value was 5.719632382 ( M =0.07 , SD = 0.25 ) . Valid g32 Table 11 : Popularity-age of mainstream music fan ( whole set ) N Valid 938 N Missing 0 Missing 0 Mean 6.417845476 Mean .O7g97000041 Std . Error of Mean 2.342394337 Std . Error of Mean 0084807815 Std . Deviation 71.74000931 Std . Deviation 2589070219 Minimum ( 0020529470 Minimum 000008266 Maximum 2486.223529 Maximum §.719632382 Table 10 : Popularity-age of alternative music fan ( whole set ) Then , once again , means were compared with the use of T-Test . The results in Table 12 showed that the difference in the means is statistically significant at the 0.01 level ( p = .007 ) . From the results , what we conclude is that the recommendation algorithms of YouTube , tends to use the tag in videos with higher values of popularity- age , and that can be seen by the 14.1 difference in the means . In the alternative music fan , the algorithm tends to use the tag in videos that were not in the edge of the popularity -age value but close enough to the mean of this value , the difference is only 18 0.03 , which could also be translated that the algorithm uses the tag in videos with higher value of popularity-age . That is shown by the fact that the 76 videos with the tag have a mean of 0.102 while the 932 videos have a mean of 0.079 . N Mean Std . Deviation Std . Error user Mean mainstream “ fan ” 938 ] 6.417845476 71.74000931 2342394337 alternative “ fan ” 932 | .0797000041| .25890702219 .0084807815 Table 12 : T-Test popularity of all songs 3.4 Viewed vs Recommended videos In order to examine the filter bubble assumption , it was considered necessary to compare the videos that were recommended with the videos that were used to load both users with content and construct the users ’ profile in terms of musical taste . Unfortunately , during the process of loading , the researcher did not manage to record the information about the seconds since publication of the videos , so it was not possible to compute the value of popularity for those songs ; this is the reason why we will compare only the views of the videos . The purpose of the analysis was twofold : first , to examine whether more popular content is promoted , through the recommendations , to the mainstream content fan ; second , to examine whether the recommended content was more popular compared to the content the two “ users ” consumed in the first place ( namely , the songs used to load the accounts ) . For the alternative music fan ( Table 13 ) , the minimum number of views of a video ( in the dataset used to load the accounts ) was 41 and the maximum was 500798 ( M = 44284.84 , SD = 71371.81 ) . For the mainstream music fan ( Table 14 ) , the minimum number of views ( again in the dataset used to load the account ) was 272211355 and the maximum was 4725409580 ( M = 784206748.9 , SD = 640457467.5 ) . The recommended videos of the mainstream music fan ( Table 15 ) , had a minimum number of views of 138200 and a maximum number of views of 4683051115 ( M = 332413196 , SD = 561143147.7 ) . The recommended videos of the alternative music fan ( Table 16 ) had a minimum number of views of 1 and a maximum number of views of 122051751 ( M = 5315792.38 , SD = 13157346.18 ) . As noted above , we can not provide a more accurate analysis of this data as the seconds since publication of the video that were used for the 19 loading of the accounts was not obtained . Nevertheless , in the mainstream music fan , there was a difference in the means of the videos that were used to load the account and the recommended videos , but in both cases the number of views was more than 100000000 . In the alternative music fan the difference in the means was also huge with 44284 .84 in the loaded videos and 5315792.38 of the recommended videos . N Valid Missing Mean Std . Error of Mean Std . Deviation Minimum Maximum 938 0 332413196.0 18321973.25 561143147.7 138200 4683051115 N Mean Std . Deviation Minimum Maximum Valid Missing Table 14 : Views of loaded videos , Alternative music fun N Valid Missing Mean Std . Deviation Minimum Maximum 513 0 44284.84 71371.816 44 500798 Table 15 : Views of recommended videos , Mainstream music fun Table 13 : Views of loaded videos , Mainstream music fun N Valid Missing Mean Std . Error of Mean Std . Deviation Minimum Maximum 932 oS 9315792.38 430983.204 13157346.18 1 122051751 Table 16 : Views of recommended videos , alternative music fun A T-Test analysis was also conducted , in order to examine if the difference in the means was statistically significant . The first analysis ( see Table 17 ) compared the views of the videos that were used to load the alternative music fan with content and the views from the videos that the user was recommended . Their difference is statistically important at the .00 level with p < .001 . Regarding the mainstream music fan ( Table 18 ) , the difference was once again statistically important in the .00 level with p < .001 , however the mean number of views was smaller in the recommendations dataset compared to the viewed videos dataset . What we conclude from this analysis is that in the case of the alternative music fan , the algorithm suggested videos with more views on average , compared to the views of the videos that were used to load the user ’ s 20 account . This means that the user was suggested more popular content , in terms of views , albeit still within the alternative music genre . Thus , it did not make it easier for the user to encounter undiscovered or inconspicuous content . In the mainstream music fan , the algorithm suggested videos with fewer views compared to the views of the videos that were used to load the user ’ s account , on average . Yet , the mean number of views was still significantly high ( over 300 million views ) . user N Mean Std . Deviation | Std . Error Mean Viewed videos 513 44284 84 71371.816 3151.143 Recommended videos | 1000 5146791.91 13212337.92 .0084807815 Table 17 : T-Test alternative user : loaded vs recommended videos user N Mean Std . Deviation | Std . Error Mean Viewed videos 470| 784206748.9 640457467.6 29542100.06 Recommended videos | 1000 ] 312938149.6 548767037.4 17353537.43 Table 18 : T-Test mainstream user : loaded vs recommended videos Another analysis that was conducted is related to diversity of the artists or bands , namely the possibility that the recommended videos suggested more songs of the same artists or opened up the user to more diverse content . A new variable , coded for the sameness/uniqueness of the artists or music groups was created . The findings show , quite surprisingly , that regarding the alternative music fan , only 5.6 % of the recommended videos were from artists that were used during the process of loading the account with content . This suggests that recommendations steer the user towards discovering new ( for her/him ) content . On the other hand , regarding the mainstream music fan , 70.5 % of the recommended videos were from artists that were used during the process of loading the account with content . Here , this diversity is significantly diminished . 3.5 The non-songs The results , so far , show a clear profiling of the users , in both accounts . But to go even deeper we conducted a qualitative analysis of the recommended videos that were not music-related , to understand what the algorithms tried to “ serve ” the users . In 21 the alternative music fan , 68 videos ( 7 % ) could not be classified as mainstream or alternative , so they were classified as non-music content . Of those 68 videos , five of them had as main subject the coronavirus , and four were connected to the genre/taste of the account ( i.e . a deathcore song about the virus —and deathcore was classified as a subgenre of alternative metal ) . Those videos were considered in the analysis as non- songs because they were not created or recorded by an official studio or artist , but they seemed to be made for fun . All the other videos were close to the culture of alternative rock and metal , e.g . top 10 lists , interviews with artists , tutorials on how to scream , headbang challenges etc . Fifteen of those videos ( 22 % ) were marked with the tag “ Recommended for you ” . In the mainstream music fan , there were 62 videos ( 6 % ) that were classified as non-music content . From those videos there were again some lists , like top 10 songs of a specific artist or top 100 songs from the 2000s etc. , while other videos included content that was gossip about the life of mainstream artists , like Selena Gomez and Justin Bieber . Moreover , there were videos from Disney ’ s productions , like movies and series , and videos from talent shows like “ The Voice ” . Furthermore , 16 of those 62 videos ( 26 % ) had the “ Recommended for you ” tag . 3.6 Non-songs & “ Recommended for you ” On both users , non-music content that had the “ Recommended for you ” tag , appeared more often than in the other videos of the dataset . So , we ran an analysis to compare the non-music recommended videos with both mainstream and alternative videos ( Table 15 ) . The results showed that the song videos had 245 videos ( 13 % ) with the tag and 1625 videos ( 87 % ) without the tag , while in the non-music videos , 31 of the videos ( 24 % ) had the tag and 99 of the videos ( 76 % ) had not . This difference is significant at the .05 level [ x° ( 1 , n=2000 ) =11796 , p < .001 ] . The results show that the “ Recommended for you ” tag appears more often in non-music videos . When we compared the non-music content of the two accounts ( Table 16 ) , it was the only result that was not statistically significant [ x7 ( 1 , n=130 ) =251 , p=.616 ] . The platform of YouTube does not provide only music videos but a variety of topics and kinds of videos . The question here is : why would the algorithm suggest videos that are not songs to a user that has been watching only songs on the platform ? What is more , why are videos not only recommended , by appearing at the recommended list , but also added a 22 tag , which can make the user feel more confident that the content of this video is relevant to his/her preferences ? Those questions can not be answered from the current analysis , but they could be used to trigger further research on the platform of YouTube , with real users , so their behaviour could be examined regarding the recommended videos . Song or non-song Song Non-song | Count Count “ Recommended for you ” tag_ Without the tag 1625 99 With the tag 245 31 Pearson Chi-Square Tests User “ Recommended for you ” tag Chi-square 11.796 df 1 Sig . .001 '' Table 19 : Songs and non-songs with and without the tag User Mainstream | Alternative Count Count “ Recommended for you ” tag_ Without the tag 46 53 . With the tag 16 15 Pearson Chi-Square Tests User “ Recommended for you ” tag Chi-square 251 df 1 Sig . 616 Table 20 : Non-songs with and without the tag 23 4 Discussion and conclusion The analysis that preceded focused on answering the research question of the present thesis . But from the analysis of the data that was collected , more aspects of the recommendation system of YouTube were examined , for example , the use of YouTube ’ s recommendation system as a cultural algorithm . First , as it is evident from the results , a filter bubble was created according to the content that was used to load the accounts . In the mainstream music fan , the majority of the videos that were recommended were classified as mainstream music , whereas in the alternative account most recommended videos were classified as alternative music . Thus , in this case we encounter a manifestation of the filter bubble phenomenon , based on the cultural content recommended by the platform . As a result , a user that starts to use the platform having a specific taste in music and over time seeks to use the platform in order to widen her/his horizons in music , s/he is more likely to encounter content very similar to his/her preexisting taste in music . Second , in the case where alternative music videos were recommended in the mainstream music fan , the popularity of those videos was close to the popularity of the mainstream videos . This result leads to the conclusion that the views as well as “ freshness ” of the videos are compatible with the entire set of recommendation , irrespectively of the genre of the music . This means that even when alternative music content makes it into the recommendations of YouTube to a user with mainstream tastes , this content is highly likely to be already popular , in terms of views , as well as “ fresh ” ( recent ) . This renders unlikely that a user with mainstream music tastes encounters diverse “ undiscovered ” cultural content , as there seems to be at work a process of making more salient particular songs that are already popular , recent or both , even within the alternative music genres . The same goes for the alternative music fan : whenever a mainstream music video appeared as recommended , the popularity of the video was similar to the popularity of the alternative songs what were recommended . Compared to the mainstream music fan , the popularity of the mainstream recommended videos in the alternative music fan , was lower . The paradox of the analysis was that even the recommended videos to the alternative music fan , that were categorized as mainstream , 24 had a popularity similar to the alternative recommended videos . In this case , a filter bubble , this time according to the popularity of the videos , was created too . The big difference between the two accounts lies in the videos that were not music-related content . In the entire dataset , these videos appeared more often tagged as “ Recommended for you ” , compared to the music videos . The analysis of those videos , both qualitative and quantitative , leads us to the examination of a commercial filter bubble . In the alternative account , the non-music videos were really close to the genre of the content that was used to load the account , namely content that belonged to the alternative rock and metal culture . On the other hand , in the mainstream account , the recommended videos were highly commercial content originating from popular culture products such as talent shows , videos about the lives of celebrities or parts from Disney ’ s productions . The main difference here is that in the case of the alternative account the non-music recommended videos can be seen as additional information that reaffirms the user ’ s belonging to this kind of content and culture . On the other hand , in the mainstream account , the recommended videos try to “ pull ” the user into other kind of activities , outside music consumption , that are connected to mainstream culture , like the productions of Disney . Because of the diversity of content that is hosted in the platform of YouTube , we examined Pariser ’ s ( 2011 ) idea of the filter bubble from different aspects and in all cases it was verified that the recommendation were similar to the viewpoints that were already held . To come to this result , it was necessary to examine and compare the frequencies of the videos that were used to load the accounts with content to the recommended videos of each user . The results showed that in the alternative music fan , only 5.6 % of the 1000 videos that were recommended was from the same artists that were used during the loading process , which means that a filter bubble was not created as far as the artists or bands are concerned . On the other hand , in the mainstream music fan , 70.5 % of the 1000 recommended videos were from artists that were used during the process of loading . That high percentage of repetition of the same artists leads to the conclusion that much of the content that was used to load the account was repeated , in terms of individual artists or bands . Here , we observe the creation of a filter bubble , not only in terms of the genre , but of the artists too . 25 In light of the results of this study , we now turn to consider anew the concept of the “ algorithmic culture ” , introduced by Hallinan & Striphas ( 2017 ) . We can argue that the alternative music fan seems to have fallen victim of the “ algorithmic governance ” . From the start , the recommendation algorithm suggested videos with more views and popularity than the songs that were used in the procedure of loading the account . This means that simulating the tastes and preferences of a user who prefers “ fringe ” bands and artists , in the recommendations we encountered more popular and well-known music videos , albeit still in the alternative music genre . Thus , artists with an already low popularity in the YouTube platform are unlikely to see their videos in the recommended lists of users ( even users who actively select this kind of music ) . Because neither the exact logic of the recommendation algorithm of YouTube nor the actual motives behind it are known , we can not explain why this is so . A plausible cause points to profit maximization as the videos by artists from more official discography companies , or from artists who already have a social influence and impact , are more likely to spend money in order to promote their videos from YouTube to other social and mass media in their attempt to increase their popularity . It works as a win-win situation for both sides . The platform of YouTube gets more clicks , and the artists/companies gain more fame . But what if we look at the recommendation algorithm of YouTube as a “ technology of the self ’ , as discussed by Karakayali et al . ( 2018 ) ? In their work they argued about how the algorithms make a circle in order to recommend more personalized content and engage the user to their content . The circle begins with the algorithm tracking both the offline and online activities of the user . To develop this discussion , we focused completely on the online activities of the users , because there were not any offline activities , as the accounts were fake and were only used for this specific research purpose . Thus , it appears that the algorithm used only one user action , the history from the videos that the user had already viewed . The first set of recommended videos appeared in the “ Homepage ” , where different videos appeared . The fact that the user chose one of these recommended videos was the recursive feedback of the data , which drove the user to the second set of recommended videos , the ones that appeared in the right side of the webpage . From the choices the user made on the second set of recommendation , the algorithm created an “ objectified ” aspect of the user but was always ready to modify the user ’ s selections , which in this case occurred 26 the next day , where the cycle began once again . As a result of this , the recommendation algorithm of YouTube can be considered as a technology of the self . This result can be clearly seen if we analyze the separate days of the recommended videos . For example , the second day in the mainstream account , the first suggested song was from an alternative artist with high popularity . From the 100 recommended videos that we collected , only 17 of them were from mainstream artists . This means that the algorithm may have modified the user ’ s activity and did not disregard previous activities . More important is the impact of the technologies of the self in the creation of a possible identity , or in the case of this study , the creation of music taste of the users in order for the algorithm to engage the users with content that serves the interests of the platform , namely , steering the user toward specific videos to satisfy the goal of maximizing profits within new media capitalism . The filter bubble phenomenon has triggered the interest of the academic community to examine its existence in different platforms , from different point of views and different concepts . For example , Allen et al . ( 2017 ) examined real users and their behaviour , in the platforms of “ Pandora ” and “ last.fm ” and the creation of a filter bubble in the case of music . The results were similar to this thesis . A filter bubble emerged to surface in the platforms , but in some cases the bubble was not created by the algorithm but by the users ’ activities , who were prone to create their own bubble , a musical “ safe zone ” for them to consume their music taste , over and over again . Similar studies took place in the YouTube platform examining the existence of an ideological filter bubble this time . O'Callaghan et al . ( 2013 , 2015 ) published about the creation of an ideological filter bubble in the extreme right content and the creation of a pipeline . The results showed that in a case a user consumes ideological right content is more likely to be recommended extreme right content . Cross-checking those results with the results of this thesis , some similarities were observed . For example , the mainstream music fan was recommended videos with gossipy news about artists , or videos from mainstream productions , like Disney . The user begun to consume mainstream music content and then the recommendation systems began to suggest videos that are part of the mainstream culture but not only from the music aspect . By replacing the alternative videos with the LGBTQ+ YouTubers , it could be mean that truly , the recommendation algorithms might underestimate their work in order to suggest more mainstream YouTubers who could increase the profits of the business . 27 5 _ Limitations and suggestions for future research As every research , the thesis had some limitations , as it was not possible to control all factors . First and most important limitation of the research was that fake accounts were used , which tried to mimic the behavior of a real user . So , the results can not reflect on the behavior of real users of the platforms , who are more likely to have a variety of preferences in music and not restrict their choices to one particular genre , which in tum would affect the construction of their profiles and hence their recommendations . However , it was decided to proceed with the fake accounts and indeed construct them as more or less extreme types of users in order to be able to simplify the number of different variables that play some role in algorithmic filtering . One more limitation was that we excluded a big part of the music culture , like different genres of music , such as reggae or opera ; on the other hand , however , such a limitation was necessary due to time and resources . Furthermore , the categorization of the music into two rough categories ( mainstream and alternative ) leaves out multiple shades of music genres in between . It is important to mention that the loading of the accounts was made manually by the researcher and needed a minimum of three hours per day . Moreover , more data from the videos could have been gathered , especially in the process where the two accounts were loaded with content . It would be important to gather information of those videos that were not collected from the start , such as the channel and the seconds that have passed since the publication of the song when it was first used for the purpose of the research . From the experience I gained through the entire process , I would suggest that this kind of research takes place in an environment more specialized in music , like “ Spotify ” or “ last.fm ” . It would also be interesting to conduct a similar algorithm audit specifically of a service offered by the platform of YouTube , namely the YouTube Music . The examination for different kinds of filter bubbles would also be interesting , such as the creation of a filter bubble in the case of YouTubers . In their “ About ” page , the creators of YouTube mention that “ Our mission is to give everyone a voice and show them the world ” . It may be high time that researchers took a more active role in showing how commercial recommendation algorithms , like YouTube ’ s , work and they do not show us the world as it is , but only from the platform ’ s profitable point of view . 28 REFERENCES Abdollahpouri , H. , Burke , R. , & Mansoury , M. ( 2020 ) . Unfair Exposure of Artists in Music Recommendation . arXiv preprint arXiv:2003.11634 . Adorno , T. W. ( 1991 ) . On the fetish character in music and the regression of listening . The culture industry : Selected essays on mass culture , 26-52 . Andrejevic , M. ( 2009 ) . Exploiting YouTube : Contradictions of user-generated labor . The YouTube Reader , 413 . Allen , D. P. , Wheeler-Mackta , H. J. , & Campo , J. R. ( 2017 ) . The Effects of Music Recommendation Engines on the Filter Bubble Phenomenon . Retrieved from https : //digitalcommons.wpi.edu/iqp-all/3086 . Cayari , C. ( 2011 ) . The YouTube Effect : How YouTube Has Provided New Ways to Consume , Create , and Share Music . International Journal of Education & the Arts , 12 ( 6 ) , n6 . Cheney-Lippold , J . ( 2017 ) . We Are Data : Algorithms and The Making of Our Digital Selves . New York : New York University Press ( Kindle Edition ) . Chitra , U. , & Musco , C. ( 2019 ) . Understanding Filter Bubbles and Polarization in Social Networks . arXiv preprint arXiv : 1906.08772 . Chodos , A. T. ( 2019 ) . Solving and Dissolving Musical Affection : A Critical Study of Spotify and Automated Music Recommendation in the 21st Century ( Doctoral dissertation , UC San Diego ) . Davidson , J. , Liebald , B. , Liu , J. , Nandy , P. , Van Vleet , T. , Gargi , U. , ... & Sampath , D. ( 2010 ) . The YouTube video recommendation system . In Proceedings of the fourth ACM conference on Recommender systems ( pp . 293-296 ) . ACM . Dutton , W. H. , Reisdorf , B. , Dubois , E. , & Blank , G. ( 2017 ) . Social Shaping of the Politics of Internet Search and Networking : Moving Beyond Filter Bubbles , Echo Chambers , and Fake News . Francesco Ricci and Lior Rokach and Bracha Shapira ( 2011 ) . Introduction to Recommender Systems Handbook , Recommender Systems Handbook , Springer , pp . 1-35 Gillespie , T. ( 2014 ) . The relevance of algorithms . Media technologies : Essays on communication , materiality , and society , 167 , 167 . Hallinan , B. , & Striphas , T. ( 2016 ) . Recommended for you : The Netflix Prize and the production of algorithmic culture . New media & society , 18 ( 1 ) , 117-137 . 29 John S. Breese ; David Heckerman & Carl Kadie ( 1998 ) . Empirical analysis of predictive algorithms for collaborative filtering . In Proceedings of the Fourteenth conference on Uncertainty in artificial intelligence ( UAI'98 ) . Just , N. & Latzer , M. ( 2017 ) . Governance by algorithms : Reality construction by algorithmic selection on the Internet . Media , Culture & Society , 39 ( 2 ) , 238-258 . Karakayali , N. , Kostem , B. , & Galip , I . ( 2018 ) . Recommendation systems as technologies of the self : Algorithmic control and the formation of music taste . Theory , Culture & Society , 35 ( 2 ) , 3-24 . Kennedy , H. ( 2018 ) . Living with Data : Aligning Data Studies and Data Activism Through a Focus on Everyday Experiences of Datafication . Krisis : Journal for Contemporary Philosophy , 1 , 18-30 . Kruse , H. ( 1993 ) . Subcultural identity in alternative music culture . Popular music , 12 ( 1 ) , 33-41 . O ’ Callaghan , D. , Greene , D. , Conway , M. , Carthy , J. , & Cunningham , P. ( 2015 ) . Down the ( white ) rabbit hole : The extreme right and online recommender systems . Social Science Computer Review , 33 ( 4 ) , 459-478 . O'Callaghan , D. , Greene , D. , Conway , M. , Carthy , J. , & Cunningham , P. ( 2013 ) . The extreme right filter bubble . arXiv preprint arXiv:1308.6149 . Pariser , E. ( 2011 ) . The filter bubble : What the Internet is hiding from you . Penguin UK . Papadamou , K. , Papasavva , A. , Zannettou , S. , Blackburn , J. , Kourtellis , N. , Leontiadis , I , ... & Sirivianos , M. ( 2019 ) . Disturbed YouTube for Kids : Characterizing and Detecting Inappropriate Videos Targeting Young Children . arXiv preprint arXiv : 1901.07046 . Piccone , P. ( 1978 ) . The essential Frankfurt school reader ( p. 270 ) . A. Arato , & E. Gebhardt ( Eds. ) . New York : Urizen Books . Sandvig , C. , Hamilton , K. , Karahalios , K. , & Langbort , C. ( 2014 ) . Auditing algorithms : Research methods for detecting discrimination on internet platforms . Data and discrimination : converting critical concerns into productive inquiry , 22 . Van Dijck , J . ( 2014 ) . Datafication , dataism and dataveillance : Big Data between scientific paradigm and ideology . Surveillance & Society , 12 ( 2 ) , 197-208 . Toitosxa , E. ( 2015 ) . H patiky kovatovpa od tT UXO ] TH PpavKqovptis otov HETALLOVTEPVLOLLO : 1 TEPINTMON TIS OTNMOPUOs LOVOLKI|s . Retrieved from : http : //dspace uowm . gr/xmlui/handle/123456789/189 30 Internet resources https : //musicindustryblog.wordpress.com/tag/record-label-market-shares-2019/ Retrieved : 03/05/2020 https : //en.wikipedia.org/wiki/Vevo Retrieved : 03/05/2020 https : //en.wikipedia.org/wiki/Alternative rock Retrieved : 27/01/2020 https : //Awww.youtube.com/about/ Retrieved : 07/05/2020 https : //www.theguardian.com/technology/2019/nov/22/youtube-lebt-content-lawsuit- discrimination-algorithm Retrieved 10/05/2020 https : //www.youtube.com/about/press/ Retrieved 10/05/2020 31 APPENDIX I Python code from bs4 import BeautifulSoup import pandas as pd import datetime import dateparser user = 'giorgos ' # The name of the user file = 'Alt Day 10 Path 10 ' # The file where the search results were stored - without the -html extension # Open and process the html file with open ( file+ ’ html ’ , encoding= '' utf8 ' ) as fp : soup = BeautifulSoup ( fp ) # Extract and process all the results returned data = [ ] # Works for : ytd-compact-autoplay-renderer ytd-compact-video-renderer # Does not work for : ytd-compact-radio-renderer ytd-compact-playlist-renderer counter = 1 for i , video in enumerate ( soup.select ( ‘ ytd-compact-autoplay-renderer ’ ) ) : link = video.select_one ( ‘ a.yt-simple-endpoint.style-scope.ytd-compact-video-renderer ’ ) video_id = link . get ( Chref ’ ) .split ( ? ' ) [ 1 ] .split ( & ' ) [ 0 ] [ 2 : ] title = link.select_one ( ‘ h3 span # video-title ’ ) .string.stripO 32 title_ meta = link.select_one ( ‘ h3 span # video-title ' ) .get ( ‘ aria-label ' ) .stripQ meta = link.select_one ( ‘ div.ytd-video-meta-block ’ ) ; channel = meta.select_one ( ‘ yt-formatted-string.style-scope.ytd-channel-name ’ ) .string ; try : second_meta = meta.select_one ( ‘ div.ytd-video-meta-block span.ytd-video-meta- block ’ ) .string.stripQ except : second meta = '' tmp = title_meta [ len ( title ) +4 : ] .stripQ.split¢ ' ' ) views=tmp [ len ( tmp ) -2 ] .replace ( `` , '' , `` '' ) tmp = tmp [ : -2 ] for i in range ( len ( tmp ) ) : try : int ( tmp [ i ] ) published = `` `` join ( tmp [ i : ] ) break except : pass seconds _since_publication = round ( ( datetime.datetime.now ( - dateparser.parse ( published ) ) .total_seconds ( ) ) recommended = 1 if second_meta=='Recommended for you ' else 0 data.append ( [ user , video_id , title , channel , views , seconds_since_publication , recommended , counter ] ) counter = counter+1 33 for i , video in enumerate ( soup.select ( ‘ ytd-compact-video-renderer ' ) ) : link = video.select_one ( ‘ a.yt-simple-endpoint.style-scope.ytd-compact-video-renderer ’ ) video_id = link . get ( ‘ href ’ ) .split ( ’ ? ' ) [ 1 ] .split ( & ' ) [ 0 ] [ 2 : ] title = link.select_one ( ‘ h3 span # video-title ’ ) .string.stripO title_ meta = link.select_one ( h3 span # video-title ' ) .get ( ‘ aria-label ' ) .stripQ meta = link.select_one ( ‘ div.ytd-video-meta-block ’ ) ; channel = meta.select_one ( ‘ yt-formatted-string.style-scope.ytd-channel-name ’ ) .string ; second_meta = meta.select_one ( ‘ div.ytd-video-meta-block span.ytd-video-meta- block ’ ) .string.stripQ tmp = title_meta [ len ( title ) +4 : ] .stripQ.split¢ ' ' ) views=tmp [ len ( tmp ) -2 ] .replace ( `` , '' , `` '' ) tmp = tmp [ : -2 ] for i in range ( len ( tmp ) ) : try : int ( tmp [ i ] ) published = `` `` join ( tmp [ i : ] ) break except : pass seconds _since_publication = round ( ( datetime.datetime.now ( - dateparser.parse ( published ) ) .total_seconds ( ) ) recommended = 1 if second_meta=='Recommended for you ' else 0 data.append ( [ user , video_id , title , channel , views , seconds_since_publication , recommended , counter ] ) counter = counter+1 34 df = pd.DataFrame ( data , columns= [ ‘ user ' ’ , 'video_id ' ’ , 'title ' , ‘ channel ’ , 'views ' , ‘ seconds _since_publication ' , 'recommended ' , 'order ' ] ) df.to_csv ( file+'.csv ' , index=False ) # print ( df ) 35 Hypotesen om sjalvférvallade filterbubblor The self-imposed filter bubble hypothesis Axel Ekstr6m handledare / supervisor ( s ) Petter Johansson Diederick Niehorster KOGM20 2021-06-04 Masteruppsats i kognitionsvetenskap Master ’ s thesis ( 2 years ) in Cognitive Science Avdelningen fér kognitionsvetenskap Lund University Cognitive Science Filosofiska institutionen Department of Philosophy Lunds universitet Lund University Abs . It is commonly assumed that algorithmic curation of search results creates filter bubbles , where users ’ beliefs are continually reinforced and opposing views are suppressed . However , empirical evidence has failed to support this hypothesis . Instead , we suggest that filter bubbles may result from individuals acting selectively on information made available by search engines . When presented with search engine results pages , links and sources that validate users ’ beliefs should be attended more than other links . This prediction is testable using eye-tracking technology . Here , we presented biased participants ( n = 48 ) with sets of simulated Google Search results , controlling for the ideological leaning of each link . Results indicate that , on average , politically Liberal participants spend more time viewing own-side links than other links , while political Conservatives do not . However , both Liberals and Conservatives tend to select same-side links . Further , there is a significant effect of trust , such that links associated with less trusted sources are attended less and selected less often . Implications , study limitations , and directions for further study are also discussed . 1 Introduction The problem of filter bubbles Every day , millions of people search for information online using search engines such as Google Search , Yahoo , and DuckDuckGo . The results we see on the web influence our interpretations of world events and our beliefs about the world . Google Search is particularly ubiquitous , with billions of search queries processed every day ( Internetlivestats , 2021 ) . However , it has also been subject to extensive criticism . Search engine result pages ( SERPs ) are typically based not only on the search terms used but also on users ’ previous searches . It has been alleged that this process , known as_ personalization , leads to ideological segregation and polarization . By reinforcing searchers ’ beliefs and hiding or suppressing user-opposing views , Google Search allegedly creates ideological filter bubbles , potentially emphasizing real-life political affective polarization and segregation ( Pariser , 2011 ; Sunstein , 1999 ) and fragmenting political discourse ( see Garrett & Resnick , 2011 ) . Despite widespread intuitive appeal , however , empirical evidence has largely failed to support this hypothesis . In one study of Google users , Hannak et al. , ( 2017 ) found small ( ~12 % ) differences in search results , defined as links or the position of links . Counter to the prediction of the filter bubble hypothesis , however , the authors found no measurable history-driven effect of personalization . Being logged into the Google system , and searchers ’ geographic location were the only statistically significant factors . Similarly , Haim et al. , ( 2017 ) found only minor differences in link position between accounts when 1200 individuals searched for information on suicide . Further , while Curtois et al. , ( 2018 ) did find extensive variation in search results for social and political search terms , most of that variation was explained by the time of the search . Finally , in studying the browsing histories of over 1.3 million U.S-based users , Flaxman et al. , ( 2016 ) found that while news access was segregated , online search tools such as search engines actually increased users ’ chances of being exposed to opposing or disconfirming views ( see also Cardenal et al. , 2019 ) . Empirically , then , the Google Search engine itself appears not to be driving filter bubble-type ideological segregation ( see also Zuiderveen Borgesius et al. , 2016 ) . Thus , the problem of the filter bubble phenomenon facing academics is not necessarily the facilitation of political segregation ( though that may still be so ) , but that it is apparently difficult to study in the first place . Notably , however , one aspect of online information search that remains largely unexplored is the role of the searcher himself . Typically , in studies on SERPs , top links receive the most attention from users , with less attention afforded to each subsequent link ( Salmerén et al. , 2013 ; Granka et al. , 2014 ) . Hotchkiss et al. , ( 2005 ) introduced the term golden triangle to describe a heatmap illustration of this phenomenon , where gaze is concentrated in the rough form of a right triangle with the right angle facing upwards to the left , such that gaze on average drops off significantly beyond the hypothenuse ( see Figure 1 ) . Further , while search engines typically return hundreds of pages of results , users commonly choose results from only the first page ( Joachims et al. , 2007 ) , and even in initial SERPs , more than two-thirds of all clicks tend to go to the first five link positions presented ( Petrescu , 2014 ) . Thus , available research suggests that link position tends to bias selection , which — all other things being equal — should facilitate depolarization of political beliefs ( through homogeneity in selection ) , as opposed to increased polarization . While a significant amount of research has investigated the ways in which users typically interact with search engines , few have sought to investigate the way in which users ’ beliefs interact with such behaviors . These studies have also tended to ignore political content in the links presented . Yom-Tov et al . ( 2014 ) have suggested an alternative proposition with important implications for the filter bubble hypothesis . Biased persons , acting on the large set of information made available via the internet , may be selectively curating their own newsfeeds and information sources — effectively engaging in self-segregating behavior . This assertion , henceforth referred to as the self-imposed filter bubble hypothesis , does indeed find significant support in relevant research literature from social psychology , cognitive science , and communication ( see below ) . Further , while Yom-Tov and colleagues did not themselves attempt to test this hypothesis empirically , its core assertion presents researchers with clear premises , open to investigation via experimental means . In this thesis , I present the results of one such investigation . nttps : //fs . blog How Filter Bubbles Distort Reality : Everything You Need to ... fitter t , https : //reutersinstitute.politics.ox.ac.uk The truth behind filter bubbles : Bursting some myths | Reuters https : /Avww.theverge.com 6 be so potarizi bel https : //edu.gc Digital Media Literacy : How Filter Bubbles Isolate You a filter b global.org nttps : //medium.con The Causes and Effects of “ Filter Bubbles ” and how to Break .. Filter bubbles create ar ? fF nttps : /www.nordicom gu.se . New study rejects the idea of filter bubbles | Nordicom ea of filter bubbles Figure I . In empirical studies on SERPs , users ’ attention is typically concentrated in a tniangle-like pattern , such that lower-position links are attended less and read less extensively on average , outside a “ golden tnangle ” . Ingroups , outgroups , and dealing with sources It is a well-replicated set of findings in social psychology that group identity often becomes a cause of differential treatment between groups ( Eibl- Eibesfeldt , 1979 ; Brewer , 1979 ; Tajfel & Turner , 1986 ; for acomprehensive review , see Hewstone et al. , 2002 ) and is easily established , for example , based on real- world groupings such as ethnicity and_ political affiliation ( Rand et al. , 2008 ) . These findings have been repeatedly validated and replicated , with a review by Mullen et al. , ( 1992 ) finding that ingroup favoritism did not once fail to replicate in any one culture where it was investigated . Many factors are known to influence ingroup bias , including the ease of identification , salience , and status ( see Hewstone et al. , 2002 ) . Further , ingroup and outgroup cognitive biases may extend even beyond conscious information processing . According to Cohen ( 2003 , p. 1 ) : “ [ G ] roups define the very meaning of objects in the social world. ” Indeed , dynamics of ingroup and outgroup appear to affect even unconscious cognitive processing ( for an overview , see Chong , 2013 ) , extending to seemingly objective facts about the world ( Bartels , 2008 ) . As a consequence , people often see the same thing but 1 Relatedly , Sperber et al. , ( 2010 ) have suggested that humans are equipped with mechanisms of “ epistemic vigilance ” , designed to minimize the risk of unreliable experience it differently . For example , in a classic work , Hastorf and Cantril ( 1954 ) found that participants were more likely to perceive errors in the playing of student football players from teams of students from competing schools , than they were to perceive them in players representing their own school . This was later revisited and further supported by Kahan et al. , ( 2012 ) , who showed that participants viewing identical footage disagreed about key aspects of the observed events ( a protest ) , depending on their own political ideology . There is considerable consensus in the field that partisanship biases information processing in the context of politics as well ( e.g. , Chong , 2013 ; but see also Gerber & Green , 1998 ) . Such effects also tend to be more readily found in people with greater political knowledge and insight — 1.e. , political sophisticates . For instance , a survey study by Brader ( 2006 ) found that sophisticates self-reported stronger discrete emotions toward politicians . In the words of Lodge and Taber ( 2005 , p. 473 ) : “ [ Political ] sophisticates , because of their interest in politics , have formed crystallized attitudes to a fuller set of political issues. ” Interestingly , in this regard , a difference has been found between political liberals ( i.¢. , left-wingers ) and political conservatives ( i.e. , right-wingers ) , such that liberal persons are more likely to avoid exposure to political disagreement , at least in online interactions ( e.g. , Bode , 2016 ) . ! Finally , ingroup favoritism apparently also extends to levels of perception , including visual attention , such that own-side social stimuli are more thoroughly attended to and processed ( Xiao et al. , 2016 ; Kawakami et al. , 2014 ) . For example , Kawakami et al. , ( 2014 ) found significant evidence of preferential attention to the eyes and faces of ingroup members , such that White participants tended to attend more to the eyes of White target faces , compared to Black target faces . This effect seemingly holds also for novel ingroup and outgroup faces . This state of research let us pose a set of main hypotheses . Hia : Partisans select search results in line with their group and ideology , and do not select search results that fail to conform to their group and ideology . Hb : The top-link heuristic — which posits that top- presented search results are selected more often due to their position as initial — holds when search results align with searcher ’ s ideology , but not when it does not . Another particularly meaningful marker for whether to trust information is delineated by its source . The question of how to treat others as sources is of importance to several disciplines , such as developmental psychology ( Mills , 2013 ) , decision making ( Birnbaum et al. , 1976 ; Birnbaum & Stegner , 1979 ) , and persuasion ( Petty & Cacioppo , 1984 ; 1986 ) . information sampled from others . These mechanisms may also include a check on new information , testing whether it is consistent with one ’ s own beliefs ( e.g. , Mercier , 2020 ) . On average , people have trust in search engines ’ ability to rank and present users with the best results ( Purcell et al. , 2012 ; Pan et al. , 2007 ) , though this may have diminished in recent years ( Schulthei® et al. , 2018 ) . Even when presenting participants with manipulated reverse-ordered search results , participants still placed significant trust in Google ’ s own link positioning as being relevant for assigned task purposes ( Kammerer & Gerjets , 2012 ) . However , source position does not seem to serve as an apparent clue to trustworthiness in search results , such that links with higher position are not necessarily trusted more as sources than are lower- position ones ( Kammerer & Gerjets , 2014 ) . Thus , judgements of trust in a search engine may be more concerned with relevance to search enquiries , than with explicit trust in a given source , suggesting that conscious processing and evaluation of that source may override the initial attentional bias towards top- presented search results ( e.g. , Salmerén et al. , 2013 ) . For delineating the role of trust in the reliability of communicated information , it is useful to look to models of message reliability . Olsson and Angere ’ s Bayesian model of belief updating ( see Olsson , 2011 ; Olsson & Vallinder , 2013 ) suggests that content and source reliability interact bi- directionally , such that the reliability of a source moderates evidential impact of message content — and message content , in turn , provides evidence about the reliability of the source ( for another model emphasizing this relationship , see Bovens & Hartmann , 2003 ) . Just as statements from an unreliable source are regarded as implausible , implausible statements themselves make a source appear less reliable : it leads to a reduction in subjective degree of belief of reliability . In Olsson and Angere ’ s model , source reliability is represented by a distribution over possible reliability profiles , updated via Bayesian inference . In such a model , at the bottomed-out value of P = 0 , a report would be taken as evidence of the opposite of what was asserted . More recently , these predictions have also been borne out empirically by empirically Collins et al. , ( 2018 ) . One particularly important aspect of ( mis ) trust in a source , with crucial ramifications for political cognition , is individuals ’ opinions and beliefs . In the context of political information processing , then , if a claim can be traced to an ideologically disconfirming ( opposing ) source , political partisans would — all other things being equal — be less inclined to trust it , and therefore , to engage with it : H2 : People pay more attention to links associated with trusted sources , compared to untrusted ones , and select them more often . Selective exposure and cognitive bias Research from the 1940 ’ s and onward has found that people ’ s ideological convictions skew their willed exposure to news that conform to those beliefs ( e.g. , Lazarsfeld et al. , 1948 ) , a finding that has more recently been reaffirmed by modern research ( Garrett and Resnick , 2011 ; Yom-Tov et al. , 2014 ; see also Gentzkow & Shapiro , 2011 ) . In the social sciences , selective exposure theory describes this general tendency of people to seek out information that conforms to already held convictions and avoid or disregard information that does not ( see Klapper , 1960 ; Sears & Freedman , 1967 ; Frey , 1986 ; see also Mutz & Martin , 2011 ) . To Festinger ( 1957 ) , this tendency was central to his concept of cognitive dissonance as a means of reducing the mental discomfort that results from holding incongruent beliefs . The construct also aligns closely to Nickerson ’ s ( 1998 ) definition of the confirmation bias , individuals ’ tendency to evaluate evidence and hypotheses in such a way as to support prior conclusions — which is found across populations and cultures . With impacts for political life , Dilliplane ( 2011 ) also found that selective exposure to partisan political information impacted voters ’ levels of participation over time . The technological development of the late 20 '' and early 21 % centuries has led to widespread internet access and internet use across the world , which coincides with a greatly increased access to information . Therefore , much recent literature on selective exposure — the willful engagement with some information or source over another — has focused specifically on the way users engage with information on novel social media platforms , such as Facebook ( e.g. , Bakshy et al. , 2015 ; Silflow et al. , 2019 ; Cinelli et al. , 2020 , Instagram ( Parmelee et al. , 2020 ) and Twitter ( Himelboim et al. , 2013 ; Colleoni et al. , 2014 ; see also Garrett , 2013 ) . However , unlike search engines , social media are already socially and selectively curated ( e.g. , Weeks et al. , 2017 ; Spohr , 2017 ; Messing & Westwood , 2014 ) , with Messing and Westwood ( 2014 ) arguing that social endorsements play the role of heuristic cues in individuals ’ deciding to select a story that appears in their newsfeed . There is thus an important distinction to be made between engaging with presented socially curated content , which is mediated by previous interactions weighted by social relationships — and information search using own-selected search terms , which is dynamic , continuous , and driven by task goals . It is of significant interest , then , to investigate attention and engagement with political claims and news items in an internet-based environment bereft of such social cues — where all that remains is the individual and his or her biases . Jamieson and Cappella ( 2008 ) have argued that selective exposure may facilitate ideological echo chambers , which may have some bearing on the creating of filter bubbles also . Crucial to this argument , Stinchcombe ( 2010 ) found that when discussing topics solely with like-minded individuals , their opinions tend to polarize . Knobloch-Westerwick and Meng ( 2011 ) found that participants preferred attitude-consistent messaging , which also tended to strengthen political self-concepts . However , results for the internet echo chambers , as described by Jamieson and Cappella ( 2008 ) , have been mixed . Overall , it does not appear that individuals actively avoid information that fails to conform to their own worldview . In a large internet- administrated study , Garrett ( 2009a ) found that while opinion-reinforcing information promoted exposure to news stories compared with opinion-challenging information , the difference was marginal . Importantly , however , Garrett ( 2009b ) has further argued that while partisans tend to seek out opinion-reinforcing information , they do not exhibit systematic bias against challenges to those opinions ( see also Valentino et al. , 2009 ) . However , before information can be processed , it must be attended , and a small but growing body of research now suggests that selective own-side-biased filtering may take place at an even earlier stage of processing ( e.g. , Kawakami et al. , 2014 ) . Accordingly , I argue that participants ’ ideological biases play a role in attending to novel information also . For this purpose , one tool of significance is eye tracking , which lets us investigate the early stages of attention that operate before any conscious reasoning has taken place . Visual attention and depths of processing Attention is by its nature selective , selecting for and prioritizing some stimuli in the world — and not others . One way of examining attentional processes is eye tracking , which allows for in-depth capture of eye movements in real time . Gaze behavior can often reveal intricacies of information processing ( see Duchowski , 2002 ) . For example , the eye-mind hypothesis , as posited by Just and Carpenter ( 1980 ) , proposes a direct relationship between cognition and eye movements , such that longer fixations ( or pauses in eye movements ) indicate a greater cognitive load implicit in the stimulus . In research on reading , Rayner ( 1998 ) has found support for just such a relationship . Further , saccadic eye movements are obligatorily coupled with shifts in visual attention ( see Deubel & Schneider , 1996 ) . Typically , more meaningful parts of an image will draw more attention than less meaningful ones ( Henderson & Hayes , 2017 ) . Eye movements are also influenced by a variety of factors , including the rarity or frequency ( Kliegl et al. , 2006 ; Just & Carpenter , 1980 ) , level of expectancy or consistency ( Henderson et al. , 1999 ; Luke & Christianson , 2016 ; Staub , 2015 ; V6 & Henderson , 2009 ) or meaningfulness ( Luke & Henderson , 2016 ; Henderson & Hayes , 2017 ; Peacock et al. , 2019 ) of stimuli ( or parts of stimuli ) , all of which typically elicit longer viewing times by participant . Even in settings where stimuli are identical , differences in instructions may significantly influence eye movement patterns ( Yarbus , 1967 ; Navalpakkam & Itti , 2005 ) . Finally , previous research on visual decision tasks has shown how fixations may be used to derive preferences ( Glaholt et al. , 2009 ; Glaholt & Reingold , 2009 ) . Eye tracking provides a measurement of individuals ’ attention , enabling capture even of unconscious behavioral processes that mediate conscious cognition and decision making ( Holmqvist et al. , 2011 ; Parnamets et al. , 2015 ) . Accordingly , Higgins et al. , ( 2014 ) considered eye movements as preference indicators at a very early stage of cognitive processing . Similarly , Parnamets et al. , ( 2015 ) have argued that attention plays a mediating role in decision making . Shimojo and colleagues have previously presented the gaze cascade model of preference decision making , wherein participants exhibit gaze bias toward preferred items prior to selection ( Shimojo et al. , 2003 ; Simion & Shimojo , 2006 ; 2007 ) . While this model has never been tested in the context of SERP information search , it has proven a resilient finding in a variety of decision-making tasks ( e.g. , Gidléf et al. , 2013 ; Armel et al. , 2008 ; Krajbich et al. , 2010 ) . Similarly , in preference decision-making tasks , before selecting one face as the more attractive , people tend to look more toward that face than other ones ( Shimojo et al. , 2003 ; see also Maughan et al. , 2006 ) . In online contexts , an eye tracking study by Silflow et al. , ( 2019 ) found that Facebook users tend to select news posts where content reinforced their own attitudes . This assertion finds further support in results from eye tracking studies assessing selective exposure in political advertising ( Marquart et al. , 2016 ; Schmuck , et al. , 2019 ) , and Facebook news feeds ( Vraga et al. , 2016 ; Siilflow et al. , 2019 ) . However , relatively little is known about selective exposure at the early stages of processing , such as visual attention ( but see Marquart et al. , 2016 ; Zillich et al. , 2019 ) . While eye tracking has been used extensively in web-related research ( e.g. , Nielsen & Pernice , 2010 ) , to the author ’ s knowledge , this work represents the first examination of its kind as it applies to everyday search engine link selection — and , in particular , the attention paid to links based on their perceived content . Relating specifically to search behavior in interactions with search engines , Granka et al. , ( 2004 ) found that mean time spent firxating on the first and second links in a set of links were almost equal , after which there was a steep drop-off in attention to subsequent links ; however , participants tended to select the first link in a set ( see also Salmerén et al. , 2013 ) . Thus , while earlier eye tracking studies have investigated eye movements in search such as the significance of link order , finding strong preferences for top-presented links ( Pan et al. , 2007 ) , no previous research has examined the impact of the perceived ideological content of available links on the visual attention paid to those links . In light of the above related research , we should expect that users selectively attend and select link alternatives that are distinguished by user-politically dissident and source unreliability , such that disliked sources are attended less and selected less often ( see Figure 2 ) . Thus , attention is here operationalized as aspects of gaze behavior : total time spent fixating on and number on fixations on , any one link . Selection is operationalized as the choice of clicking on one of several links in presented SERPs . H3a : People pay more attention to search results that are in line with their ideology . H3b : Liberal and left-wing partisans exhibit stronger attention bias compared to right-wing partisans . Finally , whereas there are — at the time of writing — no studies known to this author investigating political partisans ’ reading behavior , reading as general information processing has been extensively studied ( for an overview , see Rayner , 2009 ) . Reading patterns , such as thorough reading versus skimming , have been found to lead to differentiating levels of comprehension and retention ( Strukelj & Niehorster , 2018 ) . Significantly , Strukelj ( 2018 ) has investigated how readers ’ expectations — including having feelings about the topic at hand , and knowing some text originated from more or less respected news sources — may impact even the process of reading itself . The state of research thus presents researchers of political information processing with the intriguing hypothesis that partisans may engage differently with confirming versus non-confirming political reading material , such that disconfirming information would be less closely scrutinized . Against this background , I define the final hypothesis of the thesis : H4 : People inspect opposing-side information less carefully , operationalized as differences in reading depth . Thus , I suggest that searchers ’ personal beliefs lead them to act selectively on the abundant set of available information afforded by search engines , such that personal ideological biases systematically skew their attending to and selecting of information . In selecting relevant information , searchers ’ cognition may bias attention to ideologically charged content , such that ideologically confirming information is emphasized , and disconfirming content is disregarded . Continue search 2 Methods Instruments Ideology may be operationalized both as a constellation of beliefs and as group identity , separate constructs which may or may not have independent effects on political information processing . Thus , participants ’ ideology was assessed through responses to items from the SECS inventory ( Everett , 2013 ) and group identity via self-identification as left-wing , centrist , or right-wing . Finally , participants were also asked to rate , on seven-point Likert scales , ( 1 ) how much they trusted each of a set of sources and ( 2 ) how often they consumed news from those sources . Apparatus Eye movement data were recorded using Tobii Pro Spectrum remote eye trackers . The tracker sample rate was 600 Hz . The screen size of the monitors was 23.8 ” , with a resolution of 1920 x 1080 . For stimulus presentation and data acquisition , the Tobii Pro Lab software was used . Viewing distance from the monitor was ~66cm . For all participants , both eyes were tracked , and chin rests were used . Mouse clicks were also recorded . Pre-study Links were sampled from Google Search results from various online news sources , such as online magazines and newspapers , to represent a diversity of viewpoints across the political spectrum . For each topic , 10 links were sampled , for a total of 80 links . To judge the perceived ideology of each link , online participants ( 7 = 3 ) were recruited . Each link was presented once , along with a seven-point Likert scale , and participants were asked to rate how they perceived the ideological skew of each link from left ( liberal ) to right ( conservative ) , where lower ratings signified more left- se — __ No No — > Attend briefly Does information conform to prior beliefs ? Yes — > Consider for selection —— > Selected ? End search +——_ Yes Figure 2 . Selective attention in online information visual search ( hypothesized ) . wing content and higher ratings signified more right- wing content . The ordering of the links was fully randomized for each participant . The pre-study took ~5 minutes on average to complete . Participants were not compensated . Cronbach ’ s alpha for the 80 items was deemed sufficient ( a = .79 ) . In subsequent categorization of the links , raters ’ scores for each link were averaged , and the average of the scores assigned to each link . The purpose of this procedure was to obtain a value of political leaning for each link , by which to correlate the eye movement analyses . Participants Participants ( V = 48 , 22 women ) took part in the experiment . They were aged 18 — 53 ( Af = 23.19 , SD = 5.79 ) were recruited from local politically partisan groups ( e.g. , left- and right-leaning political youth groups ) and from college courses that were deemed likely to attract politically active students ( e.g. , political science ) . Six participants were excluded because of significant data loss during recording . Out of all participants , 25 self-identified as left-wing , 5 as being in the center , and 18 as right-wing . All participants were Swedish natives and spoke native Swedish . In return for participation , participants received a voucher for 100 SEK for use in a national chain of bookstores . Stimuli Stimuli were created using the EBImage R package ( Pau et al. , 2010 ) . From the original 80 links , sets of six links per topic were selected for the study proper , for a total of 64 . This number was selected because the standard setting on most desktop monitors allows for at least six links at any one time ; it also aligns closely with previous research showing selection as driven by link position ( e.g. , Salméron et al. , 2013 ) . To control Google bidrag 4 Tea m Moderate ! x Transiate this pap Debatt : Infor krav pa kunskaper i svenska for att fa bidrag stones vt , ' Figure 3 . Example SERP stimulus . for ordering effects , in each set of search results , the links were ordered according to a 6x6 Latin square , resulting in a total of six stimuli for each topic , from which one was sampled and presented to any given participant ( see Figure 3 ) . This also required the number of participants to be a factor of six . In all , 8 SERP stimuli were presented to each participant . For the sake of environmental validity , stimuli should be as visually similar as possible to real Google SERPs . All links and all linked-to sites were in Swedish . Safety precautions regarding Covid-19 As data collection took place during the Covid-19 global epidemic , a set of additional safety measures were implemented to ensure the safety of both experimenter and participants , and to limit the spread of the virus . All participants were asked to use hand- rub alcohol upon entering the lab and interactions with the experimenter were kept at a minimum . After each usage , keyboards , computer mice , and chin rests were wiped off using wet wipes . Eye trackers were not wiped . Initially , participants were limited to at most five at a time in the lab ; as recommendations changed , this was further restricted to one participant at a time in later sessions . All data collection was carried out in line with the then-current guidelines issued by the Public Health Agency of Sweden . Procedure Prior to the experiment , informed consent was obtained . Participants were informed that their data would be anonymized , that they would not be exposed to harm of any kind , and that they had the right to opt out of participation at any point during the experiment . Participants were invited to sit down in front of a Tobii Pro Spectrum eye tracker and asked to use the provided chin rest . Each participant was instructed to keep their head still for the duration of the experiment . The eye tracker was then calibrated . Participants then received on-screen instructions . They were instructed that they were about to take part in an experiment about searching for information in Google Search . They were to examine the provided sets of search results and select ( by clicking ) the link they would be most likely to select in natural search settings . In each set of search results , six links were visible . For each trial , one mouse click was saved per trial . After a participant had clicked on a link , the experiment moved on to the next trial . Once all 8 stimuli screens had been presented , participants were asked to fill in a Google Forms survey . There , they provided on 7-point Likert scales their affects towards a set of political topics and phrases ( derived from the SECS inventory ) . They were also asked to rate how important each topic was to them personally . Finally , they were asked to state their familiarity with a list of sources , as well as the degree to which they trusted each source . After the experiment , participants were debriefed as to the true motivation of the study and Table 1 . Multiple linear regression analysis of relative total fixation durations on links . ( Intercept ) Link position Nr . of characters in link Participant ideology : Conservative Participant ideology : Liberal Participant self-identification : Right-wing Participant self-identification : Left-wing Link ideology : Left-wing Link Ideology : Right-wing Trust in Link source : Low Trust in Link source : Mid Participant ideology : Conservative * Link ideology : Left-wing Participant ideology : Liberal * Link ideology : Left-wing Participant ideology : Conservative * Link ideology : Right-wing Participant ideology : Liberal * Link ideology : Right-wing Estimate Std.error tvalue P ( z ) 3.32 11 30.35 < 001 -.04 .004 -9.65 < 001 002 < .001 4.99 < 001 -.02 .07 -.27 82 -.09 .06 -1.50 .13 -.000 .03 -.007 995 11 .03 3.96 < 001 -.17 .06 -3.002 < 01 -.1 .06 -1.79 .07 -.11 .02 -5.88 < 001 -.01 .03 -41 68 02 .08 25 81 16 .07 2.43 < 05 .08 7 48 .06 1.64 10 Adjusted R ? : 0.11 offered compensation . Each experiment lasted roughly ~20 minutes . 3 Results In initial qualitative observations , it was observed that participants tended to investigate the presented search result page from top to bottom , which was consistent with Salmerén et al. , ( 2013 ) . In the present data set , no participant apparently deviated from this pattern . In addition , some participants did not attend to the last few links at all , aligning with prior research ( e.g. , Granka et al. , 2004 ) . Further , link position apparently affected how much attention was afforded to each link , generally resulting in the “ golden triangle ” -style gaze patterns as described by Hotchkiss et al. , ( 2005 ; see Figure 1 ) . For subsequent quantitative analyses , due to a coding error , two links , one from each of two trial screens had no corresponding ratings for trust in link source . Therefore , these links were excluded from eye movement analyses ; however , other links in the stimuli screen were still included . For analyses of link selection , trials containing these links were excluded , and only selected links were analyzed . In trials where the wrongly coded link was not selected , data were included in the analysis . Fixation durations Because fixation duration was highly variable between participants ( see Holmqvist et al. , 2011 ) , data distribution was significantly skewed . Therefore , data were log10 transformed prior to analysis . A multiple linear regression , excluding zeroes , was then calculated to predict total fixation duration based on Link position , Participant ideology , coded as Conservative , Liberal , or Center , Participant self- identification , coded as Right-wing , Left-wing , or Center ; Perceived link ideology , coded as Left-wing , Right-wing , or Center ; Trust in the link source , coded as High , Medium , or Low ; and interactions between Participant self-identification and Link ideology . The model met homolinearity , homoscedasticity and multicollinearity assumptions ; however , residuals were found not to be normally distributed . One data point was identified via Cook ’ s distance as highly influential and removed prior to subsequent analysis . A significant regression equation was found ( F ( 14 , 2144 ) = 19.02 , p < .001 ) , with R ? =.11 . Link position was a significant predictor of fixation duration ( p < .001 ) . Mean fixation duration was found to be longer for left wing-identifying compared to center-identifying participants ( p < .001 ) , but no difference was found between center- and right wing-identifying participants . Participants ’ trust in the sources associated with links was a significant predictor when trust was low ( p < .001 ) but not when it was medium-high or high , such that links associated with less trusted sources were attended significantly less , compared to more trusted ones . Finally , a significant interaction effect was found between participant ideology and link ideology , such that the combination of ideological liberals and left- wing links predicted greater fixation durations ( p < .05 ) . There was no independent effect of participant ideology ( see Table 1 ) . The number of characters in each link was also included in the model as a covariate and found to be highly significant ( p < .001 ) . Number of fixations In order to take account of zeroes ( unattended areas of interest ) in the data , a second regression analysis was performed including zeroes . When modelling the number of fixations per text AOI — a count variable — Table 2 . Quasi-Poisson regression analysis of fixations per link . the number of zeroes in the data were found to be overdispersed . Thus , a quasi-Poisson regression was calculated to predict the number of fixations per link based on the same predictors of Link position , Participant ideology , Participant self-identification , Link ideology , Trust in the link source , and interactions between Participant self-identification and Link ideology . A statistically significant model ( Efron ’ s R ? = .08 ) ( Efron , 1978 ) . Link position ( p < .001 ) and the number of characters in a link ( p < .001 ) were both significant predictors of fixation number per link . Participant self-identification was a significant predictor ( p < .001 ) , such that participants who identified as left-wing made more fixations than those that identified as Center or right-wing . There was no observed significant sex difference . The perceived ideology of the link was a significant predictor , such that apparently left-wing links were fixated more than centrist or right-wing ones ( p < .05 ) . Trust in the sources associated with the links was also a significant predictor of the number of fixations ( p < .001 ) , such that links associated with sources for which trust was low were attended significantly less than were links associated with sources for which trust was medium- high or high . There were no significant interaction ( Intercept ) Link position Nr . of characters in link Participant ideology : Conservative Participant ideology : Liberal Participant self-identification : Right-wing Participant self-identification : Left-wing Link ideology : Left-wing Link Ideology : Right-wing Trust in Link source : Low Trust in Link source : Mid Participant ideology : Conservative * Link ideology : Left Participant ideology : Liberal * Link ideology : Left Participant ideology : Conservative * Link ideology : Right-wing Participant ideology : Liberal * Link ideology : Right-wing Estimate Std . error t-value P @ ) 2.23 27 8.34 < 001 -.09 01 -8.43 < 001 01 .001 4.19 < 001 14 14 1.01 31 -.12 12 -1.02 31 Jl .07 1.48 14 33 .07 5 < .001 -.27 .13 -2.14 < .05 -.14 12 -.15 25 -.18 .04 -4.11 < .001 .03 .06 A2 67 -.15 17 -.89 37 .26 15 1.8 .07 -.12 .16 -.71 48 15 14 1.06 29 Efron ’ s R ? = .08 Table 3 . Multiple regression analysis of reading depth . Estimate Std.error # value P ( z ) ( Intercept ) -.93 ll -8.69 < .001 Link position -.04 .004 -9.74 < 001 Nr . of characters in link -.0001 .0004 -.26 8 Participant ideology : Conservative -.0007 .O7 -.01 Al Participant ideology : Liberal -.07 .06 -1.2 23 Participant self-identification : Right-wing 02 .03 81 A2 Participant self-identification : Left-wing 13 .03 5.05 < .05 Link ideology : Left-wing -.17 .06 -3 < .01 Link Ideology : Right-wing -.09 05 -1.58 ll Trust in Link source : Low -.11 .02 -5.66 < .001 Trust in Link source : Mid -.01 .26 -.26 .79 Participant ideology : Conservative .03 .08 34 73 * Link ideology : Left Participant ideology : Liberal 15 .06 2.6 < .05 * Link ideology : Left Participant ideology : Conservative .05 .O7 7 AD * Link ideology : Right-wing Participant ideology : Liberal 09 .06 1.43 15 * Link ideology : Right-wing Adjusted R ? : .099 effects between Participant ideology and Link ideology ( see Table 2 ) . Scrutiny in reading To investigate the hypothesis that partisans read disconfirming links less closely , a measure of reading depth was computed using the number of fixations on each text AOI , divided by the number of characters ( not including spaces ) in that same AOI . One data point was excluded based on Cook ’ s distance . A multiple linear regression was then calculated to predict reading depth based on the same variables as listed above ( see Table 3 ) . A significant regression equation was found ( F ( 14 , 2144 ) = 17.84 , p < .001 ) , with R ? = .10 . Link position was shown to be a significant predictor of reading depth ( p < .001 ) . Participant self-identification was shown to be significant , such that left-wing participants read the links more carefully than did those that identified as right-wing ( p < .05 ) , which was consistent with overall fixation time . Link ideology was shown to be a significant predictor such that left-wing links were read more closely by all participants compared to right- wing ones ( p < .01 ) . The interaction between Participant ideology and Link ideology was found to be a significant predictor of reading depth , such that political liberals read politically left-wing links more carefully ( p < .05 ) . Participant ideology was not found to be a significant predictor of reading depth . The number of characters in each link , again included covariate , was not found to be a significant predictor . Selection To investigate hypotheses Hla and H1b , a binomial regression for binary outcomes ( clicks agreed versus did not agree with beliefs ) was calculated based on Link position , Perceived link ideology , Participant self-identification , Participant ideology , and Trust in link sources , resulting in a significant model ( p < .001 ) . Link ideology was a statistically significant predictor of selection-ideology agreement when the link was left-wing ( p < .05 ) and right-wing ( p < .001 ) , compared to links representing the political center . Similarly , participant political self-identification was a significant predictor when participants identified as left-wing ( p < .001 ) or right-wing ( p < .001 ) , compared to participants who identified as being in the political center . Trust in the source of the link was a significant Table 4 . Results from logistic regression analysis of link selection 95 % CI Estimate Std . Wald = sig . Exp ( B ) Lower Upper error stat . bound bound ( Intercept ) -4.47 86 27.24 < .001 01 -6.15 -2.79 Link position .001 08 .0003 99 1 -.16 17 Link ideology : Left-wing 2.09 92 5.18 < .05 8.11 29 3.89 Link ideology : Right-wing 3.13 78 16.06 < .001 22.94 1.6 4.67 Participant self-identification : 1.93 5 14.74 < 001 6.87 94 2.91 Left-wing Participant self-identification : 2.06 AQ 1741 < 001 7.82 1.09 3.02 Right-wing Participant ideology : Conservative 2 .89 .05 82 1.22 -1.54 1.94 Participant ideology : Liberal -.58 .96 35 55 56 -2.46 1.32 Trust in Link source : Mid 94 A2 483 < .05 2.5 Al 1.78 Trust in Link source : High AS 31 2.05 15 1.56 -.17 1.06 Participant ideology : Conservative -.16 1.29 02 9 85 -2.7 2.37 * Link ideology : Left Participant ideology : Conservative 43 1.08 16 69 1.5 -1.69 2.55 * Link ideology : Right Participant ideology : Liberal 2.46 1.2 422 < 05 11.64 ll 48 * Link ideology : Left-wing Participant ideology : Liberal -.17 1.1 02 88 84 -2.32 1.98 * Link ideology : Right-wing McFadden R ? = 34 predictor when Trust was medium-high ( p < .05 ) , but not when it was low or high . Participant ideology was not a significant predictor , however , a significant interaction was observed between participant ideology and link ideology , such that selection-agreement was significantly greater for liberal participants selecting left-wing links ( p < .05 ) . There were no other statistically significant interaction effects . Link position was not a significant predictor of selection- ideology agreement , supporting hypothesis H1b ( see Table 4 ) . 4 Discussion Moving the conversation on filter bubbles The filter bubble hypothesis posits that algorithmic curation of search results facilitates ideological segregation , with significant implications for society ( Pariser , 2011 , Liljeblad , 2012 ) and the personal beliefs of individuals ( e.g. , Miller & Record , 2013 ) . However , empirical research on this topic has largely failed to support the hypothesis ( e.g. , Hannak et al. , 2017 ; Haim et al. , 2017 ) . An alternative explanation , here referred to as the self-imposed filter bubble hypothesis ( see Yom-Tov et al. , 2014 ) , posits that filter bubble-like effects may be imposed by users themselves , acting preferentially on sets of search results , attending to , and selecting from , confirming ( and trusted ) sources of information , rather than disconfirming ( and distrusted ) ones . In this thesis , I have attempted an empirical test of this hypothesis . Quantitative analysis of selection data provided support for hypothesis Hla ( Partisans select search results in line with their group and ideology , and select against search results that are not in line with their group and ideology ) , such that both left-wing identifying and right-wing identifying participants tended to select own-side links ; and strong support for hypothesis Hlb ( The top-link heuristic holds when search results align with searcher ’ s ideology , but not when it does not ) , such that link position appeared irrelevant to partisans ’ selection . Notably , some of the 10 strongest evidence found by this thesis supported confirmation of hypothesis H2 ( People pay more attention to links associated with trusted sources , compared to untrusted ones , and select them more often ) , such that trust in the source associated with a link predicted both the attention paid to , and subsequent selection of , that link . Analysis of eye movement data provided partial support for H3a ( People pay more attention to search results that are in line with their ideology ) and confirmation of hypothesis H3b ( Liberal and left-wing partisans exhibit stronger attention bias compared to right-wing partisans ) , such that Liberal partisans did exhibit a stronger attention bias to own-side ( left-wing ) links , while Conservatives did not . Consistent with the results of the other analyses described above , there was partial support for hypothesis H4 ( People inspect opposing-side information less carefully , operationalized as differences in reading depth . ) , such that Liberal participants read own-side links more closely than other-side links . The present study contributes to the current literature in several ways . Firstly , it adds to an understanding of how politically partisan users of search engines engage with political content in SERPs . It also provides some empirical evidence of partisans ’ politically self-segregating online behavior , both in the early stages of information processing and attention — a novel contribution — and in subsequent selection of content , which is consistent with prior literature on selective exposure ( Klapper , 1960 ; Sears & Freedman , 1967 ) . Notably , however , a visual attention bias for own-side content was only observed for liberal participants . This bias in left-leaning participants is consistent with some previous research . For instance , there is evidence that left-wing and liberal partisans would be more punishing of opposite-side material , such as exhibiting a stronger tendency to “ unfriend ” opposite-side endorsing friends on social networks ( e.g. , Cox & Jones , 2016 ; but for a nuanced account , see Mitchell et al. , 2014 ) . As of the time of writing , it is unclear whether liberals and conservatives exhibit some measurable differences in terms of information processing that might otherwise explain these findings ( but see Jost & Amodio , 2011 ) . Significantly , while visual attention was biased in only a subset of the sample , analysis of selection data was more broadly consistent with earlier findings on selective exposure in online environments and information search ( e.g. , Garrett , 2009a ; Bakshy et al. , 2015 ) . Both right-wing and left-wing partisans strongly curated their chosen links , effectively engaging in a process of selective exposure . Altogether , these results suggest that partisans ’ selection bias is stronger than that of their visual attention . This thesis also provides evidence that trust in a source of information serves as an important predictor of both visual attention and selection of a link . In research on message reliability , people ’ s evaluations of communicated information tend to be contingent on both relevance and plausibility ( see Sperber et al. , 2010 ; Mercier et al. , 2017 ; Mercier , 2020 ) . In this study , I assumed that political alignment and agreement signified relevance more broadly ; we further argue that participants ’ ratings of trust in sources of the presented links tapped into values of apparent plausibility , such that a more trusted source should on average be expected to provide more plausible and reliable news coverage and opinion-making . To the author ’ s knowledge , this represents the first time such results have been demonstrated in an online information search environment . Notably , however , they align with previous research on what facilitates engagement with opposite-side information or sources . For example , Yom-Tov et al. , ( 2014 ) found that people were more likely to click on documents representing the opposing view when the language model ( computed based on popular Democrat- and Republican-leaning news outlets ) of that document was consistent with their own views . Moving forward , others have emphasized the potential role of novel technology in facilitating interactions across political boundaries , such as software encouraging engagement with opposite-side sources and views ( e.g. , Bozdag & van den Hoven , 2015 ) . Thus , taking account of the cognitive mechanisms that underlie selective exposure , allows researchers to gain better understanding into the supposed problem of filter bubbles . Given the results presented in this thesis , it appears necessary that the focus of the filter bubble debate ( e.g. , Pariser , 2011 ) be shifted to properly incorporate the role of the individual user and how he or she engages with the information made available by internet search engines . If validated further , the findings presented in this work may have significant implications for government policy ( and the choice of whether or not to regulate internet search engines ) , and for internet tech companies more broadly . After all , attempts at counteracting possible filter bubble-type effects through changes to the algorithms that generate search results — e.g. , by presenting users with ideologically diverse information — has little consequence , if those users do not attend to other-side information , and thus never choose to interact with it . Itis therefore necessary that researchers seek to move the discussion on filter bubbles , from algorithmic curation of search results ( for which empirical results are few ) to the mind of users who see , attend , and select from them . Limitations The study suffered from several limitations that need addressing . First , in our data , some ideological concepts appeared almost universally appreciated . For example , only 4 out of 48 participants claimed to have negative feelings towards abortion . Thus , it appears that the SECS inventory ( Everett , 2013 ) ( which was invented for studying ideology in the US ) may be less useful in a Swedish context . Swedes are , on average , high on secular values , and highly liberal by international standards ( World Values Survey , 2021 ) . 11 They are also among the people in the world scoring the highest on values of self-expression , signifying general acceptance of societal outgroups such as immigrants and sexual minorities ( e.g. , homosexuals ) , and trust in government . Thus , the lack of hypothesized interaction effect may stem from a failure to sample a sufficiently high number of Swedish conservatives ( as defined by Everett , 2013 ) . Relatedly , the present study also did not attempt to control for participants ’ actual knowledge of political affairs and events ( 1.e. , political sophistication , see Lodge & Taber , 2005 ) . It is likely that possessing demonstrable knowledge on some political topic may impact attention to presented information on that same topic . Further , it is possible that a simple three-level coding of political material ( left-Center-right ; , Liberal- Center-Conservative ) is not sophisticated enough to capture the mechanisms of political information processing in a Swedish sample . Specifically , the lack of statistically significant effect of visual attention to own-side material in Conservative and right-wing participants may be an artefact of link sampling . Currently , Swedish right-wing politics is divided between a socially liberal but fiscally conservative faction , and another more socially conservative , anti- establishment faction ( for an overview , see Esaiasson & Wangnerud , 2016 ) . Meanwhile , no equivalent discrepancy currently exists for left-wing politics . It is possible , then , that supposedly right-wing content in presented links played to one of these right-wing factions and not the other , attracting some right-wing identifying participants but repelling others . Were this to be addressed in future research , it is possible that a visual attention bias for own-side content would be found for Conservative and right-wing participants . However , as no research of this kind is known to the author at the point of writing , this possibility remains solely hypothetical . A second point of contention concerns the generalizability of the findings . Importantly , much eye-tracking research has shown discrepancies in eye movements for laboratory settings , as compared with their real-life counterparts ( e.g. , Gidléf et al. , 2013 ; Mulckhuyse et al. , 2008 ; Born et al. , 2011 ; Foulsham et al. , 2011 ) . In light of these findings , we can not rule out the possibility that our information search task is not close enough to the real experience of online information search . In real life , search terms are not given but thought up dynamically by the user . Typically , users tailor search terms to current needs , using combinations of phrases they deem likely to produce wanted results . For political partisans , this may also involve searching for political information in biased terms , more likely to return lists of results appropriate to those same views . Thus , as links used in the present study were controlled for political content , this is unlikely to reflect the real-life situation of biased attention in online information search . The above limitation also dovetails with a more general concern for the ecological validity of the presented work . Specifically , when participants are probed for responses to affectively charged stimuli — such as political content — they may be prone to self- censorship , shying away from particularly radical or unusual responses ( i.e. , exhibit demand characteristics ) . For this reason , future work on the topic may thus strive for more naturalistic settings . For instance , recent developments in eye tracking present the possibility of conducting eye movement research using participants ’ own webcams in their home ( e.g. , Papoutsaki et al. , 2017 ; see also Semmelmann & Weigelt , 2018 ) . However , it remains yet to be seen how this development could be used in the scientific study of visual attention in online information search outside of formal lab environments . Finally , we can not rule out any effect of framing . The sampled links included as stimuli were not controlled for any attention-grabbing quality inherent in their headlines . For instance , some authors have suggested that “ clickbait ” — a style of headline designed to generate engagement from its online audience by inducing them to click to access its content — may drive affective polarization between left-wing and right-wing online audiences ( e.g. , Settle , 2018 ) . This possibility can not as of yet be ruled out , although recent work on clickbait headlines by Munger et al. , ( 2020 ) found no effect of clickbait headlines on affective polarization . There are also no studies known to this author , showing differences in prevalence or effectiveness of clickbait-style articles for left-wing or right-wing content . Additionally , while clickbait-type headlines were effective early to mid-2010 ’ s , they have recently seen a drastic reduction in use — and in profitability in recent years ( see Rayson , 2018 ) . Therefore , effects of framing of news items inherent in the links may be negligible — though it not possible to say for certain . Summary and directions for future research This work investigated potential filter bubble-type effects resulting from partisans ’ visual attention and subsequent selection . It appears that link position significantly affects which links are initially attended — but evaluation and ( especially ) selection are mediated by partisans ’ perception of its apparent content and by the trust placed in the sources associated with those contents . The expected interaction effect for visual attention between partisanship and link content was only found a subset of participants , Liberal participants attending left-wing content . As for now , however , this picture remains incomplete . Whereas the literature on selective attention in web search has integrated eye movement research , there is much still in the fields of cognitive science that might provide insights into any potential polarizing behavior . Firstly , prior research on eye movements during reading have found that readers ’ expectations ( Strukelj , 2018 ) , and working memory capacity ( Daneman & Carpenter , 1980 ; Dixon et al. , 1988 ; Strukelj et al. , 2017 ) may affect their visual processing of reading 12 material . This thesis contributes to this body of literature , suggesting that ( some ) partisans read own- side affirming information more carefully than other- side affirming , and that readers , in general , read trusted information more carefully than they do mistrusted information . For political information processing , this raises the possibility of social group differences in processing of reading material — something largely unexplored in the relevant literature . It is also possible that opposite-side information constitutes a different working memory load compared to own-side information , where the first prompts avoidance and the second prompts engagement . The results presented in this thesis thus presents intriguing possible implications for future studies on the subject of political information processing in real time . How do partisans engage ( or fail to engage ) when reading news items or opinion pieces written by writers they distrust or presenting a disliked conclusion ? Further research on the topic may help further elucidate the intricacies of biased information processing . A second area for future investigation is that of so- called knowledge resistance ( see Wikforss , 2017 ; Klintman , 2019 ; see also O'Connor & Weatherall , 2019 ; Mercier , 2020 ) . In recent years , there has been widespread concern that ( some or all ) individuals are somehow resistant to information that might otherwise change their minds . The work presented in this thesis , attempting to integrate eye movements within a framework of partisans ’ information processing , helps point the way toward a formal integration of cognitive science with this novel and significant development ( but see Mercier , 2020 ) . Finally , the findings presented in this thesis help provide clues into the cognitive mechanisms that underlie political partisanship — a development that should be seen against the backdrop of neuropsychological studies of partisan information processing ( see Jost & Amodio , 2011 ; Jost et al. , 2014 ) . For example , a functional magnetic resonance imaging study by Westen et al. , ( 2006 ) observed selective activity in the brains of American political Liberals and Conservatives while reasoning about information that was threatening either to their own candidate in the 2004 American presidential election or to the opposing candidate . Results suggested that motivated reasoning implicated emotional processing and was not linked to activity in brain regions associated with “ cold ” ( or objective ) reasoning . The authors argued that motivated reasoning was qualitatively distinct from reasoning , when participants do not have a strong emotional stake in the conclusions . Such and similar work may provide clues as to how partisans ’ treat information , once attended . As communication research has progressively sought to integrate tools of cognitive science , an extension to neuroscientific tools has become feasible . Moreover , the strong effect of trust found in this thesis suggests a role in information processing more broadly . Significantly , it also supersedes any definition of ideology and extends to settings outside of online political information processing . Moving forward , neuropsychological research should seek to investigate the relationship between motivated reasoning , objective reasoning , and trust , incorporating what is known about selective exposure , so as to provide deeper knowledge of the partisan brain and mind . 5 Conclusions This thesis presented the self-imposed filter bubble hypothesis , the proposition that political partisans engage in self-segregating behavior in online information search . It found partial empirical support for its main hypothesis and strong support that such behavior may be driven less by political persuasion per se , and more by the trust individuals place in the sources of link material , such that less trusted sources are typically both attended less and selected against . Acknowledgements This Master ’ s thesis originated in discussions between Axel Ekstrém — the author — and Erik J. Olsson , Professor of Theoretical Philosophy at Lund University , in the context of the research project Filter Bubbles and Ideological Segregation Online : Do We Need Regulation of Search Engines ? , funded by The Bank of Sweden Tercentenary Foundation ( 2019-2021 , Olsson PI ) . The original idea of studying filter bubbles in search engines using eye-tracking technology was the author ’ s . The experimental design was developed by the author in collaboration with Olsson , who also contributed to the hypothesis formation . The original hypotheses were supplemented and refined by the author , who also recruited and administered all participating subjects , and carried out all experiments ( including the described pre-study ) and subsequent data analyses . Ekstrém ’ s administration of the experiments was funded by the above research project , in which he participated as a research assistant , as were the vouchers that were given to the subjects as compensation for their participation . References Armel , K. C. , Beaumel , A. , & Rangel , A . ( 2008 ) . Biasing simple choices by manipulating relative visual attention . Judgment and — Decision making , 3 ( 5 ) , 396-403 . Bakshy , E. , Messing , S. , & Adamic , L. A . ( 2015 ) . Exposure to ideologically diverse news and opinion on Facebook . Science , 348 ( 6239 ) , 1130-1132 . Bartels , L. M. ( 2018 ) . Unequal democracy : The political economy of the new gilded age . Princeton University Press . Birnbaum , M. H. , Wong , R. , & Wong , L. K. ( 1976 ) . Combining information from sources that vary in credibility . Memory & Cognition , 43 ) , 330-336 . 13 Birnbaum , M. H. , & Stegner , S. E. ( 1979 ) . Source credibility in social judgment : Bias , expertise , and the judge 's point of view . Journal of Personality and Social Psychology , 37 ( 1 ) , 48 . Bode , L. ( 2016 ) . Pruning the news feed : Unfriending and unfollowing political content on social media . Research & Politics , 3 ( 3 ) , 2 053 168 016 661 873 . Born , S. , Kerzel , D. , & Theeuwes , J . ( 2011 ) . Evidence for a dissociation between the control of oculomotor capture and disengagement . Experimental Brain Research , 208 ( 4 ) , 621-631 . Bozdag , E. , & Van Den Hoven , J . ( 2015 ) . Breaking the filter bubble : democracy and design . Ethics and information technology , 17 ( 4 ) , 249-265 . Bovens , L. , & Hartmann , 8 . ( 2003 ) . Bayesian epistemology . Oxford University Press on Demand . Brader , T. ( 2006 ) . Campaigning for hearts and minds : How emotional appeals in political ads work . University of Chicago Press . Brewer , M. B . ( 1979 ) . In-group bias in the minimal intergroup situation : A cognitive-motivational analysis . Psychological bulletin , 86 ( 2 ) , 307 . Cardenal , A. S. , Aguilar-Paredes , C. , Galais , C. , & Pérez-Montoro , M. ( 2019 ) . Digital technologies and selective exposure : How choice and filter bubbles shape news media exposure . The international journal of press/politics , 24 ( 4 ) , 465- 486 . Chong , D. ( 2013 ) . Degrees of rationality in politics . In ( L. Huddy , D. O. Sears , & L. S. Levery ( Eds . ) , The Oxford handbook of political psychology ( pp . 96-129 ) . Cinelli , M. , Brugnoli , E. , Schmidt , A. L. , Zollo , F. , Quattrociocchi , W. , & Scala , A . ( 2020 ) . Selective exposure shapes the Facebook news diet . PloS one , 15 ( 3 ) , 0229129 . Cohen , G. L. ( 2003 ) . Party over policy : The dominating impact of group influence on political beliefs . Journal of personality and _ social psychology , 85 ( 5 ) , 808 . Colleoni , E. , Rozza , A. , & Arvidsson , A . ( 2014 ) . Echo chamber or public sphere ? Predicting political orientation and measuring political homophily in Twitter using big data . Journal of communication , 64 ( 2 ) , 317-332 . Collins , P. J. , Hahn , U. , von Gerber , Y. , & Olsson , E. J . ( 2018 ) . The bi-directional relationship between source characteristics and message content . Frontiers in psychology , 9 , 18 . Courtois , C. , Slechten , L. , & Coenen , L. ( 2018 ) . Challenging Google Search filter bubbles in social and political information : Disconfirming evidence from a digital methods case study . Telematics and Informatics , 35 ( 7 ) , 2006-2015 . Cox , D. , & Jones , R. ( 2016 ) . Merry Christmas ’ vs.Happy Holidays ’ : Republicans and Democrats are polar opposites . Public Religion Research Institute report . Daneman , M. , & Carpenter , P. A . ( 1980 ) . Individual differences in working memory and reading . Journal of verbal learning and verbal behavior , 194 ) , 450-466 . Deubel , H. , & Schneider , W. X . ( 1996 ) . Saccade target selection and object recognition : Evidence for a common attentional mechanism . Vision research , 36 ( 12 ) , 1827-1838 . Dilliplane , S. ( 2011 ) . All the news you want to hear : The impact of partisan news exposure on political participation . Public Opinion Quarterly , 75 , 287— 316 . Dixon , P. , Lefevre , J . A. , & Twilley , L. C. ( 1988 ) . Word knowledge and working memory as predictors of reading skill . Journal of educational psychology , 80 ( 4 ) , 465 . Duchowski , A. T. ( 2002 ) . A breadth-first survey of eye-tracking applications . Behavior Research Methods , Instruments , & Computers , 34 ( 4 ) , 455— 470 . Eibl-Eibesfeldt , I . ( 1979 ) . Human ethology : Concepts and implications for the sciences of man . Behavioral and Brain Sciences , 2 ( 1 ) , 1-26 . Efron , B . ( 1978 ) . Regression and ANOVA with zero- one data : Measures of residual variation . Journal of the American Statistical Association , 73 ( 361 ) , 113- 121 . Esaiasson , P. , & Wangnerud , L. ( 2016 ) . Political parties and political representation . In J. Pierre ( Ed . ) , The Oxford Handbook of Swedish Politics ( pp . 188-205 ) . Oxford University Press . Everett , J . A . ( 2013 ) . The 12 item social and economic conservatism scale ( SECS ) . PloS — one , 8 ( 12 ) , e82131 . Festinger , L. ( 1957 ) .4 theory of cognitive dissonance ( Vol . 2 ) . Stanford university press . Flaxman , S. , Goel , S. , & Rao , J. M. ( 2016 ) . Filter bubbles , echo chambers , and online news consumption . Public opinion quarterly , 80 ( S1 ) , 298-320 . Foulsham , T. , Walker , E. , & Kingstone , A . ( 2011 ) . The where , what and when of gaze allocation in the lab and the natural environment . Vision research , 51 ( 17 ) , 1920-1931 . Frey , D. ( 1986 ) . Recent research on selective exposure . In L. Berkowitz ( Ed . ) , Advances in experimental social psychology ( Vol . 19 , pp . 41- 80 ) . New York : Academic Press . Garrett , R. K. ( 2009a ) . Echo chambers online ? : Politically motivated selective exposure among Internet news users . Journal of Computer- Mediated Communication , 14 ( 2 ) , 265-2835 . Garrett , R. K. ( 2009b ) . Politically motivated reinforcement seeking : Reframing the selective exposure debate . Journal of communication , 594 ) , 676-699 . Garrett , R. K. , & Resnick , P. ( 2011 ) . Resisting political fragmentation on the Internet . Daedalus , 140 ( 4 ) , 108-120 . 14 Garrett , R. K. ( 2013 ) . Selective exposure : New methods and new directions . Communication Methods and Measures , 7 ( 3-4 ) , 247-256 . Gerber , A. , & Green , D. P. ( 1998 ) . Rational learning and partisan attitudes . American journal of political science , 794-818 . Gentzkow , M. , & Shapiro , J. M. ( 2011 ) . Ideological segregation online and offline . The Quarterly Journal of Economics , 126 ( 4 ) , 1799-1839 . Gidléf , K. , Wallin , A. , Dewhurst , R. , & Holmqvist , K. ( 2013 ) . Using eye tracking to trace a cognitive process : Gaze behaviour during decision making in a natural environment . Glaholt , M. G. , & Reingold , E. M. ( 2009 ) . Stimulus exposure and gaze bias : A further test of the gaze cascade model . Attention , — Perception , & Psychophysics , 71 ( 3 ) , 445-450 . Glaholt , M. G. , Wu , M. C. , & Reingold , E. M. ( 2009 ) . Predicting preference from fixations . PsychNology Journal , 7 ( 2 ) , 141-158 . Granka , L. A. , Joachims , T. , & Gay , G. ( 2004 , July ) . Eye-tracking analysis of user behavior in WWW search . In Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval ( pp . 478- 479 ) . Haim , M. , Arendt , F. , & Scherr , S. ( 2017 ) . Abyss or shelter ? On the relevance of web search engines ’ search results when people google for suicide . Health communication , 32 ( 2 ) , 253-258 . Hannak , A. , Sapiezynski , P. , Molavi Kakhki , A. , Krishnamurty , B. , Lazer , D. , Mislove , A. , & Wilson , C. ( 2013 , May ) . Measuring personalization of web search . In Proceedings of the 22 '' 4 international conference on World Wide Web ( pp . 527-538 ) . Hastorf , A. H. , & Cantril , H. ( 1954 ) . They saw a game ; a case study . The Journal of Abnormal and Social Psychology , 491 ) , 129 . Henderson , J. M. , Weeks Jr , P. A. , & Hollingworth , A . ( 1999 ) . The effects of semantic consistency on eye movements during complex scene viewing . Journal of experimental psychology : Human perception and performance , 25 ( 1 ) , 210 . Henderson , J. M. , & Hayes , T. R. ( 2017 ) . Meaning- based guidance of attention in scenes as revealed by meaning maps . Nature Human Behaviour , 1 ( 10 ) , 743-747 . Hewstone , M. , Rubin , M. , & Willis , H. ( 2002 ) . Intergroup bias . Anmual review of psychology , 53 ( 1 ) , 575-604 . Higgins , E. , Leinenger , M. , & Rayner , K. ( 2014 ) . Eye movements when viewing advertisements . Frontiers in psychology , 5 , 210 . Himelboim , I. , Smith , M. , & Shneiderman , B . ( 2013 ) . Tweeting apart : Applying network analysis to detect selective exposure clusters ~— in Twitter . Communication methods and measures , 7 ( 3-4 ) , 195-223 . Holmgqvist , K. , Nystrém , M. , Andersson , R. , Dewhurst , R. , Jarodzka , H. , & Van de Weijer , J . ( 2011 ) . Eye tracking : A comprehensive guide to methods and measures . OUP Oxford . Hotchkiss G. , Alston S. , & Edwards G. ( 2005 ) . Google Eye Tracking Report : How Searchers See and Click on Google Search Results ( Enquiro Search Solutions ) . Accessed January 24 , 2021 , https : //searchengineland .com/figz/wp- content/seloads/2007/09/hotchkiss-eye-tracking - 2005.pdf . Google Search Statistics . ( 2021 , May 12 ) . Internet Live Stats . hitps : //www.internetlivestats.com/google-search- statistics/ Jamieson , K. H. , & Cappella , J. N. ( 2008 ) . Echo chamber : Rush Limbaugh and the conservative media establishment . Oxford University Press . Joachims , T. , Granka , L. , Pan , B. , Hembrooke , H .. , Radlinski , F. , & Gay , G. ( 2007 ) . Evaluating the accuracy of implicit feedback from clicks and query reformulations in web search . ACM Transactions on Information Systems ( TOIS ) , 25 ( 2 ) , 7-€s . Jost , J. T. , & Amodio , D. M. ( 2012 ) . Political ideology as motivated social cognition : Behavioral and neuroscientific evidence . Motivation and Emotion , 36 ( 1 ) , 55-64 . Jost , J. T. , Nam , H. H. , Amodio , D. M. , & Van Bavel , J. J . ( 2014 ) . Political neuroscience : The beginning of a beautiful friendship . Political Psychology , 35 , 3-42 . Just , M. A. , & Carpenter , P. A . ( 1980 ) . A theory of reading : From eye fixations to comprehension . Psychological review , 87 ( 4 ) , 329 . Kahan , D. M. , Hoffman , D. A. , Braman , D. , Evans , D. , & Rachlinski , J. J . ( 2012 ) . They saw a protest : Cognitive illiberalism and the speech-conduct distinction . Stan . L . Rev. , 64 , 851 . Kammerer , Y. , & Gerjets , P. ( 2012 ) . How search engine users evaluate and select Web search results : The impact of the search engine interface on credibility assessments . In Web search engine research . Emerald Group Publishing Limited . Kammerer , Y. , & Gerjets , P. ( 2014 ) . The role of search result position and source trustworthiness in the selection of web search results when using a list or a grid interface . International Journal of Human- Computer Interaction , 30 ( 3 ) , 177-191 . Kawakami , K. , Williams , A. , Sidhu , D. , Choma , B. L. , Rodriguez-Bailon , R. , Cafiadas , E. , 2 . & Hugenberg , K. ( 2014 ) . An eye for the I : Preferential attention to the eyes of ingroup members . Journal of Personality and Social Psychology , 107 ( 1 ) , 1 . Klapper , J. T. ( 1960 ) . The effects of mass communications . Glencoe , IL : Free Press . Kliegl , R. , Nuthmann , A. , & Engbert , R. ( 2006 ) . Tracking the mind during reading : The influence of past , present , and future words on_ fixation 15 durations . Journal of experimental psychology : General , 135 ( 1 ) , 12 . Klintman , M. ( 2019 ) . Knowledge resistance : How we avoid insight from others . Manchester University Press . Knobloch-Westerwick , S. & Meng , J . ( 2011 ) . Reinforcement of the political self through selective exposure to political messages . Journal of Communication , 61 ( 2 ) , 349-368 . Krajbich , I. , Armel , C. , & Rangel , A . ( 2010 ) . Visual fixations and the computation and comparison of value in simple choice . Nature neuroscience , 13 ( 10 ) , 1292-1298 . Lazarsfeld , P. F. , Berelson , B. , & Gaudet , H. ( 1948 ) . The people ’ s choice : How the voter makes up his mind in a presidential campaign . New York : Columbia University Press . Liljeblad , J . ( 2012 ) . The Implications of Personal Internet Search for Theories of Global Civil Society . International Journal of Technology , Knowledge & Society , 8 ( 1 ) . Lodge , M. , & Taber , C. S. ( 2005 ) . The automaticity of affect for political leaders , groups , and issues : An experimental test of the hot cognition hypothesis . Political Psychology , 26 ( 3 ) , 455-482 . Luke , S. G. , & Henderson , J. M. ( 2016 ) . The influence of content meaningfulness on eye movements across tasks : evidence from scene viewing and reading . Frontiers in psychology , 7,257 . Maughan , L. , Gutnikov , S. , & Stevens , R. ( 2007 ) . Like more , look more . Look more , like more : The evidence from eye-tracking . Journal of Brand management , 14 ( A4 ) , 335-342 . Marquart , F. , Matthes , J. , & Rapp , E. ( 2016 ) . Selective exposure in the context of political advertising : A behavioral approach using — eye-tracking methodology . International Journal of Communication , 10 , 20 . Mercier , H. , Dezecache , G. , & Scott-Phillips , T. ( 2017 ) . Strategically Communicating Minds . Current Directions in Psychological Science , 26 ( 5 ) , 411- 416 . Mercier , H. ( 2020 ) . Not born yesterday : The science of who we trust and what we believe . Princeton University Press . Messing , S. , & Westwood , S. J . ( 2014 ) . Selective exposure in the age of social media : Endorsements trump partisan source affiliation when selecting news online . Communication — research , 41 ( 8 ) , 1042-1063 . Miller , B. , & Record , I . ( 2013 ) . Justified belief in a digital age : On the epistemic implications of secret Internet technologies . Mills , C. M. ( 2013 ) . Knowing when to doubt : Developing a critical stance when learning from others . Developmental psychology , 49 ( 3 ) , 404 . Mitchell , A. , Gottfried , J. , Kiley , J. , & Matsa , K. E. ( 2014 ) . Political Polarization & Media Habits : From Fox News to Facebook . How Liberals and Conservatives Keep Up with Politics , Washington , DC : Pew Research Center . Mulckhuyse , M. , van Zoest , W. , & Theeuwes , J . ( 2008 ) . Capture of the eyes by relevant and irrelevant onsets . Experimental Brain Research , 186 ( 2 ) , 225- 235 . Mullen , B. , Brown , R. , & Smith , C. ( 1992 ) . Ingroup bias as a function of salience , relevance , and status : An integration . European journal of social psychology , 22 ( 2 ) , 103-122 . Munger , K. , Luca , M. , Nagler , J. , & Tucker , J . ( 2020 ) . The ( null ) effects of clickbait headlines on polarization , trust , and learning . Public opinion quarterly . Mutz , D. C. , & Martin , P. S. ( 2001 ) . Facilitating communication across lines of political difference : The role of mass media . American political science review , 97-114 . Navalpakkam , V. , & Itti , L. ( 2005 ) . Modeling the influence of task on attention . Vision research , 45 ( 2 ) , 205-231 . Nickerson , R. S. ( 1998 ) . Confirmation bias : A ubiquitous phenomenon in many guises . Review of general psychology , 2 ( 2 ) , 175-220 . Nielsen , J. , & Pernice , K. ( 2010 ) . Eyetracking web usability . New Riders . O'Connor , C. , & Weatherall , J. O . ( 2019 ) . The misinformation age : How false beliefs spread . Yale University Press . Olsson , E. J . ( 2011 ) . A simulation approach to veritistic social epistemology . Episteme- Edinburgh , 8 ( 2 ) , 127 . Olsson , E. J. , & Vallinder , A . ( 2013 ) . Norms of assertion and communication in _ social networks . Synthese , 190 ( 13 ) , 2557-2571 . Pan , B. , Hembrooke , H. , Joachims , T. , Lorigo , L. , Gay , G. , & Granka , L. ( 2007 ) . In Google we trust : Users ’ decisions on rank , position , and relevance . Journal of computer-mediated communication , 12 ( 3 ) , 801- 823 . Papoutsaki , A. , Laskey , J. , & Huang , J . ( 2017 , March ) . Searchgazer : Webcam eye tracking for remote studies of web search . In Proceedings of the 2017 Conference on Conference Human Information Interaction and Retrieval ( pp . 17-26 ) . Pariser , E. ( 2011 ) . The Filter Bubble : What the Internet 1s Hiding from You . Penguin Press . Parmelee , J. H. , & Roman , N. ( 2020 ) . Insta-echoes : Selective exposure and selective avoidance on Instagram . Telematics and Informatics , 52 , 101432 . Pamamets , P. , Johansson , P. , Hall , L. , Balkenius , C. , Spivey , M. J. , & Richardson , D. C. ( 2015 ) . Biasing moral decisions by exploiting the dynamics of eye gaze . Proceedings of the National Academy of Sciences , 112 ( 13 ) , 4170-4175 . Pau , G. , Fuchs , F. , Sklyar , O. , Boutros , M. , & Huber , W. ( 2010 ) . EBImage—an R package for image processing with applications to cellular phenotypes . Bioinformatics , 26 ( 7 ) , 979-981 . 16 Peacock , C. E. , Hayes , T. R. , & Henderson , J. M. ( 2019 ) . Meaning guides attention during scene viewing , even when it is irrelevant . Affention , Perception , & Psychophysics , 81 ( 1 ) , 20-34 . Petrescu , P. ( 2014 , October 1 ) . Google Organic Click- Through Rates in 2014 . MOZ Blog . https : //moz.com/blog/google-organic-click- through-rates-in-2014 . Petty , R. E. , & Cacioppo , J. T. ( 1984 ) . Source factors and the elaboration likelihood model of persuasion . ACR North American Advances . Petty , R. E. , & Cacioppo , J. T. ( 1986 ) . The elaboration likelihood model of persuasion . In Communication and persuasion ( pp . 1-24 ) . Springer , New York , NY . Purcell , K. , Rainie , L. , & Brenner , J . ( 2012 , March 9 ) . Search engine use , 2012 . Pew Internet and American Life Project , 9 . Retrieved from http : //pewinternet.org/Reports/2012/Search- Engine-Use-2012.aspx Rand , D. G. , Pfeiffer , T. , Dreber , A. , Sheketoff , R. W. , Wernerfelt , N. C. & Benkler , Y . Dynamic remodeling of in-group bias during the 2008 presidential election . Proc . Natl . Acad . Sci . USA 106 , 6187-6191 ( 2009 ) . Rayner , K. ( 1998 ) . Eye movements in reading and information _ processing : 20 ~years ” =s of research . Psychological bulletin , 124 ( 3 ) , 372 . Rayson , S. ( 2018 ) . Content , shares , and links : Insights from analyzing 1| million articles . moz . com , 8 . Salmerén , L. , Kammerer , Y. , & Garcia-Carrién , P. ( 2013 ) . Searching the Web for conflicting topics : Page and user factors . Computers in Human Behavior , 29 ( 6 ) , 2161-2171 . Schmuck , D. , Tribastone , M. , Matthes , J. , Marquart , F. , & Bergel , E. M. ( 2019 ) . Avoiding the other side ? An eye-tracking study of selective exposure and selective avoidance effects in response to political advertising . Journal of Media Psychology : Theories , Methods , and Applications . Schultheif , S. , Siinkler , S. , & Lewandowski , D. ( 2018 ) . We still trust in Google , but less than 10 years ago : an eye-tracking study . Information Research : An International Electronic Journal , 23 ( 3 ) , n3 . Sears , D. O. , & Freedman , J. L. ( 1967 ) . Selective exposure to information : A critical review . Public Opinion Quarterly , 31 ( 2 ) , 194-213 . Semmelmann , K. , & Weigelt , S. ( 2018 ) . Online webcam-based eye tracking in cognitive science : A first look . Behavior Research Methods , 50 ( 2 ) , 451- 465 . Settle , J. E. ( 2018 ) . Frenemies : How social media polarizes America . Cambridge University Press . Shimojo , S. , Simion , C. , Shimojo , E. , & Scheier , C. ( 2003 ) . Gaze bias both reflects and influences preference . Nature neuroscience , 6 ( 12 ) , 1317- 1322 Simion , C. , & Shimojo , S. ( 2006 ) . Early interactions between orienting , visual sampling and decision making in facial preference . Vision research , 46 ( 20 ) , 3331-3335 . Simion , C. , & Shimojo , S. ( 2007 ) . Interrupting the cascade : Orienting contributes to decision making even in the absence of visual stimulation . Perception & psychophysics , 694 ) , 591-595 . Spohr , D. ( 2017 ) . Fake news and _ ideological polarization : Filter bubbles and selective exposure on social media . Business Information Review , 34 ( 3 ) , 150-160 . Staub , A . ( 2015 ) . The effect of lexical predictability on eye movements in reading : Critical review and theoretical interpretation . Language and Linguistics Compass , 98 ) , 311-327 . Stinchcombe , A. L. ( 2010 ) . Going to extremes : How like minds unite and divide . Contemporary Sociology : A Journal of Reviews , 39 , 205-206 . Strukelj , A . ( 2018 ) . Reading expectations : How expectations influence our reading , eye movements , opinions , and judgments . Lund University . Strukelj , A. , & Niehorster , D. C. ( 2018 ) . One page of text : Eye movements during regular and thorough reading , skimming , and spell checking . Journal of Eye Movement Research , 11 ( 1 ) . Strukelj , A. , Nystrém , M. , & Holmqvist , K. ( 2017 ) . The effects of conceptual and perceptual difficulty on processing and engagement in text during reading and learning . In /9¢h European Conference on Eye Movements . Silflow , M. , Schafer , S. , & Winter , S. ( 2019 ) . Selective attention in the news feed : An eye- tracking study on the perception and selection of political news posts on Facebook . new media & society , 21 ( 1 ) , 168-190 . Sunstein , C. R. ( 1999 ) . The law of group polarization . University of Chicago Law School , John M. Olin Law & Economics Working Paper , ( 91 ) . Tajfel , H. , & Turner , J. C. ( 1986 ) . The social identity theory of intergroup behavior . In S. Worchel & W. G. Austin ( Eds . ) , Psychology of intergroup relations ( 2nd ed. , pp . 7-24 ) . Nelson-Hall . Valentino , N. A. , Banks , A. J. , Hutchings , V. L. , & Davis , A. K. ( 2009 ) . Selective exposure in the Internet age : The interaction between anxiety and information utility . Political Psychology , 30 ( 4 ) , 591-613 . V6 , M. L. H. , & Henderson , J. M. ( 2009 ) . Does gravity matter ? Effects of semantic and syntactic inconsistencies on the allocation of attention during scene perception . Journal of Vision , 9 ( 3 ) , 24-24 . Vraga , E. , Bode , L. , & Troller-Renfree , S. ( 2016 ) . Beyond self-reports : Using eye tracking to measure topic and style differences in attention to social media content . Communication Methods and Measures , 10 ( 2-3 ) , 149-164 . Weeks , B. E. , Lane , D. S. , Kim , D. H. , Lee , S. S. , & Kwak , N. ( 2017 ) . Incidental exposure , selective exposure , and political information sharing : 17 Integrating online exposure patterns and expression on social media . Journal of Computer-Mediated Communication , 22 ( 6 ) , 363-379 . Westen , D. , Blagov , P. S. , Harenski , K. , Kilts , C. , & Hamann , S. ( 2006 ) . Neural bases of motivated reasoning : An fMRI study of emotional constraints on partisan political judgment in the 2004 US presidential election . Journal of cognitive neuroscience , 18 ( 11 ) , 1947-1958 . Xiao , Y. J. , Coppin , G. , & Van Bavel , J. J . ( 2016 ) . Perceiving the world through group-colored glasses : A perceptual model of intergroup relations . Psychological Inquiry , 27 ( 4 ) , 255-274 . Wikforss , A . ( 2017 ) . Alternativa fakta : Om kunskapen och dess fiender . Falun : Fri Tanke Forlag . World Values Survey . ( 2021 , April 24 ) . Findings and Insights https : //www.worldvaluessurvey.org/W VSContents Jjsp ? CMSID=findings & CMSID=findings Yom-Tov , E. , Dumais , S. , & Guo , Q . ( 2014 ) . Promoting civil discourse through search engine diversity . Social Science Computer Review , 32 ( 2 ) , 145-154 . Zillich , A. F. , Kessler , S. H. , Peter , C. , Naab , T. , & Kine , R. ( 2019 ) . Measuring selective exposure to online information : combining eye-tracking and content analysis of users ’ actual search behavior . Methoden und Forschungslogik der Kommunikationswissenschaft , ( 14 ) , 196-220 Zuiderveen Borgesius , F. , Trilling , D. , Moller , J. , Bodo , B. , De Vreese , C. H. , & Helberger , N. ( 2016 ) . Should we worry about filter bubbles ? . Jnternet Policy Review . Journal on Internet Regulation , 5 . 18 This article has been accepted for publication in 15th ACM Conference on Recommender Systems . Association for Computing Machinery . Citation information : https : //doi.org/10.1145/3460231.3474241 An Audit of Misinformation Filter Bubbles on YouTube : Bubble Bursting and Recent Behavior Changes MATUS TOMLEIN , Kempelen Institute of Intelligent Technologies , Slovakia BRANISLAV PECHER , Kempelen Institute of Intelligent Technologies , Slovakia JAKUB SIMKO , Kempelen Institute of Intelligent Technologies , Slovakia IVAN SRBA , Kempelen Institute of Intelligent Technologies , Slovakia ROBERT MORO , Kempelen Institute of Intelligent Technologies , Slovakia ELENA STEFANCOVA , Kempelen Institute of Intelligent Technologies , Slovakia MICHAL KOMPAN , Kempelen Institute of Intelligent Technologies , Slovakia ANDREA HRCKOVA , Kempelen Institute of Intelligent Technologies , Slovakia JURAJ PODROUZEK , Kempelen Institute of Intelligent Technologies , Slovakia MARIA BIELI KOVAT , Kempelen Institute of Intelligent Technologies , Slovakia The negative effects of misinformation filter bubbles in adaptive systems have been known to researchers for some time . Several studies investigated , most prominently on YouTube , how fast a user can get into a misinformation filter bubble simply by selecting “ wrong choices ” from the items offered . Yet , no studies so far have investigated what it takes to “ burst the bubble ” , ie. , revert the bubble enclosure . We present a study in which pre-programmed agents ( acting as YouTube users ) delve into misinformation filter bubbles by watching misinformation promoting content ( for various topics ) . Then , by watching misinformation debunking content , the agents try to burst the bubbles and reach more balanced recommendation mixes . We recorded the search results and recommendations , which the agents encountered , and analyzed them for the presence of misinformation . Our key finding is that bursting of a filter bubble is possible , albeit it manifests differently from topic to topic . Moreover , we observe that filter bubbles do not truly appear in some situations . We also draw a direct comparison with a previous study . Sadly , we did not find much improvements in misinformation occurrences , despite recent pledges by YouTube . CCS Concepts : - Information systems — Personalization ; Content ranking ; - Human-centered computing — Human computer interaction ( HCI ) . Additional Key Words and Phrases : audit , filter bubble , misinformation , personalization , ethics , youtube ACM Reference Format : 2203.13769v1 [ cs.IR ] 25 Mar 2022 Matus Tomlein , Branislav Pecher , Jakub Simko , Ivan Srba , Robert Moro , Elena Stefancova , Michal Kompan , Andrea Hrckova , Juraj Podrouzek , and Maria Bielikova . 2021 . An Audit of Misinformation Filter Bubbles on YouTube : Bubble Bursting and Recent Behavior Changes . In Fifteenth ACM Conference on Recommender Systems ( RecSys '21 ) , September 27-October 1 , 2021 , Amsterdam , Netherlands . ACM , New York , NY , USA , 16 pages . https : //doi.org/10.1145/3460231.3474241 arXiv “ Also with slovak.AI . t Also with slovak.AI . Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . Copyrights for components of this work owned by others than the author ( s ) must be honored . Abstracting with credit is permitted . To copy otherwise , or republish , to post on servers or to redistribute to lists , requires prior specific permission and/or a fee . Request permissions from permissions @ acm.org . © 2021 Copyright held by the owner/author ( s ) . Publication rights licensed to ACM . Manuscript submitted to ACM This article has been accepted for publication in 15th ACM Conference on Recommender Systems . Association for Computing Machinery . Citation information : https : //doi.org/10.1145/3460231.3474241 RecSys ’ 21 , September 27-October 1 , 2021 , Amsterdam , Netherlands Tomlein , et al . 1 INTRODUCTION In this paper , we investigate the misinformation filter bubble creation and bursting on YouTube . In our auditing study we simulate user behavior on the YouTube platform , record platform responses ( e.g. , search results , recommendations ) and manually annotate them for the presence of misinformative content . Then , we quantify the dynamics of misinformation filter bubble creation and also dynamics of bubble bursting , which is the novel aspect of the study . With this paper , we publish the implementation of the experimental infrastructure and also the data we collected ! . Our study adds to the previous works [ 1 , 8 , 14 , 17 , 23 ] that used audits to quantify the portion of misinformative content being recommended on social media platforms . We directly build on works [ 8 , 14 , 23 ] that observed and quantified the creation of misinformative filter bubbles on YouTube . The general motivation of our work is to emphasize the need for independent oversight of personalization behavior of large platforms . In the past , platforms have been accused of being contributors to the misinformation spreading due to their personalization routines . Simultaneously , they have been reluctant to revise these routines [ 27 , 33 ] . And when they promise some changes , there is a lack of effective public oversight that could quantitatively evaluate their fulfillment . Auditing studies are tools that may improve such oversight . While previous works investigated how a user can enter a filter bubble , no audits have covered if } how or with what “ effort ” can the user “ burst ” ( exit or lessen ) the bubble . Multiple studies demonstrated that watching a series of misinformative videos would strengthen the further presence of such content in recommendations [ 1 , 8 , 14 ] , or that following a path of the “ up next ” videos can bring the user to a very dubious content [ 23 ] . However , no studies investigated what type of user ’ s watching behavior ( e.g. , switching to credible news videos or conspiracy debunking videos ) would be needed to lessen the amount of misinformative content recommended to the user . Such knowledge would indeed be valuable . Not just for the sake of knowledge about the inner workings of YouTube ’ s personalization , but also to improve the social , educational , or psychological strategies for building up resilience against misinformation . As the first contribution , this paper reports on the behavior of YouTube 's personalization in a situation when a user with misinformation promoting watch history ( i.e , with a developed misinformation filter bubble ) starts to watch content debunking the misinformation ( in an attempt to burst that misinformation filter bubble ) . The key finding is that watching misinformation debunking videos ( e.g. , credible news , scientific content ) generally improves the situation ( in terms of recommended items or search result personalization ) , albeit with varying effects and forms , mainly depending on particular misinformation topic . We aligned our methodology with previous works , most notably with the work of Hussein et al . [ 8 ] who also investigated the creation of misinformation filter bubbles using user simulation . As part of our study , we replicated parts of Hussein ’ s study . We have done this for the sake of replication and to bootstrap bots with history of watching misinformation promoting videos . We re-used maximum of Hussein ’ s seed data ( topics , queries , videos ) , used similar scenarios and the same data annotation scheme . Therefore , we were able to directly compare the outcomes of both studies ( e.g. , on the number of observed misinformative videos present in recommendations or search results ) . Due to recent changes in YouTube policies [ 28 ] , we expected to see less filter bubble creation behavior than Hussein et al . However , this was generally not the case . As the second contribution , we report changes in misinformation video occurrences on YouTube , which took place since the study of Hussein et al . [ 8 ] ( mid 2019 ) . We observe worse situation regarding the topics of 1 Available at https : //github.com/kinit-sk/yaudit-recsys- 2021 This article has been accepted for publication in 15th ACM Conference on Recommender Systems . Association for Computing Machinery . Citation information : https : //doi.org/10.1145/3460231.3474241 An Audit of Misinformation Filter Bubbles on YouTube RecSys ’ 21 , September 27-October 1 , 2021 , Amsterdam , Netherlands vaccination and ( partially ) 9/11 conspiracies and some improvements ( less misinformation ) for moon landing or chemtrails conspiracies . 2 BACKGROUND : FILTER BUBBLES AND MISINFORMATION To some extent , intellectual isolation is a natural human defense against information overload [ 13 ] and provides us with stronger inner confidence [ 6 ] . However , it also comprises negative effects such as selective exposure ( focusing on information that is in accordance with one ’ s worldview ) or confirmation bias [ 5 , 11 ] . In social media , intellectual isolation contributes to the creation of echo chambers [ 3 ] : the same ideas are repeated , mutually confirmed and amplified in relatively closed homogeneous groups . Polarization and fragmentation of the society increases [ 25 , 32 ] . The negative effects of echo chambers can be amplified by filter bubbles . Filter bubbles ( as states of intellectual isolation ) were firstly recognized by Pariser [ 15 ] as a negative consequence of personalization in social media and search engines . Researchers [ 15 , 25 ] agree that algorithms of such platforms support cognitive bias , as users are presented with the content that complies with their hitherto attitudes . Besides that , this effect also has ethical implications . Users are often unaware of the existence of filter bubbles , as well as of the information that was filtered out . Moreover , personalization and recommendation tailored to the users ’ interests can escalate the problems with misinformation [ 23 ] . Misinformation is a false or inaccurate information that is spread regardless of an intention to deceive . Due to significant negative consequences of misinformation on our society ( especially during the ongoing COVID-19 pandemic ) , tackling misinformation attracted a plethora of research efforts ( see [ 29 , 31 ] for recent surveys ) . While the majority of such research focuses on various characterization studies [ 21 ] or detection methods [ 16 , 24 ] , the studies investigating the relation between misinformation and adaptive systems are still relatively rare ( e.g. , [ 8 , 14 ] ) . We denote filter bubbles that are characterized by the presence of misinformative content as misinformation filter bubbles . They are states of intellectual isolation in false beliefs or a manipulated perceptions of reality . Analogically to topical filter bubbles , misinformation filter bubbles can be characterized by a high homogeneity of recommenda- tions/search results that share the same positive stance towards misinformation . In other words , the content adaptively presented to a user in a misinformation filter bubble supports one or several false claims/narratives . The proportion of such content represents how deep inside the bubble the user is . To prevent misinformation and misinformation filter bubbles , social media conduct various countermeasures . These are usually reactions to public outcry or are required by legislation , e.g. , EU ’ s Code of practice on disinformation ” . Currently , the effectiveness of such countermeasures is evaluated mainly by self-evaluated reports . However , such reports are difficult to verify since social media are reluctant to provide access to their data for independent research . The verification of countermeasures is further complicated by interference of psychological factors . For example , some researchers argue that cognitive bias is more influential than algorithms when it comes to intellectual isolation [ 2 , 5 ] . To separate these influences , researchers employ platform audits , such as the one in this paper . 3 RELATED WORK : AUDITS OF ADAPTIVE SYSTEMS In this context , an audit is a systematic statistical probing of an online platform , used to uncover socially problematic behavior underlying its algorithms [ 8 , 19 ] . Audits come in multiple forms [ 19 ] and two of them are also suitable to investigate the effect of ( misinformation ) filter bubbles : crowdsourcing audits and sockpuppeting audits . “ https : //digital-strategy.ec.europa.eu/en/policies/code-practice- disinformation 3 This article has been accepted for publication in 15th ACM Conference on Recommender Systems . Association for Computing Machinery . Citation information : https : //doi.org/10.1145/3460231.3474241 RecSys ’ 21 , September 27-October 1 , 2021 , Amsterdam , Netherlands Tomlein , et al . Crowdsourcing audit studies are conducted using real user data . Silva et al . [ 20 ] developed a browser extension to collect personalized ads with real users on Facebook . Hannak et al . [ 7 ] recruited Mechanical Turk users to run search queries and collected their personalized results . However , such auditing methodology suffers from a lack of isolation ( users may be influenced by additional factors , e.g . confirmation bias ) . Moreover , uncontrolled environment makes comparisons difficult or unfeasible ; it is difficult to keep users active ; audits also raise several privacy issues . Sockpuppeting audits solve these problems by employing non-human bots that impersonate the behavior of users in a predefined controlled way [ 19 ] . To achieve representative and meaningful results in sockpuppeting audits , researchers need to tackle several methodological challenges [ 8 ] . First is the selection of appropriate seed data ( e.g. , the initial activity of bots , search queries ) . Second , the experimental setup must measure the real influence of the investigated phenomena . At the same time , it must minimize confounding factors and noise ( e.g. , of name , gender or geolocation [ 7 ] ) . Another challenge is how to appropriately label the presence of the audited phenomena ( expert-based/crowdsourced [ 8 , 20 ] or automatic labeling [ 14 ] can be employed ) . Audits can be further distinguished by the social media they are applied on ( e.g. , social networking sites [ 8 , 14 , 20 ] , search engines [ 10 , 12 , 18 ] , e-commerce sites [ 9 ] ) , by adaptive systems being investigated ( e.g. , recommendations [ 8 , 14 , 23 ] , up-next recommendation [ 8 ] , search results [ 8 , 10 , 12 , 14 , 18 ] , autocomplete [ 18 ] ) and by phenomena being studied ( e.g. , misinformation [ 8 , 14 ] , political bias [ 10 , 12 ] , political ads [ 20 ] ) . In our study , we focus specifically on misinformation filter bubbles in the context of the online video platform YouTube and its recommender and search system . As argued by Spinelli et al . [ 23 ] , YouTube is an important case to study as a significant source of socially- generated content and because of its opaque recommendation policies . Some information about the inner workings of YouTube adaptive systems are provided by research papers published at RecSys conference [ 4 , 30 ] or blogs [ 28 ] published directly by the platform , nevertheless , a detailed information is unknown . Therefore , we feel a need to conduct independent auditing studies on undesired phenomena like unintended creation of misinformation filter bubbles . The existing studies confirmed the effects of filter bubbles in YouTube recommendations and search results . Spinelli et al . [ 23 ] found that chains of recommendations lead away from reliable sources and toward extreme and unscientific viewpoints . Similarly , Ribeiro et al . [ 17 ] concluded that YouTube ’ s recommendation contributes to further radicalization of users and found paths from large media channels to extreme content through recommendation . Abul-Fottouh et al . [ 1 ] confirmed a homophily effect in which anti-vaccine videos were more likely to recommend other anti-vaccine videos than pro-vaccine ones and vice versa . Recently , we can observe first audits focused specifically on misinformation filter bubbles . Hussein et al . [ 8 ] and Papadomou et al . [ 14 ] found that YouTube mitigates pseudoscientific content in some handpicked topics such as COVID-19 . Hussein et al . [ 8 ] found that demographics and geolocation ( within the US ) affect personalization only after having acquired some watch history . These studies provide evidence of the existence and properties of misinformation filter bubbles on YouTube . From the properties that remain uninvestigated , we specifically address two . Firstly , the adaptive systems used by YouTube are in continuous development and improvement . Information on how YouTube proceeds in countering misinformation is needed . Secondly , while the existing studies focused on misinformation filter bubble creation , we do not have the same perspective on the inverse process — filter bubble bursting . 4 STUDY DESIGN AND METHODOLOGY To investigate the dynamics of bursting out of a misinformation filter bubble , we conducted an agent-based sockpuppet- ing audit study . The study took place on YouTube , but its methodology and implementation can be generalized to any adaptive service , where recommendations can be user-observed . 4 This article has been accepted for publication in 15th ACM Conference on Recommender Systems . Association for Computing Machinery . Citation information : https : //doi.org/10.1145/3460231.3474241 An Audit of Misinformation Filter Bubbles on YouTube RecSys ’ 21 , September 27-October 1 , 2021 , Amsterdam , Netherlands In the study , we let a series of agents ( bots ) pose as YouTube users . The agents performed pre-defined sequences of video watches and query searches . They also recorded items they saw : recommended videos and search results . The pre-defined actions were designed to first invoke the misinformation filter bubble effect by purposefully watching videos with ( or leaning towards ) misinformative content . Then , agents tried to mitigate the bubble effect by watching videos with trustworthy ( misinformation debunking ) content . Between their actions , the agents were idle for some time to prevent possible carry-over effects . The degree of how deep inside a bubble the agent is was observed through the number and rank of misinformative videos offered to them . The secondary outcome is the partial replication of a previous study done by Hussein et al . [ 8 ] ( denoted onwards as the reference study ) . This replication allowed us to draw direct comparisons between quantities of misinformative content that agents encountered now ( March 2021 ) and during the reference study done in mid 2019 . 4.1 Research Questions , Hypotheses and Metrics RQ1 ( comparison to the reference study ) : Has YouTube 's personalization behavior changed with regards to misinfor- mative videos since the reference study ? In particular , we seek to validate the following hypothesis : e H1.1 : Compared on SERP-MS and normalized score metrics ( see below ) , we would see better scores ( after constructing a promoting watch history ) than in the reference study in both search and recommendations ( given YouTube ’ s pledges [ 28 ] ) . RQ2 ( bubble bursting dynamics ) : How does the effect of misinformation filter bubbles change , when debunking videos are watched ? The “ means of bubble bursting ” would be implicit user feedback - watching misinformation debunking videos . In particular , we seek to validate the following hypotheses : e H2.0 : Watching videos belonging to promoting misinformation stance leads to their increased presence in both search results and recommendations ( worse SERP-MS and normalized score metrics ) . e H2.1 : Watching the sequence of misinformation debunking videos after the sequence of misinformation promot- ing videos will improve the metrics in comparison to the end of the promoting sequence . e H2.2 : Watching the sequence of misinformation debunking videos after the sequence of misinformation promot- ing videos will improve the metrics in comparison to the start of the experiment . The metrics we use - SERP-MS and normalized score - are drawn directly from the reference study . Both metrics quantify misinformation prevalence in a given list of items ( videos ) , which are annotated as either promoting ( value 1 ) , debunking ( value -1 ) or neutral ( value 0 ) . The output of both metrics is , similarly , from the ( -1 , 1 ) interval . Lists populated mostly with debunking content would receive values close to -1 , with promoting close to 1 and with balanced or mostly neutral , close to 0 . In other words , a score closer to -1 means better score . Normalized score . A metric computed as average of individual annotations of items present in the list . It is suited for unordered , shorter lists ( in our case , recommendations ) . SERP-MS ( Search result page misinformation score ) . A metric capturing amount of misinformation and its rank . It is suited for longer , ordered lists ( in our case , search results ) . Itis computed as SERP-MS = Dyer Gietn rH ) sai 5 where x ; is annotation value , r search result rank and n number of search results in the list [ 8 ] . 4.2 Experiments scenarios We let agents interact with YouTube following a scenario composed of four phases , as depicted in Figure 1 . 5 This article has been accepted for publication in 15th ACM Conference on Recommender Systems . Association for Computing Machinery . Citation information : https : //doi.org/10.1145/3460231.3474241 RecSys ’ 21 , September 27-October 1 , 2021 , Amsterdam , Netherlands Tomlein , et al . Fetch 40 promoting ‘ Open Google Fetch configuration Fetch 5 queries Login to youtube Visit homepage Execute eo bh ) and 40 debunking > | chrome in incognito Lm > ) > and topic videos from topic from topic with adblock ercbled and accept cookies and save results Search phase ® Execute ® Execute @ ox Clear history ME Watch phase with WE Watch phase with debunking videos promoting videos Watch 3 phase Randomly select @ Watch video for Save Visit homepage Execute video from the list of - > — } > 30 minutes Pi recommendations | ] and save results T Search phase remaining videos > @ Already watched 2 videos since last Search phase No videos remaining in the list of videos ath Search hase - Randomly select Search for videos Save query from the list of +o ea | bt ) ait 20 minutes remaining queries using the query search results » No queries remaining in the list of queries mr Fig . 1 . Agent scenario for creating and bursting misinformation filter bubbles Phase 0 : Agent initialization . At the start of a run , the agent fetches its desired configuration , including the YouTube user account and various controlled variables ( the variable values are explained further below ) . Also , the agent fetches t € T , a topic with which it will work ( e.g. , “ 9/11 ” ) . The agent fetches Vprom and Vgep , which are lists of nprom = 40 and ngep = 40 most popular videos promoting , respectively debunking , misinformation within topic r. Afterward , it fetches Q , a set of ng = 5 search queries related to the particular r ( e.g. , “ 9/11 conspiracy “ ) . The agent configures and opens a browser in incognito mode , visits YouTube , logs in using the given user account , and accepts cookies . Finally , the agent creates a neutral baseline by visiting the homepage and saving videos , and performing a search phase . In the search phase , the agent randomly iterates through search queries in Q , executes each query on YouTube , and saves the search results . To prevent any carry-over effect between search queries , the agent waits for twair = 20 minutes after each query . Phase 1 ( promoting ) : Create the filter bubble . For creating a filter bubble effect , the agent randomly iterates through Vprom and “ watches ” each video for tyatch = 30 minutes ( or less , if the video is shorter ) . Immediately after watching a video , the agent saves video recommendations on that video ’ s page and visits the YouTube homepage , saving video recommendations listed there as well . After every f , = 2 videos , the agent performs another search phase . Phase 2 ( debunking ) : Burst the filter bubble . The agent follows the same steps as in phase 2 . The only difference is the use of Viep instead of Vprom- Phase 3 : Tear-down . In this phase , the agent clears YouTube history ( using Google ’ s “ my activity “ section ) , making the used user account ready for the next run . For each selected topic , we run the scenario 10 times ( in parallel ) . This way , we were able to deal with recommendation noise present at the platform . In order to run our experiments multiple times , we used the reset ( delete all history ) button provided by Google instead of creating a new user profile for each run . Before deciding to use the reset button in our study , we first performed a short verification study to see whether using this button really deletes the whole history and resets the personalization on YouTube . We randomly selected few topics , from which we manually watched few videos ( 5 for each ) . Then , we used the reset button and evaluated the difference between videos appearing on the YouTube homepage , recommendations , and search . We found no carry-over effects . We needed to set up several attributes of agents ( e.g. , YouTube user profiles ) . For geolocation , we use N. Virginia to allow for better comparison with the reference study . The date of birth for all accounts was arbitrarily set to 6.6.1990 to represent a person roughly 30 years old . The gender was set as “ rather not say ” to prevent any personalization based on 6 This article has been accepted for publication in 15th ACM Conference on Recommender Systems . Association for Computing Machinery . Citation information : https : //doi.org/10.1145/3460231.3474241 An Audit of Misinformation Filter Bubbles on YouTube RecSys ’ 21 , September 27-October 1 , 2021 , Amsterdam , Netherlands gender . The names chosen for the accounts were composed randomly of the most common surnames and unisex given names used in the US . There were also process parameters that we needed to keep constant . These include 1 ) nprom = 40 and ngep = 40 representing the number of seed videos used in promoting and debunking phases ; 2 ) tyarch = 30 representing the maximum watching time in minutes for every video ; 3 ) ng = 5 representing the number of queries used ; 4 ) twair = 20 representing the wait time in minutes between query yields and 5 ) fj = 2 representing the number of videos to watch between search phases . Values of the process parameters greatly influence the total running time and results of the experiment . Yet , de- termining them was not straightforward given many unknown properties of the environment ( first and foremost YouTube ’ s algorithms ) . For example , prior to the experiment , it was unclear how often we need to probe for changes in recommendations and search result personalizations to answer our research questions . Therefore , we run a pre-study in which we determined the best parameter setup . Measuring the Levenshtein distance between ordered results and overlap of lists of recommended videos we determined to run 10 individual agents for each topic , as we observed instability between repeated runs ( e.g. , the same configuration yielded ~ 70 % of the same recommended videos ) . For the nprom and ngep parameters , we observed that in some cases , a filter bubble could be detected after 20 watched videos . Yet in others , it was 30 or more . Due to this inconsistency , we opted to watch 40 videos for a phase . To determine the optimal value of twareh , we first calculated the average running time of our seed videos . Most of the videos ( ~ 85 % ) had a running time of about 30 minutes or shorter , so 30 minutes became the baseline value . In addition , we compared the results obtained by watching only 30 minutes with results from watching the whole video regardless of its length , but found no apparent differences . To determine the number of queries ng and periodicity of searches fj , we ran the scenario with all seed queries introduced by the reference study and used them after every seed video . We observed that the difference in search results between successive seed videos was not significant . As the choice of search queries and the frequency of their use greatly prolonged the overall running time of the agents , we opted to run the search phase after every second video . In addition , we opted to use only 5 queries per topic . The only parameter not set by a pre-study is fwair , which we set to 20 minutes based on previous studies . These found that the carry-over effect ( which we wanted to avoid ) is visible for 11 minutes after the search [ 7 , 8 ] . 4.3 . Seed Data We used 5 topics in our study ( same as the reference study ) : 1 ) 9/11 conspiracies claiming that authorities either knew about ( or orchestrated ) the attack , or that the fall of the twin towers was a result of a controlled demolition , 2 ) moon landing conspiracies claiming the landing was staged by NASA and in reality did not happen , 3 ) chemirails conspiracy claiming that the trails behind aircraft are purposefully composed of dangerous chemicals , 4 ) flat earth conspiracy claiming that we are being lied to about the spherical nature of Earth and 5 ) vaccines conspiracy claiming that vaccines are harmful , causing various range of diseases , such as autism . The narratives associated with the topics are popular ( persistently discussed ) , while at the same time , demonstrably false , as determined by the reference study [ 8 ] . For each topic , the experiment required two sets of seed videos . The promoting set , used to construct a misinformation filter bubble ( its videos have a promoting stance towards the conspiratorial narrative or present misinformation ) . And the debunking set , aimed to burst the bubble ( and contains videos disproving the conspiratorial narratives ) . As a basis for our seed data sets we used data already published in the reference study , which the authors either used as seed data , or collected and annotated . To make sure we use adequate seed data , we re-annotated all of them . 7 This article has been accepted for publication in 15th ACM Conference on Recommender Systems . Association for Computing Machinery . Citation information : https : //doi.org/10.1145/3460231.3474241 RecSys ’ 21 , September 27-October 1 , 2021 , Amsterdam , Netherlands Tomlein , et al . The number of seed videos collected this way was insufficient for some topics ( we required twice as many seed videos as the reference study ) . To collect more , we used an extended version of the seed video identification methodology of the reference study . Following is the list of approaches we used ( in a descending order of priority ) : YouTube search , other search engines ( Google search , Bing video search , Yahoo video search ) , YouTube channel references , recommendations , YouTube homepage , and known misinformation websites . To minimize any biases , we used a maximum of 3 videos from the same channel . As for search queries , we required fewer of them than the reference study . We selected a subset based on their popularity on YouTube . Some examples of the used queries are : `` 9/11 conspiracy '' , `` Chemtrails '' , “ flat earth proof '' , “ anti wo vaccination '' , “ moon landing fake '' . 44 Data collection and annotation Agents collect videos from three main components on YouTube : 1 ) recommendations appearing next to videos presently watched , 2 ) home page videos and 3 ) search results . In case of recommendations , we collect 20 videos that YouTube normally displays next to a currently watched video ( in rare cases , less than 20 videos are recommended ) . For home page videos and search results , we collect all videos appearing with the given resolution , but no less than 20 . In case when less than 20 videos appear , the agent scrolled further down on the page to load more videos . For each video encountered , the agent collects metadata : 1 ) YouTube video ID , 2 ) position of the video in the list , and 3 ) presence of a warning/clarification message that appears with problematic topics such as COVID-19 . Other metadata , such as video title , channel or description , are collected using the YouTube API . To annotate the collected videos for the presence of misinformation , we used an extended version of the methodology proposed in the reference study . Each video was viewed and annotated by the authors of this study using a code ranging from -1 to 10 . The videos are annotated as debunking ( code -1 ) , when their narrative provides arguments against the misinformation related to the particular topic ( such as `` The Side Effects of Vaccines - How High is the Risk ? `` ) , neutral ( code 0 ) when the narrative discusses the related misinformation but does not present a stance towards it ( such as `` Flat Earthers vs Scientists : Can We Trust Science ? | Middle Ground '' ) , and promoting ( code 1 ) , when the narrative promotes the related misinformation ( such as `` MIND BLOWING CONSPIRACY THEORIES '' ) . The codes 2 , 3 , and 4 have the same meaning as codes -1 , 0 , and 1 , but are used in cases when they discuss misinformation not related to the topic of the run ( e.g. , video dealing with climate crisis misinformation encountered during a flat earth audit ) . The code 5 is applied to videos that do not contain any misinformation views ( such as `` Gordon ’ s Guide To Bacon '' ) . This includes completely unrelated videos ( e.g. , music or reality show videos ) , but also videos that are related to the general audit topic , but not misinformation ( e.g. , original news coverage of 9/11 events ) . In rare cases of videos that are not in English and do not provide English subtitles , code 6 is assigned . Also rare are the cases when the narrative of the video can not be determined with enough confidence ( code 7 ) . Videos removed from YouTube ( before they are annotated ) are coded as 8 . Finally , as an extension of the approach used in the reference study , we use codes 9 and 10 to denote videos that specifically mention misinformation but rather than debunk them , they mock them ( 9 for related misinformation , 10 for unrelated misinformation , for example `` The Most Deluded Flat Earther in Existence ! '' ) . Mocking videos are a distinct ( and often popular ) category , which we wanted to investigate separately ( however , for the purposes of analysis , they are treated as debunking videos ) . To determine how many annotators are needed per video , we first re-annotated the seed videos released by the reference study . Each was annotated by at least two authors , and the annotations were compared between each other and with annotations from the reference study . We achieved Cohen ’ s kappa value of 0.815 between us and 0.688 with 8 This article has been accepted for publication in 15th ACM Conference on Recommender Systems . Association for Computing Machinery . Citation information : https : //doi.org/10.1145/3460231.3474241 An Audit of Misinformation Filter Bubbles on YouTube RecSys ’ 21 , September 27-October 1 , 2021 , Amsterdam , Netherlands the reference study . We identified characteristics of edge cases . Following the re-annotation and the findings from it , when annotating our collected videos , we assign only one annotator per collected video with instructions to indicate and comment if an edge case video is encountered . These were then reviewed by another annotator . For the purpose of this study and to evaluate our hypotheses , we annotated the following subset of collected videos : e All recorded search results . e Videos recommended for first 2 seed videos at the start of the run and last 2 seed videos of both phases ( resulting in 6 sets of annotated videos per topic ) . This selection was a compromise between representativeness , correspondence to the reference study , and our capacities . @ We have not annotated the home page videos for the purpose of this study . These videos were the most numerous , the most heterogeneous , and with little overlap across bots and seed videos . 4.5 Data ethics assessment To consider various ethical issues regarding the research of misinformative content , we carried out a series of data ethics workshops . We explored questions related to data ethics issues [ 26 ] within our audit and its impact on stakeholders . Based on the topics that emerged during the data ethics workshops , we identified different stakeholder groups . The most affected ones were platform users , annotators , content creators , and other researchers . For every stakeholder group , we devised different engagement strategies and specific action steps . Our main task was to devise countermeasures to the most prominent risks that could emerge for these stakeholder groups . First , we were concerned about the risk of unjustified flagging of the content as misinformation and their creators as conspirators . To minimize this risk , we decided to report hesitations in the annotation process . These hesitations were consequently back-checked by other annotators and independently validated until the consensus was reached . One of our main concerns was also not to harm or delude other users of the platform . To avoid disproportional boost of the misinformation content by our activity , we select the videos with at least 1000 views and warn annotators not to watch videos online more than one time , or in case of back-checks , two times . After each round , we reset user account and delete the watch history . Other concerns were connected to the deterioration of well-being of human annotators . Specifically , that their decision-making abilities would be negatively affected after a long annotation process . We proposed the daily routines for annotation , including the breaks during the process and advised to monitor any changes in annotators beliefs . Our annotators also underwent the survey on their tendency to believe in conspiracy theories ’ and none of them showed such tendency at the end of the study . 4.6 Anote on comparability with the reference study by Hussein et al . In order to be able to draw comparisons , we kept the methodology of our study as compatible as possible with the previous study by Hussein et al . [ 8 ] . We shared the general approach of prompting YouTube with implicit feedback : both studies used similar scenarios of watching a series of misinformation promoting videos and recording search results and recommended videos . We re-used the topics , a subset ( for scaling reasons ) of search queries , and all available seed videos ( complementing the rest by using a similar approach as the reference study ) . Moreover , both studies used the same coding scheme , metrics , sleep times , and annotated a similar number of videos . 3https : //openpsychometrics.org/tests/GCBS/ This article has been accepted for publication in 15th ACM Conference on Recommender Systems . Association for Computing Machinery . Citation information : https : //doi.org/10.1145/3460231.3474241 RecSys ’ 21 , September 27-October 1 , 2021 , Amsterdam , Netherlands Tomlein , et al . We should also note differences between the studies , which mainly source from different original motivations for our study . For instance , no significant effects of demographics and geolocation of the agents were found in the reference study , so we only controlled these . In Hussein ’ s experiments , all videos were first “ watched ” and only then all search queries were fired . In our study , we fired all queries after watching every 2nd video ( with the motivation to get data from the entire run , not just the start and end moment ) . The reference study created genuine 150 accounts on YouTube , while we used fewer accounts and took advantage of the browsing history reset option . In some aspects , our study had a larger scale : we executed 10 runs for each topic instead of one ( to reduce possible noise ) and used twice as many seed videos ( to make sure that filter bubbles develop ) . There were also technical differences between the setups , as we used our own implementation of agents ( e.g. , different browser , ad-blocking software ) . Given the methodological alignment ( and despite the differences ) , we are confident to directly compare some of the outcomes of both studies , namely quantity of misinformative content appearing at the end of the promoting phases . 5 RESULTS AND FINDINGS Following the study design , we executed the study between March 2nd and March 31st , 2021 . Together , we executed 50 bot runs ( 10 for each topic ) . On average , runs for a single topic took 5 days ( bots for a topic ran in parallel ) . The bots watched 3951 videos ( collected 78763 recommendations associated with them , 8526 of them unique ) , executed 10075 queries ( collected 201404 search results , 942 of them unique ) , and visited homepage 3990 times ( collected 116479 videos there , 9977 of them unique ) . Overall , we recorded 17405 unique videos originating from 6342 channels . Using the selection strategy and annotation scheme described in Section 4.4 , 5 annotators annotated unique 2914 videos ( covering 255844 appearances ) . In total , 244 videos were identified as promoting misinformation ( related or unrelated to respective topics ) , 628 as debunking ( including mocking videos ) , 184 as neutral , 1829 as not about misinformation . Other videos ( unknown , non-English , or removed ) numbered 29 . We report the results according to research questions and hypotheses defined in Section 4.1 . SERP-MS score metrics are reported for search results and mean normalized scores for recommendations . Since the metrics are not normally distributed with some samples of unequal sizes , we make use of non-parametric statistical tests . Pairwise tests are performed using two-sided Mann-Whitney U test . In cases where multiple comparisons by topics are performed , Bonferroni correction is applied on the significance level ( in that case a = 0.05 is divided by number of topics ny = 5 , resulting in a = 0.01 ) . 5.1 RQI1 : Has YouTube ’ s personalization behavior changed since the reference study ? Overall , we see a small change in the mean SERP-MS score across the same search queries in our and reference data : mean SERP-MS worsened from -0.46 ( std 0.42 ) in reference data to -0.42 mean ( std 0.3 ) in our data . However , the distributions are not statistically significantly different ( n.s.d. ) . There is a similar small change towards the promoting spectrum in up-next ( first result in recommendation list ) and top-5 recommendations ( following 5 recommendations ) . We compared the up-next and top-5 recommendations together ( as top-6 recommendations ) using last 10 watched promoting videos in reference watch experiments and last two watched videos in our promoting phase . We see mean normalized score worsened from -0.07 ( std 0.27 ) in reference data to -0.04 ( std 0.31 ) in our data . These distributions are also not significantly different ( U=45781.5 , n.s.d. ) . More considerable shifts in the data can be observed when looking at individual topics . Table 1 shows a comparison of SERP-MS scores for top-10 search results between our and reference data . Improvement can be seen within certain queries for the chemtrails conspiracy that show a large decrease in the number of promoting videos . The reference 10 This article has been accepted for publication in 15th ACM Conference on Recommender Systems . Association for Computing Machinery . Citation information : https : //doi.org/10.1145/3460231.3474241 An Audit of Misinformation Filter Bubbles on YouTube RecSys ’ 21 , September 27-October 1 , 2021 , Amsterdam , Netherlands Table 1 . Comparison of SERP-MS scores for top-10 search results with data from the reference study . The scores range from ( -1,1 ) , where -1 denotes a debunking and 1 a promoting stance towards the conspiracy . Only search results from queries that were executed both by the reference study and us are considered . Topic Hussein Ours Change Inspection 9/11 -0.16 -0.06 No ( ns.d . ) Smaller changes that depend on search query . Chemtrails -0.2 -0.47 . No ( ns.d . ) Drop in promoting videos ( from 45 % to 12 % ) in 2 queries . Flat earth -0.58 -0.41 No ( ns.d . ) 2 queries worsen a lot due to new content . Other queries improve . Moon landing -0.6 -0.59 No ( ns.d . ) Smaller decrease in number of neutral and increase of debunking videos . Anti-vaccination -0.8 -0.63 Worse Drop in number of debunking and increase in number of neutral videos . ( U=324 , p=1.3e-9 ) Table 2 . Comparison of normalized scores for up-next and top-5 recommendations with data from the reference study . Normalized scores range from { —1 , 1 ) , where -1 denotes a debunking and 1 a promoting stance towards the conspiracy . Last 10 out of 20 watched videos in reference data are considered . Last 2 out of 40 watched videos in our data are considered . Topic Hussein Ours Change Inspection 9/11 0.14 0.26 No ( ns.d . ) Similar distribution , more promoting videos . Chemtrails 0.05 0.03 No ( ns.d . ) More neutral results . Flat earth -0.16 -0.15 No ( ns.d . ) Similar distribution . Moon landing -0.08 -0.32 Better ( U=2954.5 , p=8e-6 ) More debunking videos . Anti-vaccination —-0.28 -0 Worse ( U=664 , p=1.6e-9 ) — Less debunking videos , more neutral and promoting . study reported that this topic receives significantly more misinformative search results compared to all other topics . In our experiments , their proportion was lower than in the 9/11 conspiracy . On the other hand , search results for flat earth conspiracy worsened . Queries such as “ flat earth british ” resulted in more promoting videos , likely due to new content on channels with similar names . Within the anti-vaccination topic , there is an increase in neutral videos ( from 12 % to 35 % ) and thus a drop in debunking videos ( from 85 % to 61 % ) . This may relate to new content regarding COVID-19 . Table 2 shows a comparison of normalized scores for up-next and top-5 recommendations . Only the moon landing and anti-vaccination topics come from statistically significantly different distributions . Similar to search results , recommendations for the 9/11 and anti-vaccination conspiracy topics worsened . There were more promoting videos on the 9/11 topic ( 27 % instead of 18 % ) . In the anti-vaccination topic , we observed a drop in debunking videos ( from 29 % to 9 % ) and a subsequent increase in neutral ( from 70 % to 78 % ) and promoting videos ( from 1 % to 8 % ) . The change within the anti-vaccination controversy is even more pronounced when looking at up-next recommendations separately . Within up-next , the proportion of debunking videos drops from 77 % to 19 % , neutral videos increase from 22 % to 70 % , and promoting increase from 1 to 11 % . On the other hand , in the moon landing topic , we see much more debunking video recommendations—40 % instead of 23 % in reference data . These results bring up a need to distinguish between endogenous ( changes in algorithms , policy decisions made by platforms to hide certain content ) and exogenous factors ( changes in content , external events , behavior of content creators ) as discussed by Metaxa et al . [ 12 ] . Our observations show that search results and recommendations were in part influenced by exogenous changes in content on YouTube . Within the chemtrails conspiracy , we observed results related to a new song by Lana del Rey that mentions “ Chemtrails ” in its name . Search results and recommendations in the anti-vaccination topic seem to be influenced by COVID-19 . Flat earth conspiracy videos were influenced by an increased amount of activity within a single conspiratorial channel . 1 This article has been accepted for publication in 15th ACM Conference on Recommender Systems . Association for Computing Machinery . Citation information : https : //doi.org/10.1145/3460231.3474241 RecSys ’ 21 , September 27-October 1 , 2021 , Amsterdam , Netherlands Tomlein , et al . Table 3 . Comparison of SERP-MS scores for top-10 search results in promoting and debunking phase of our experiment . Three points are compared : start of promoting phase ( S1 ) , end of promoting phase ( E1 ) , end of debunking phase ( E2 ) . Topic SERP-MS Change Inspection 9/11 S1 : -0.07 S1-E1 : ns.d . E2 : More debunking videos in one query ( 30 % instead of 12 % at S1 and E1 : -0.06 E1-E2 : ns.d . 11 % at E1 in query “ 9/11 ” ) . E2 : -0.11 S1-E2 : n.s.d . Chemtrails S1 : -0.45 S1-E1 : ns.d . E2 : The “ Chemtrail ” search query showed an increase in number of E1 : -0.47 E1l-E2 : ns.d . debunking videos ( from 66 % at S1 and 69 % at E1 to 80 % ) and a decrease E2 : -0.49 S1-E2 : better ( U=915 , p=0.0097 ) in promoting ( from 10 % to 0 % ) . Flat S1 : -0.27 S1-E1 : better ( U=762.5 , p-0.0004 ) E1 : Change goes against expectations . Promoting videos disappear in earth E1 : -0.41 E1-E2 : n.s.d . 3 search queries and decrease in another one ( from 36 % to 30 % ) . E2 : -0.45 S1-E2 : better ( U=704.5 , p=0.0001 ) E2 : Similar change as in E1 with a further decrease in promoting videos in one query ( from 30 % to 22 % ) and reordered videos in another . Moon S1 : -0.57 S1-E1 : ns.d . E2 : Reordered search results in “ moan hoax ” query—debunking videos landing E1 : -0.57 E1-E2 : ns.d . moved higher . E2 : -0.59 S1-E2 : better ( U=900 , p=0.0068 ) Anti- S1 : -0.6 S1-E1 : ns.d . E2 : Increase in debunking videos across multiple queries ( from 60 % at vacc . E1 : -0.63 E1-E2 : better ( U=699.5 , p=0.0054 ) S1 and 61 % at El to 67 % ) . E2 : -0.68 S1-E2 : better ( U=641.5 , p=0.0001 ) Table 4 . Comparison of changes in average normalized scores for top- 10 recommendations in promoting and debunking phase of our experiment . Three points are compared : start of promoting phase ( S1 ) , end of promoting phase ( E1 ) , end of debunking phase ( E2 ) . Topic Score Change Inspection 9/11 S1 : 0.1 S1-E1 : worse ( U=45.5 , p=2.6e—5 ) E1 : Number of promoting videos increased ( from 14 % to 43 % ) and E1 : 0.42 E1-E2 : better ( U=28 , p=2.9e-6 ) neutral videos decreased ( from 83 % to 56 % ) . E2 : 0.07 S1-E2 : ns.d . E2 : The numbers of promoting and neutral videos returned to levels comparable to start ( 13 % and 82 % ) . Chemtrails S1 : 0 S1-E1 : ns.d . E2 : There is an increase in a number of debunking videos ( from 0 % at E1 : 0.05 E1-E2 : better ( U=323 , p=0.0006 ) $ 1 and 3 % at E1 to 19 % ) . In return , we end up in a state that is better E2 : -0.15 S1-E2 : better ( U=330 , p=0.0002 ) than at the start . Flat S1 : -0.17 S1-E1 : ns.d . E2 : Similar to the Chemtrails conspiracy , there is an increase in number earth E1 : -0.06 E1-E2 : better ( U=375 , p=1.8e-6 ) of debunking videos ( from 19 % at S1 and 16 % at El to 48 % ) . E2 : -0.47 S1-E2 : better ( U=347 , p=0.0001 ) Moon S1 : -0.2 S1-E1 : ns.d . E1 : Mean normalized scores changes against expectation and improves landing El : -0.4 E1-E2 : ns.d . ( but not significantly ) . E2 : -0.42 S1-E2 : ns.d . Anti- $ 1 : -0.1 S1-E1 : worse ( U=74.5 , p=0.0008 ) | E1 : Increase in number of promoting videos ( from 2 % to 13 % ) . vacc . E1 : 0.04 E1-E2 : better ( U=310 , p=2.5e-6 ) E2 : Increase of debunking videos ( from 12 % at S1 and 9 % at El to 37 % ) E2 : -0.37 S1-E2 : better ( U=307.5 , p=0.0002 ) and disappearance of promoting ( from 2 % at S1 and 13 % at E1 to 0 % ) . 5.2 RQ2 : What is the effect of watching debunking videos after the promoting phase ? Answering this question requires three comparisons : ( 1 ) comparison of metrics between start of promoting phase ( S1 ) and end of promoting phase ( E1 ) , ( 2 ) comparison of metrics between end of promoting phase ( E1 ) and end of debunking phase ( E2 ) , ( 3 ) comparison of metrics between start of promoting phase ( S1 ) and end of debunking phase ( E2 ) . Comparison ( 1 ) shows changes in search results and recommendations after watching promoting videos ( E1 ) compared to the start of the experiment ( S1 ) . If there was a misinformation bubble created , we would expect the metrics to worsen 12 This article has been accepted for publication in 15th ACM Conference on Recommender Systems . Association for Computing Machinery . Citation information : https : //doi.org/10.1145/3460231.3474241 An Audit of Misinformation Filter Bubbles on YouTube RecSys ’ 21 , September 27-October 1 , 2021 , Amsterdam , Netherlands due to watching promoting videos . Regarding search results , the distribution of SERP-MS scores between S1 and E1 is indeed significantly different ( MW U=34118.5 , p-value=0.028 ) . However , the score actually improves—mean SERP-MS score changed from -0.39 ( std 0.28 ) to -0.42 ( std 0.3 ) . Table 3 shows the change for individual topics . Only the flat earth conspiracy shows significant differences and improved the SERP-MS score due to a decrease in promoting and an increase of debunking videos . Top-10 recommendations also change their distribution of normalized scores significantly at E1 compared to S1 ( MW U=4085 , p-value=0.0397 ) . We observe that the mean normalized score worsens from -0.07 ( std 0.24 ) to 0.01 ( std 0.31 ) . Looking at individual topics in Table 4 , we can see that the change is significant in topics 9/11 and anti-vaccination that gain more promoting videos . Comparison ( 2 ) relates the change in search results and recommendations between the end of promoting phase ( E1 ) and the end of debunking phase ( E2 ) . We expect the metrics would improve due to watching debunking videos , ie , that we would observe misinformation bubble bursting . However , SERP-MS scores in search results between E1 and E2 are not from statistically significantly different distributions , which is consistent with the fact that we did not observe misinformation bubble creation in search results in the first place . Table 3 shows that only a single topic—anti-vaccination—significantly changed its distribution and improved its mean score . Nevertheless , we see minor improvements in SERP-MS scores also in other topics . Top-10 recommendations show more considerable differences and their overall distribution is significantly different comparing E1 and E2 ( MW U=7179.5 , p-value=1.8e—9 ) . Mean normalized score improves from 0.01 ( std 0.31 ) to -0.27 ( std 0.27 ) . Table 4 shows significantly different distributions for all topics except for moon landing conspiracy . All topics show an improvement in normalized scores . The 9/11 topic shows a decrease in promoting videos , while other topics show an increase in the number of debunking videos . Comparison ( 3 ) shows differences between the start ( S1 ) and end of the experiment ( E2 ) . We expect the metrics would improve due to watching debunking videos despite watching promoting videos before that . The distribution of SERP-MS scores in search results is statistically significantly different when comparing S1 and E2 ( MW U=36515 , p-value=0.0002 ) . Overall , we see an improvement in mean SERP-MS score from -0.39 ( std 0.28 ) to -0.46 ( std 0.29 ) . In contrast with comparison ( 2 ) , Table 3 shows that all topics except 9/11 significantly changed their distributions . All topics show an improvement according to our expectations . The improvement is due to increases in debunking videos , decreases in promoting videos , or reordered search results in some search queries . Similarly , top-10 recommendations at E2 come from a significantly different distribution than at S1 ( MW U=6940.5 , p-value=2.9e—7 ) . Mean normalized score improves from -0.07 ( std 0.24 ) to -0.27 ( std 0.27 ) . Table 4 shows a significant difference in distributions for all topics except for 9/11 and moon landing conspiracies . Mean normalized scores improve compared to S1 in all topics except for 9/11 . Nevertheless , the numbers of promoting and neutral videos in 9/11 topic at E2 are comparable to S1 . Other topics show increases in the numbers of debunking videos . 6 DISCUSSION AND CONCLUSIONS In the paper , we presented an audit of misinformation present in search results and recommendations on the video- sharing platform YouTube . To support reproducibility , we publish the collected data and source codes for the experiment . We aimed at verifying a hypothesis that there is less misinformation present in both search results and recommenda- tions after recent changes in YouTube policies [ 28 ] ( H1.1 ) . The comparison was done against a study done in mid 2019 by Hussein et al . [ 8 ] . We were interested , whether we could still observe the formation of misinformation bubbles after watching videos promoting conspiracy theories ( H2.0 ) . In contrast to the previous studies , we also examined bubble bursting behavior . Namely , we aimed to verify whether misinformation bubbles could be burst if we watched videos debunking conspiracy theories ( H2.1 ) . We also hypothesized that watching debunking videos ( even after a previous 13 This article has been accepted for publication in 15th ACM Conference on Recommender Systems . Association for Computing Machinery . Citation information : https : //doi.org/10.1145/3460231.3474241 RecSys ’ 21 , September 27-October 1 , 2021 , Amsterdam , Netherlands Tomlein , et al . sequence of promoting videos ) would still decrease the amount of misinformation compared to the initial state with no watch history at the start of the study ( H2.2 ) . Regarding hypothesis H1.1 , we did not find a significantly different amount of misinformation in search results in comparison to the reference study . A single topic ( anti-vaccination ) showed a statistically significant difference . However , it did not agree with the hypothesis as the metric worsened due to more neutral and less debunking videos . Recommendations showed significant differences across multiple topics but were not significantly different overall . A single topic ( moon landing ) improved normalized scores of recommendation in agreement with the hypothesis . Yet , the anti-vaccination topic worsened its scores . We suspect the changes in search results and recommendations were influenced mostly by changes in content . Overall , our results did not show a significant improvement in the fight against misinformation on the platform , as stated in the hypothesis . We did not observe the creation of misinformation filter bubbles in search results ( H2.0 ) despite watching promoting videos . On the other hand , recommendations behaved according to our hypothesis , and their overall normalized scores worsened . Since there was no filter bubble creation effect in search results , we did not observe any bubble bursting effect there . Results did not show a statistically significant difference between the end of promoting phase and the end of the debunking phase . Only a single topic ( anti-vaccination ) showed a statistically significant difference and an improvement following the hypothesis H2.1 . Recommendations showed more considerable differences that were statistically significant and confirmed the hypothesis . Lastly , we showed that watching debunking videos decreases the number of misinformation videos both in search results and recommendations , which confirms our hypothesis H2.2 . We observed an improvement of SERP-MS scores in all topics except for one and an improvement of normalized scores for recommendations in most topics . Based on our results , we can conclude that users , even with a watch history of promoting conspiracy theories , do not get enclosed in a misinformation filter bubble when they search on YouTube . However , we do observe this effect in video recommendations with varying degrees depending on the topic . However , watching debunking videos helps in practically all cases to decrease the amount of misinformation that the users see . Additionally , although we expected to see less misinformation than the previous studies reported , this was in general not the case . Worsening in the anti-vaccination topic was partially expected due to the COVID-19 pandemic . However , it is interesting that we also observed a worse situation with the 9/11 topic . In fact , this topic served as a sort of a gateway to misinformation videos on other topics . A limitation of our results lies with the limited amount of topics that we investigated —- these did not include , for example , recent QAnon conspiracy and COVID-19 related conspiracies were present only through anti-vaccination narratives . However , our topics were explicitly selected to allow comparison with the reference study . Next , we included only a limited set of agent interactions with the platform ( search and video watching ) . Real users also like or dislike videos , subscribe to channels , leave comments or click on the search results or recommendations . A more human-like bot simulation , with these interactions and possible inclusion of human biases bursting remains our future work . Nevertheless , our audit showed that YouTube ( similar to other platforms ) , despite their best efforts so far , can still promote misinformation seeking behavior to some extent . The results also motivate the need for independent continuous and automatic audits of YouTube and other social media platforms [ 22 ] , since we observed that the amount of misinformation in a topic could change over time due to endogenous as well as exogenous factors . ACKNOWLEDGMENTS This research was partially supported by TAILOR , a project funded by EU Horizon 2020 research and innovation programme under GA No 952215 . This article has been accepted for publication in 15th ACM Conference on Recommender Systems . Association for Computing Machinery . Citation information : https : //doi.org/10.1145/3460231.3474241 An Audit of Misinformation Filter Bubbles on YouTube RecSys ’ 21 , September 27-October 1 , 2021 , Amsterdam , Netherlands REFERENCES { 1 ] Deena Abul-Fottouh , Melodie Yunju Song , and Anatoliy Gruzd . 2020 . Examining algorithmic biases in YouTube ’ s recommendations of vaccine videos . Int . Journal of Medical Informatics 140 ( 2020 ) , 104175. https : //doi.org/10.1016/j.ijmedinf.2020.104175 [ 2 ] Eytan Bakshy , Solomon Messing , and Lada A. Adamic . 2015 . Exposure to ideologically diverse news and opinion on Facebook . Science 348 , 6239 ( 2015 ) , 1130-1132 . [ 3 ] Alessandro Bessi . 2016 . Personality traits and echo chambers on facebook . Computers in Human Behavior 65 ( 2016 ) , 319-324 . [ 4 ] Paul Covington , Jay Adams , and Emre Sargin . 2016 . Deep Neural Networks for YouTube Recommendations . In Proc . of the 10th ACM Conference on Recommender Systems ( RecSys °16 ) . ACM , New York , NY , USA , 191-198. https : //doi.org/10.1145/2959 100.2959190 [ 5 ] Michela Del Vicario , Alessandro Bessi , Fabiana Zollo , Fabio Petroni , Antonio Scala , Guido Caldarelli , H Eugene Stanley , and Walter Quattrociocchi . 2016 . The spreading of misinformation online . Proc . of the National Academy of Sciences 113 , 3 ( 2016 ) , 554-559 . [ 6 ] Leon Festinger . 1957 . A theory of cognitive dissonance . Vol . 2 . Stanford university press . [ 7 ] Aniko Hannak , Piotr Sapiezynski , Arash Molavi Kakhki , Balachander Krishnamurthy , David Lazer , Alan Mislove , and Christo Wilson . 2013 . Measuring Personalization of Web Search . In Proc . of the 22nd International Conference on World Wide Web ( WWW 13 ) . ACM , New York , NY , USA , 527-538. https : //doi.org/10.1145/2488388.2488435 [ 8 ] Eslam Hussein , Prerna Juneja , and Tanushree Mitra . 2020 . Measuring Misinformation in Video Search Platforms : An Audit Study on YouTube . Proc . ACM Hum.-Comput . Interact . 4 , CSCW1 , Article 048 ( May 2020 ) , 27 pages . https : //doi.org/10.1145/3392854 [ 9 ] Prerna Juneja and Tanushree Mitra . 2021 . Auditing E-Commerce Platforms for Algorithmically Curated Vaccine Misinformation . In Proc . of the 2021 CHI Conference on Human Factors in Computing Systems ( CHI ’ 21 ) . https : //doi.org/10.1145/3411764.3445250 arXiv:2101.08419 { 10 ] Huyen Le , Andrew High , Raven Maragh , Timothy Havens , Brian Ekdale , and Zubair Shafiq . 2019 . Measuring political personalization of Google news search . In Proc . of the World Wide Web Conference ( WWW °19 ) . 2957-2963. https : //doi.org/10.1145/3308558.3312504 [ 11 ] Ben Lockwood . 2017 . Confirmation Bias and Electoral Accountability . Quarterly Journal of Political Science 11 , 4 ( February 2017 ) , 471-501. https : //doi.org/10.1561/100.00016037 [ 12 ] Danaé Metaxa , Joon Sung Park , James A. Landay , and Jeff Hancock . 2019 . Search Media and Elections : A Longitudinal Investigation of Political Search Results . Proc . ACM Hum.-Comput . Interact . 3 , CSCW , Article 129 ( Nov. 2019 ) , 17 pages . https : //doi.org/10.1145/3359231 [ 13 ] Diana C. Mutz and Lori Young . 2011 . Communication and public opinion : Plus ca change ? Public opinion quarterly 75 , 5 ( 2011 ) , 1018-1044 . [ 14 ] Kostantinos Papadamou , Savvas Zannettou , Jeremy Blackburn , Emiliano De Cristofaro , Gianluca Stringhini , and Michael Sirivianos . 2020 . `` It is just a flu '' : Assessing the Effect of Watch History on YouTube ’ s Pseudoscientific Video Recommendations . arXiv:2010.11638 [ cs.CY ] ( 15 ] Eli Pariser . 2011 . The filter bubble : What the Internet is hiding from you . Penguin UK . [ 16 ] Branislav Pecher , Ivan Srba , Robert Moro , Matus Tomlein , and Maria Bielikova . 2021 . FireAnt : Claim-Based Medical Misinformation Detection and Monitoring . In Proc . of the Joint European Conference on Machine Learning and Knowledge Discovery in Databases ( ECML PKDD ’ 20 ) . 555-559. https : //doi.org/10.1007/978-3-030-67670-4_38 [ 17 ] Manoel Horta Ribeiro , Raphael Ottoni , Robert West , Virgilio A. F. Almeida , and Wagner Meira . 2020 . Auditing Radicalization Pathways on YouTube . ACM , New York , NY , USA , 131-141. https : //doi.org/10.1145/3351095.3372879 [ 18 ] Ronald E. Robertson , David Lazer , and Christo Wilson . 2018 . Auditing the personalization and composition of politically-related search engine results pages . Proc . of the World Wide Web Conference ( WWW ’ 18 ) , 955-965. https : //doi.org/10.1145/3178876.3186143 [ 19 ] Christian Sandvig , Kevin Hamilton , Karrie Karahalios , and Cedric Langbort . 2014 . Auditing algorithms : Research methods for detecting discrimination on internet platforms . Data and discrimination : converting critical concerns into productive inquiry 22 ( 2014 ) , 4349-4357 . [ 20 ] Marcio Silva , Lucas Santos de Oliveira , Athanasios Andreou , Pedro Olmo Vaz de Melo , Oana Goga , and Fabricio Benevenuto . 2020 . Facebook Ads Monitor : An Independent Auditing System for Political Ads on Facebook . In Proc . of The Web Conference ( WWW ’ 20 ) . ACM , New York , NY , USA , 224-234. https : //doi.org/10.1145/3366423.3380109 [ 21 ] Jakub Simko , Patrik Racsko , Matus Tomlein , Martina Hanakova , Robert Moro , and Maria Bielikova . 2021 . A study of fake news reading and annotating in social media context . New Review of Hypermedia and Multimedia ( 2021 ) , 1-31 . [ 22 ] Jakub Simko , Matus Tomlein , Branislav Pecher , Robert Moro , Ivan Srba , Elena Stefancova , Andrea Hrckova , Michal Kompan , Juraj Podrouzek , and Maria Bielikova . 2021 . Towards Continuous Automatic Audits of Social Media Adaptive Behavior and Its Role in Misinformation Spreading . In Adjunct Proc . of the 29th ACM Conference on User Modeling , Adaptation and Personalization ( UMAP ’ 21 ) . ACM , New York , NY , USA , 411-414. https : //doi.org/10.1145/34506 14.3463353 [ 23 ] Larissa Spinelli and Mark Crovella . 2020 . How YouTube Leads Privacy-Seeking Users Away from Reliable Information . In Adjunct Publication of the 28th ACM Conference on User Modeling , Adaptation and Personalization . ACM , New York , NY , USA , 244-251. https : //doi.org/10.1145/3386392.3399566 [ 24 ] Ivan Srba , Robert Moro , Daniela Chuda , Maria Bielikova , Jakub Simko , Jakub Sevcech , Daniela Chuda , Pavol Navrat , and Maria Bielikova . 2019 . Monant : Universal and Extensible Platform for Monitoring , Detection and Mitigation of Antisocial Behavior . In Proc . of Workshop on Reducing Online Misinformation Exposure ( ROME °19 ) . 1-7 . [ 25 ] Cass R Sunstein . 1999 . The law of group polarization . University of Chicago Law School , John M. Olin Law and Economics Working Paper 91 ( 1999 ) . [ 26 ] Pernille Tranberg , Gry Hasselbalch , Catrine S. Byrne , and Birgitte K. Olsen . 2020 . DATAETHICS — Principles and Guidelines for Companies , Author- ities and Organisations . Dataethics.eu . https : //spintype.com/book/dataethics-principles-and-guidelines-for-companies-authorities-organisations 15 This article has been accepted for publication in 15th ACM Conference on Recommender Systems . Association for Computing Machinery . Citation information : https : //doi.org/10.1145/3460231.3474241 RecSys ’ 21 , September 27-October 1 , 2021 , Amsterdam , Netherlands Tomlein , et al . [ 27 ] Siva Vaidhyanathan . 2018 . Antisocial media : How Facebook disconnects us and undermines democracy . Oxford University Press . [ 28 ] YouTube . 2020 . Managing harmful conspiracy theories on YouTube . https : //blog-youtube/news-and-events/harmful-conspiracy-theories-youtube/ [ 29 ] Savvas Zannettou , Michael Sirivianos , Jeremy Blackburn , and Nicolas Kourtellis . 2019 . The Web of False Information : Rumors , Fake News , Hoaxes , Clickbait , and Various Other Shenanigans . Journal of Data and Information Quality ( 2019 ) , 1-37. https : //doi.org/10.1145/3309699 arXiv:1804.03461 [ 30 ] Zhe Zhao , Lichan Hong , Li Wei , Jilin Chen , Aniruddh Nath , Shawn Andrews , Aditee Kumthekar , Maheswaran Sathiamoorthy , Xinyang Yi , and Ed Chi . 2019 . Recommending what video to watch next : A multitask ranking system . In Proc . of the 13th ACM Conference on Recommender Systems ( RecSys 719 ) . ACM , 43-51. https : //doi.org/10.1145/3298689.3346997 ( 31 ] Xinyi Zhou and Reza Zafarani . 2020 . A Survey of Fake News : Fundamental Theories , Detection Methods , and Opportunities . Comput . Surveys 53 , 5 ( Dec. 2020 ) . https : //doi.org/10.1145/3395046 arXiv:1812.00315 [ 32 ] Fabiana Zollo , Petra Kralj Novak , Michela Del Vicario , Alessandro Bessi , Igor Mozetic , Antonio Scala , Guido Caldarelli , and Walter Quattrociocchi . 2015 . Emotional Dynamics in the Age of Misinformation . CoRR ( 2015 ) . http : //dblp.uni-trier.de/db/journals/corr/corr1505.html # ZolloONVBMSCQ15 [ 33 ] Shoshana Zuboff . 2019 . The Age of Surveillance Capitalism : The Fight for a Human Future at the New Frontier of Power . Profile Books . ACADEMIA Accelerating the world 's research . Living in The Filter Bubble : Is What We Lose Something We Need to Preserve ? Krzysztof J Jankowski Cite this paper Downloaded from Academia.edu4 Get the citation in MLA , APA , or Chicago styles Related papers Download a PDF Pack of the best related papers 7 ary Bursting the Filter Bubble : Democracy , Design and Ethics ( PhD Thesis ) Engin Bozdag Bias in algorithmic filtering and personalization Engin Bozdag Breaking the filter bubble : democracy and design Jeroen van den Hoven , Engin Bozdag Research Paper Living in The Filter Bubble Is What We Lose Something We Need to Pre- serve ? By Krzysztof J. Jankowski November 26 '' , 2014 University of Ottawa , Faculty of Law Living in The Filter Bubble Table of Content I How We Consented to Live in the Filter Bubble 1 . Filtering of Information 2 . Internet Search Engines 3 . Do We Live in the Filter Bubble ? IL . Personalized Filtering - What Can We Lose ? Search Engine Bias and Democracy . ll . Is There Space For Regulation ? Responsibility Over Comfort . Key words : search engines bias , filter bubble , search engine , information filtering , personalization search , personalized services . Abstract This paper examines the negative consequences of the filter bubble phenomenon , described by Eli Pariser in his book “ The Filter Bubble . What the Internet Is Hiding from You ” — the limitation of access to certain information due to the excessive and constant personalization of the content on web . The focus is given to the special role the search engines like Google , Yahoo or Bing play in the creation of filter bubble . The general aim of this paper is to raise awareness about the drawback of the current situation , to highlight possible threats posed to the deliberative democracy and briefly examine the possible solutions . Although it is arguable , the problem we might be facing with the personalization of Web and search results is that it poses a number of threats to the democratic society as well as to the values embodied in it e.g . freedom of speech , access to information or pluralism of opinions . The first chapter examines the filter bubble phenomenon in the context of how search engines contribute and might contribute to its existence . In this author ’ s view , although the search engines are just one of the personalized services creating the filter bubble , because of the role they play as actual information intermediaries in the information-based society , they are one of the most important factors in creation or destruction of the filter bubble . The part of the present paper discusses this interplay between search engines and information cocoons in which 1 Living in The Filter Bubble we apparently live . The second chapter examines the threats posed by the filter bubble and so thus by the personalized Web search services . Following Sunstein ’ s thought , this paper assumes that the requirement of the deliberative democracy is not only that citizens have freedom of speech and the right to pluralism of thoughts , but that they are effectively exposed to other ’ s views and opinions . Being close in the filter bubble does not allow that to the significant degree , therefore it is possible that although the search engines do not block access to certain information , but somehow ‘ hide ’ it from users , that might be sufficient to pose a threat to the effective functioning of the exchange of opinions and thought , so thus to the deliberative democracy in general . Should then this issue be regulated ? How ? This issue is discussed in the final chapter of the paper , which suggest , that while the legal regulation is possible and needed , the field where the changes could happen now more easily and likely are social norms on the use of search engines . On the one hand , as to the principle , the public enjoys personalized content of the Web , as well as enhanced search results which it finds more accurate and helpful Gndividual interest ) . On the other hand , as indicated previously , the public interest might be endangered . Any discussion on possible regulation needs to acknowledge two opposite points of view . Therefore , the question of regulation remains not easily solvable . Following Lessig ’ s Code , the author examines whether the solution to the identified problem might be found through the change of architecture , social norms , and law or by the market forces . At the end of the day , the author suggests that the issue of the filter bubble and search engines appear to be a moral question on civil responsibility and therefore the first response to it could be found in the proper shaping of social norms . The ultimate response to the phenomenon of the filter bubble depends from the choice of values to be made by the members of society — little comfort or small act of social responsibility in pursue of protection of democratic values ? Individualism over collectivism . Living in The Filter Bubble “ Democracy requires citizens to see things from one another 's point of view , but instead , we're more and more enclosed in our own bubbles . Democracy requires a reliance on shared facts ; instead we 're being offered parallel but separate universes. ” Eli Pariser , The Filter Bubble . What the Internet Is Hiding from You . I . How We Consented to Live in The Filter Bubble “ Imagine a future in which your interface agent can read every newswire and newspaper and catch every TV and radio broadcast on the planet , and then construct a personalized summary . This kind of newspaper is printed in an edition of one . ( ... ) Call it the Daily Me. ” Nicholas Negroponte , ” 1995 This chapter aims to depict the several elements of our reality and to provide an explanation of the circumstance , which ( as we are going to see in the second chapter ) might pose certain threats to the deliberative democracy . In my opinion , the filter bubble , to which creation the search engines greatly contribute , poses certain threats as to the quality of pluralism of thoughts and ideas which we enjoy as society , and therefore to the deliberative democracy too . While I second the need of certain legal regulation of search engines , in my view the proper response to the indicate threat , currently could happen primarily thought the change of social norms . Ultimately , this response to the said threat might depend on choice between responsibility and comfort . The present paper is divided into three parts , from which the first one aims to depict the situation which is potentially dangerous to the quality of the democracy we enjoy ; the second one explains the nature of possible threats ; the last one examines possibilities of employing certain regulatory factors to remedy the current situation , which potentially has a deteriorating effect . This chapter examines subsequently ( 1 ) the general concerns connected with processing and therefore filtering information , ( 2 ) the important role the search engines play nowadays , particularly as information intermediaries , and ( 3 ) the phenomenon of the filter bubble i.e . the 'Eli Pariser , The Filter Bubble . What the Internet Is Hiding From You ( New York : The Penguin Press , 2011 ) at 5 . * Nicholas Negroponte , Being Digital ( New York : Alfred . A. Knopf , 1995 ) at 153 . 3 Living in The Filter Bubble information cocoon in which we might live , as well as interconnections between those issues . 1 . Filtering Information Stating that we live in the Information Age is to say almost nothing about our nowadays reality . Information and access to it became such crucial and important part of our day-to-day lives that no one reasonable can claim that it does not play the significant role in the modern World . We live in the knowledge-based society , where concerns on information have been elevated to one of the most crucial queries regarding in fact the shape and condition of societies , economies , political systems etc. ? At the much ‘ lower ’ level , an exemplary proof of the importance of information is that the present paper is the fruit of extensive dimension of access to information and the overload of information available , which the phenomena we face nowadays . The number of sources of information which anyone can consult appears to be indefinite and therefore also non-manageable by an individual or even a group of them . Due to the Information Revolution , we live in the World where information has become a crucial factor of production and a basis for whole industries built around the value information can have . * Noteworthy , even though we might want to see ourselves as flooded with a stream of information and therefore being placed in the extraordinary and new reality , the problems concerning information the human mankind currently faces appear to remain the same from the very beginning of our history . The questions regarding the load of existing knowledge , which people have been asking themselves for several hundred years , appear to be built around several general issues of which the following two are worth mentioning in the context of the subject matter of present paper : ( 1 ) how to process and make use of information , and ( what appears more important in the context of the present paper ) ( 2 ) how to filter information to obtain only relevant data . As previously stated , these problems are not new . Seneca complained about the overflow of information already in ancient times : “ What is the point of having countless books and libraries whose titles the owner could scarcely read through in his whole lifetime ? The mass ° > Frank Webster , “ Introduction : Information Society Studies ” in Frank Webster ed. , The Information Society Reader ( London and New York : Routledge , 2004 ) at 9 . “ For more information on the Information Age and its development please see : Kevin Robins & Frank Webster , “ The Long History of The Information Revolution ” in Frank Webster ed. , supra at 55-80 . 4 Living in The Filter Bubble of books burden the student without instructing. ” * > Nowadays such complaint would be probably welcomed with a charitable smile . However , even though the dimension of influx of information has changed , the problem of processing amounts of data too huge to allow one to comprehend them has remained the same.° According to the research published in 2009 , during the precedent year only U.S. citizens ‘ consumed ’ 3.6 zettabytes of information , ’ what is truly the BIG number.® It is easy to get confused and lost while operating on such amounts of data . The problem of their digestibility arises — the form of data , level to which they are comprehensive etc . The processing of information is preceded by an elementary choice of the input to be processed , what leads us straight to the second of the mentioned general issues concerning information and its usage . Notably , most of the information we receive from the reality surrounding us is of no true relevance ; there is a limited number of data we need to obtain and process in order to achieve a given goal ( e.g . to pass an exam ) . That forces us to pose a question on how to distinguish the relevant data from those which are not important . The filtering of obtained information remains as important part of the whole process of comprehension as its other stages , namely collection of data and subsequent processing and analyzing with the view to obtain certain outcome . The form and the manner in which the employed filter operates have undeniable influence on the effects of information processing . Therefore , to effectively control the process one needs to analyse the nature and features of the used information filter . How does it operate ? What kind of factors does it take into account while deciding whether the given information is important or not ? What factors are decisive ? What is the algorithm behind it ? How many information of what kind and form can it filter in a given time period ? These are questions referring to the technical aspects of the filter and they determine whether it is efficient or not . There are , however , queries of different nature which are more important is evaluating whether the filter is good for its user. ” Is the filter value-neutral ? If not , what kind of values , view and opinions does it support ? Is a given tendency visible to the user ? Is the process of selection of information transparent ? Is the user conscious of how the * Lucius Annaeus Seneca ( trans . C.D.N . Costa ) , Dialogues and Letters ( Penguin UK , 1997 ) at 45 . 6 Alexander Halavais , Search Engine Society ( Polity Press , 2009 ) at 10 . 7For you reference , the mentioned number amounts to 3.6 times 10 ? ' . SRoger E. Bohn , James E. Short , How Much Information ? 2009 Report on American Consumers ( University of California — San Diego : Global Information Industry Center , 2009 ) , online : Global Information Industry Center < http : //hmi.ucsd.edu/howmuchinfo.php > . °Compare : Halavais , supra at 32 . Living in The Filter Bubble information is selected ? What influence the user has on the manner in which a given filter operates ? To translate these questions into example , if a professor proposes several leading handbooks to a class , each student willing to pass would first ( most probably ) briefly familiarize him- or herself with the books ( collection of data ) , analyse pros and cons of each title ( too long , too short , too theoretical etc . ) , make a choice basing on the adopted criteria ( those merely willing to pass would chose the shorter handbook ; those more ambitious — the one giving more in-depth sight etc . ) , and then read the content of chosen book with the view to learn from it ( processing data for a given purpose ) . While in that simple as well as simplified example the students were given a limited amount of possible input data ( handbooks to choose from ) and they used their ‘ internal filters ' ( that is the mere human perception what proved to be sufficient to handle the size of input information ) the situation changes dramatically with the increase of number of data to be processed . For the number of years traditional medias like radio , newspapers and even TV have served not only as a source of information to people , but also as pre-filters of the information , providing the audience with data which for some reason were considered to be important or worth mentioning . '° With the raise of the World Wide Web , the situation has grown even more complex . The Internet appears to be almost bottomless source and repository of knowledge ; the volume of existing information fairly exceeded the state which Seneca already found excessive . Finding an Internet blog which interests us and fits our purposes might be quite difficult as apparently there are ca . 150.000.000 blogs on the Web. ' ! How to filter such volume of data or , in other words , how to reduce such amount of data to the dimension comprehensive by an individual ? This fairly exceeds the scope of the present paper , but in this context it would be interesting to notice psychological aspects connected with the filtering big volumes of information , namely the information anxiety , fear of processing not enough information , of having filtered too less data what could subsequently negatively influenced our further actions . ' ” In order to cure such and other problems , as David Wienberger indicates , “ we have rapidly evolved a set of technologies to help us . They fall into two categories , algorithmic and social 10See : Cass R. Sunstein , Republic.com 2 ( Princeton and Oxford : Princeton University Press , 2007 ) at 29-32 . `` How Many Blogs are on the Internet , WPVirtuoso , online : < http : //www.wpvirtuoso.com/how-many-blogs-are-on- the-Internet/ > . The author does not provide source of these data , thus the mentioned number remains unconfirmed . Because of technical reasons it can be only , accurate or not , estimation . It does not however differ substantially from the similar calculations which can be found . For further information please see : David Weinberger , Too Big To Know . Rethinking Knowledge Now That the Facts Are n't the Facts , Experts Are Everywhere , and the Smartest Person in the Room Is the Room ( New York : Basic Books , 2011 ) at 9 . 6 Living in The Filter Bubble ( ... ) . Although techniques use the vast memories and processing power of computers to manipulate swirling nebulae of data to find answers . The social tools help us find what's interesting by using our friends ' choices as guides. ” ' ? These two techniques are both employed in processing Internet data and importantly , as Wienberger also accurately points , they are usually both combined . This is the case of the modern Internet search engines — technology which changed the way we filter and process data and which , as we are going to see , have very meaningful repercussions on how do we perceive the reality . 2 . Internet Search Engines Alexander Halavais indicates that the term “ search engine might refer to an information retrieval system that allows for keyword searches of distributed digital text. ” ' * Even though he refers to a search engine in general , he clearly means the Internet search engines explaining further that “ while a search engine is usually a system that indexes web pages , the term has been extended more broadly to include range of information environments and media forms , including multimedia and other content found on restricted intranets and individual computers. ” ' > The idea of Internet search engine is generally as old as Internet in its modern form - the first search engine was invented in 1990 . '° Since then we could observe a rapid development of search mechanisms out of which one has become particularly well known . In 1996 two students of Stanford University , Sergey Brin and Larry Page , came up with the algorithm called PageRank . ! ” In two years later , the same students incorporated the small company , giving its creation the little-then-meaning name Google . '® The rest remains the history . In order to move forward , to analyse a phenomenon of so-called filter bubble we might live in , there are several comments to be made on search engines . These are merely observations concerning the manner and environment in which the search engines operates , however each of them should be given a high significance while attempting to create any regulatory framework David Weinberger , supra at 9 . “ Halavais , supra at 5-6 . Ibid . '6Interestingly it was invented by a student of McGill University , Montreal . See : Tom Chatfield , 50 Digital Ideas You Really Need to Know ( London : Quercus , 2011 ) at 36 . `` Chatfield , supra at 36-37 . 18Tbid . Living in The Filter Bubble ( what in my view could be of certain benefit ) concerning Web search and filtering and while trying to discover whether there is any problem with the way the search engines operate at all . There are at least four comments to be made . Firstly , obvious as it is , the search engines play very important role in the day-to-day life of millions of people all around the World. ' ? Secondly , the search engines field remains widely non-regulated space , what apparently is an exceptional case among information intermediaries. ” ° Thirdly , the search services market is dominated by several major players out of which just one name has been vigorously discussed both by public and antitrust regulatory bodies. ” ! Finally , the way in which a search algorithm operates is far way more complex than an average person could expect and usually takes into consideration not only fact-based criteria , but also whole volume of personal information on an engine 's user . Interestingly , the survey published in 2012 indicated that 66 % of respondents agreed with the statement “ Yes , I think Internet search engines are a fair and unbiased source of information . ” ? The last observation forces us to ask questions as to the nature of personalization of search results and will lead us straight to the next section of this paper . Before that happens the abovementioned comments deserve some further explanatory remarks . The role which search engines play in modern societies is undeniably great and at the same time ( maybe quite surprisingly ) appears to be inversely proportional to the interest regulators put in the search engines . Leaving behind the complex and usually well-justified reasons of the lack of general regulation of search engines , in order to prove to what extent the search engines play the important role in our lives the following numbers might be helpful . The Paw Internet study from 2012 indicated that 91 % of Internet users uses search engines too , what has always been — next to using an email — the most popular activity on the Ken Hillis , Michael Petit & Kylie Jarrett , Google and The Culture of Search ( New York and London : Routledge , 2013 ) at 3-4 . 2°See for example : The Structure of the Mass Media and Government Regulation , Cliffs Notes , online : < http : //www.cliffsnotes.com/more-subjects/american-government/the-mass-media/the-structure-of-the-mass-media- and-government-regulation > . For more information see for example official Federal Communication Commission site : < http : //www.fec.gov > . 21As to the antitrust proceedings against Google see for example : Federal Trade Commission . Statement Regarding Google 's Search Practices . In the Matter of Google Inc. , FTC File No . 111-0163 ( 2013 ) and Google Inc. Commitments . Foundem and Others , Case COMP/C-3/39.740 ( 2013 ) . The Pew Research Center 's Internet & American Life Project Winter 2012 Tracking Survey ( January 20- February 19 , 2012 ) , online : PewlInternet.org < http : //www.pewinternet.org/files/old- media/Files/Reports/2012/PIP_ Search Engine Use_2012.pdf > . See also : Kristen Purcell , Joanna Brenner , Lee Rainie , Main findings , PewResearch Internet Project < http : //www.pewInternet.org/2012/03/09/main-findings-11/ > . 8 Living in The Filter Bubble Web. ” ? Out of all search engines users , more than the half do it at least once a day . The numbers should be found convincing , however their true significance is clearly revealed when confronted with the actual number of Internet users world-wide , amounting to nearly three billion people at the end of the year 2014 . Even though this is the statistic and therefore the numbers are by their nature arguable , they clearly show that ( as to the principle ) when we discuss the role of search engines we refer to the phenomenon which is a part of everyday life of most of us . This is just one reason why the issue of information filtering deserves proper attention . Moreover , it should be noticed that because of the extent to which we use search engines , they have become leading intermediaries in people 's access to information , news etc . Like other entities or mechanisms of such kind , they are regulated , however , in this author ’ s opinion — to the lesser degree and with the less holistic approach. ” While TV , radio or newspapers and magazines industries are widely subjected to legal rules posed by governmental bodies , the search engines ( which apparently have started playing a role similar to the one the mentioned mass media means used to play in the past century ) are somehow out of scope of media regulation , besides several commercial aspects arising from the antitrust law , content liability and advertising . * ° Deciding not to evaluate whether it is good or bad situation , it is worth to realize that our everyday filter of information is generally not subject to any other verification than of its own , private-based creators . Mentioning search service providers , what a word comes to your mind first when hearing the term 'search engines ’ ? Basing on different researches , there is from 65 to 90 % chance that this word was 'Google'. ’ The Silicon Valley potentate is undeniably the most popular search service provider all over the World , even if its dominance over concurrence in different jurisdictions varies . In fact , Google managed to become to some extent a generic name for a search engine and for a search process . You might not believe it ? ‘ Just google it . ' Under the record 'to google ' in The Oxford English Dictionary the following definition can be found : “ to search for information about ( a person or thing ) ( ... ) ” . ? 8 While Google nowadays is certainly Ibid . See also : Hillis , Petit & Jarrett , supra at 3 . Internet Users in The World ( 2014 ) Internet Live Stats , online : < http : //www.internetlivestats.com/internet-users/ > . 25 For more information on overall regulation of search engines in U.S. please consult : Urs Gasser , “ Regulating Search Engines : Taking Stock and Looking Ahead ” 8:1 Yale Journal of Law and Technology 201 . 26 See : Ibid at 216-219 . `` The Pew Research Center 's Internet & American Life Project Winter 2012 Tracking Survey ( January 20- February 19 , 2012 ) . See also : Hillis , Petit & Jarrett , supra at 3 . * ®The Oxford English Dictionary , online : < www.oed.com > . 9 Living in The Filter Bubble something much more than merely search services providers , the PageRank mechanism and its subsequent developments remained the core part of Google 's business . That company is not the only player present in the market . There are other services providers out of which only few however are worth mentioning e.g . Bing , Ask.com , Yahoo or Baidu . The fact is , that even though we might find several entities competing in the market , the researches show that just three of those companies hold at least over 90 % of the market. ” ? The number even grows , depending on jurisdiction but as to the principle never decreases . This reveals another important circumstance regarding the reality which any possible regulation or change concerning the search engines needs to take into account — the search services market is almost fully dominated by the three companies , if not monopolized by one of them . While the economical perspective falls out of scope of the present paper , this might make us wonder about the fact that these are practically no more than three private entities which act in the realm of Internet as information intermediaries and filter for us relevant information from trifles . While it is hard to argue that this is not the case of traditional mass medias , with the leading example of Mr. Murdoch 's empire , yet the described situation might rise questions as to the neutrality of search results , their accurateness and quality.°° Being aware of the above , in order to decide whether there could be any kind of problem with the current state of search engine services , one need to at least briefly analyse the scheme of manner in which the search process is operated . As to the principle the following remarks concern all search engines — functions and general structure of each of them are the same. * ! In its simplified version , the whole process can be framed into three interdependent stages : ( 1 ) providing input data , ( 2 ) processing a query and ( 3 ) obtaining a search record . * ” At each of these stages several important questions should be asked and answered in order to fully understand significance of each process step for the overall scheme . As to the initial query it is relevant to realize what kind of information do we seek . Is that information we need or we think we need , or , the one we want or think we want ? Do we know exactly what we are searching for ? What do we expect to find by making a given query ? These are the thinking points referring primarily to The Pew Research Center 's Internet & American Life Project Winter 2012 Tracking Survey ( January 20- February 19 , 2012 ) at 35 . Baidu operates in only in Chinese market . Keith Robert Murdoch is an owner of News Corporation which owns , among other , The Sun , New York Post , The Times , Daily News , British Sky . 31Halavais , supra at 14 . > See : Ibid . 10 Living in The Filter Bubble the psychological aspect of the individual in his pursuit of knowledge . As to the second stage of the process we might want to know how the search algorithm operates . What kinds of criteria are taken into account in determination of relevance of search results and which criteria are decisive . Is the search engine value-neutral ? Does it prefer some records from the others ? Is the used algorithm transparent and comprehensive ? Lastly , when the input data are processed by the search engine what we receive are search results . Are they accurate ? Are they satisfactory ? Do they answer the initial query ? Do they respond for the query we actually made or we think we made or even — what is more and more often the case currently — the query of which the algorithm somehow knew we had wanted to make it in real ? Is the search result something we wanted to see or the particular outcome is something what someone else wanted us to see ( what about advertisements ? ) ? That third set of questions obviously refers to the very core reason for which we use search engines , namely obtaining accurate and trustworthy results and so thus an answer for our question . As indicated above , these three stages are interdependent , but not only in the way in which input information influences processing of data and subsequently obviously the results . The web of connection is much more complex as e.g . the search results of one query influences the others . We already learned from Weinberger that both the algorithmic and social techniques are employed . The high-end complex search engines take into consideration whole volume of personal data of its user and notably of other ( correlated or not ) users : browsing history , former queries , established habits , strictly personal information , geospatial data etc . * ” The analysis of these data allows the engine not only to process the query but also to influence the content of query itself throughout the system of automatic suggestions . What in my view emerges from the above scheme is that the level crucial for the whole process is the second stage of it — the query processing . Although arguable , if we acknowledge the dominant role of search engine in the process ( and even more importantly the extraordinary level of influence the search engine has on the other stages of the process ) we would need to realize that any possible regulation of the Internet-based information search needs to focus exactly on that element , if only intended to be effective . As we will see in the last chapter , this notion is not isolated and at the same time creates certain troubles . In fact , in strictly legal terms very few information used by Google in its search algorithm are personal information in statutory meaning . The algorithm generally operates on 'depersonalized ' data . Still , the fact remains , that even though these data are not personal in legal terms , they are of importance from the privacy perspective and are ‘ personal ’ in the ordinary meaning . See : Randall Stross , Planet Google . One Company 's Audacious Plan to Organize Everything We Know ( New York : Free Press , 2008 ) at 64 . 11 Living in The Filter Bubble More than ever before and to the greater extent , the key element of the process of filtering information is now the search engine . That is due to the dimension of use of personal ( in its wide meaning ) data regarding users . These data are collected , processed and used with one purpose — to provide more accurate and more satisfactory search results . Worth mentioning , the search records are to be accurate and satisfactory from the subjective individualistic perspective — the use of subjective criteria to determine the search results implies that the results would be also subjective . To the great extent , all Internet search results are personalized , to fit better the search engines ' users . The underlying explanation is that by personalization of search records users are granted faster and more effective access to the information . But what if it is just the half of truth and the personalization has further , less desirable consequences ? 3 . Do We Live im the Filter Bubble ? In 2011 Eli Pariser * published the book under the title “ The Filter Bubble . What the Internet Is Hiding from You ” . The main argument of the book has been widely disputed since then and while there are several voices opposing Pariser ’ s findings , * > most of the public has been attracted with the smoothness of idea of phenomenon he described . In short , due to the personalization of the content , although still free to choose what we read and find on the Web , we lose the freedom as what we see on our screens depends less and less from our actual choices but rather from what someone ( or more accurately - something ) else chooses for us . Quite ironically , what has been chosen for us is to the big extend decided upon our former decisions and preferences . The significance of our small everyday Internet choices has been strongly amplified as the content we find on the Web is more and more tailored for cach of us , with the aim to let us see more of the content we want , more of the information we seek and more experiences we want to share . In the result we might find ourselves to be closed in the filter bubble — our own sphere where interests are satisfied to the greater extend and where the access to any information or experience we want is easier and faster than ever before . That is the positive side of the results of personalized filtering giving the huge significance to our personal needs and choices . On the other hand , what was not often being mentioned before Pariser ’ s 4US . Internet and left-wing political activist , born in 1980 . 35 See for example : Louis Grey , Why The Filter Bubble Is No Bubble and It 's Not Bad Either ( 2011 ) Louis Grey Blog , online : < http : //blog.louisgray.com/2011/05/why-filter-bubble-is-no-bubble-and-its.html > . 12 Living in The Filter Bubble publication , there is a whole class of data which is left beyond our bubble , the access to which is in fact harder as in order to reach such information one need first to ‘ pop ’ the bubble surrounding him or her . * ° While familiarizing with Pariser ’ s idea , one might wonder whether it is the real problem — the filter bubble does not create any psychical and actual barriers for access to other data than those which can be found ‘ inside ’ the bubble . Weinberger rightly points that “ Filters no longer filter out . They filter forward , bringing their results to the front . What does n't make it through a filter is still visible and available in the background. ” % ’ The whole point is however , that in order to find what we are looking for we need first to be aware of its existence . Even if the bubble does not stop us from searching for content on the Web , it does however hide a big part of it from us , making it less or not visible at all . Provided we find a value in pluralism of thoughts that might be quite a problem . Yet , it must be noted that the filter bubble is not just the phenomenon regarding the way in which current search engines operate . Regardless our opinion , the fact is that personalization is present everywhere on the Web . * * Everywhere . Robert W. McChesney notices that “ Pariser's Filter Bubble documented how the Internet is quickly becoming a personalized experience wherein people get different results on Google searches for identical queries ( ... ) They are soon to get different websites on the screen than other people who enter the same URL. ” * ° In 2010 Google CEO Eric Schmidt predicted : “ The technology will be so good , it will be very hard for people to watch or consume something that has not in some sense been tailored for them. ” * ° This tells us something about our reality — there is less and less space for our idealistically understood free choice in the Internet medium as well as less freedom of free speech as the possible audience has been closed within its own filter bubbles . John Parry Barlow ‘ ! is his famous “ Declaration of the Independence of Cyberspace ” claimed that “ The global conveyance of thought no longer requires your < i.e . governmental > factories to accomplish. ” underlining the 36 Edi ~=s- Pariser , Beware online “ filter bubbles ( TED Talk , 2011 ) online . TED.com < http : //www.ted.com/talks/eli_pariser_beware_online_filter_bubbles ? language=en > . 37 Weinberger , supra at 11 . * 8Pariser , The Filter Bubble at 8 . For further reference see also footnotes there . Robert W. McChesney , Digital Disconnect . How Capitalism Is Turning The Internet Against Democracy ( New York , London : The New Press , 2013 ) at 157 . “ Pariser , The Filter Bubble at 47 after Holman W. Jenkins Jr , Google and the Search for the Future ( Wall Street Journal , Aug. 14 , 2010 ) . 41Co-founder of the Electronic Frontier Foundation , to some might be better known as a musician of Grateful Dead . “ John Perry Barlow , A Declaration of the Independence of Cyberspace ( Davos : 1996 ) , online : Electronic Frontier Foundation < https : //projects.eff.org/~barlow/Declaration-Final.html > . 13 Living in The Filter Bubble freedom of Web and circulation of thoughts or ideas on the Internet , which where underlying promises of this communication mean . Well , that might not be a case anymore as apparently even without any ‘ help ’ from governmental bodies the Barlow ’ s vision of the extent to which the free speech is ensured on the web has been slowly turning into the past . The filter bubble in Pariser ’ s view is the sum of all personalization mechanisms we are forced to use during surfing the Web. ? While it would be an exaggeration to claim that just one website , service etc . can limit us from recognizing the existence of ‘ other ’ content and create our own bubble , it is important to notice that there is in fact only one kind of services which always plays big role in the creation of the filter bubble . The one which is used by nearly all Internet users out of which more than the half use it on daily basis . If only there is one decisive factor and mechanism contributing to the existence of the personalized closed bubble for each of us , this is the search engine . The role of search engines in creation of the information cocoons is a simple derivative of significance we give to such services by using it every single day . The dimension of that phenomenon has already been described above . Additionally , referring again to our previous findings , it is worth to realize that the search engines are modern information intermediaries and to the great extent they have replaced the traditional mass media . While hearing the news it is easier and faster to type the query on the phone search than to find a pilot and launch a TV , in order to hear more of on the given topic . While most of the websites include both some kind of search mechanism and personalized content , still it is more about the content possible to find on the site than about filtering it . As to the contrary , search services providers focus much less on the content and more on the filtering of what already exists in the depths of the Web . As the filtering is the key process for the creation of bubbles , the key generator of our reality is who or what filters the information for us . I am far from making such exaggerated statements like “ What does not appear on the first site of Google search results does not exist at all ’ , however one can not deny that there is some point in such belief . In order to deliver personalized search results Google takes into account tens of different factors. “ As indicated before , that comprises e.g . our localization , other geospatial data , type of browser we use , our previous browsing history , our previous clicks on search results , former queries as well as whole bunch of public or personal ( not in strict legal sense ) data on our “ Pariser , Be Ware of Filter Bubbles . “ Danny Sullivan , Dear Bing , “ We Have 10,000 Ranking Signals To Your 1,000 . Love , Google , ” Search Engine Land ( November 11 , 2010 ) , online : < http : //searchengineland.com/bing-10000-ranking-signals-google-55473 > . 14 Living in The Filter Bubble activity on the Web , consumer preferences etc . Because of the variety of information the complex algorithm uses for processing purposes , there is no an easy way out , no obvious solution to escape personalization . Certainly , every individual might tick the box ‘ opt-out from personalization services ' on Google ’ but this could just partial and none systemic solution . The problem in question overlaps with the issues of privacy and control over personal data on the Web . The rise of Information Age and universe fast access to Internet has revolutionized our thinking about privacy and materially decreased the sphere of life which still can be firmly described as fully private . Unlike many people might think , everything what one does on the Internet is visible and leaves a trace . It constitutes information which in the modern World in economic terms is practically a commodity , as has value to many companies present in the market . * 5 Elementary deduction based on the set of information on a given user might easily lead to discovering other , more vulnerable data . Google and other search engines gathers those information to provide what they describe as better and more accurate search services . Because of the complexity of this process and the huge volume of data concerning ourselves we publish or make available every single day , there is no easy way to stop personalization . Besides , even if we manage to opt out from personalized search services that only decreases the bubble — it is not possible to opt-out from the personalization of Web as it became fully personalized . To quit personalization practically means to stop using the Internet . Therefore , the filter bubble develops and it is hard to expect that this trend would revert . On the other hand — why should we want the trend to revert ? We might live in the filter bubble , however as I presume basing on my own experience such situation is not unpleasant to our minds . Quite to the contrary , I am of view that many would agree that they truly enjoy the search results they obtain as they find them trustworthy and handful . In fact , as already shown , the statistic provides that most of us find the search results accurate and unbiased . The personalization mechanism makes the search service more tailored to my needs . I can find the information I seek faster and access it easier . If for years e.g . I used to go to RPA for holidays I am glad to find a good new hotel and current car rental offers on my search . I am not necessarily interested in learning on economic and political issues as well as on apartheid and Mr. Pistorius ’ judicial proceeding . I could , but I might not want to . Is there any problem then ? Is there any * Brian J. Perry , “ Is Information a Commodity ? ” ( October 20 , 1999 ) online : National Institute of Informatics < http : //www.nii.ac.jp/publications/kaken/HTML1999/99Perry02-E.html > . 15 Living in The Filter Bubble reason I should or should want to ‘ pop ’ my filter bubble and subsequently use less comfortable non-personalized search engines ? II . _—_— Personalized Filtering - What Can We Lose ? Search Engines Bias and Democracy . “ Everything which bars freedom and fullness of communication sets up barriers that divide human beings into sets and cliques , into antagonistic sects and factions , and thereby undermines the democratic way of life. ” John Dewey “ At the dawn of Information Era , in 1995 Nicholas Negraponte , the MIT engineer , faced the problem most of us might have experienced and which some people tend to escalate on Saturday evenings into the one of the most important problems of human mankind — what to watch on TV while there is literally nothing interesting there ? * ’ Instead of solving this vital problem , Negraponte predicted that the problem itself could easily disappear if only the future TV was personalized so thus instead of watching news or any other general programs or channels any person in front of a TV screen would receive an information package tailored just for him or her . Such package would be “ printed in an edition of one ( ... ) Call it the Daily Me. ’ * * The prophecy has proved to be right — as already shown , the personalization mechanisms are present everywhere and even to the greater extent on the Web than on TV . The personalization of content in its current form , where this is the third party who decides what the effect of personalization is , and where an Internet user has in fact little control over what he or she sees on the Web , leads to the situation where “ you don ’ t need to create a Daily Me . Others can create it for you ( ... ) can discover , and tell you , what ‘ people like you ’ tend to like ( ... ) in a matter of seconds. ’ Notably , on the Internet these are not governmental but private entities who decide on personalization of content we find , including the search engines realm . In this context , Sunstein , in his well-known early Internet age piece “ Republic.com ” poses a question : “ How will the increasing power of “ John Dewey , Essays , Reviews and Miscellany , 1939-1941 , The Later Works of John Dewey , 1925-1953 . Vol . 14 ( Carbondale : Southern Illinois University Press , 1998 ) at 227 . * 7Pariser , The Filter Bubble at 22 . Sunstein , supra at 4 . * 8Negroponte , supra at 153 . “ Sunstein , supra at 4 . 16 Living in The Filter Bubble private control affect democracy ? ” * ® While the question is extremely broad he further gives focus to the interplay between filtering information and freedom of speech as the democratic value , presenting two requirements which must be met to create an effective system of democratic free expression : “ First , people should be exposed to materials that they would not have chosen in advance ( ... ) Second , many or most citizen should have a range of common experiences. ” He calls for pluralism and circulation of thoughts and ideas within the civic society , what unarguably is crucial to its existence . The principal problem connected to the personalized filtering of information ( and therefore to the search engines ) is that it neither foster pluralism of thoughts , nor strengthen sharing common experiences between members of the society . Moreover , the threats arising from the manner in which personalization of content is made are that it ultimately limits pluralism and might effectively block us from sharing experiences , discussing different opinion and therefore weaken the very principle mechanism on which democracy is based — freedom of thought and their exchange . As noticed above , many could argue that there can not be any threat to pluralism as the search engines technically do not block the access to any information , they filter forward instead of filtering out . Still , the underlying question is here not whether there is pluralism of thoughts on the Web , as it undoubtedly exists , but rather whether the quality material access to diverse information is ensured and people have a real chance to be exposed to other views . Halvani notices that numerous ethical concerns as to the functioning of search engines might be organized in “ four broad categories : ( i ) search-engine bias and the problem of opacity/non-transparency , ( ii ) personal privacy and informed consent , ( iii ) monitoring and surveillance , and ( iv ) censorship and democracy. ” > ' The second and the third ones fall out of the scope of the present paper , while the first and the last categories overlap — in my view the search engines bias greatly contribute to the creation of possibility of threat to democracy , what I will try to picture in this chapter . The brief analysis of them would bring us the broader picture of how search engines ' contribution to the filter bubble poses threats to the values we embodied in the society and to our political system of “ the rule of the people , by the people , for the people ” . > As already established , the search engines greatly contribute to the creation of Sunstein , supra at 5 . Even though I use the second edition of his book , published in 2007 , in its core its is just revised and enhanced version of the previous Republic.com published six years earlier . ! Halvani , supra . Lech Walesa , Address to the U.S. Congress ( Nov. 15 , 1989 ) text of the speech available online : Milestone Documents < https : //www.milestonedocuments.com/documents/view/lech-wasa-address-to-the-u.s.-congress/text > . 17 Living in The Filter Bubble information cocoons we might live in . The form and the content of the bubble - and therefore our perception of the World , pluralism we notice and experiences we share — highly depend on the manner in which information are filtered for us . In this context , many authors indicate possible “ search engines bias ” under which term the following general concerns can be understood : that “ ( L ) search-engine technology is not neutral ( ... ) ( 2 ) major search engines systematically favor some sites ( and some kind of sites ) over others ( ... ) ; and ( 3 ) search algorithms do not use objective criteria in generating their lists of results for search queries. ” Starting from the first of mentioned doubts , if the search engine is value-neutral our cocoon will be too ; if the search service is not biased and provides truthful and trustworthy results , the data bubble around us will reflect the objective reality and therefore will not be biased neither . * * However , there are several ground to claim that this is not the case . Quite to reverse , “ while some users may assume that search engines are “ neutral ” or value-free , critics argue that search engine technology , as well as computer technology in general , is value-laden and thus biased because of the kinds of features typically included in their design. ” * > Going further , Introna and Nissenbaum indicate that the search engines “ systematically exclude certain sites and certain types of sites , in favor of others , systematically giving prominence to some at the expense of others. ” °° One of the many reasons of such concern is the fact that all relevant search engines are private-based and private- sponsored. > ’ For Google Inc. , the Web search advertising still remains the most crucial and income-gaining part of its business.° * The doubt in question has been for long recognized by the stakeholders : “ We expect that advertising funded search engines will be inherently biased towards the advertisers and away from the needs of the consumers ( ... ) The better the search engines is , the fewer advertisements will be needed for the consumer to find what they want ( ... ) We believe the issue of advertising causes enough mixed incentives that it is crucial to have a competitive search engine that is transparent and in the academic realm. ” Tronically , these are the very own words of Google ’ s co-creators , which they wrote in 1998 . * ° Moreover , many * Halvani , supra . For sake of those consideration , let ’ s assume that there is some sort or form of objective reality or at least the reality we might agree to deem for some reasons to be objective . * Halvani , supra . Lucas Introna , Helen Nissenbaum , “ Shaping the Web : Why The Politics of Search Engines Matters ” 16:3 The Information Society 169 . * 7Halvani , supra . Omar El Akkad , “ Google falls short as ad business shows cracks ” , The Globe and Mail ( October 17 , 2014 ) B1 . Sergey Brin , Lawrence Page , “ Anatomy of a Large-Scale Hypertextual Web Search Engine ” Section 8 Appendix 18 Living in The Filter Bubble companies and individuals present on the Web try to manipulate search results by introducing various search engine optimization . To appear on the first page of Google results is often crucial to the mere existence of the business , as “ Jn the world of Web , esse est indicato in Google : to exist is to be indexed on Google. ” ® Additionally , the problem of search algorithm objectivity arises , particularly as to “ ( A ) objectivity regarding criteria used in search algorithms ; and ( B ) objectivity with respect to the results returned by a particular search engine in its responses to multiple users entering the same search query. ” ® ' Importantly , we must acknowledge that any discussion on the first remark is fundamentally biased as the algorithms used by search services providers are not publicly known and therefore cach discussion is to some degree hypothetical . The lack of transparency is often raised in the literature as a separate fundamental problem of search engines itself , as well as an obvious field were the possible remedy can be found. ” Hinsman seems to believe however , the search algorithm should remain unrevealed to the public.© All in all , they are trade secrets of the companies. “ Additionally , if the manner they operate was fully known to the public , that would only equip the stakeholders with new tools and possibilities of search results optimization and manipulation , what would probably not fix the more general problem of search engine possible bias . We know however , that the numerous and various criteria are taken into account for processing each search query and that they are aimed to provide personalized results . Pariser in his book gives various examples of how different search results people might receive while making the same query on Google ’ s website . The phenomenon of Web personalization is therefore another ground on which the search engines bias can be found . Personalized content is different for each user ; it does not allow to share experiences as they are differently tailored for everyone ; it does not facilitate the access to opposing views as such opinions are not the part of one 's 'Web identity ’ and are in fact in the contrary to it . These observations lead us to the next out of two Halvani 's general concerns indicated at the beginning of this chapter — the ethical interplay between democracy and search engines . A , online : Stanford.edu < http : //infolab.stanford.edu/~backrub/google.html > . 6° ] awrence M. Hinman , “ Esse est indicato in Google : ethical and political issues in search engines ” 3 International Review of Information Ethics 20 at 21 . 61Halvani , supra . ®Halvani , supra . Hinman , supra at 22 . Tbid . Tbid . 19 Living in The Filter Bubble The possible search engines bias ( and the biased filter bubble being created in the result ) could equally significantly contribute to threatening the democratic ideals and democracy itself . As indicated above , the threat of some kind of censorship has been recognized by Introna and Nissenbaum , while the same authors acknowledge that there are possible advantages of Internet as it could “ give voice to diverse social , economic , and cultural groups , to members of society not frequently heard in the public sphere [ and ] empower the traditionally disempowered , giving them access both to typically unreachable modes of power and to previously unavailable troves of information ” °° The search engine bias might have important impact on pluralism of thoughts in the society , as the search engines direct users “ towards some content and not others , towards some sources and not others. ’ ’ ° ’ The US Supreme Court in 1945 ruled that “ the dissemination of the widest possible information from diverse and antagonistic sources is essential to the welfare of the public ” ® what is generally the core of the concept of deliberate democracy . It is generally agreed that in order to let democracy function well , the members of society need to not only to have a chance to access to the opposing views but actually be exposed to the different views and opinions. ” It might not be a case in the World where we all live in the filter bubbles . So the ultimate question is whether the search engines , creating information cocoons around us , somehow block us from being exposed to the views being contrary to ours . This lead us subsequently straight to the question on the intermediary role , the search engines play in the realm of Internet . Many commentators underline , that the search engines are modern gatekeepers to knowledge. ’ ! Like the traditional mass media before , Google and other filter information for us . The promise of Internet was to eliminate any intermediaries and to give people unlimited direct access to all kind of information. ” With the raise of massive private-sponsored search engines that promise has been revised and the questions then actual as to the traditional mass media became once again current and important in the cyberspace . Diaz accurately summaries this situation in the following way : “ So when Steven Levy ( 1995 ) said that “ instead of a gatekeeper , ®Introna , Nissenbaum , supra at 169 . 7A . Diaz , “ Through the Google Goggles : Sociopolitical Bias in Search Engine Design. ” in A. Spink and M. Zimmer ed. , Web Search : Multidisciplinary Perspectives ( Berlin : Springer-Verlag , 2008 ) at 11 . °8 Associated Press v. United States , 1945 U.S. Supreme Court [ 1945 ] 326 U.S. 20 . “ Diaz , supra at 12 . Hinman , supra at 25 , “ Halvani , supra . ™Pariser , Beware of The Filter Bubbles . 20 Living in The Filter Bubble users get an open invitation to the electronic world and can choose whatever they want ’ , he was being less than accurate . Internet users do get a gatekeeper — the search engine — and they choose primarily among the sites it offers to them . As with all such intermediaries , we expect search engines to present the available information in a fair and diverse manner ; we expect them , in other words , to be “ democratic. ” We should ask about search engines like Google the same questions scholars have asked about the traditional media : Can underrepresented voices and diverse viewpoints be heard through the filter of search engines ? What role does advertising play in the returned results ? Do a few players dominate the industry ? Only by answering these questions — as we will do in turn — can one assess the true “ deliberativeness ” of the Web itself ” ? These questions ask for what kind of intermediaries we want to have between us and information we seek . Therefore , we can not stick to the thinking on the search engines as merely private services , while they play very important public role too . In my view that justifies public interest in the way Google and others run their businesses and attempts to regulate it . Following that , in order to realize , what I argue , that there might be quite a problem with the effect of search engines on the society another remark must be made . People have embodied internal ethic , so do the information intermediary of the past . The content we could find on the pages of newspaper , on a TV screen and on radio used to be chosen for us by the group of people , individuals , program boards etc . Certainly , there was always present threat that these people would act in morally doubtful manner while choosing what to show to the public or not . The example of the remedy used in the past is the so-called fairness doctrine , “ once requiring radio and television broadcasters to devote time to public issues and to allow an opportunity for opposing views to speak. ” ” * Unlike their human equivalent , the new cyber intermediaries do not have ethics . Obvious as it is , the algorithm itself has no moral sense as to what should be shown in search results . As the role which the human beings and machine accordingly used to play and currently play is as to the principle the same , should we expect from them the same — to be responsible for the quality of information they forward ? It is important to realize that even though the search engines might not have any ethics or might be value-neutral , their creators must have some moral views or other aims which inherently influence the form and operation manner of the engines . As these mechanisms are not ®Diaz , supra at 15 . “ Sunstein , supra at 72 . 21 Living in The Filter Bubble transparent , we do not know whether they prefer some site or view than the other because they were ‘ told ’ to do so . What we however know is that they are generally fully controlled by the three private companies , incorporated with the view of creating financial profit . And as much as we want to believe that they act for our common good in the best case they act a/so for the common good . I do not argue that the present situation is materially different from the private- founded mass media companies , besides the ‘ ethical ’ difference indicated above . I am rather of the view that , as Diaz suggested , we need to deserve from the search engines the same as from any other relevant information intermediaries . We should expect them and possibly force them to work for the good of society and not to the contrary of democracy and its ideals . II . Is There Space For Regulation ? Responsibility Over Comfort . In this final chapter I am going to elaborate on the following question : is there any space for regulation of the problems we previously identified ? My argument is that the current state of affairs does not leave much space for any regulatory framework ( yet there might be some possibilities , among others , to regulate architecture of algorithms throughout various means , including both soft- and hard-law ) . I do not intend to provide the deep in-sight into regulatory possibilities , rather to come to some general conclusions on regulation . However , what in my view ultimately emerges from this analysis is that at the end of the day the only sphere where changes might happen now lays beyond the elements of information search process we have previously identified . Pathetically as it sounds , if we want to preserve some democratic ideals , the change needs to start from ourselves . It is about the little everyday choices — comfort over responsibility , to act more consciously or to remain pleasantly negligent . In his well-known classic piece “ Code ” Lawrence Lessig indicated four regulatory factors of each given situation : ( 1 ) the market , ( 2 ) architecture , ( 3 ) law and ( 4 ) social norms. ” > The scheme aspirates to be universally applicable for each and every class of situation , when it comes to regulation of any issues connected with broadly understood technology . ’ °I find it helpful for a purpose of analysis of the case of search engines and filter bubbles too . The regulation by the ( 1 ) market forces is unrealistic and therefore unlikely to happen . ™Lawrence Lessig , Code . Version 2.0 . ( New York : Basic Books , 2006 ) at 120 . See : Ibid . 22 Living in The Filter Bubble The search engines market is dominated by several international corporations with the strong position of the dominant company . In economic terms that situation can be easily described as an oligopoly being actually close to a monopoly . That does not leave much space or create a need for the market self-regulation . Besides , I doubt whether the issues of deliberative democracy , pluralism of thoughts and access to information might be efficiently and correctly regulated by market forces , which have ( as to the principle ) an economic nature . Probably they could somehow contribute to ensuring the existence of mentioned values ; however , as they tend to fall out of scope of interests of economics I would exclude possibility to efficiently regulate the said problem by the market forces . The ( 2 ) architecture of search engines is the field where the changes theoretically can happen more easily than in other fields , as we identified it in the first chapter . All we need is the decision of engines ’ operators to employ their creations to work for our good in broader sense as they allegedly do it now . There are , however , too many unknowns in the discussion on fixing the architecture of algorithms . As noted above , we do not know any of these algorithms for real as they are trade-secrets . Therefore , we even do not exactly know what can be changed . Still , the search engines are created and being operated by people . If we believe that algorithms create the filter bubbles for us and threat deliberative democracy , we should try to influence their creators . That would be ironic indeed to try to protect deliberative democracy and not to use its principal tool — discussion and exchange of thoughts and ideas . There are firm grounds for the discussion in case of the ( 3 ) legal framework . I found the problems described in the second chapter of the present paper to be the sufficient non-legal justification for regulation , so thus also — or rather primarily , as we voluntarily subject ourselves under the rule of law ” — for legal regulation . In order to act however , the legislators ( or judges if we believe that the change can happen throughout precedents , over which process there would be no general control ) need to identify the clear legal basis for regulation first . Without going into details , in my view the pluralism of thoughts and deliberative democracy are deemed to be not only non-legal values but also as legal ideals , embodied either in letter or the spirit of law . Finding the proper statutory basis or precedence for legislative action is however not sufficient per se . We discuss highly controversial issue as it refers to the values and possibly to the choice “ Whereas Canada is founded upon principles that recognize the supremacy of God and the rule of law ( .. ) ” , Canadian Charter Of Rights And Freedoms , Preamble . 23 Living in The Filter Bubble of balance which needs to be made between concurrent values present in the legal system . At the level of legal meta-norms , the question of legal regulation of search engines and information cocoons can be phrased as following : is there any legal value concurrent to deliberative democracy and its derivatives in the current system of law , and , if so , should that legal value be given a preference and therefore the regulation could not happen ? The proper in-depth answer for the above questions is not my aim and would deserve some further comments and analysis . I would like , however , to draw attention to the one particular circumstance which , personally , put me into doubts as to whether there is any space and need of regulation at all . So far we have adopted the approach of analyzing functioning of search engines throughout the prism of democracy and its ideals . The other possible approach is a commercial view . Search engines are aimed to provide commercial services . As we already established , they are provided by private entities , which were incorporated for one aim — gaining profits . None of the search engines operators would be keen on developing their inventions if they could not somehow cash it . While in my view there is a need of ensuring the public interest by regulating search engines , we need to realize that there is the great risk of excessive inference with very privately-based commercial issues . All in all , this is the choice of values to be made : private over public . Going further however , it is not hard to notice that on the site of 'private ' forces there is another class of stakeholders , namely us all — the search engines ’ users , consumers , members of society and citizens . Our position in the dispute differs significantly depending on the approach we adopt to analyse it — the individualistic or collective one . In the first scenario , me , an individual , I am entirely free to make my own choices and to enter into contractual relationships with anyone I choose . That embraces my freedom to turn on a computer , open a browser and make use of any search engine I choose . The following finding may in legal terms vary from jurisdiction to jurisdiction , but in broad terms by using search engine I , a consumer , conclude a contract with the service provider . I agree to the terms of use and to the clause on personalization of search results . As the service is allegedly free , I pay ' with my personal data , feeding up the algorithm with information which let it function better and better . Additionally , I know I will be exposed to advertisements as this is the way in which my service provider creates an income . By concluding the contract I agree to receive this and not the other service or product , which can be characterized , among others , by the following features : auto suggestions and personalized 24 Living in The Filter Bubble results . The transparency of the service is not the subject of contract as much as the knowledge of how they make fries and cheeseburgers is not a subject of agreement concluded with an employee of McDonald 's . If I feel cheated because I expected to receive the trustworthy and unbiased results , I should have read the terms of use first and familiarize myself with the features of the service . Still , I concluded it because I wanted to do so . Most probably , it is not the first and not the last time neither — I am quite satisfied with the service I receive , like millions of people every day . Usually I am able to find the desired information very fast . Using my search engine is convenient , handful and the service is rather accurate . Not to acknowledge the fact that people are rather happy than upset with the services provided by the search engines ’ * in my view means to omit very core of the problem of the possible legal regulatory framework . From the individualistic standpoint everyone is free to enter into contractual relationships , what subsequently embraces the freedom to shape these relations and their content . One could argue that if I am not satisfied with the 'product ' search engine operators 'sell ' me , than I am free not to use such engine . What is to some degree convincing from the individualistic perspective , does not necessary needs to be such from the collective standpoint . In the context of the important role the search engines play in the society as information intermediaries , the suggestion that I can simply stop using search engines is boldly simplified solution and therefore is not realistic — not to use the search engines is to resign on discovering the depths of Internet , being a bottomless source of data , crucial in the modern World ( and by these very words , following Introna and Nissenbaum I acknowledge the good features of the search engines ) . The individualistic argument underlining my free choice as to whether to use the search engines or not reminds me the ever-lasting argument in the discussions on privacy — ‘ one has nothing to fear if one has nothing to hide'. ” To the big extent we have less and less control over our privacy than it was the case several years ago and the level to which we enjoy privacy might in fact not depend from us anymore . The situation with search engines appears to be the same . The big question then is not whether I stop using the search engines or 78 “ 91 % of search engine users say they always or most of the time find the information they are seeking when they use search engines 73 % of search engine users say that most or all the information they find as they use search engines is accurate and trustworthy ( ... ) ” The Pew Research Center 's Internet & American Life Project Winter 2012 Tracking Survey ( January 20- February 19 , 2012 ) at 3 . For more information on use and misuse of the 'nothing to hide ' argument in on going public discussion on the privacy please consult : Daniel J. Solove , Nothing to Hide : The False Tradeoff Between Privacy and Security ( Yale University Press , 2011 ) . 25 Living in The Filter Bubble not , but rather how to ensure that the algorithms work for my good — understood either individualistically or collectively and idealistically — in both ways jointly . In collective terms there is much more to lose than to gain . While one person using personalized search engines is rather just a happy user of the Web tailored for him or her , from the point of view of society a mass of people exercising their right to freedom and free contractual relationships might be somehow scary , as in the result instead of civil society we would have a mass of non-interconnected individuals closed in their own information bubbles , each of them presenting rather polarized own views . Needless to say , this is not what the civil society is about . Therefore , to correctly comprehend whether there is a legal meta-norm , a value underlying the possible regulation one need to make a choice between personal , individualistic freedom and some kind of common , public good of civil society . Any future regulation needs to take these two approaches into account and balance them . Even though I do recognize that there is a threat to the society and its citizen — and therefore to the deliberative democracy we would like ( ? ) to enjoy , I am far from suggesting what the night choice here is . In fact , I believe there is nothing like 'the right choice ’ when it comes to telling the preference of one democratic value over another . The history gives us arguments for both sides . Too much personal freedom enjoyed by nobles of XVI-century Poland , combined with their lack of common identity ( we can call it ‘ the lack of shared experience ’ ) contributed to the collapse of the state which could be described as one of the longest-lasting progenitors of modern republics . On the other hand , we perfectly know the political systems created in the first half of the last century , which put the collective interest over the good of individuals in the hierarchy of values . We also know their consequences and the fact that they ultimately collapsed too . At the end of the day , it is all about balancing rights and values . Checks and balances — this is what the democracy is about , is n't ? The above considerations show that the principal question of legal regulation — whether to regulate or not at all — is extremely hard to answer . What emerges to me from the above analysis is that the big picture of the regulatory problem touches the issue of individual responsibility . The choice of values to be made by a legislator is in fact an echo of the question on responsibility each citizen , the member of civil society , should ask him- or herself . The society is strong by the strength of 1ts members and responsibility they take for the group . Needless to say , that it is not possible to create well-functioning democracy without the civil society which takes responsibility and shape the reality it functions in . With that , I must admit , 26 Living in The Filter Bubble somehow pathetic notion we come to the last of Lessig 's factors — ( 4 ) social norms . I argue that for now this is the proper ground where the most can be achieved . It is at the same time the field where the changes are the hardest to be introduced and followed . In the first chapter I concluded that out of three stages of search process this is the part concerning an algorithm where the possible regulation is most likely to happen and be provided . While I upheld the previous finding I wonder whether — bearing the nature of the choice-of-value problem - is n't it worth to draw our attention to the other stage of the process , namely the initial one ? Or even further , leaving the process behind , focusing on an individual being a rational for any search process to happen . In my opinion we might do so , provided that we see some chances of regulating the problem in question throughout the social norms . This regulation in idealistic words could be as following . People shall be aware of the way the search engines operate ; aware of the biases and possible threats . We shall use the algorithms consciously and do not stop on what is given to us by the engines ‘ on the plate ’ but pursue further for deeper and broader understanding of the given matter . In that pursue of knowledge , we should try to consciously expose ourselves to the opposing views with an aim to comprehend and debate them . Even though I felt uncomfortable with these pathetic and general instructions as to ensure the well- functioning civil society , the solution to the problem might be hidden in these very actions and could be shortly described by the following suggestion : be responsible . These big words and ideas can be easily transformed into more specific and far less pathetic instruction to be followed if the change has to happen throughout shift of social norms . Take care for your privacy — do not let the engines to be fed up with information allowing them to personalize search records to the greater extent than they do now . Do not just stick to the search results on the first page . Use different search engines . Familiarize yourself with different research tools and techniques . Use software which does not allow websites to track your activity . Check sometimes what your political opponents have to say on a given topic . Think ‘ out of the box ’ . Do not consume culture and information , rather explore . Google certainly is not evil , but if it does not work for our good let just howl down the possible negative effects it creates . This might be just temporary solution , by if combined with changes regarding the other three regulatory factors , might prove to be efficient in preserving deliberate democracy , if not in ‘ popping ’ the filter bubble . All these simple things deserve us to take some little responsibility over what we do on the Web and force us to make the ultimate choice : little comfort or some signs of social 27 Living in The Filter Bubble responsibility ? All of that without even moving out from in front of the screen . Would that solution to the problem work ? It depends only whether we believe that people are able to sacrifice some comfort for the public good . In the pessimistic or maybe more realistic version , the same question can phrased as whether we are able to fight for some deliberative and abstract idea of civil society and give up on our quite accurate , satisfactory , fast and handful search results Google and others provide us every single day . Lessig 's modalities are interdependent . Therefore a claim that it is enough to change just one of them is both too simplified and untrue . While I believe that as for now the change could happen throughout the social norms , I think we should constantly encourage ourselves to ask question about other three modalities to be employed for regulatory actions . It is important to notice that change of social norms is more likely to preserve ideals of deliberative democracy , while in my opinion it does not constitute sufficient response to the general problem of personalization . At the end of the day , the question of the form of regulation is just a derivative of the much more basic query , whether there is the problem at all . I believe that there is certain threat to the deliberative democracy , caused by the way the search engines operate . The question of how and with what tools provide the remedy for this situation remains open . Conclusions Undoubtedly , the search engines constitute the important part of our day-to-day lives . To the great extent , they are the first source of information to many people and as such play the important role of information intermediaries . Therefore , the manner in which the search results are rendered and delivered is not only of concern of separate users , but should relevant to the whole society . That being said , the search engines bias may contribute to the creation of the filter bubbles . As the information cocoons surrounding us create the threat to the concepts of deliberative democracy , its ideals and civil society , there might be a need to find a remedy against that . If we acknowledge that there is the need of regulation , the primary question becomes 'How to regulate ? ' . As the regulatory force of the market is out of question , we know little about the algorithms of search engines and the ground for legal response are highly controversial , as for now the only appropriate ground for changes are social norms concerning 28 Living in The Filter Bubble the way we use search engines , our awareness of its possible biases etc . At the end of the day , it is the moral question on responsibility everyone needs to take for its own activity on the Web , provided he or she sees the described threat to the civil society . There is a choice to be made : to act more consciously and responsibly or rather to stick to what others give ? Responsibility over comfort . At the same time , the regulatory question is the derivative of the more basic problem : is there the threat to the civil society ? I argue that there is , but as the matter of fact I would not mind being wrong . Bibliography 1 . Akkad Omar El , “ Google falls short as ad business shows cracks ” , The Globe and Mail ( October 17 , 2014 ) B1 . 2 . Associated Press v. United States , 1945 U.S. Supreme Court [ 1945 ] 326 U.S. 3 . Barlow John Perry , A Declaration of the Independence of Cyberspace ( Davos : 1996 ) online : Electronic Frontier Fundation < https : //projects.eff.org/~barlow/Declaration- Final . html > . 4 . Bohn Roger E. & Short James E. , How Much Information ? 2009 Report on American Consumers ( University of California — San Diego : Global Information Industry Center , 2009 ) , online : Global Information Industry Center < http : //hmi.ucsd.edw/howmuchinfo.php > . 5 . Brin Sergey & Page Lawrence , “ Anatomy of a Large-Scale Hypertextual Web Search En- gine ” Section 8 Appendix A , online : Stanford.edu < http : //infolab.stanford.edu/~backrub/google.html > . 6 . Chatfield Tom , 50 Digital Ideas You Really Need to Know ( London : Quercus , 2011 ) . 7 . Dewey John , Essays , Reviews and Miscellany , 1939-1941 , The Later Works of John Dew- ey , 1925-1953 . Vol . 14 ( Carbondale : Southern Illinois University Press , 1998 ) . 8 . Diaz A. , “ Through the Google Goggles : Sociopolitical Bias in Search Engine Design. ” in A. Spink and M. Zimmer ed. , Web Search : Multidisciplinary Perspectives ( Berlin : Springer-Verlag , 2008 ) . 9 . Gasser Urs , “ Regulating Search Engines : Taking Stock and Looking Ahead ” 8:1 Yale Journal of Law and Technology 201 . 29 Living in The Filter Bubble 10 . 11 . 12 . 13 . 14 . 15 . 16 . 17 . 18 . 19 . 20 . 21 . 22 . 23 . 24 . 25 . Halavais Alexander , Search Engine Society ( Polity Press , 2009 ) . Hillis Ken et al. , Google and The Culture of Search ( New York and London : Routledge , 2013 ) . Hinman Lawrence M. , “ Esse est indicato in Google : ethical and political issues in search engines ” 3 International Review of Information Ethics 20 . How Many Blogs — are on the _—_ Internet , WP Virtuoso , online : < http : //www.wpvittuoso.com/how-many -blogs-are-on-the-Internet/ > . Intemet Users in The World ( 2014 ) Internet Live Stats , online : < http : //www.intemetlivestats.com/intemnet-users/ > . Introna Lucas & Nissenbaum Helen , “ Shaping the Web : Why The Politics of Search En- gines Matters ” 16:3 The Information Society 169 . Lech Walesa , Address to the U.S. Congress ( November 15 , 1989 ) text of the speech available online : Milestone Documents < https : /Avww.milestonedocuments.com/documents/view/lech-wasa-address-to-the-u.s.- congress/text > . Lessig Lawrence , Code . Version 2.0 . ( New York : Basic Books , 2006 ) . Louis Grey , Why The Filter Bubble Is No Bubble and It 's Not Bad Either ( 2011 ) , online : < http : //blog louis gray.com/2011/05/why-filter-bubble-is-no-bubble-and-its.html > . McChesney Robert W. , Digital Disconnect . How Capitalism Is Turning The Internet Against Democracy ( New York , London : The New Press , 2013 ) . Nicholas Negroponte , Being Digital ( New York : Alfred . A. Knopf , 1995 ) . Pariser Edi , “ Beware online “ filter bubbles ” ’ ” ( TED Talk , 2011 ) , online : TED.com < http : //www.ted.com/talks/eli_pariser_beware_online_filter_bubbles ? language=en > . Pariser Eli , The Filter Bubble . What the Internet Is Hiding From You ( New York : The Penguin Press , 2011 ) . Perry Brian J. , “ Is Information a Commodity ? ” ( October 20 , 1999 ) online : National Insti- tute of Informatics < http : //www.nii.ac.jp/publications/kaken/HTML1999/99Perry02- E.html > . Purcell Kristen et al. , Main findings , PewResearch Internet Project , online : PewInter- net.org < http : /Avww.pewlnternet.org/20 12/03/09/main-findings- 11/ > . Robins Kevin & Webster Frank , “ The Long History of The Information Revolution ” in 30 Living in The Filter Bubble 26 . 27 . 28 . 29 . 30 . 31 . 32 . 33 . 34 , Webster Frank ed. , The Information Society Reader ( London and New York : Routledge , 2004 ) . Seneca Lucius Annaeus ( trans . C.D.N . Costa ) , Dialogues and Letters ( Penguin UK , 1997 ) . Stross Randall , Planet Google . One Company 's Audacious Plan to Organize Everything We Know ( New York : Free Press , 2008 ) . Sullivan Danny , “ Dear Bing , We Have 10,000 Ranking Signals To Your 1,000 . Love , Google , ” Search Engine Land ( November 11 , 2010 ) , online : < http : //searchengineland.com/bing-10000-ranking-signals-google-55473 > . Sunstein Cass R. , Republic.com 2 ( Princeton and Oxford : Princeton University Press , 2007 ) . Tavani Herman , “ Search Engines and Ethics ” in Edward N. Zalta ( red . ) , Spring ed. , The Stanford Encyclopedia of Philosophy ( 2014 ) online : Stanford Encyclopedia of Philosophy < http : //plato.stanford.edu/entries/ethics-search/ > . The Pew Research Center 's Internet & American Life Project Winter 2012 Tracking Sur- vey ( January 20 - February 19 , 2012 ) , online : Pewlnternet.org < http : //www.pewintermet.org/files/old- media/Files/Reports/2012/PIP_ Search Engine Use_2012.pdf > . The Structure of the Mass Media and Government Regulation , Cliffs Notes , online : < http : //www.cliffsnotes.com/more-subjects/american-government/the-mass-media/the- structure-of-the-mass-media-and-government-regulation > . Webster Frank , “ Introduction : Information Society Studies ” in Webster Frank ed. , The In- formation Society Reader ( London and New York : Routledge , 2004 ) . Weinberger David , Too Big To Know . Rethinking Knowledge Now That the Facts Aren't the Facts , Experts Are Everywhere , and the Smartest Person in the Room Is the Room ( New York : Basic Books , 2011 ) . 31 Filter Bubble and Enframing : On the Self-Affirming Dynamics of Technologies Andreas Beinsteiner Ph.D. Student Institute of Philosophy Leopold-Franzens-Universitat Innsbruck andreas.beinsteiner @ gmail.com ABSTRACT This paper tries to relate the recent concerns about personalized filtering on the internet to Martin Heidegger ’ s philosophy of technology . In “ The Filter Bubble ” , Eli Pariser describes how personalized filtering of online contents may result in a “ self loop ” , amplifying the user ’ s interests and opinions . It will be argued that there are structural similarities between the concept of the filter bubble and Heidegger ’ s concept of technology as enframing . Also the latter addresses a filtered perception of reality which reinforces itself . In both cases , the dynamics under consideration ultimately threaten human freedom . A comparison of filter bubble and enframing might not only produce a deeper understanding of both phenomena , but reveal the discussion of self-affirming dynamics as an essential task for media studies . Keywords enframing , filter bubble , Heidegger , technology 1 . INTRODUCTION As the vast amount of data on the Internet is growing faster than ever , filtering becomes a necessity . Internet giants like Facebook or Google have chosen a way that is different from the editorial selection typical of traditional broadcast media . They offer personalized filters instead of general ones . While for a long time this break with the agenda setting of traditional broadcast media was considered an advantage of the Internet , in the new millennium a different a different perspective evolved . In a book released in 2011 , Eli Pariser expresses his concerns about this tendency towards personalization on the web . As personalization becomes more and more usual , he argues , we will increasingly become embedded in a filter bubble , in “ your own personal , unique universe of information that you live in online. ” ( [ 10 ] ) The pervasive tendency towards personalization is problematic , as it “ moves us very quickly toward a world in which the Internet is showing us what it thinks we want to see , but not necessarily what we need to see. ” ( [ 10 ] ) The idea is not new : In 2001 , Cass Sunstein conceived personalized news as “ The Daily We ” and wondered if the Internet really was a blessing for democracy ( cf . [ 13 ] ) . Also , concerns have been raised for quite a while about a fragmentation of the public sphere , where communication only takes place between people with similar interests and attitudes . My claim in this paper is that the filter bubble may serve as a model that illustrates a more general concept about the self- affirming dynamics of our technologies : Martin Heidegger ’ s concept of the enframing . Relating these two ideas may result in mutual benefits : it might help to establish a better understanding of Heidegger ’ s notoriously difficult and notoriously misunderstood concerms , and in turn the kind of problem that Eli Pariser calls attention to may be grasped more precisely in Heidegger ’ s terms . Ultimately the paper suggests developing the concept of a local enframing as a critical tool for media studies . 2 . FILTER BUBBLE Facebook and Google were the places where Pariser first became aware of the effects of personalization . “ I noticed one day that the conservatives had disappeared from my Facebook feed ” , he tells us . “ And what it turned out was going on was that Facebook was looking at which links I clicked on , and it was noticing that , actually , I was clicking more on my liberal friends ’ links that on my conservative fnends ’ links . And without consulting me about it , it had edited them out. ” ( [ 10 ] ) The same kind of editing , Pariser found out , also happened on Google : He asked two friends to search for “ Egypt ” on Google . The results were drastically different : “ Daniel didn ’ t get anything about the protests in Egypt at al in his first page of Google results . Scott ’ s results were full of them . And this was the big story of the day at that time . That ’ s how different these results are becoming. ” ( { 10 ] ) Personalization is used at a lot of other places too : On online dating platforms , obviously , but also more and more on news portals . Why is Pariser worried about this development ? He sees a number of problematic effects that occur with the rise of filtering . One serious consequence for democracy is the decline of the public sphere : “ In the filter bubble , the public sphere — the realm in which common problems are identified and addressed — is just less relevant. ” ( { 11 ] , p. 148 ) Another one is the “ friendly world syndrome ” : “ [ S ] ome important public problems will disappear . Few people seek out information about homelessness , or share it , for that matter . In general , dry , complex , slow moving problems — a lot of the truly significant issues — wo n't make the cut. ” ( [ 11 ] , p. 150f ) This relates to another issue : “ [ I ] nstead of a balanced information diet , you can end up surrounded by information junk food. ” ( { 10 ] ) However , at the centre of all these tendencies there is one effect that Pariser calls “ the you loop : ” “ The filter bubble tends to dramatically amplify confirmation bias — in a way , it ’ s designed to . Consuming information that conforms to our ideas of the world is easy and pleasurable ; consuming information that challenges us to think in new ways or question our assumptions is frustrating and difficult. ” ( [ 11 ] , p. 88 ) Personalized filtering directs us towards doing the former : , , [ T ] he filter bubble isn ’ t tuned for a diversity of ideas or of people . It ’ s not designed to introduce us to new cultures . As a result , living inside it , we may miss some of the mental flexibility and openness that contact with difference creates. ” ( [ 11 ] , p. 101 ) This is not only a danger for democracy , but also for freedom . For freedom , Pariser explains , can not be reduced to being able to do what you want . First you need to know what is possible to do . ( cf . [ 11 ] , p. 112 ) “ When you enter a filter bubble , you ’ re letting the companies that construct it choose which options you ’ re aware of . You may think you are the captain of your own destiny , but personalization can lead you down a road to a kind of informational determinism in which what you ’ ve clicked on in the past determines what you see next — a Web history you ’ re doomed to repeat . You can get stuck in a static , ever-narrowing vision of yourself — an endless you-loop. ” ( { 11 ] , p. 16 ) Also Cass Sunstein perceived filtering as a threat to democracy and freedom . ' An important difference , however , is that Sunstein was concerned with personalization that the user consciously chooses . This does not hold in the filter bubble : “ When you tum on Fox News or read The Nation , you ’ re making a decision about what kind of filter to use to make sense of the world . It ’ s an active process , and like putting on a pair of tinted glasses , you can guess how the editor ’ s leaning shapes your perception . You don ’ t make the same lind of choice with personalized filters . They come to you — and because they drive up profits for the Web site that uses them , they ’ ll become harder and harder to avoid. ” ( [ 11 ] , p. 10 ) So for Pariser maybe the most dangerous thing about filter bubbles is that they are not aware of them : “ In fact , from within the bubble , it ’ s nearly impossible to see how biased it is. ” ( [ 11 ] , p. 10 ) Accordingly , the mission of his book , and the first step towards solving the problem , is to render the filter bubble visible ( cf . [ 11 ] , p. 20 ) . A second step would be to think about how serendipity happens and how it could be promoted by software design decisions ( cf . [ 11 ] , p. 235f ) . My claim in what follows will be that the filter bubble can serve as a model to understand a more generic concept about the self-amplifying dynamics of technologies : Martin Heidegger ’ s concept of technology as enframing . 3 . ENFRAMING Martin Heidegger ’ s esoteric and idiosyncratic terminology has given rise to a lot of misunderstandings . As often , building bridges between different kinds of vocabularies might help to clarify things . I will try to do this by relating the dynamics Eli Pariser describes to the ones Heidegger describes . If for Pariser it is the enormous amount of data online that requires filtering , Heidegger ’ s concern is the inexhaustible richness of Being getting filtered . Being is no mythic or divine entity but simply refers to the meaning of the word “ to be ” , to our understanding of what it means that something “ is ” . So Being obviously is strongly intertwined with language . The inexhaustible richness of Being is not a kind of mythological postulate , but a simple consequence of the historicity of Being . As Heidegger tries to show , every culture and epoch had its own understanding of Being . This understanding changes , as language changes . And as we have no idea about how ' “ Unanticipated encounters , involving unfamiliar and even irritating topics and points of view , are central to democracy and to freedom itself. ” ( [ 13 ] ) language might develop , there is no basis for determining a definite set of possible understandings of Being . As a consequence , every historical culture has its own clearing of Being , which is at the same time concealment and unconcealment . While a vast majority of possible understandings of reality remain hidden for us , a certain understanding unfolds . Thus with every clearing of Being , only certain few aspects of reality become accessible for us . This means that the respective clearing defines our possibilities in thinking and acting , and , more fundamentally , our possible horizons of meaning . Richard Rorty puts it this way : “ For Heidegger — early and late — what one is is the practices one engages in , and especially the language , the final vocabulary , one uses . For that vocabulary determines what one can take as a project. ” ( [ 12 ] , p. 109 ) ’ The clearing of Being thus provides a refined concept for discussing a matter that also Pariser is concemed with : “ Not knowing that it is possible to be an astronaut is just as much a prohibition against becoming one as knowing and being barred from doing so. ” ( [ 11 ] , p . 112f . ) The matter at stake is freedom . If the clearing of Being is historical , it can change . With Heidegger , we can grasp freedom precisely as the mutability of the conceptual framework that mediates our access to reality . Freedom relies on what I want to call hermeneutic oscillation : on a condition where various modes of unconcealment are suspending and balancing each other . * We can consider the clearing of Being as a filtering of the inexhaustible richness of Being : “ Beings can be as beings only if they stand within and stand out within what is cleared in this clearing. ” ( [ 7 ] , p. 178 ) Freedom thus requires that this filtering must not become static : It must not always be the same aspects of reality that get filtered out or that make it through the filter . Only then new aspects of reality may appear and provide us with new possibilities of thinking and action . Heidegger ’ s history of Being could thus be rephrased as a history of filters on the possible meanings of Being . In the modern age , or , as Heidegger puts it , “ the Age of the World Picture ” , “ a essential decision takes place regarding what is , in its entirety. ” ( [ 8 ] , p. 130 ) Man is understood as the subject and all entities become objects : “ Man becomes that being upon which all that is , is grounded as regards the manner of its Being and its truth . Man becomes the relational center of that which is as such. ” ( [ 8 ] , p. 128 ) As man is placed as the relational center of everything that is , the world becomes a picture , a representation for him . “ Here to represent [ vor-stellen ] means to bring what is present at hand [ das Vorhandene ] before oneself as something 2 As we will see in the course of the following considerations , the clearing of being is not only constituted by language , but also by technologies and technical artefacts . Both aspects have been addressed frequently in Heidegger ’ s writings . 3 For Heidegger ’ s concept of freedom , cf . “ On the Essence of Truth , p. 115-138 in [ 7 ] . Understood in this way , freedom is not something that man possesses as a property . “ At best , the converse holds : freedom , ek-sistent , disclosive Da-sein possesses man — so originally , that only it secures for humanity that distictive relatedness to being as a whole which first founds all history. ” ( [ 7 ] , p. 127 ) standing over against , to relate it to oneself , to the one representing it , and to force it back into this relationship to oneself as the normative realm. ” ( [ 8 ] , p. 131 ) This means that everything that is , is , insofar it can be related to man . With other words , everything that can not be related to man is filtered from the clearing of Being : all aspects of reality that are not relevant to man cease to exist . * My suggestion is that the age of the world picture , as a reconfiguration of the ontological sphere , structurally corresponds to the introduction of personalized filtering on the internet : Everything that can not be related to oneself as relevant in some way is filtered out of existence . For Heidegger , the modern reconfiguration of the clearing of Being has serious ethical consequences , as it implies that in everything man does , he is only concerned with aspects of reality that in some way relate to himself . However , this constellation is radicalized with the advent of modern technology . Heidegger calls the Wesen of technology the enframing [ Ge- stell ] . While Wesen usually is translated as essence , I suggest that ontological dynamics is a more appropriate translation . Por in Heidegger the notion does not refer to any supposed nature of things , but to the way they relate to changes in the clearing of Being. ” Technology , according to Heidegger , is not merely a means . “ Technology is a mode of revealing . The dynamics of technology are situated in the realm where revealing and unconcealment take place , where aletheia , truth , happens. ” ( [ 7 ] , p. 319° ) What are those ontological effects of technology that Heidegger describes as Ge-stell ? Everything is revealed only as standing-reserve [ Bestand ] , things may only enter the clearing of Being to the extent that they can be conceptualized as an instrument or challenged as a resource . Observe that the Ge-stell mode of revealing is narrower than the world-picture mode : * As the man of the modern age , according to Heidegger , is metaphysically conceived as animal rationale , there are first and foremost two modes of that relation : either things serve as an experience [ Erlebnis ] for man as an animal , or things can be measured scientifically by rational man . ° Although Heidegger dedicates several pages to explaining his reinterpretation of the term ( cf . eg . [ 7 ] , p. 334ff ) , many interpreters still hold on to the traditional notion of Wesen . © Translation modified . German orginal : , ,Die Technik west in dem Bereich , wo Entbergen und Unverborgenheit , wo aletheia , wo Wahrheit geschieht.~ ( [ 6 ] , p. 17 ) This statement has to be read carefully : The realm , where the dynamics of technology , understood in the Heideggerian sense as enframing , are situated , is the clearing of Being . In many of his writings , Heidegger indicates that this clearing is not only constituted by language , but also by artifacts , tools and machines ( cf . e.g . the fool analysis in “ Being and Time ” ) . So there is always a technological aspect in the clearing of Being . This aspect , however , is to be distinguished from enframing as a certain tendency in the dynamics of the clearing of Being in the age of technology . For any attempt to estimate Heidegger ’ s relevance for media studies , it is essential to clarify the exact relation between technological artifacts and the tendency of enframing : What kinds of artifacts and infrastructures do promote enframing , and why ? “ Whatever stands by in the sense of standing-reserve no longer stands against us as object. ” ( [ 7 ] , p. 322 ) Now what in some way relates to man may no more pass through the filter but only that which is useful for our purposes . This means that our possibilities of being in the world become more narrow too : ’ Heidegger contrasts the river Rhine , technologically perceived as an energy supplier or as a tourist attraction , with the Rhine as it appears in the poetry of Hélderlin ( cf . [ 7 ] , p. 321 ) . Technology filters reality in a way so that we perceive only the aspects of reality where it is successful . '' And the more we perceive technology as successful , the more it will reinforce not only its own take on reality , but also the corresponding horizons of meaning that drive our activities . “ Man clings to what is readily available and controllable [ ... ] , concealing as a fundamental occurrence has sunk into forgottenness. ” ( [ 7 ] , p. 132f ) In a similar way , Pariser states that the filter bubble transforms “ known unknowns into unknown unknowns ” . ( [ 11 ] , p. 106 ) We can explore this structural resemblance further : “ Left to their own devices , personalization filters serve as a kind of invisible autopropaganda , indoctrinating us with our own ideas , amplifying our desire for things that are familiar and leaving us oblivious to the dangers lurking in the dark territory of the unknown. ” ( [ 11 ] , p. 15 ) As everything is filtered that is mysterious or does not fit into the established conceptualizations , those conceptualizations become static . “ By disavowing itself in and for forgottenness , the mystery leaves historical man in the sphere of what is readily available to him [ ... ] , ” states Heidegger . And Pariser stresses that “ Tijf personalization is too accute , it could prevent us from coming into contact with the mind-blowing , perception-shattering , experiences and ideas that change how we think about the world and ourselves. ” ( [ 11 ] , p. 15 ) Both in the filter bubble and in enframing , man is stuck in a certain conceptualization of reality . When Heidegger says that thus the essence [ Wesen ] of man is threatened by technology ( cf . [ 7 ] , p. 333 ) , this does not involve any essentialist claims about the nature of man . On the contrary , it means that the ontological dynamics of man have come to stagnate ; that the indefinite possibilities of what man might be have been narrowed down to one single understanding of man that is amplified and reinforced by the relational system of our technologies . In the same way , “ the economics of personalization , ” according to Pariser , “ push toward a static conception of personhood. ” ( [ 11 ] , p. 216 ) 7 “ The only thing that is ever questionable is how we can measure and fathom and exploit the world as quickly as possible , as securely as possible , as completely as possible [ ... ] . ” ( [ 2 ] , p . Alf . ) ® Quantification is an essential feature in the filtering that renders technological access to reality successful : “ Calculation refuses to let anything appear except what is countable . Everything is only whatever it counts . [ ... ] Only because number can be infinitely multiplied , irrespective of whether this occurs in the direction of the large or the small , can the consuming dynamics of calculation hide behind its products and lend to calculative thinking the semblance of productivity - whereas already in its anticipatory grasping , and not primarily in its subsequent results , such thinking lets all beings count only in the form of what can be set at our disposal and consumed .. ” ( [ 3 ] , p 235 , translation modified ) This section tried to make transparent that Heidegger ’ s philosophy of technology does not address any supposed opposition of nature and technology , but a self-amplifying dynamics that structurally resembles the one described by Eli Pariser ’ s filter bubble . One thing we can learn from these similarities is that there are actually multiple ways of drawing on Heidegger for a critical enquiry into today ’ s media environments . The more traditional way would be analyze if and how media and technological infrastructures contribute to enframing by making everything available as a standing reserve . However , for those who do not accept Heidegger ’ s narrative about the totality of technological access to the world in our age , there exists another way of making use of Heidegger 's considerations . Since enframing , like the filter bubble , is about self-amplifying dynamics , the concept can also be employed without any claims of totality , to identify local enframings : ? conceptual frameworks that reinforce themselves , horizons of meaning that we have become stuck in without being aware of it . In this approach , concrete media or technological infrastructures could be analyzed with respect to their ontological dynamics : Do they promote hermeneutic oscillation or do they establish local enframings ? Do they allow for a mutability of concepts , or do they reinforce established understandings ? The first crucial step in destabilizing local enframings , however , might be to realize that we always are exposed to a clearing of Being that is constituted by our language and our technologies and that is in danger of becoming static . 4 . THE SELF-AFFIRMING DYNAMICS OF TECHNOLOGIES According to Heidegger , the lock-in in one clearing of Being is particularly strong because man is not aware of the filtering that is at work in this clearing : “ Man stands so decisively in subservience to on the challenging-forth of enframing that he does not grasp enframing as a claim , that he fails to see himself as the one spoken to , and hence also fails in every way to hear in what respect he ek- sists , in terms of his ontological dynamics [ Wesen ] , in a realm where he is addressed [ ... ] . ” ( [ 7 ] , p. 332 , translation modified ) After Heidegger had conceived the revealing in the mode of enframing as the supreme danger , his text takes an irritating turn . He refers to a verse of Hélderlin to declare that “ where danger is , grows [ t ] he saving power also. ” ( [ 7 ] , p. 333 ) This might seem arbitrary , but Heidegger explains : “ The danger itself , if it is as the danger , is the saving power. ” ( [ 8 ] , p. 41 ) If the danger becomes perceived explicitly as the danger , this might free us from the lock-in in enframing : “ [ W ] hen we once open ourselves expressly to the ontological dynamics [ Wesen ] of technology we find ourselves unexpectedly taken into a freeing ° The notion of a local enframing is choosen in order to discard two aspects of totality connected to Heidegger ’ s original concept : 1. the planetary dimension of enframing which pervades all of the contemporary world and 2. the totality of the specific interpretation of reality that Heidegger links to the self- affirming dynamics of technology . As we can learn from Pariser , such dynamics may be restricted to small groups or even individuals , and they are not necessarily linked to this specific understanding of reality . The point here is not to qualify the scope of Heidegger ’ s cultural diagnostics , but to enhance the applicability of the concept for analyzing self-affirming dynamics in a variety of concrete technological settings . claim. ” ( [ 7 ] , p. 331 , translation modified ) Heidegger seems to hope that , as the ontological dynamics of technology become more intense , they might also become visible as such : as a selective filtering that amplifies established concepts and horizons of meaning . Self-affirming dynamics are not exclusive to technology but denote a danger that always threatens man . Being exposed to the potential infinity of possible ways of conceptualizing the world , man tends to hold on to those kinds of conceptualizations that he already is familiar with : “ As ek-sistent , Dasein is insistent. ” ( [ 7 ] , p. 132 ) Also for Pariser , the consumption of news that confirm one ’ s own belief existed before the filter bubble . “ And while this phenomenon has always been true , the filter bubble automates it . In the bubble , the proportion of content that validates what you know goes way up. ” ( [ 11 ] , p. 89 ) I want to suggest that the automation of the phenomenon might be a crucial point . As the self-affirming dynamics in questions have been objectified into software by several different internet platforms who offer personalization , and as Pariser has written a book about it , the problem has become explicit . In a way , the danger now is unconcealed as the danger . Pariser ’ s aim was to render the filter bubble visible , just like Heidegger ’ s concem was whether enframing would reveal itself as such . The structural similarities of filter bubble and enframing indicate that a useful notion of a local enframing can be developed . However , one has to restrain from a premature identification of filter bubble and enframing . Instead , the differences of the two concepts have to be clarified . Here only a few of these differences are exposed in order to raise some productive questions . I . One difference is that the filter bubble seems to be an epistemological problem , while the enframing is an ontological one . The filter bubble defines what we are able to find out about , while the clearing of Being ultimately defines what is . This is the case , because the filter bubble is not our only access to reality . We also find out about things when we are not online . But , in contrast , there is nothing outside of the clearing of Being . This difference , however , might blur , as we spend more and more of our lives online and as the internet begins to colonize our offline world with the development of augmented reality . If ultimately , as Pariser describes ( cf . [ 11 ] , p. 207ff ) , our whole lives might be absorbed by the filter bubble , would those filters thus obtain the ontological totality that Heidegger envisioned ? This might depend upon whether interactions with other individuals in the social sphere might allow us to break through the filters . We are thus lead to another important difference . II . While , according to Pariser , every individual human being is enclosed in its own filter bubble , Heidegger became less and less concemed with individuals in the course of his philosophical career . After the individualistic “ Being and Time ” , he came to be more occupied with the fate of the Germans as a “ historic people ” . After World War two , when his philosophy of technology took shape , he was interested in mankind as such , since he supposed that with technology , European thinking had pervaded the whole globe . Every individual is enclosed in its own filter bubble , but the whole mankind is enclosed in enframing . So while social interaction and communication might crash our individual bubbles , Heidegger is interested in the basic understandings that we all already take for granted and which thus can not be shaken that easily by communication . In particular this is the case for understandings which are entailed by the communication infrastructures themselves . ! ° Moreover , it is the case for understandings that influenced the design of our communication technologies . This raises also the question about the relation of individual filter bubbles and the ones that pervade the whole society . Filtering algorithms are developed and programmed on the basis of certain established understandigs and horizons of meaning . As Heidegger mentions , the “ functionaries ” for “ making public civilized opinion ” are “ at once driver and driven ” ( [ 4 ] , p. 212 ) , they constitute understandings and are constituted by them . If one tries to follow Pariser ’ s suggestion and looks for ways to design and implement serendipity ( cf . [ 11 ] , p. 235f ) , one has to be aware : Also programming decisions tend to be a result of a filtered perception of reality . Ill . There is a certain ambivalence within Pariser ’ s grasp of the problem . Although he generally seems to be concerned about a loop that reinforces ones attitudes and interests ( as described in Section 2 ) , there are also some passages where he seems to be worried that the authentic self of the user could become manipulated by the filters : “ You become trapped in a you loop , and if your identity is misrepresented , strange patterns begin to emerge , like reverb from an amplifier. ” ( { 11 ] , p. 125 ) If the problem was only that of a misrepresentation of an authentic self , then building Popperian falsification strategies into the filtering algorithms ( cf . [ 11 ] , p.132ff ) might really help . This understanding of the problem , however , drops the insight , how deeply we are shaped by our language and our technologies . | ! As he became aware of how fundamentally man was constituted by the clearing of Being , Heidegger stopped using his early notion of authenticity . “ For there is no such thing as a man who is as a man singly and solely by his own virtue. ” ( [ 7 ] , p. 337 , translation modified ) It is worth noting that Heidegger ’ s “ Question Concerning Technology ” contains an answer to Werner Heisenberg . Heisenberg had described the technological age as a condition where man always and everywhere only encounters himself ( cf . “ Das Naturbild der heutigen Physik ” , pp . 109-127 in [ 9 ] ) . Heidegger objects that man “ ek-sists , in terms of his ' 0 How communication technologies interfere with language became an essential question in several of Heidegger ’ s late writings . E.g. , in [ 1 ] , Heidegger addresses the univocity ( i.e . the suppression of hermeneutic oscillation ) that language needs to assume in order to become suitable for automated data processing . This is an issue that continues to be relevant as the semantic web emerges . It might be instructive to discuss ontology engineering in the context of Heidegger ’ s critique of metaphysics . ' ! Maybe Pariser ’ s occasional worries about the manipulation of an authentic self express discomfort about the fact that this sphere , where man is addressed and constituted , is , to an increasing extent , organized according to the interests of private and profit-oriented corporations . Pariser calls this “ the commercialization of everything — even of our sensory apparatus itself ‘ ( [ 11 ] , p. 215 ) Doubtlessly , the static self produced by filter bubbles is useful for profit-oriented enterprises as it makes the behaviour of consumers computable . For Heidegger , however , the desire to calculate human behaviour is not just an effect of capitalism but rather of the cybernetic paradigm in the age of technology . ontological dynamics [ Wesen ] , in a realm where he is addressed , so that he can never encounter only himself. ” ( [ 7 ] , p. 332 , translation modified , emphasis in the original text ) The realm where he is addressed is the historical clearing of Being which is constituted by language and technological artefacts . In this respect Heidegger agrees with many contemporary theorists of media and technology : There is no authentic pretechnological self . However , such a notion of authenticity is not needed as normative concept for critique , since the Heideggerian understanding of freedom as hermeneutic oscillation provides an alternative normative perspective . From this perspective , the identification of self- amplifying tendencies in our technologies — which is , though on different levels , the aim of both Heidegger and Pariser — assumes an essential role in any critical inquiry into our evolving online media environments . 5 . ACKNOWLEDGMENTS This work was supported by a stipend of the Vizerektorat fiir Forschung , Leopold-Franzens- Universitat Innsbruck . 6 . REFERENCES [ 1 ] Heidegger , Martin . 1989 . Uberlieferte Sprache und technische Sprache . Erker : St. Gallen . Heidegger , Martin . 1996 . Hélderlin ’ s Hymn “ The Ister ” ’ . Indiana University Press , Bloomington . [ 2 fair [ 3 = Heidegger , Martin . 1998 . Pathmarks . Cambridge University Press , Frankfurt am Main . [ 4 fa Heidegger , Martin . 2001 . Poetry , Language , Thought . HarperCollins , New York . Heidegger , Martin . 2002 . Die Technik und die Kehre . Klett- Cotta , Stuttgart . Heidegger , Martin . 2004 . Vortriige und Aufsdtze . Klett- Cotta , Stuttgart . [ 5 = [ 6 Se [ 7 & Heidegger , Martin . 2008 . Basic Writings . HarperCollins , New York . Heidegger , Martin . 2008 . The Question Concerning Technology and Other Essays . Harper & Row , New York . [ 8 oe [ 9 = Heisenberg , Werner . 1971 . Schritte iiber Grenzen . Piper , Miinchen . [ 10 ] Pariser , Eli . 2011 . Beware online filter bubbles . TED talk . http : //www.ted.com/talks/eli_pariser_beware_online_filter_b ubbles.html . [ 11 ] Pariser , Eli . 2011 . The Filter Bubble . Viking , London . [ 12 ] Rorty , Richard . Contingency , Irony , and Solidarity . Cambridge Unversity Press , New York . [ 13 ] Sunstein , Cass . 2001 . The Daily We . Boston Review . http : //bostonreview.net/BR26.3/sunstein.php ResearchGate See discussions , stats , and author profiles for this publication at : https : //www.researchgate.net/publication/3 14489583 How Online Tracking and the Filter Bubble Have Come to Define Who We Are Article in SSRN Electronic Journal - January 2013 DOI : 10.2139/ssm.2878750 CITATIONS READS 2 1,267 lauthor Thomas Beretich University of Southern Maine Q PUBLICATIONS 130 CITATIONS SEE PROFILE All content following this page was uploaded by Thomas Beretich on 11 October 2017 . The user has requested enhancement of the downloaded file . How Online Tracking and the filter bubble have come to define who we are . Thomas Beretich University of Maine School of Law From its early years as a principally research and education oriented resource , the internet has evolved into a heavily commercialized and ubiquitous component ( see figure 1 . ) of the public ’ s daily routine. ’ In fact , research by the Pew Research Center ’ s Internet & American Life Project shows the extent to which internet commerce has become a part of everyday life with a proportion of the general public that has purchased services such as airline tickets or hotel rooms online rising from 22 % in May 2000 to 52 % in May 2010. ” ° What technologies have facilitated this transition of the web to a commercially-focused research tool and what has been the outcome in terms of the user experience and where it is heading ? This paper discusses these points and illustrates how the “ web experience ” has taken on a different aspect that was probably not envisaged by its early creators and users . Far from being an efficient research tool to help us make smarter decisions about what we buy , who we meet or even how we arrive at our moral and political positions , the tracking technologies that are so instrumental in furthering the 'This evolution did not occur without controversy . The Scientific and Advanced-Technology Act , , 42 US.C . § 1862 ( g ) , allowed the National Science Foundation to support access to networks with commercial interests , thus further clouding what had been clear lines between commercial and non-commercial networks . As a result , the research and education communities were worried that the internet would be less responsive to their needs . http : //www.gao.gov/new.items/og00033r.pdf . The final walls between the commercial and non-commercial world on the internet fell in 1995 , when the NSF ended its financial support to the NSFNET backbone service and helped regional research and education networks transition to commercial Internet Service providers . A Brief History of the Internet , http : //www.walthowe.com/navnet/history.html . ? The author of the paper , Jim Jansen , a research fellow at the Pew Research Center notes that “ E-commerce is now a 360-degree experience for shoppers - it begins with research that in turn leads to purchases that then trigger commentary and reviews by shoppers . Every part of the online experience seems to have become second nature to internet veterans. ” http : //www.pewinternet.org/Press-Releases/2010/Online-Product-Research.aspx ? From the e-merchants perspective , the internet continues to make steady advancesas as a source of revenues that can not be ignored . See Figure 2. http : //www.census.gov/retail/mrts/www/data/pdf/ec_current.pdf objectives of the commercial players of the world wide web have arguably restricted our choices vis-a-vis research and the user experience on the internet . The choices are not necessarily smarter ; they are reduced however , and certainly more efficient from a commercial standpoint ; but by allowing those services such as search engines ’ that are the gateway to internet research , to continue to track , model and predict our interests , we have delegated to them not just control of the important and much more debated matter of our privacy but also our ability to choose in an unrestricted and unfettered manner those areas and people of interest to us and thus in the context of internet socialization , the definition of our very personality . Respondents who use internet . 90 % « 85 % « 80 % « 75 % « 70 % « 65 % ¢ 60 % ¢ 55 % « 50 % 45 % 40 % So 5 a —— = “ According to FairSearch which references the Pew Internet & American Life Project research reports , as of May 2011 , 92 % of adults are using search engines to find information online . http : //www.fairsearch.org/wp- content/uploads/201 1/10/Googles-Transformation-from-Gateway-to-Gatekeeper.pdf Figure 1 . Percentage ( bold line ) of respondents ( with outer lines as margins-of-error ) answering positively to a Pew Research Center survey asking whether they used the internet . Data from http : //www.pewinternet.org/Static- Pages/Trend-Data- ( A dults ) /Usage-Over-Time.aspx Estimated Quarterly U.S. Retail E-commerce Sales as a Percent of Total Quarterly Retail Sales : 1st Quarter 2004 - 1st Quarter 2013 Percent of Total 6.8 1Q 2Q 3Q 4Q 12 2Q 30 4Q 1Q 2Q 30 4Q 1G 2 3Q 4Q 1Q 20 3Q 40 1 2Q 3Q 4Q 1Q 2Q 3 4Q 10 2Q 3Q 4Q 1Q 2Q 3Q 4Q 1 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 Not Adpsted = ee = Adu Figure 2 . Quarterly E-commerce Sales over time from 2004 to 2013 . ( 3 ) Tracking Technologies and their uses In Omer Tene and Jules Polonetsky ’ s exhaustive paper To Track or “ Do Not Track ” : Advancing Transparency and Individual Control in Online Behavioral Advertising , , a thorough survey of tracking technologies and their evolution over the life of the internet was included. ” Cookies , Flash Cookies , Browser fingerprinting , unique identifying numbers on mobile devices , deep packet inspection , and history sniffing are all described from a technological standpoint , while juxtaposing the level of transparency in their use by online businesses against the expectations of privacy and control by internet users.° The underlying element that is crucial to how the internet works today from a commercial standpoint and that is described in Tene and Polonetsky ’ s paper , but from the perspective of third party analysis and services , is online ° Tene , Omer and Polonetsky , Jules , To Track or 'Do Not Track ’ : Advancing Transparency and Individual Control in Online Behavioral Advertising ( August 31 , 2011 ) . Available at SSRN : http : //ssrn.com/abstract=1920505 or http : //dx.doi.org/10.2139/ssrn.1920505 ® Id. , 300. behavioral tracking . The use of online behavioral tracking has exploded and this explosion in growth is a function of commercial demand as well as the arrival of big data technology which has enabled the analysis of ever greater stores of data in predicting user behavior. ’ The ever increasing quality of analysis and predictability has led to more targeted , efficient and effective advertisement , according to online advertising companies and their executives . * Although the use of personalization agents in collecting and analyzing user activity on the web to deliver tailored content is by no means a new phenomenon , ” it is the explosion in their use by large search engines and web advertisers which has created so much concern in terms of privacy issues . However , Ad Technology executives seem to make numerous and compelling arguments for why the use of today ’ s tracking technology is a good thing . '° Aaron Bell and Adam Berker from AdRoll feel that marketing becomes relevant and effective because it is compelling and not intrusive , with the key element being that the user is in control . This results in a true partnership between the internet user and advertisers which in turn ensures that the content and information on the web remains free . 7 In her article in the Wall Street Journal , Julia Angwin reports how in less than a two year span , the instance of data collection from visiting 50 of the most popular websites went from 10 to 56 instances , an increase of 460 % . One of the reasons for this dramatic increase is the advent of real time bidding auctions which allow the winning bidder to use online behavior to tailor advertisements more expediently and often in immediately . http : //online.wsj.com/article/SB 1000142405270230383640457747249 1637833420. html ? mod=rss_whats_news_tec hnology & utm_source=feedburner & utm_medium=feed & utm_campaign=Feed % 3A+wsj % 2Fxml % 2Frss % 2F3_7015 + % 28WSJ.com % 3A+What % 27stNewstTechnology % 29 ® http : //www.adexchanger.com/online-advertising/why-is-tracking-g00d/ ° Mobasher in this seminal paper describes an approach to web-mining that includes co-occurrence page patterns within usage data , using path profiles to predict future HTTP requests , and using data mining techniques to extract usage patterns . These methods are combined within Mobasher ’ s Usage based Web-Personalization Architecture which includes 1. the preprocessing of Web usage logs and the grouping of URL references into sets and 2. the mining of these user transaction sets through the techniques of transaction clustering , usage clustering , and association rule discovery . Bamshad Mobasher , Robert Cooley , Jaideep Srivastava , Automatic personalization based on Web usage mining , Communications of the ACM , v.43 n.8 , p.142-151 , Aug. 2000 http : //www.adexchanger.com/online-advertising/why-is-tracking-go0od/ Chad Little of Fetchback ( Ebay ) speaks in terms of the efficiencies of complete data access and how cost savings that are ultimately passed on to the consumer . He proffers that online behavioral tracking is to be embraced and not feared as it ultimately simplifies and improves the consumer online experience . Bill Todd of ValueClick Media highlights the real value that online behavioral advertising brings to the web experience . Relevant advertising keeps the content and services on the web free . Furthermore , he insists that consumers value the more personalized online ads and prefer them to the more general and largely irrelevant ads that have been the industry standard in the past . David Nelson of Unanimis.co.uk speaks about the importance of content in making the web so appealing to consumers . If not for this interesting content , there would be no web . If not for online behavioral advertising , , content ( ads ) would irrelevant and uninteresting . Eric Bosco of ChoiceStream feels that privacy is a good thing , but describes online behavioral advertising as simply the same type of mechanism by which the local shopkeeper would make a point of knowing what his loyal customers were interested in when entering his store . In fact , Bosco insists that this degree of localized , friendly customer experience has disappeared from Main Street USA but is thriving on the internet thanks to the use of online behavioral tracking . Maria Schimke of AudienceScience sums up the two major themes that seem to pervade the logic of online Advertisers when they defend the use of online behavioral tracking . There are two major consumer benefits : keeping the internet free and delivery of advertisements that are relevant and add extra value to the consumer ’ s experience . But are all these Ad Executives ’ comments valid reasons for online behavioral tracking or simply excuses for technology that has changed the very fabric of the internet . As Alex Kelleher of CognitiveMatch says , Tracking is the only way for companies to figure out what the consumer really wants without asking in person . And it is not the individual differences that concem the ad company but the similarities amongst consumers which allow deducing what to offer and ultimately how to get a better return on the ad companies investment . If we look at tracking technology from the viewpoint of its use in online behavioral advertising , the debate seems to be purely about a struggle between consumers and businesses over control of advertising content and frequency . However , the uses of tracking technology have now reached areas that touch more closely fundamental rights of privacy and freedom of choice in associating with ideas and groups of people . A report by ENISA '' , the European Network and Information Security Agency , highlights how tracking technology use has created the following areas of concern : 1 . A diversionary debate — some , maybe most , advertising companies focus on Do Not Track as an opt-out question for behavioral advertising , but ENISA maintains that Tracking is the actual problem , not behavioral advertising , ul http : //www.infosecurity-magazine.com/view/293 76/enisa-and-the-privacy-considerations-of-online-behavioral- tracking/ SOT naa UO ) N ) Coach Figure 3 . Spying software manufacturer Finfisher is becoming popular with governments who feel the need to spy on their own and other citizens . ( 13 , 15 ) 2 . User profiling for other purposes than behavioral advertising — user profiling now goes beyond just behavioral advertising and now includes global surveillance ! ” which can be performed by governmental entities to track its citizens ’ * and those of other countries ' * ! > : '® , but it also includes surveillance by companies for commercial reasons . ! ” Of course the recent well publicized endeavors of the National Security Agency and its spying program PRISM are such an example where a government has been able to obtain search history , content of emails , file transfers and live chats directly from the servers of the most important U.S. Service Providers . http : //www . guardian.co.uk/world/2013/jun/06/is-tech-giants-nsa-data '' Nigeria is one of many countries who plans apparently to ramp up surveillance of its own citizens , with the purchase of equipment and software that will allow it to “ conduct surveillance on an unprecedented scale ” by using products such as Finfisher which can “ obtain passwords from your computer , monitor Skype calls , and even turn on your computer ’ s camera and sound recording so as to watch you at work. ” http : //advocacy.globalvoicesonline.org/2013/07/12/nigerian-g overnment-to-ramp-up-internet-surveillance/ “ The United States has not comered the market on extra-territorial surveillance of foreign citizens . Broad networks of “ infiltrated computer systems including foreign ministries , news media , NGOs and political dissidents ” point to IP addresses based in China that are receiving the purloined information . Even supposedly backwater regimes such as Gadhafi ’ s were spying on dissidents based in the United Kingdom , as well as , foreign activists and political adversaries amongst others . https : //www.eff.org/deeplinks/20 13/06/spies-without-borders-i-using-domestic- networks-spy-world 3 . The wrong data — user profiling that contains incorrect data on a user creates potential harms such as “ error , abuse , lack of transparency and accountability. ” In fact , incorrect tracking data in the hands of government could “ prove terminally wrong. ” 4 . Reality/Physical Mining — the automatic and continuous gathering of information on location and users of smartphones raises many questions about privacy and leads to the image of a surveillance society . 5 . Augmented reality — using inference techniques from different websites to identify what is presumed to be anonymous information . An example would be the use of facebook photos to identify anonymous photos on a dating website . 6 . Service and price discrimination — most notable in the realm of insurance where a profile might reveal risk of a certain disease thereby resulting in the denial of insurance coverage . 7 . Personalization — as to be discussed further in this paper , this is where users get trapped in a filter bubble . As described by ENISA , as well as George Orwell , in authoritarian states , this filter bubble is the manifestation of the states aims at ® Angola , Bahrein and Germany are amongst those nations that are implicated in the use of extra-territorial espionage with the help of commercially available software such as Finfisher . ( see footnote 13 also ) . http : //www.edri.org/edrigram/number ] 1.2/germany-finfisher-spyware 'S http : //www . businessinsider.com/countries-with-finfisher-spying-software-2013-5 '' This of course is one core aspect of the debate - what is surveillance ? Countries may have fewer problems debating the intricacies of what constitutes Personally Identifiable Information when there whole purpose is to monitor and gather information on an individual , while companies ( who can not legally spy on an individual unless told to do so by the jurisdictional powers to which they find themselves subject ) , can arguably gather as much information as they deem necessary for marketing purposes , as long as they follow governmental guidelines , laws and industry practices which purportedly protect the privacy of the individual . Of course many times one doesn ’ t know what PII one has until it is observed . Much like the Schrédinger ’ s cat paradox , the entanglement of unobserved PII in customer data can help associate concretely the interaction between seemingly separate customer data , thereby helping to cluster disparate data sources and then after its removal , remnants of its presence still remain as part the unique user profile created . http : //online.wsj.com/article/SB 1000 1424052748703 9409045 753950735 12989404 html censorship by the careful selection of news and information that can be showed to specific users . The Filter Bubble The filter bubble ” is the term invented by internet activist Eli Pariser in his book “ The Filter Bubble : What the internet is Hiding from You ” . ’ ® It is described as the result state in which internet users are separated from information that disagrees with their viewpoints , thus 929 This tailoring of information to the internet isolating them in a cultural or ideological bubble . user is a result of advances in tracking technology and data mining algorithms . Specifically , the website algorithms use information about the user such as location , click behavior , search history and any other specific information ( gender , education level , sexuality , etc . ) about the user either explicitly or implicitly gathered and then chooses information to show to the user based on the algorithm ’ s predictions . The players : Google — considered the pioneer in personalization with its personalized search results . Google ’ s personalized search results were based on a logged in users search history . As opposed to earlier web search algorithms which looked at the relevancy of the search terms to web pages and thus a larger universe of possibilities , this focused more on the user ’ s past activity in terms of surfing history and made inferences based on this information. ” As of December 4 , 2009 , the Personalized Search was introduced to all users of Google , even those not logged in to a Google Account. ” Concerns brought up regarding this development in search technology included ' 8 Eli Pariser , The Filter Bubble : What the Internet Is Hiding from You , Penguin Press ( New York , May 2011 ) ISBN 978-1-59420-300-8 ' ? nttp : //en.wikipedia.org/wiki/Filter_bubble ? ° http : //www.searchenginejournal.com/the-google-filter-bubble-and-its-problems/29879/ 2 ] ittp : //news.cnet.com/Google-automates-personalized-search/2 100-1032 3-5766899 html ” ittp : //googleblog . blogspot.com/2009/12/personalized-search-for-everyone.html decreasing the likelihood of finding new information by bias based on previously found search results , privacy problems for those users unaware of the personalization aspect of their search , and a disruptive effect to the search engine optimization industry which relied standardized rankings across users and not individualized ones. ” * Facebook — touted by some as the feature that allows the wall between the social network and the world to be broken ” , Facebook ’ s instant personalization feature was launched in February of 201 land ( by default ) allowed sites such as Pandora or Bing to personalize their sites based on data gathered from your account . By allowing third party apps and websites to gain access to Facebook user ’ s personal data , Facebook in turn will gain access ( own ) the data that results from this interaction and further its strategy of Data Dominance ” . Facebook from a commercial perspective of course , has no choice to do otherwise since it is in direct competition with Google and must develop ways to keep its users engaged with Facebook even when they are not on the site ( through for example an external ad network that uses the data assets acquired by Facebook Exchange —a realtime bidding ad system ” ) . Yahoo — In early 2012 , Yahoo has begun a push towards the increased emphasis on personalization of content for the user . For new users , the news feed starts off in a generic manner , but as more stories are clicked on , then the feed will begin to adjust based on the user choice of articles and stories . * ’ There is some active and conscious user input however , in that hovering over the right side of each story and clicking an X will de-emphasize that specific topic in the news feeds whatever that may be . In a further nod to the importance of integration with 3 nttp : //www.networkworld.com/news/2009/120709-google-personalized-results-could-be.html * http : //www.zdnet.com/blog/igeneration/facebook-instant-personalization-how-to-disable-it-and-why/8006 5 hittp : //www.geekwire.com/20 12/facebook-personalization-engine-web/ ? 6 itty : //techcrunch.com/2012/06/13/facebook-exchange/ 27 tty : //techcrunch.com/2013/02/20/yahoo-personalized-front-page/ other social media sites , Yahoo will allow users to interact with sites such as Flickr , Facebook and Twitter and presumably exchange customer data about these social transactions . Microsoft — like Facebook , Microsoft has a common enemy named Google , and the personalization strategy created for its search engine Bing serves as a counterweight to Google ’ s dominance on the web . Bing now includes search results with Facebook activity by a user ’ s friends related to the search term . * * And as Bing ’ s web algorithm thinks the social results are relevant they show up ( within the Facebook module ) higher in the page . Interestingly , those users who feel uncomfortable with the Facebook instant personalization and Bing combination technology , will be able to opt out via a pop-up message within the first five times they access the feature . It is apparent from the four examples above , that competition is driving the use of personalization online , as much as consumer demand . In fact , 66 % of business respondents surveyed in one study answered that both an improved customer experience and improved business performance are the main drivers of personalized web services . ? ” However , even despite the level of personalization attained by the major players , it is still considered in its early days and thus it is difficult to see how far personalization will be allowed to extend into the privacy of internet users and the control of their personality The Inviolate Personality and the Right to Privacy Within the philosophy of self , the personality can be described as those qualities in a person that describes him or her uniquely as compared to others . Personality at least from a modern understanding derives its roots from the Renaissance period , where introspection and the concept self-development of the individual as opposed to the membership of a class defined the 8 http : //gigaom.com/2010/10/13/bing-launches-facebook-instant-personalization/ 2 ? ttp : //econsultancy.com/us/blog/62583-94-of-businesses-say-personalisation-is-critical-to-their-success 3° http : //econsultancy.com/us/reports/the-realities-of-online-personalisation-report self ! This interpretation of self is in stark contrast to Stephen Greenblatt ’ s more Medieval concept of defining self in the framework of the “ household , the kinship network , the guild and the corporation ” as described in his book on the history and recovery of Lucretius ’ poem “ De Rerum Natura ” , - The Swerve : how the world became modern . In Warren and Brandeis ’ 1890 article “ The Right to Privacy ” , the 20 '' century foundations were laid to answer the question of what the Right to Privacy meant in the modern era. ” The publication of the paper , while clearly a response to what was the invasiveness of the then recent technological innovation of photography and the rise of “ ‘ yellow journalism ” served to define Privacy more as the “ right to be let alone ” with the focus on protecting the individual . Later in Olmstead v. United States , Brandeis further developed the right to privacy from a constitutional perspective , thereby implicating the government as a potential invader of the individual ’ s privacy . * ® Prosser in his work , Privacy * * , wrote that under the mantra of the “ right to be left alone ” , there were four separate torts : 1 . “ Intrusion upon the plaintiffs seclusion or solitude , or into his private affairs. ” 2 . “ Public disclosure of embarrassing private facts about the plaintiff. ” 3 . “ Publicity which places the plaintiff in a false light in the public eye. ” 4 . Appropriation , for the defendant ’ s advantage , of the plaintiffs name or likeness. ” Finally Prosser , in his article “ The Right of Privacy ” * * ( and more recently in his interviews ) ” , approaches privacy rights from almost a purely economic standpoint . He argues that : 3 http : //www.arcaneknowledge.org/histschol/renaissance.htm 2 Warren and Brandeis , `` The Right To Privacy '' , 4 Harvard Law Review 193 ( 1890 ) . 3 ? Olmstead v. United States , 277 U.S. 438 , 1928 . * 4 Dean Prosser , ‘ Privacy ’ ( 1960 ) , 48 California Law Review 383 . * > Posner , Richard A. , `` The Right of Privacy '' ( 1978 ) . Sibley Lectures . Paper 22 . 36 http : //bigthink.com/videos/judge-richard-posner-privacy Privacy and curiosity are considered to be intermediate goods which have instrumental as opposed to ultimate value . The demand for private information is understandable where possible relationships create opportunities for the demander such as the tax collector , fiance ’ , partner , etc . It is also understandable in terms of casual prying into the private lives and is motivated by self-interest of the person who is prying . The supplier of private information also may make use of his or her private information through misrepresentation , thus manipulating other people ’ s opinion of them . Thus the wish for privacy is about controlling “ others ’ perceptions and beliefs vis-a-vis the self-concealing person ” or put more succinctly to “ control the flow of information about ” one ’ s self . As disclosure is resisted by those who wish to maintain their own privacy and is valuable to others , this would seem to imply that property rights exist in people ’ s own information about themselves . However , transaction costs “ militate ” against assigning property rights to the possessor of a secret . What ’ s more , information acquired by government entities have protections built in to assure against disclosure . In terms of discreditable information , the possessor can use this information to mislead those with whom there is a transaction such as an employer , an insurer or a potential spouse . It is wrong on economic grounds for an individual to conceal material facts about themselves . Although a duty of full and frank disclosure would be burdensome , everyone should be allowed to protect himself from disadvantageous transactions . In summary , Posner ’ s economic efficiency approach to the Right of Privacy is that 1 ) trade and business secrets are protected to allow one to exploit superior knowledge or skills , 2 ) no protection for facts about people , - health , temper , income but some ability to prevent their discover if not unduly intrusive and 3 ) limitations of eavesdropping or other forms of surveillance to only illegal activities . The Filter Bubble and the Right to Privacy It should be clear from Warren and Brandeis ’ essay all the way to Posner ’ s Lecture that Privacy Rights offer little in the way of protecting users against the Filter Bubble . Online service providers and advertisers have integrated personalization technologies into the user experience to the point where , we have lost the ability to control the information that is fed to us . The Renaissance model of personality emphasizes the individual ’ s ability to “ self-determine ” through the continuous and unfettered freedom of choice of association . The medieval model instead associates self with class or more specifically with the `` household , the kinship network , the guild and the corporation ” . One needs not delve to long in thinking to understand that this recent development in the personalization of the web-experience is much more medieval in nature . Solutions and Recommendations ENISA makes several recommendations in its paper “ Privacy Considerations of online behavioural tracking : 1 . Refocus on tracking not on OBA -— the debate today seems almost diversionary as 37 if Online Behavioural Advertising was the bogeyman of internet privacy issues . However , “ creepiness ” is not a harm against which the constitution protects us . 37 http : //venturebeat.com/2012/02/22/the-7-creep-factors-of-online-behavioral-advertising/ Moreover , it has been hard for plaintiffs to make claims of harm due to OBA stick . Given the more constitutionally protected rights being infringed by government surveillance , this refocusing on tracking itself , may allow the legal system to find other solutions to protect internet users . 2 . More meaningful privacy policies — the notice and choice aspect of privacy standards is seriously limited according to ENISA and more must be done to overcome their limitations . However , given weak enforcement , a lack of substantial restrictions , lack of real notice and the lack of real choice ? ® , this recommendation seems far from practical . 3 . Easier to use tools for transparency and control — TETs ( Transparency Enhancing Technologies ) are suggested to help improve user awareness about their being tracked and profiled while engaging in web activity . This still however requires a level of knowledge that is beyond the average user and probably impractical from an implementation standpoint . At what level does the usability of these tools have to reach to ensure that everyone is informed of their rights ? 4 . Compliance and monitoring initiatives -ENISA suggests Privacy impact assessments and possibly privacy certification as important initiatives to show how a service or application might affect a user ’ s privacy . More importantly , in a shift away from the traditional notice and choice to what may become an accountability standard , ENISA suggests that the monitoring and detecting of violations and the enforcement of rules become important tools in protecting online users from illegal privacy practices . 38 http : //digitalads.org/documents/Schwartz Solove Notice Choice NPLAN BMSG memo.pdf 5 . Anti-tracking initiatives for Mobile Apps — since current browser technology has not adapted to mobile platforms , most tracking is occurring through mobile applications which offer no DNT choice except for uninstalling of the application . 6 . Privacy-by-design - although unsuccessful till now , regulation would have an important role in pushing the burden of enforcing online privacy to businesses . Until they are obligated through laws or regulation , it is unlikely that companies will integrate privacy into their products or processes when they can simply disclaim liability through privacy policies that are largely ignored by the consumer . As described from the ENISA study on online behavioural advertising , there are several solutions to privacy issue of personalized tracking . Some solutions if endorsed by governments would probably be successful , however , given that governments have come to know the power of tracking in furthering their goals of citizen and extra-territorial surveillance , it is possible that these new regulations and laws may never come . What can work and has worked in the past is for the legal system to understand the nature of the constitutional infringements that occur when user personalization stifles the free flow of information and choice in association . If newspapers were to begin printing individualized papers based on the subscribers religious , ethnic or sexual orientation , there would be a resounding howl of protest from the public and legal community based on First Amendment rights here in the United States.° ’ And more explicitly from the perspective of the Universal Declaration of Human Rights , Artice 19 , “ everyone has the right to freedom of opinion and 3° http : //www.archives.gov/exhibits/charters/constitution zoom 1.html expression ; this right includes freedom to hold opinions without interference and to seek , receive and impart information and ideas through any media and regardless of frontiers. ” * htto : //www.un.org/en/documents/udhr/ See discussions , stats , and author profiles for this publication at : https : //www.researchgate.net/publication/3 15953992 Filter bubbles and fake news Article in Crossroads - April 2017 DOL : 10.1145/3058153 CITATIONS READS 74 22,465 2 authors , including : Dominic James Difranzo Lehigh University 27 PUBLICATIONS 224 CITATIONS SEE PROFILE Some of the authors of this publication are also working on these related projects : Project Evaluation of a peer-support based mobile application for reducing non-suicidal self-injury View project All content following this page was uploaded by Dominic James Difranzo on 29 November 2017 . The user has requested enhancement of the downloaded file . ResearchGate Filter Bubbles and Fake News The results of the 2016 Brexit referendum in the U.K. and presidential election in the U.S. surprised polls and traditional media , and social media is now being blamed in part for creating echo chambers that encourage the spread of fake news that influenced the voters . By Dominic DiFranzo and Kristine Gloria-Garcia DOI : The EU referendum in the U.K. and the U.S. presidential election both shocked journalists , pollsters , and citizens around the world . The outcomes—the U.K. voting to leave the EU and Donald Trump winning the presidency—traise the question of how traditional media and polls could have been so wrong in their predictions [ 1 ] . While plenty of fingers have pointed to outside interference , changing demographics , and economic concerns , one scapegoat—social media—has received special attention . Some critics place the fault with Facebook , Google , and other social media platforms for allowing the spread of “ fake news , ” pointing to , for example , the creation and facilitation of echo chambers , where users are not exposed to outside options and views [ 2 ] . According to The New York Times , following Trump ’ s victory , executives at Facebook began to privately chat about the role their company and platform had on the election [ 1 ] . However , Facebook CEO Mark Zuckerberg downplayed the company ’ s role in the election , saying , “ Voters make decisions based on their lived experience ” and the theory that fake news shared on Facebook “ influenced the election in any way , is a pretty crazy idea. ” [ 3 ] . So we ask , did social media play a role in these election upsets ? In this review , we examine whether social media really played a role , if fake news and filter bubbles had an effect , and if so , what can be done about it in the future . Social Media Effect Social media trends ( in terms of , say , numbers of posts , shares , and likes ) on the day of the elections favored both Brexit and Trump , [ 4 ] which was counter to the narrative of reputable polling and traditional media . Trump had more followers across social media platforms . He did , however , and continues to , push messages using social media rather than traditional media channels , and had higher engagement rates compared to his opponent . One of the most shared posts on social media leading to the election was “ Why I ’ m Voting For Donald Trump , ” a blog post by a well-known conservative female blogger [ 4 ] . The trend was similar during the EU Referendum in the U.K . The official “ Leave ” campaign had more followers and engagement on social media platforms , as well as more success in spreading pro-leave hashtags and messages [ 5 ] . Moreover , according to Pew Research , 61 % of millennials use Facebook as their primary source for political news [ 6 ] . Such news stories have been shown to have a direct effect on political actions , attitudes and outcomes . In 2012 , a study reported in Nature described a randomized controlled trial of political mobilization messages delivered to 61 million Facebook users during the 2010 U.S. congressional elections . It found the messages directly influenced political self- expression , information seeking , and real-world voting behavior [ 7 ] . This is not surprising , as the dominant funding strategy of most social media platforms follows the assumption that sponsored social media posts , or advertisements , can change the buying behavior of their users [ 8 ] . In another example , the past decade has seen a rise in political movements ( such as the Arab Spring and Black Lives Matter ) that start on and are sustained through social media platforms like Twitter and Facebook . Hampton and Hargittai [ 9 ] showed evidence that the demographic most disconnected from social media and the web were also the most likely to be Trump supporters . Voters without a college degree supported Trump by a nine-percentage-point margin , whereas in past elections they were equally likely to support Democrats as Republicans . These gaps widen greatly when pollsters look at white non-college educated voters , who supported Trump by 39 percentage points , the largest margin of support from this demographic since 1980 [ 9 ] . This group in particular—white non-college educated—were also most likely to not have access to the Internet , and of those who do are most likely to not use social media [ 6 ] . Additionally , research from Pew Research shows that while millennials ( people born 1977 to 1995 ) get their political news from social media platforms , most Americans still rely on their local TV news stations and other traditional mass-media sources [ 6 ] . These are the same mass- media sources where Trump received significantly more attention and coverage compared to Hillary Clinton [ 6 ] . And while social-media-savvy millennials overwhelmingly supported Clinton , voter turnout from this demographic was lower than in both the 2008 and 2012 presidential elections . Further data analysis shows Clinton supporters were most likely to be engaged on social media platforms like Twitter and Reddit [ 9 ] . Why then did a first pass look at social data trends show more support for Trump than Clinton if social media users seemed to support Clinton more ? The answer is still being investigated , but one answer may be in the use of botnets . Two recent studies—one from researchers at the University of Southern California and another from Oxford University , the University of Washington , and Corvinus University of Budapest—both showed AlI-controlled bots were spreading pro-Trump content in overwhelming numbers . Kollanyi , Howard and Woolley [ 11 ] from Oxford University estimate that one-third of pro-Trump tweets came from automated bots , which they classified by how often these accounts tweet , at what time of day , and their relation to other accounts . This created the illusion of more support for Trump on Twitter than there may have been naturally [ 10,11 ] . Kollanyi , Howard and Woolley [ 11 ] noted similar automated patterns on Twitter leading up to the EU referendum in the U.K. in which pro-Leave tweets greatly outnumbered pro-Stay tweets . Filter Bubble Another criticism of social media is that it constructs “ filter bubbles , ” digital echo chambers where users see content and posts that agree only with their preexisting beliefs [ 12 ] . While there is an active dialogue taking place as to whether filter bubbles exist , here , we highlight work that explores whether it contributed to the 2016 election results . In 2015 , Facebook funded a study that showed that while Facebook ’ s own newsfeed algorithm might favor posts that support a user ’ s political beliefs , the related filter-bubble effect is due to the user ’ s network and past engagement behavior ( such as a clicking only on certain news stories ) ; that is , it is not the fault of the newsfeed algorithm but the choices of users themselves . They also found that this favoritism effect is small overall . The study showed users are only 6 % less likely to see a post that conflicts with their political views when compared to an unfiltered newsfeed [ 13 ] . Personal recommendation systems , or systems that learn and react to individual users , have been claimed to be one cause of filter bubbles [ 12 ] . Other studies have shown that personalized recommendations can actually expose users to content they might not have found otherwise [ 14 ] and that personalized recommendations are not used as extensively as once thought [ 15 ] . A 2011 national survey by Pew Research found Facebook use is actually correlated with knowing and interacting with a greater variety people from different backgrounds and demographics [ 16 ] . This correlation persists despite controlling for the demographic characteristics of Facebook users compared the U.S. population as a whole . In a sense , social media may actually be bursting filter bubbles . This same survey showed that people who are offline are more likely to be socially isolated and have less diverse social relationships , thereby being exposed to less-diverse ideas and viewpoints [ 16 ] . While these studies are compelling , evidence of filters bubbles and their effect on users continues to grow . For example , several scholars have criticized the 2015 Facebook Newsfeed Study cited earlier . Specifically , Zeynep Tufekci rebutted many of the findings and methodology of the study [ 17 ] , accusing the study of underplaying its most important conclusion indicating the newsfeed algorithm decides placement of posts and this placement greatly influences what users click and read . Tufekci also highlighted that the sampling was not random and thus can not be generalized across all Facebook users . Even if one takes the Facebook study at face value , it still shows this filter bubble effect is real and the algorithm actively suppresses posts that conflict with a user ’ s political viewpoint . Other recent studies ( such as Del Vicario et al . [ 18 ] on the sharing of scientific and conspiracy stories on Facebook ) found evidence of the formation of echo chambers that cause “ confusion about causation , and thus encourage speculation , rumors , and mistrust. ” Fake News On the theme of “ speculation , rumors , and mistrust , ” fake news is another issue that has plagued social media platforms during , as well as after , the U.S. elections . Fake news is a recent popular and purposefully ambiguous term for false news stories that are packaged and published as if they were genuine . The ambiguity of this term—an inherent property of what it tries to label— makes its use attractive across the political spectrum , where information that conflicts with an ideology can be labeled “ fake. ” The Times published an article [ 19 ] chronicling the spread of fake news on social media , saying one such fake story was shared at least 16,000 times on Twitter and more than 350,000 times on Facebook . According to BuzzFeed [ 20 ] , in the months before the U.S. elections , fake news stories on Facebook actually outperformed real news from mainstream news outlets . BuzzFeed [ 20 ] said these fake news stories overwhelmingly favored Trump . For example , a fake news story reported that Pope Francis endorsed Trump and was shared more than one million times on social media feeds . Pope Francis , an advocate for refugees , made no such endorsement . Not only were these fake news sources shared on social media platforms they were also shared by Trump and members of his campaign [ 9 ] . Fake news stories have a real effect offline as well . A shooting took place ina Washington , D.C. , pizzeria , Comet Ping Pong , after fake news stories and conspiracy theories spread about it being part of a child trafficking ring [ 21 ] . Army Lt. Gen. Michael Flynn , Trump ’ s current National Security Adviser shared fake news stories related to this so-called “ Pizzagate ” scandal more than 16 times , according to a Politico review of his Twitter posts [ 22 ] . Although fake news may be a problem ( though not unique to social media ) , its dissemination may not break out of the filter bubble at its point of origin . Several studies have shown the spread of fake news is similar to epidemics compared to real news stories and that such stories usually stay within the same communities [ 23 ] ; that is , these stories tend to not reach or convince outsiders . Likewise , Mark Zuckerberg said in a Facebook post following the U.S. election , “ Of all the content on Facebook , more than 99 % of what people see is authentic . Only a very small amount is fake news and hoaxes . Overall , this makes it extremely unlikely hoaxes changed the outcome of this election in one direction or the other ” [ 3 ] . He did not provide any data or evidence to back this claim . As the dust continues to settle from the elections , research into the role of social media and digital media platforms as key influencers will continue . We acknowledge how unlikely it is analysts will ever reach a commonly accepted explanation for the election outcomes . However , it is imperative to acknowledge the need to study such potential cause and effects . This has laid out the potential research questions ; now , we turn to possible solutions . Future Solutions Even though fake news and filter bubbles are a problem that indeed affected the U.S. presidential election , social media platforms like Facebook and Google are exploring ways to reduce these influences on their platforms . Both Google and Facebook recently , November 2016 , announced the banning of websites that publish fake news from their advertising networks , effectively killing the revenue stream of these sites [ 24 ] . Facebook has also created new tools to flag fake content and is partnering with third-party fact-checking organizations like Snopes and Politifact [ 25 ] . Facebook is also developing better automatic fake-news-detection systems that will limit the spread of such content . Researchers and software developers have been looking into tools to help break out of filter bubbles [ 26 ] , including filtering algorithms and user interfaces that give users better control and allow more diversity . Other tools ( such as browser plugin Ghostery and search engine DuckDuckGo ) are being developed to help anonymize users actions online , thus disabling personalized recommendations . Bot and spam detection is another major area of research . Many social media platforms already use a range of tools , from machine learning to social network analysis , to detect and stop bots . Independent groups and researchers have also developed tools to detect bots ; for example , researchers at Indiana University have developed BotOrNot ( http : //truthy indiana.edu/botornot/ ) , a service that allows anyone to check if a particular Twitter user is a bot . Difficult Questions In addition to technical enhancements and design choices , what other avenues , even public policymaking , are available for combating these issues ? This may be a particularly difficult question in the U.S. due to free-speech protections under the First Amendment of the U.S. Constitution . We already see legal and political tensions as Twitter implements internal policies for flagging hate speech and closing specific accounts . Others have suggested a reinstatement of media- and civic-literacy initiatives to help users discern trustworthy , genuine news sources . These issues of fake news and filter bubbles are vague , nuanced and pre-date social media , with no easy solution , but it is vital that researchers continue to explore and investigate them from diverse technical and social perspectives . Their skills , knowledge , and voices are needed now more than ever , and for the good of all , to address them . References [ 1 ] Isaac , M. Facebook , in cross hairs after election , is said to question its influence . The New York Times ( Nov. 12 , 2016 ) ; https : /Awww.nytimes.com/2016/11/14/technology/facebook-is-said- to-question-its-influence-in-election . html [ 2 ] Isaac , M. and Ember , S. For election day influence , Twitter ruled social media . The New York Times ( Nov. 8 , 2016 ) ; http : /Avww.nytimes.com/2016/11/09/technology/for-election-day -chatter- twitter-ruled-social-media.html [ 3 ] Kokalitcheva , K. Mark Zuckerberg says fake news on Facebook affecting the election is a “ crazy idea. ’ Fortune ( Nov. 11 , 2016 ) ; http : //fortune.com/2016/1 1/1 1/facebook-election-fake- news-mark-zuckerberg/ ? iid=sr-link1 10 [ 4 ] El-Bermawy , M.M . Your filter bubble is destroying democracy . Wired ( Nov. 18 , 2016 ) ; https : //www.wired.com/2016/11/filter-bubble-destroying-democracy/ [ 5 ] Sigdyal , P. and Wells , N. At least on Twitter , the ‘ leave ’ Britain vote has the edge Twitter users scream ‘ leave ’ in Brexit vote , but ‘ remain ’ gains ground ( June 23 , 2016 ) ; http : //www.cnbc.com/2016/06/23/twitter-users-scream-leave-in-brexit-vote-but-remain-gains- ground.html [ 6 ] Mitchell , A. , Gottfried , J. , and Matsa , K.E . Facebook top source for political news among millennials . Pew Research Center ( June 1 , 2015 ) ; http : //www.jourmalism.org/2015/06/0 1/facebook-top-source-for-political-news-among- millennials/ [ 7 ] Bond , R.M. , Fariss , C.J. , Jones , J.J. , Kramer , A.D.I. , Marlow , C. , Se le , J.E. , and Fowler , J.H . A 61-million-person experiment in social influence and political mobilization . Nature 489 , 7415 ( Sept. 2012 ) , 295-298 . [ 8 ] Taylor , D.G. , Lewin , J.E. , and Strutton , D. Friends , fans , and followers : Do ads work on social networks ? Journal of Advertising Research 51 , | ( 2011 ) , 258-275 . [ 9 ] Hampton , K. and Hargittai , E. Stop blaming Facebook for Trump ’ s election win . The Hill ( Nov. 2016 ) ; http : //thehill.com/ blogs/pundits-blog/presidential-campaign/307438-stop-blaming- facebook-for-trumps-election-win 11 [ 10 ] Fields , J. , Sengupta , S8. , White , J. , Spetka , S. et al . Botnet Campaign Detection on Twitter. , Master of Science Thesis in Computer and Information Sciences , Department of Computer Sciences , SUNY Polytechnic Institute , Utica , NY , 2016 ; https : //dspace.sunyconnect.suny .edu/handle/195 1/6835 1 [ 11 ] Kollanyi , B. , Howard , P.N . and Woolley , 8.C . Bots and automation over Twitter during the third U.S. presidential debate . Political Bots ( Oct. 31 2016 ) ; http : //politicalbots.org/wp- content/uploads/2016/10/Data-Memo-Third-Presidential-Debate pdf [ 12 ] Pariser , E. The Filter Bubble : How the New Personalized Web Is Changing What We Read and How We Think . Penguin , New York , 2011 . [ 13 ] Bakshy , E. , Messing , S. , and Adamic , L. Exposure to ideologically diverse news and opinion on Facebook . Science 348 , 6239 ( 2015 ) , 1130-1132 . [ 14 ] Hosanagar , K. , Fleder , D. , Lee , D. , and Buja , A . Will the global village fracture into tribes ? Recommender systems and their effects on consumer fragmentation . Management Science 60 , 4 ( 2013 ) , 805-823 . [ 15 ] Weisberg , J . Bubble trouble : Is web personalization turning us into solipsistic twits . S/ate ( June 10 2011 ) , http : //www.slate.com/articles/news_and_politics/the_big_idea/2011/06/bubble_trouble.html 12 [ 16 ] Hampton , K. , Sessions Goulet , L. , Rainie , L. , and Purcell , K. Social networking sites and our lives . Pew Research ( 2011 ) http : /Awww.pewinternet.org/20 1 1/06/16/social-networking-sites- and-our-lives/ [ 17 ] Tufekci , Z . How Facebook ’ s algorithm suppresses content diversity ( modestly ) and how the newsfeed rules the clicks . Medium ( 2015 ) ; https : //medium.com/message/how-facebook-s- algorithm-suppresses-content-diversity -modestly -how-the-newsfeed-rules-the-clicks- b5f8a4bb7bab # . kw4xqeif0 [ 18 ] Del Vicario , M. , Bessi , A. , Zollo , F. , Petroni , F. , Scala , A. , Caldarelli , G. , Stanley , E. , and Quattrociocchi , W. The spreading of misinformation online . Proceedings of the National Academy of Sciences 113 , 3 ( 2016 ) , 554-559 . [ 19 ] Maheshwari , 8S . How fake news goes viral : A case study . The New York Times ( Nov. 20 2016 ) . http : /Awww.nytimes.com/2016/1 1/20/business/media/how-fake-news-spreads . html [ 20 ] Silverman , C. This analysis shows how viral fake election news stories outperformed real news on Facebook . BuzzFeed ( Nov. 16 , 2016 ) ; https : //www.buzzfeed.com/craigsilverman/viral- fake-election-news-outperformed-real-news-on-facebook ? utm_term=.xu3M8zonA # .xqbRqV1D8 [ 21 ] Kang , C. Fake news onslaught targets pizzeria as nest of child-trafficking . The New York Times ( Nov. 21 , 2016 ) ; http : //www.nytimes.com/2016/11/2 1Aechnology/fact-check-this- 13 pizzeria-is-not-a-child-trafficking-site.html [ 22 ] Bender , B. and Hanna , A. Flynn under fire for fake news . Politico ( Dec. 5 , 2016 ) ; http : //www.politico.com/story/20 16/12/michael-flynn-conspiracy-pizzeria-trump-232227 [ 23 ] Jin , F. , Dougherty , E. , Saraf , P. , Cao , Y. , and Ramakrishnan , N. Epidemiological modeling of news and rumors on Twitter . In Proceedings of the Seventh Workshop on Social Network Mining and Analysis ( 2013 ) . ACM Press , New York , Article No . 8 . [ 24 ] Kottasova , I. Facebook and Google to stop ads from appearing on fake news sites . CNN ( Nov. 15 , 2016 ) ; http : //money.cnn.com/2016/11/15/technology/facebook-google-fake-news- presidential-clection/index . html [ 25 ] Heath , A. Facebook is going to use Snopes and other fact-checkers to combat and bury ‘ fake news. ’ Business Insider ( Dec. 15 , 2016 ) ; http : /Awww.businessinsider.com/facebook-will-fact- check-label-fake-news-in-news-feed-20 16-12 [ 26 ] Resnick , P. , Kelly Garrett , R. , Kriplean , T. , Munson , S.A. , and Jomini Stroud , N. Bursting your ( filter ) bubble : Strategies for promoting diverse exposure . In Proceedings of the 2013 Conference on Computer Supported Cooperative Work ( San Antonio , TX , Feb. 23-27 ) . ACM Press , New York , 2013 , 95-100 . Biographies Dominic DiFranzo is a post-doctoral associate in the Social Media Lab at Cornell 14 University , Ithaca , NY ; he holds a Ph.D. in computer science from the Rensselaer Polytechnic Institute , Troy , NY , and was a member of the Tetherless World Constellation . Kristine Gloria-Garcia joined the Aspen Institute Communications and Society Program as a project manager in September 2016 ; previously , she served as a visiting researcher at the Internet Policy Research Initiative at MIT , Cambridge , MA , and as a privacy research fellow at the Startup Policy Lab . She holds a Ph.D. in cognitive science from Rensselaer Polytechnic Institute , Troy , NY , and a master ’ s in media studies from the University of Texas at Austin . pull quotes pick 2 of 3 ? ? 4 Why then did a first pass look by pollsters ? ? at social data trends show more support for Trump than Clinton if social media users seemed to support Clinton more ? 5 Personal recommendation systems , or systems that learn and react to individual users , have been argued claimed ? ? to be one cause of filter bubbles . 9 We already see legal and political ? ? tensions as Twitter implements internal policies for flagging hate speech and closing specific accounts . 15 16 IMAGE BY ECHO3005 / SHUTTERSTOCK.COM DIALOGUES | STANDPOINT Who Wants to Live ina Filter Bubble ? From ‘ Zillow Surfing ’ to Data-Driven Segregation © Yanni Alexander Loukissas , Georgia Tech —a peak moment of Covid-induced the New York Times published ” an increasingly common any U.S. readers will be et ’ s dominant service for ancing residential real ndemic , people are finding ite . “ What many are se Zillow , ” explains the rchase , but an alternate life. ” dto my own home for the ised that people are turning ir living circumstances might ‘ w months of the pandemic , ngs on the site increased more than fifty percent year over year . For many of these new users , Zillow is simply a convenient and comforting means of temporarily escaping the reality of the pandemic . The article , titled “ Zillow Surfing Is the Escape We All Need Right Now , ” appeared in the Style section of the Times with Zillow , buying , renti nthe context creative use and was meant to be a light diversion from more serious investigative pieces on the political and health impacts of the pandemic . However , Zillow surfing highlights an important phenomenon that predates Covid-19 . People have learned to use data to refresh the timeworn dream of owning the right home in the right neighborhood . This new version , which we might call the algorithmic American dream goes something like this : Access to data and algorithmic tools can help us get control of our lives by reducing uncertainties and making our lived realities resemble our filter bubbles . We create filter bubbles when we use algorithms to personalize our online experiences , by blocking any information that doesn ’ t conform to our existing belief system [ 2 ] . The term fier bubble was first used in 2010 to characterize the way that people curate their social media feeds online , effectively excluding perspectives they do not care to see . The same kinds of filters also allow us to address the uncertainties we might face in online dating or in using an app to find a nearby restaurant . Why not use Insights > People are using data on Zillow to refresh the timeworn dream of owning the right home in the right neighborhood . > However , in a society split along racial and class lines , finding your dream home means accepting and navigating many structural inequalities . = > The market that Zillow aims to optimize is a system by which society segregates itself to preserve social hierarchies . INTERACTIONS.ACM.ORG MAY-JUNE 2022 INTERACTIONS 37 DIALOGUES | STANDPOINT data to seek out a new and more fulfilling home life , if only as a fantasy ? Without the need for a real estate agent , who can only show a couple of listings at a time , visitors to Zillow can filter properties by the home features they care about . As with the news , home searches can be made to conform to almost any preexisting belief system . Unfortunately , this way of using data ensures that we do not see the implications of what we filter out . Rashida Richardson ’ s illuminating and cautionary article , “ Racial Segregation and the Data-Driven Society : How Our Failure to Reckon with Root Causes Perpetuates Separate and Unequal Realities ” [ 3 ] , highlighted in this issue of Interactions , suggests one particular concern that might be painful for some to see : How does the history of racial segregation shape the way users of Zillow identify their ideal homes ? In my 2019 book , Ail Data Are Local : Thinking Critically in a Data-Driven Society , | write about Zillow as a data setting , a context in which property values are meant to be operationally rather than truly understood [ 4 ] . Data settings define what we can do with data and what claims about the world we can use them to support . I explain Zillow as part of the “ interface economy ” [ 5 ] , a rapidly growing area of business in which companies aggregate data from various sources and provide access as well as interpretive tools . Some of these companies charge a fee . Others use the popularity of their services to draw advertising revenue . Zillow offers a combination of visual , discursive , and algorithmic tools to make sense of data from county records , multiple listing services , and even homeowners themselves . It is best known for generating daily estimates of the current value of nearly every home in the U.S . The widespread fascination with Zillow is not just about appreciating beautiful homes , which is something that I can relate to as a former architect . Rather , the company encourages visitors to think of real estate data as a vehicle for personal fulfillment . “ We can help you move forward , ” reads the messaging on its website . Visitors to Zillow are responding to this sentiment en masse . “ There ’ s something therapeutic about searching houses and starting to make plans for something with a positive outcome , ” explains one Zillow user . “ It makes me think there is a light at the end of the tunnel , and someday I ’ ll be at my dream house ” [ 1 ] . Completing this dream image takes more than data on property values . Zillow offers access to data on other issues of interest to potential homebuyers , such as neighborhood school performance and crime rates . “ It ’ s easier to picture your future when you have access to the floor plan of the space or know which school your children would attend if you lived there , ” says one Zillow user [ 1 ] . This is where the true stakes of Zillow become clearer . The understanding that where you live determines the opportunities available to your children underlies the very notion of segregation . 38 INTERACTIONS MAY-JUNE 2022 opportunities available to your children . very notion of 5 tg 8 determines the og .e ? . Epedd e -3°82 % 38 ? underlies the + @ - cee @ eece oge8eias segregation . 8 . Teseak TSE 8s . - @ 0 « e . ott Hi e e @ - . ee - @ @ -e oe © In a society split along racial and class lines , finding your dream home means accepting and navigating these structural inequalities . As Richardson explains , your zip code is a social marker that can be used to discriminate against you . For example , in the 1930s the Home Owners ’ Loan Corporation created “ redlining maps ” to claim that there were differential risks of investing in segregated neighborhoods throughout the U.S . Using these maps , federal agencies and private banks alike directed disproportionate financial support to homeowners in predominantly white neighborhoods . Today , the racist effects of redlining can still be felt in cities The under- standing that where you live across the country . Could Zillow have similar cumulative effects , by empowering its users to enact their own beliefs about financial risk through algorithmic filters ? Let me unpack some relevant considerations about how Zillow works as a data setting . The visual interface for the site is a parking-lot-gray map . It is laced with thin white roads and spotted with patches of green and blue to indicate natural areas . Small red dots on the map indicate data points , which are properties available for sale or rent . Underneath each dot is a single value : 425K , 587K , 245K . Zoom in further , and the map subdivides into parcels . Clicking on one brings up more information : an address , the number of bedrooms and bathrooms , the square footage . More-sumptuous details also reveal themselves in this interaction . Artful photographs show off the property , inside and out . Evocative descriptions evoke interior details ( “ hardwood flooring ” ) and surface materials ( “ granite countertops ” ) , as well as nearby amenities ( “ local restaurants and coffee shops ” ) . This context for data exploration is complimented by a discursive framework built around the metaphor of a @ INTERACTIONSMAG 000+ -0 @ e @ O-OO800 -O80- - 0 . - + © @ O- @ 000eSOSSOCCe cGo-00 OSSD » DOGS PSSST Se * °° © + + COCHSOHSOONHSDe - 0D- OHeHe > : - - IMAGE BY BEST VECTOR / SHUTTERSTOCK.COM - @ ©00888e -G00GD-O80-Oe -G0- ° personal journey . “ We can help you find your way home , ” promises the site . Finally , the entire setting is brought to life by its underlying algorithms . Whether or not they are on the market , each parcel mapped on Zillow comes with a Zestimate : an estimated property value , generated anew each day by the company ’ s proprietary valuation model . According to Zillow , these values are within 4.5 percent of the final sale price of properties fifty percent of the time . Real estate agents are often dismissive of Zestimates . But they can be extremely alluring to buyers and sellers alike . Even if users know that Zillow ’ s numbers are not entirely reliable , Zestimates give them a handhold in an otherwise Hie uncertain and rapidly changing marketplace . What ’ s more , they are free . But there are unseen costs to using Zillow that fall disproportionately on nonusers , particularly those in low-income communities . In 2019 , I wrote about my own experience learning about Zillow as a first-time homebuyer in Atlanta , Georgia : I found that Zillow supported certain kinds of desires : the right neighborhood , the right price , the right school zone , and the expectation of a stable investment , or even a profit . But it did not support other things my partner and I cared about . We were wary of contributing to Atlanta ’ s latest wave of gentrification . There are few policies in Georgia to protect low-income homeowners and renters from the increasing costs of staying in their own neighborhoods . In fact , we were ambivalent about becoming homeowners at all , ifit meant participating in an inherently unjust system [ 6 ] . Eventually , I did buy a home . It was a challenge to find a neighborhood in Atlanta that was not either segregated or actively gentrifying . During the civil rights movement , Atlanta became a center for Black cultural life . More recently , middle-class white newcomers , like myself , have INTERACTIONS.ACM.ORG either chosen to live apart from long-term Black residents or displaced those who have not had the means to compete in the market . Tragically , gentrification is fundamentally altering some of Atlanta ’ s most historically significant Black neighborhoods , such as the Old Fourth Ward , where Martin Luther King Jr. once lived and is still memorialized today . On Zillow , the neighborhood is represented as no more than a collection of listings for sale . The photos reveal dreamy interiors ( remodeled to sell ) and their Zestimates are on the rise . The interface economy seems to take all data at face value , without regard for local or contested meanings . In Zillow , more rights are afforded to data than the people or places that they rather crudely represent . If researchers who contribute to human-computer interaction are to understand the dynamics that Robinson has described , and formulate just responses , we need to raise our own critical consciousness . Looking for an indication of how the field is doing in this regard , Irana search on “ race + segregation ” in the digital archives of this publication , Zvteractions . 1 also searched the proceedings of three conferences connected with the Association of Computer Machinery ( ACM ) : Computer-Supported Cooperative Work ( CSCW ) , Computer-Human Interaction ( CHI ) , and Designing Interactive Systems ( DIS ) . The past 10 years show a steady increase in the number of articles that mention both terms , which is promising . But 10 years before that , my search returned few or no results . The study of racial segregation in HCI deserves to be more than a niche topic for a few “ social justice ” researchers . This can not happen without the support of the institutions of higher education that host HCI research programs . At the same time , each of us must confront the implications for our own research . Robinson identifies two primary conditions that might be holding individual researchers back from doing so : 1 ) a lack of understanding about the local histories of segregation and 2 ) a fear of revealing their own complicity , since most HCI researchers are white and middle class . This analysis rings true . It also indicates several opportunities to pivot . There are things that HCI researchers can do to raise their own awareness and that of the field overall . They can work to increase the diversity of HCI programs by making those programs more accessible and relevant for BIPOC young people . They can challenge oppressive legislation targeting “ critical race theory , ” which threatens to keep public universities from teaching the truth about race . Through cross-listed courses and collaborative grants , they can learn from and support researchers who study the effects of racial segregation in Black media studies , American studies , urban sociology , and cultural geography . From my own research , I can offer HCI researchers a few tools for reconnecting data to local histories . I agree with Robinson that racial segregation can only be understood locally , in relation to specific spatial , cultural , and policy conditions . Unfortunately , some researchers in HCI misinterpret local as meaning small scale . They fear that a local perspective will limit the application of their technologies or result in a statistically insignificant study . I contend that /oca/is not a particular scale . Rather , it is a relative designation that is dependent on context . For a nuclear physicist , the local is subatomic . For an MAY-JUNE 2022 INTERACTIONS 39 DIALOGUES | STANDPOINT astrophysicist , it is the solar system . In HCI , a local perspective is one that acknowledges the seams inherent in computing systems . When HCI researchers dismiss the local , they are assuming that it doesn ’ t matter where , when , or who we are . We are all just users . This is the “ myth of digital universalism , ” writes Anita Chan [ 7 ] . Thinking locally can be a form of critical thinking . It is an antidote to digital universalism , which can help us see the human consequences of our filter bubbles . Richardson ’ s article offers us three important questions for assessing data-driven systems , such as Zillow , from a local perspective . These questions have the power to reveal the underlying connections of data and algorithms to racial segregation : 1 ) What problem is being solved by the system ? 2 ) What data is being used to train the system ? 3 ) How is the system being evaluated ? The creators of these systems usually have ready answers to these questions . But they are rarely local answers , and often overlook important implications . Zillow provides a useful object lesson in this regard . Let ’ s consider each of Richardson ’ s questions in relationship to Zillow . What problem is being solved by Zillow ? According to its own messaging , Zillow aspires to help visitors address a personal question : “ How can I find my way home ? ” Judging by the overwhelming popularity of the site , this question resonates broadly . Users of Zillow may not feel at home in their current life circumstances . These feelings may have been exacerbated by the pandemic , which has forced us to meet many more of our needs at home . Our homes have become our primary workplaces , our schools , and often our only places for respite . It is understandable that people need things their current homes are unable to provide . However , buying or selling a home in a market economy has implications that go beyond personal fulfillment . As I explained above , the sale value of a house feeds back into Zillow as a new data point , with effects on how comparable houses are valued . Depending on the local policy environment , this can lead to increases in rent or property taxes for nearby residents , as well as the overall affordability of a neighborhood . In Atlanta , there are few protections from displacement afforded to low-income residents , most of whom are Black . In this way , finding your dream home can cause others to lose theirs . In a society where wealth is inequitably distributed by race and class , the cumulative effect is segregation . How are Zillow ’ s algorithms being trained ? Zillow ’ s algorithms make use of publicly available data to follow the housing market , with the intention of increasing transparency and helping people understand the rapidly changing dynamics of real estate : Our mission is to empower consumers with information and tools to make smart decisions about homes , real estate , and mortgages . For this reason , we do not remove public record 40 INTERACTIONS MAY-JUNE 2022 segregates itself to pre- hierarchies , such as class and race . : property data from Zillow unless it is shown to be erroneous |8\\ . The idea of using public data to help people can seem benevolent . After all , this data is created for the public good . Unfortunately , I have found that public data , such as that which is created for tax assessment purposes , can vary widely in its formulation and accuracy [ 4 ] . Zillow uses this data because it is better than nothing . Moreover , the company can blame public entitles for any errors , while also putting the responsibility for finding them onto users of the site . Visitors to Zillow may see and correct errors about their own properties , but are unlikely to know about more systemic errors , particularly in data from other places . The entire real estate market that Zillow aims to optimize is a system by . e @ e 0 @ ee @ . - @ @ « @ which society ° @ ; $ s | soeeee serve social . The : _ @ e @ e @ e @ e ee @ @ - soe 33838 ge : 5838 : e e @ 6.Uw° @ e 7 . 5686 se : e @ e0 os dt 8ey pt e:8 Instead , visitors are likely to accept that Zestimates are good enough , and check back regularly to see how their homes , dream or real , are faring . I do this myself , usually with an underlying feeling of anxiety . In this way , Zillow is training not only its algorithms but its visitors as well . Repeat visits to Zillow may be good for the company , but this constant checking in encourages visitors to think about property in terms of fear and financial risk , sentiments that motivated the original redlining maps . How is Zillow evaluated ? Like many companies that operate online , Zillow got its start with an advertising model of revenue . It has long connected users of the site to lenders , real estate agents , inspectors , photographers , designers , contractors , and property managers . These are the original customers of Zillow , and they pay significant fees to be represented on the site . Zillow benefits less from the veracity of its Zestimates than their allure for visitors . More recently , Zillow has begun competing for other kinds of work . It is now a lender , a real estate agent , and a property manager . These roles expand its sources of potential revenue without changing the conditions on @ INTERACTIONSMAG eeec @ e-ofeceees ) O0- eo ePeQHeHeHeeHe eH-c @ . IMAGE BY BEST VECTOR / SHUTTERSTOCK.COM which its data and algorithms are evaluated . Data makes Zillow a destination , but the company does not seem to rely on data or algorithms to make money . It is not clear that Zillow holds itself accountable for the quality of its Zestimates or the social implications of generating them on a frenetic daily basis . I was encouraged to find that Robinson ’ s three questions for data-driven systems connect well to the visual , discursive , and algorithmic framework I have developed for analyzing data settings . Data settings establish what claims can be made visible through data ( the problem ) , what counts as data ( the training ) , and what makes for i - ©0 @ NSe -Heece ( ) - eceee- eeceee - C0HCHHHH- COeeHhece © G0G0 - CoHSeHH/eeeeHhecece > CoeSSodeONOoSceHeeee-e -- CODD ) NOS ea ) OeeSecOee -- -- 00 COO - OPOOCOHOS /0o @ ) ) OGee eOs eee GeQeeces 8000 990 -eeecce 0000 ) eOO - OND -HOCOHHOGC > - 0 . Ge - cele ec eOOO : eGel ) S-ce SeceQHe eHeHoeePecee -- e-0 @ © @ - -GeeeQgggeec -Heeceee- ceecePeceeceNgnve- an acceptable claim ( the evaluation ) . It is important to remember that data settings can be shaped by a variety of interpretive motivations . For example , a data setting might alternatively address the problem of racial segregation , integrate the accounts of those who are most affected , and be evaluated in terms of its ability to raise awareness . Such a setting would not simply establish a more equitable means of shopping for a home . It would reveal the inequitable nature of all property valuation and inspire HCI researchers to help people imagine alternative forms of cooperative inhabitation . Jean Baudrillard once quipped , “ Disneyland is there to conceal the fact that it is the ‘ real ’ country , all of ‘ real ’ America , which is Disneyland ” [ 9 ] . He means that we see Disneyland as a distinctive place for fantasy and for being childlike . We imagine that Disney is distinct from the outside world , which is run by serious adults . This distracts us from the reality that most of our own behavior is childish , and that no one is a complete adult . Zillow surfing accomplishes something similar . We tell ourselves it is merely an escape . Who doesn ’ t want the fantasy of a dream home ? Meanwhile , we ignore the obvious : The entire real estate market that Zillow aims to optimize is a system by which society segregates itself to preserve social hierarchies , such as class and race . Who in our society is actually entitled to their dreams ? What I have described as a new algorithmic American dream , in which we can use data-driven decision making to reduce the uncertainty in our lives without considering the impacts on others . It has found one of its most insidious manifestations in real estate . Zillow surfing is merely a heightened manifestation of this dream , absurd enough to be entertaining and appropriately distracting for weekend readers of the New York Times . We do not need to give up on data— provided it is used responsibly and locally—as a means of sharing what we know about the places we live . In All Data Are Local , 1 suggest approaching unfamiliar data as a starting point , a source of questions , and an opportunity to get closer to the people and places beyond data . “ Do not take the availability of data , ” I caution , “ as permission to remain at a distance ” [ 4 ] . For those who engage in Zillow surfing , adopting this attitude could be transformative . If we give up the fantasy of the right house in the right neighborhood , we can use data to awaken our curiosity about the neighborhoods where we have never considered living and the people we might meet there . ENDNOTES 1 . Lorenz , T. Zillow surfing is the escape we all need right now . The New York Times . Nov. 19 , 2020 ; https : //www.nytimes . com/2020/11/19/style/zillow-surfing-home-listings.html . Pariser , E. The Filter Bubble : How the New Personalized Web Is Changing What We Read and How We Think . Penguin Books , New York , 2012. . Richardson , R. Racial segregation and the data-driven society : How our failure to reckon with root causes perpetuates separate and unequal realities . Berkeley Technology Law Journal 36 , 3 ( 2022 ) ; https : //ssrn.com/abstract=3850317 . Loukissas , Y.A . All Data Are Local : Thinking Critically in a Data- Driven Society . The MIT Press , Cambridge , MA , 2019. . Finn , E. What Algorithms Want : Imagination in the Age of Computing . The MIT Press , Cambridge , MA , 2018 . Loukissas , Y.A . Let ’ s change the way big data present the places we live . Big Data & Society : Essays and Provocations . Aug. 15 , 2019 ; https : //bigdatasoc.blogspot.com/p/essays-and-provocations . html . Chan , A.S. Networking Peripheries : Technological Futures and the Myth of Digital Universalism . The MIT Press , Cambridge , MA , 2016. . How doI remove my home from Zillow ? Zillow Help Center ; https : //zillow.zendesk.com/hc/en-us/articles/360058140754- How-do-I-remove-my-home-from-Zillow- . Baudrillard , J . Selected Writings . Stanford Univ . Press , Stanford , 2001 . 6 . © Yanni Alexander Loukissas is an associate professor of digital media in the School of Literature , Media , and Communication at Georgia Tech . His current research interests include participatory mapping , critical visualization , data studies , and smart cities . He is the author of two books , All Data Are Local : Thinking Critically in a Data-Driven Society ( The MIT Press , 2019 ] and Co-Designers : Cultures of Computer Simulation in Architecture ( Routledge , 2012 ) . + > yanni.loukissas { @ lmc.gatech.edu DOI : 10.1145/3529958 COPYRIGHT HELD BY OWNER/AUTHOR INTERACTIONS.ACM.ORG MAY-JUNE 2022 INTERACTIONS 41 Session : Data Navigation CHI 2013 : Changing Perspectives , Paris , France Beyond the Filter Bubble : Interactive Effects of Perceived Threat and Topic Involvement on Selective Exposure to Information Q. Vera Liao & Wai-Tat Fu Department of Computer Science University of Illinois at Urbana-Champaign 201 N. Goodwin Avenue , Urbana IL , 61801 liao28 , wfu @ illinois.edu ABSTRACT We investigated participants ’ preferential selection of information and their attitude moderation in an online environment . Results showed that even when opposing views were presented side-to-side , people would . still preferentially select information that reinforced their existing attitudes . Preferential selection of information was , however , influenced by both situational ( e.g. , perceived threat ) and personal ( e.g. , topic involvement ) factors . Specifically , perceived threat induced selective exposure to attitude consistent information for topics that participants had low involvement . Participants had a higher tendency to select peer user opinions in topics that they had low than high involvement , but only when there was no perception of threat . Overall , participants ’ attitudes were moderated after being exposed to diverse views , although high topic involvement led to higher resistance to such moderation . Perceived threat also weakened attitude moderation , especially for low involvement topics . Results have important implication to the potential effects of “ information bubble ” — selective exposure can be induced by situational and personal factors even when competing views are presented side-by-side . Author Keywords Information Seeking , Filter bubble ; Attitude Change ; Perceived Threat ; Topic Involvement , Peer Opinions . ACM Classification Keywords H.5.m . Information interfaces and presentation ( e.g. , HCI ) : Miscellaneous . General Terms Human Factors . INTRODUCTION Internet has provided a rich and diverse information environment to modern societies . It has , however , also conveniently encouraged selective exposure to information — defined as a tendency to be exposed to information that Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . To copy otherwise , or republish , to post on servers or to redistribute to lists , requires prior specific permission and/or a fee . CHI 2013 , April 27—-May 2 , 2013 , Paris , France . Copyright © 2013 ACM 978-1-4503-1899-0/13/04 ... 815.00. supports one ’ s own beliefs or attitudes [ 8 ] . The selective exposure phenomenon has made many to believe that the Internet is leading to increasing social fragmentation and ideology polarization , as personalized web algorithms that present information based on interests of individual users may eventually lead users to find only information that agrees with their viewpoints and separates them from other viewpoints . In addition , like-minded people may share their views within “ echo chambers ” on the Internet to reinforce their viewpoints [ 23 ] . Premised on this “ filter bubble ” concern , new technology ( typically in the form of information aggregator ) has been developed to promote exposure to diverse perspectives in various domains such as politics [ 15,18,20 ] , healthcare [ 13 ] , science [ 5 ] , and consumer reviews [ 26 ] to avoid the potential negative effects of the filter bubble [ 19 ] . Research has begun to investigate how to design information systems that optimally present diverse information to avoid the filter bubble [ 10 , 25 ] . Information seekers ’ preference for diversity may , however , also be influenced by situational and personal factors such as personality , knowledge , information search context , and personal involvement ( see reviews in [ 2 , 6 , 8 , 11 ] ) . Our goal is to supplement this growing body of research by systematically investigating the influence of two major factors — perceived threat and topic involvement — which arise in a wide range of information search contexts on information seekers ’ selective exposure and attitude change . To preview our results , we found that even in the absence of external information filter — i.e. , when opposing views are presented side-by-side to promote consumption of diverse information ( e.g . [ 13 , 15 , 18 ] ) , selective exposure to information may still exist . Situational Factor — Perceived Threat Information seeking under perceived threat is pervasive . In everyday life , people are constantly facing the need to search for wide ranging assortments of opinions for tackling troubling situations or making critical decision that are either personal , such as those regarding security , health , finance , or societal , such as crime , terrorism , economic crisis . Surprisingly , given the risk of vital loss , people are often biased in seeking information . For example , it is commonly observed by physicians that patients are not 2359 Session : Data Navigation well-motivated to seek balanced information about treatment or diagnosis methods that they assume will bring adverse effects [ 2 ] . Bankers and investors ’ ignorance of warnings given by other experts was believed to have led to the financial crisis . Studies on political anxiety showed that , following major social or political crisis , such as 911 or Iraq war , anxious citizens could be biased in knowledge acquisition about such events [ 7 ] . From a design perspective , it is important to understand users ’ behavior in an information diverse environment under threatening circumstances to inform the design of adaptive , or domain specific information system . For example , an intelligent news aggregator may be able to foresee the potential change of information seeking patterns induced by political or social anxiety in the public atmosphere ; or , by sensing the increased level of anxiety in the individual , and adapt its selection and presentation of information to mitigate potential biases in judgment and decisions . The same applies to various user posting systems , decision support systems , or search engines when employed for topics that are sensitive to perception of threat or anxiety , such as healthcare , politics , finance , etc . Personal Factor — Topic Involvement Topic involvement is often studied together with information seeking and attitude change as a critical moderator ( e.g . [ 21 ] ) . For high involvement topics , users often have a relatively high motivation to extensively seek information to learn more about the topic , even for information that is inconsistent with their existing views . For low involvement topics , users may be less motivated to seek information and therefore possibly more selective in their information consumption . Another interesting practical question is whether there is selective exposure to different types of information . The Internet environment is rich in formal , factual knowledge as well as “ word-of-mouth ” knowledge contributed by peer users , the later of which has become increasingly prevalent by virtue of “ social technologies ” . There is substantial evidence supporting the fact that Internet users seek both factual knowledge and peer opinions . The question , however , is in what kind of situation , and for what kind of users , should the system provides more factual knowledge , or more peer users opinions that support or challenge users ’ existing attitude . In summary , the current research is centered around the following research questions : 1 . How does perceived threat influence users ’ selective exposure to attitude consistent and inconsistent information ? How does such potential change in information seeking process impact attitude change ? 2 . How does topic involvement moderate the impact of perceived threat on selective exposure , as well as attitude change ? CHI 2013 : Changing Perspectives , Paris , France 3 . How do perceived threat and topic involvement influence users ’ preference for factual arguments and peer opinions that convey competing views ? 4 . How does selective exposure to diverse information influence attitude changes ? LITERATURE REVIEW Most research on selective exposure was conducted within the framework of cognitive dissonance theory [ 8 ] . It asserts that people experience cognitive dissonance when they have to consider the negative implications of their selected choice or pre-existed position . To reduce the unpleasant psychological state , information seekers are motivated to expose themselves to attitude consistent information while avoid or discredit attitude inconsistent information . Researchers have studied users ’ selective consumption of diverse , and often competing online information [ 5 , 16 , 18 ] . For example , users ’ selective exposure to online partisan news or opinions is a frequently studied topic [ 9 , 10 , 17 , ] . Because of the greater availability and reduced access cost for diverse information , researchers have found that although Internet users desire for opinion reinforcing information , they do not necessarily show aversion to opposing opinions [ 9 ] . When studying selective exposure , CHI researchers have focused on improving system design to better present diverse information . Frequently they ask questions such as “ what is the optimal diversity level and optimal presentation for agreeable and disagreeable items ” [ 5 , 17 , 18 ] . Results suggest that there is seldom a universally correct answer to such question , but design decisions often depend on various factors . For example , [ 17 ] found that when browsing political news online , some users appear to be diverse-seeking while others are challenge-averse . It appears that the lack of a relatively complete understanding of the underlying factors that influence selective exposure has created obstacles for developing better intelligent and reliable personalization technologies [ 10 ] . Recent studies showed that an increase in relevant dimensions of individual ’ s topic involvement such as topical importance , interests , certainty and confidence could promote information seekers ’ exposure to attitude challenging information [ 1 , 8 , 11 ] . To some extent , the result suggests that , as people become more interested and knowledgeable about a topic , they may as well become more motivated to learn from different opinions to form a better representation of the reality . It is worth pointing out , however , that it does not necessarily mean they are more subject to the persuasive influence of competing views . To the contrary , they may scrutinize the information more deliberatively , thus their attitudes were moderated only when they perceived strong arguments [ 21 , 22 ] . Meanwhile , people who are less involved in the topic tend to put more weight on factors that are peripheral to the information ( e.g. , other people ’ s agreement , information 2360 Session : Data Navigation source , etc ) [ 21 ] , therefore may differ from those highly involved in their preference for factual arguments and peer opinions when seeking for diverse information . As an example , in [ 16 ] , a study on patients using social media to learn alternative disease models showed that when evaluating alternative views , patients who committed to a prior existing model put more weight on factual information while patients started with no clear model tended to rely on other patients ’ agreement . Selective exposure is also highly dependent on the social context . Among others , perceived threat , or anxiety it brings , has raised increasing attention recently ( see review in [ 6 ] ) . This body of research shows mixed evidence for whether threat reduces or increases selective exposure . Some argued that threatening perspective encourages users to be more vigilant in information seeking , thus carry out more cognitive effort to process unbiased information [ 24 ] . In contrast , from a motivational perspective , some argue that the cognitive dissonance theory predicts the increased levels of selective exposure because users have to cope with the increased level of cognitive discomfort and dissonance incurred by threat . These mixed results motivated researchers to attempt to disclose the underlying factors that moderate the effects of threat [ 6 ] . METHODOLOGY Participants We recruited 28 participants from the Illinois Champaign- Urbana community . They mainly consisted of a mix of college students , faculties and university staff . According to [ 4 ] , younger people with higher education are most likely to seek political news and participate in political activities online . Although it is possible that people with different social , cultural , and educational backgrounds may exhibit different information seeking behavior , we believe our sample is at least representative of a most active subset of the online user population who are concerned with seeking information about controversial social-political issues . Participants were randomly assigned to the conditions with ( group 2 ) and without ( group 1 ) the threat manipulation . The demographical information questionnaire showed there is no significant difference ( p > 0.10 ) in age ( M1=26.30 , M2=28.78 ) , gender ( 64.3 % in group 1 and 57.1 % in group 2 are female ) education level ( 35.7 % in group 1 and 42.9 % in group 2 are graduate students or have graduate degree ) , Internet use frequency ( M1=1.72 , M2=1.53 , for scale from 1-less than an hour per day to 5-more than 8 hours per day ) , political leaning ( M1=3.4 , M2=3.1 , scale from 1- conservative to 5-liberal ) , and self-reported knowledge about the topics between the two groups . Materials and Measurements We first selected 13 candidate topics that are commonly deemed as controversial . To ensure a reasonably balanced distribution of topic involvement level among participants , we selected topics from various domains ( e.g. , ethics , 2361 CHI 2013 : Changing Perspectives , Paris , France healthcare , crime , sports ) ranging from common focus of public debate ( e.g. , death penalty ) to topics that are less prevalently discussed ( e.g. , using steroids for sports ) . We measured participants ’ attitude on each topic by using a 5- item semantic differential scale , which is often used to derive attitude towards given concept by measuring its connotative meanings [ 12 ] . For example , when measuring participants ’ attitude on the issue of vegetarianism , instead of directly asking whether they held a positive or negative attitude , we asked them to choose their position on a 7- point Likert scale for five pairs of bipolar adjectives : unfavorable-favorable , bad-good , unnecessary-necessary , harmful-beneficial , unhealthy-healthy . We calculated the mean rating of the five items to be the subject ’ s prior attitude on the topic . The Cronbach ’ s alpha reaches 0.87 , which is close to excellent internal consistency [ 3 ] in measuring the pre-existing attitudes toward each topic . Topic involvement is generally considered a multi- dimensional construct concerned with the topic importance and relevance to an individual . Following [ 14 ] , we started by measuring two types of topic involvement : 1 ) value- relevant involvement , which measures the extent to which the attitudinal topic is linked to important value . We measured value-relevant involvement by asking participant a ) how much this topic is related to his/her core value , and b ) how important it is to him/her to defend his/her point of view on this issue , both of which based on a 1 ( little ) to 7 ( a lot ) scale ; 2 ) outcome-relevant involvement , which measures the extent to which one is motivated to process relevant information to correctly understand the topic . We measured outcome-relevant involvement by asking participants a ) how interested he/she is in learning about the topic , and b ) how much he/she desires to know the truth about the topic . It turned out the results of two types of involvement measures are highly correlated ( r=0.84 ) , which echoed the conclusion of previous studies on topic involvement [ 22 ] . To simplify the analysis , we combined the two measures by averaging the ratings of the four questions above and created the topic involvement index . The Cronbach ’ s alpha of the four items reaches 0.93 , which is considered excellent internal consistency in measuring the same latent variable of topic involvement . After measuring participants ’ attitude and topic involvement for each candidate topic , we excluded those topics that were highly imbalanced in the pre-existing attitudes and topic involvement scales . Specifically , we excluded the topics in which the number of people on one side of the attitude or topic involvement scale ( higher/lower than neutral ) were more than two times the number of people on the other side . This was done to ensure that for each topic there were a balanced number of participants having high or low pre-existing attitudes or involvement in our samples . This left us with 8 topics used in the experiment . Examples include “ should euthanasia be legal ? ” and “ should people become vegetarian ? ” The complete topic list can be found at the appendix . Session : Data Navigation We selected items of arguments and user opinions on each topic from this website http : //procon.org . It is developed by a non-profit organization that aims at providing resources for critical thinking for various controversial topics . For each topic the website provides pros and cons arguments by summarizing factual information from multiple formal sources including academic publication , newspaper , government document , ete . For example , a pro argument for video game leading to increasing youth violence is : “ Violent video games desensitize players to real-life violence . It is common for victims in video games to disappear off screen when they are killed or for players to have multiple lives . In a 2005 study , violent video game exposure has been linked to reduced P300 amplitudes in the brain , which is associated with desensitization to violence and increases in aggressive behavior. ” The website also allows users to submit their own opinions . An example of pro user opinions for the same topic is : “ Violence influences the mind , brain , and the way we act on what we would 've just seen . Those thoughts would still be in our mind even after an hour or so because our mind is still re-playing what we saw on screen . This would then reflect on our actions and how we think for 30-45 minutes . Even I have experienced this. ” We randomly selected 8 pros and 8 cons arguments , as well as 5 pros and 5 cons user opinions for each topic . We slightly modified the material to ensure there is no significant difference in length ( about 60-90 words ) or rigor of arguments between items of each side . To manipulate perceived relevant threat , we followed the approach used by [ 6 ] in their series of studies on threat and selective exposure . During the experiment , participants assigned to the condition with threat were exposed to an image conveying strongly threat-inducing outcomes relevant to the topic . To avoid biasing the choice and comprehension of information , we chose pictures highlighting the negative outcomes related to the topic while remaining neutral in terms of the discussion . For example , for the question “ does violent video games contribute to increases of youth violence ” , a picture depicting a badly injured teenager was presented , which highlighted the threat-inducing aspect of youth violence without suggesting whether violent video game is a cause . After showing the picture , we asked the participants to imagine how they felt if they themselves , or their beloved ones were involved in such a threatening situation . For example , participants were asked “ how much does it make you feel suffering if seeing the scene of youth violence ” , and “ how much will you be worried if your beloved ones are involved in violence scene ? ” based on a | ( little ) to 5 ( a lot ) scale . Following [ 6 ] , the questions were designed to strengthen the manipulation of perceived threat . Procedure As described earlier , participants were first asked to complete a survey to measure their prior attitude for all candidate topics , as well as demographic information . After CHI 2013 : Changing Perspectives , Paris , France one week the topics were selected , participants were contacted to complete the main experiment . The experiment consisted of eight tasks , each corresponding to one selected topic . For each task , participants assigned to the threat condition were firstly presented with the threat inducing image and questions described in earlier section , while participants in the control condition would skip this step . Then they were presented with the topic , e.g. , “ should certain performance enhancing drugs be legal ? ” as the heading on screen . They were then instructed to imagine they were writing an essay on the given topic using the website presenting pros and cons arguments and user opinions on the topic . They were allowed to freely browse the website , and afterwards they would be asked to write a short summary of the essay they planned to write . The interface is shown in Figure 1 . The page presents arguments on top and user opinions at the bottom . Arguments and user opinions were placed in different two- column tables , with all pros arguments or opinions on one side and cons ones on the other . This two-column format is similar to the interface adopted by many systems that present competing viewpoints ( e.g. , [ 15,18 ] ) , in the purpose of promoting balanced selection of information and avoiding selective exposure to one-sided information . For each topic the participants were shown 8 pros and cons arguments , and 5 pros and cons user opinions , respectively . Every user opinion was shown with a pseudo user name . The order of arguments and user opinions were randomized in each table . For each argument or opinion , only a snippet of the first sentence was shown , which we specifically rewrote to give participants a general idea of the item . Participant could choose to click on “ read more ” if he or she wanted to continue reading . A popup window would show the complete argument or opinion , where participants were also asked to rate their agreement with the particular argument or user opinion based on a 5-point Likert scale . ‘ Question : Should certain performance enhancing drugs ( euch as ster : Jopted in sports ? EDs doesnt help Figure 1 . Screenshot of experiment interface : factual argument ( top ) and user opinions ( bottom ) Participants were told to freely read any numbers of items in any order , and there was no time limit for reading them . The system automatically recorded their clicks on different items . After they felt confident to write the essay they could proceed to the next page , where they would be asked to write down the main points in their essays . In the end of 2362 Session : Data Navigation each task they were asked to finish a questionnaire to measure their attitude on the topic again , which was the same scale used in the pre-experiment survey . RESULTS First , we conducted manipulation check on participants ’ ratings on how they felt suffered/worried after the threat inducing scenarios . The ratings ( M=4.70 , SD=0.60 ) were significantly higher ( t ( 111 ) =29.96 , p < 0.01 ) than neutral ( rating=3 ) , confirming the manipulation was successful . To differentiate topics that participant had low or high involvement , we performed median splits on the topic involvement index of the eight topics for each participant . As a result , each participant had 4 high-involvement and 4 low-involvement topics . The mean value of the medians for all participants was 3.75 ( SD=0.60 ) , and there was no outlier ( more than +/- 3 SD of the mean ) . Therefore the distribution of topic involvement across participants was well distributed in our samples . We also recoded participants ’ prior attitude as positive or negative according to whether the mean score of the five semantic differential items was more or less than neutral ( rating=4 ) , which was also the median of the overall attitude ratings from all participants . For the 6 out of 224 cases participants gave rating 4 we randomly assigned them to either side . There was no significant difference of the proportion of tasks for which participants had positive prior attitude between the two experiment ( threat and no-threat ) groups ( ¢ * ( 1,224 ) =0.18 , p=0.89 ) . Prior attitudes between the two groups therefore did not significantly differ . In this study , our focus was not on features of information seekers ’ prior attitude , therefore we did not control for magnitude of prior attitude bias but conducted random sampling , which resulted in reasonably uniformly distributed prior attitudes in our samples . On the other hand , since we did not intend to infer the general attitude distribution in the population , we believe the current sample size was sufficient for our research questions . To exclude the influence of attitude related factor on interpreting the potential effect of topic involvement , we examined in our sample whether there was correlation between topic involvement index and attitude extremity , defined as the absolute deviation of prior attitude rating from neutral ( rating=4 ) , and found no significant correlation ( r=-0.06 ) . On average , participants checked 8.28 items ( SD=4.93 ) , in which they clicked on average 6.12 ( SD=3.64 ) arguments and 2.16 ( SD=2.16 ) opinions , and they spent M=33.98 ( SD=30.39 ) seconds reading each item . There was no significant difference between the groups with and without threat in all the four measures described above ( p > 0.10 ) , suggesting that the general participation level was about the same between the two groups . Information Selection To examine participants ’ exposure to attitude consistent and inconsistent information , we created an index : selectivity CHI 2013 : Changing Perspectives , Paris , France count , by calculating the difference of the number of attitude-consistent and attitude-inconsistent items clicked for each topic . Here whether an item is attitude consistent or not was decided by whether the attitude conveyed by the message was consistent with the coded prior attitude index ( positive/negative ) as described above . E.g. , if a participant held a positive prior attitude towards the topic , then a pro argument or user opinion was considered attitude consistent while a con argument or user opinion was considered attitude inconsistent . The selectivity count was calculated to capture the tendency of selective exposure , such that a higher magnitude of the index indicated a stronger bias to select more attitude-consistent ( or attitude-inconsistent ) than attitude-inconsistent ( or _ attitude-consistent ) information if the index was positive ( or negative ) . We first performed an ANOVA on selectivity count with prior attitudes extremity ( rating < 3 or > 5 as high , others low ) as independent variable , but the effect was not significant . Given the lack of effect on selectivity count ( as well as other variables we examined in later sections ) and the fact that the current focus was not on effects of prior attitudes , we did not analyze the effects of prior attitudes in the rest of the analysis . However , we will discuss our results in relation to prior attitudes in the discussion section . We performed a two-way repeated measure ANOVA on selectivity count with condition ( without/with threat ) as between-subjects variable and involvement ( low/high ) as within-subjects variable . The result showed that the main effect of threat was significant ( F ( 1,26 ) -9.61 , p < 0.01 , 7°=0.27 ) , and the two-way interaction between condition and involvement was significant ( F ( 1,26 ) =4.91 , p=0.04 , 7°=0.16 ) . Figure 2 plotted the mean value of selectivity count for topics with high and low involvement separately . The figure shows that this interaction was caused by the very different effects of threat to participants with low and high involvement with the topics : When relevant threat was presented to low-involvement participants , they became more selective by reading significantly more attitude- consistent than inconsistent information ( F ( 1,26 ) =10.46 , p < 0.01 , n 7=0.29 ) . In contrast , threat had little effect on high-involvement participants as they behaved consistently by seeking balanced information with or without threat ( F ( 1,26 ) =0.02 , p=0.90 , 1° < 0.01 ) . 1 0 -—_—_—_———_ without threat with threat Selectivity Count low involvement 1 high involvement Figure 2 . Mean selectivity count for topics one had low/high involvement with absence/presence of threat 2363 Session : Data Navigation In addition , we performed one sample t-tests to compare each participant ’ average selectivity count to zero ( balanced in selecting both sides ) with each of the four combinations of with/without threat and high/low topic involvement . The result showed that none of them were significantly different from zero , except when participants were presented with threat in low involvement topics , the selectivity count was significantly higher than 0 ( t ( 13 ) =2.57 , p=0.02 ) . The above results showed that when participants were presented with contextually relevant threat , they exhibited pronounced selective exposure for attitude-consistent information , but only in topics that they had low involvement . In summary , by comparing participants ’ selection of attitude consistent and attitude inconsistent information , we found that the presence of contextually relevant threat induced selective exposure for topics that participants had low involvement , but there was no effect for topics that they had high involvement . While previous research ( e.g. , [ 6 ] ) found that contextually relevant threat increases information seekers ’ tendency of being preferentially exposed to attitude consistent information , our results suggested that there is an additional underlying factor : topic involvement , to moderate this tendency . When seeking information for topics that one has high involvement , users seem to be able to maintain balanced information search even when facing relevant threats . In other words , contrary to common beliefs , not all users exhibit selective exposure to information and lead to the “ echo chamber ” effect . Our results suggest that the combination of threat and low involvement will more likely induce selecting exposure to attitude-consistent information . Information judgment Users ’ attitude change , after being exposed to information diverse environment , is likely not only influenced by their selection of information but also their self-evaluated agreement with the information they read . To analyze participants ’ self-evaluated agreement with attitude consistent and attitude inconsistent information , we created another variable : selective rating , by calculating the difference between the average rating given to attitude consistent and that of attitude inconsistent items for each topic . A positive selective rating indicated that attitude consistent information was evaluated more favorably , and a higher magnitude would indicate that this preference was stronger . We performed a two-way repeated measure ANOVA on selective rating with condition ( with/without threat ) as between-subjects variable and involvement ( high/low ) as within-subjects variable . We found that the main effect of topic involvement was significant ( F ( 1,28 ) =4.24 p=0.05 , 1°=0.14 ) . No effect of condition or interaction between the two was observed . As illustrated in Figure 3 , it suggested that participants ’ high involvement with the topic was a reliable predictor of how much they evaluated attitude consistent information more preferentially than attitude CHI 2013 : Changing Perspectives , Paris , France inconsistent one , regardless of the presence of contextual threat . The result echoed conclusion of previous studies suggesting that high topic involvement promotes the tendency of critically scrutinizing the attitude inconsistent information [ 21 , 22 ] . without threat with threat Selective Rating low involvement high involvement Figure 3 . Mean selective ratings for high/low involvement topics in conditions with and without perceived threat Attitude change In this study , we are interested in whether being exposed to diverse views in the online environment could prevent attitude polarization . Therefore , when examining attitude change , we conceptually distinguished situations where attitude was moderated , i.e , moved to the opposite direction of one ’ s prior attitude , and attitude became more extreme , i.e. , moved further along the same direction of prior attitude . Given the prior and post attitude measurement we used was based on a | ( negative ) to 7 ( positive ) scale , we created a variable , attitude moderation by : 1 ) if the participant held a positive prior attitude , attitude moderation was calculated by prior attitude index minus post attitude index ; 2 ) if the participant held a negative prior attitude , attitude moderation was calculated by the post attitude index minus prior attitude index . Hence a positive attitude moderation value would indicate that the participant ’ s attitude was moderated , while a negative value would indicate that it became more extreme , and the magnitude of the index indicates the extent of attitude change to either direction . In our experiment both for topics with high ( t ( 29 ) =7.15. , p < 0.01 ) and low involvement ( t ( 29 ) =7.89 , p < 0.01 ) , participants ’ average attitude moderation were significantly higher than zero ( no change ) , suggesting that for both types of topics individual ’ s attitudes were moderated after being exposed to a system presenting diverse information . We first performed a two-way repeated measure ANOVA on attitude moderation with condition ( with/without threat ) as between-subjects variable and topic involvement as within-subjects variable . We found that the main effect of involvement was significant ( F ( 1,26 ) =12.82 , p < 0.01 , 1°=0.27 ) , and the main effect of presence of threat was marginally significant ( F ( 1,26 ) =3.09 , p=0.09 , y°=0.11 ) . It suggested that , as shown in Figure 4 , in general participants ’ attitudes were less moderated for topics they had high than low involvement , while the presence of threat also led to slightly less moderation of attitude . 2364 Session : Data Navigation Attitude Moderation without threat with threat low involvement high involvement Figure 4 . Mean attitude moderation score for topics one had high/low involvement with and without threat In addition to attitude moderation , we also examined the number of topics in which participants ’ attitude flipped ( i.e. , shifted to the other side over the neutral point ) . The findings were generally consistent with the results of analysis on attitude moderation : the main effect of topic involvement was significant ( F ( 1,26 ) =28.26 , p < 0.01 , 1°=0.52 ) , and the main effect of threat was marginally significant ( F ( 1,26 ) = 3.44 , p=0.08 , 7 ? =0.12 ) . We also found the two-way interaction between threat and topic involvement was marginally significant ( F ( 1,26 ) =3.14 , p=0.09 , 17=0.11 ) , suggesting that the presence of threat had higher impact on reducing the tendency of attitude flip for topics participants had low than high involvement . In summary , both the presence of threat and topic involvement influenced how attitude changed after being exposed to the information diverse environment . In general , all participants ’ attitudes were moderated , although they were less subject to change if they had high than low involvement with the topic . The current results can be combined with the results on selective ratings , in which participants who had high topic involvement agreed with attitude-consistent information significantly more than attitude inconsistent information ( see Figure 3 ) , and thus were less moderated by the persuasive effects of attitude- inconsistent information . Meanwhile , the presented threat also made participants less likely to change attitude , especially for topics that they had low involvement . We could understand this finding by combining the results to those in the analysis of information selectivity presented earlier ( see Figure 2 ) : when seeking information under perceived thread for low involvement topics , participants became significantly more selective in processing attitude- consistent information over inconsistent n. Therefore , overall they were exposed to less attitude inconsistent information that could moderate their attitude in the presence of perceived threat . Selection of User Opinions versus Factual Arguments When facing competing views , people may seek factual argument , as well as peer opinions to solicit different views . From a design perspective , it is important to understand users ’ preferential selection of these two types of information under different situational and individual factors . To this end , we examined the overall preferential seeking of peer opinions versus factual arguments , as well CHI 2013 : Changing Perspectives , Paris , France as participants ’ selective exposure to these two types of information that conveyed competing views . First , we calculated the percentage of user opinions selected as compared to the total number of selected items for each topic . We performed a two-way repeated measure ANOVA on this percentage value by using condition ( with/without threat ) as between-subjects variable and topic involvement ( high/low ) as within-subjects variable . Interestingly , we found a significant two-way interaction between condition and topic involvement ( F ( 1,28 ) =6.07 , p=0.02 , 7 ? =0.17 ) . We illustrated this interaction in Figure 5 : participants checked on more user opinions for low than high involvement topics without perceived threat ( F ( 1,13 ) =16.4 , p=0.01 , 7°=0.56 ) . This difference , however , disappeared when they perceived threat ( F ( 1,13 ) =0.02 , p=0.90 , 7 ’ < 0.01 ) . User Opinions 4 Percentage of Selecting K with threat low involvement without threat high involvement Figure 5 . Mean percentages of the selection of user opinions for high/low involvement topics in with and without threat To further understand participants ’ differential preference for user opinions that convey competing views , we divided user opinions into attitude consistent and inconsistent to analyze if there was selective exposure between them . We calculated the same selectivity count index by including only selection of user opinions ( i.¢e. , the difference between the frequencies of selection of attitude consistent and inconsistent user opinions ) . We performed the same two- way repeated ANOVA on user opinions selectivity count with condition and perceived threat . We found that the two- way interaction between topic involvement and presence of threat was marginally significant ( F ( 1,28 ) =3.31 , p=0.08 , 7 ’ =0.11 ) . Figure 6 showed that it was caused by the differential effects of perceived threat on inducing the tendency of preferentially selecting more attitude consistent user opinions under threat for low involvement topics ( F ( 1,13 ) =3.76 , p=0.06 , y °=0.13 ) , but not for high involvement ones ( F ( 1,13 ) =0.32 , p=0.58 , 7 ’ =0.01 ) . without threat with threat low involvement Selectivity Count of User Opinions high involvement Figure 6 . Mean user opinions selectivity count for high/low involvement topics in conditions with and without threat 2365 Session : Data Navigation We then analyzed the selective exposure for only factual arguments . We calculated the selectivity count among factual arguments in the same manner as for user opinion and conducted the same two-way repeated measure ANOVA . It showed the main effect of threat was significant ( F ( 1,26 ) =5.04 , p=0.03 , 1 °=0.16 ) and the two- way interaction between threat and topic involvement was marginally significant ( F ( 1,28 ) =3.15 , p=0.08 , 7 7=0.11 ) . Figure 7 illustrated that this interaction was again caused by the differential effect of threat on low and high involvement topics : perceived threat induced selective exposure towards attitude consistent factual arguments for low involvement topics ( F ( 1,28 ) =7.31 , p=0.01 , y 7=0.22 ) , but not for high involvement topics ( F ( 1,28 ) < 0.01 , p=0.95 , 7 < 0.01 ) . without threat with threat Selectivity Count of Factual Arguments low involvement high involvement Figure 7 . Mean factual argument selectivity count for topics one had high/low involvement with absence/presence of threat In summary , the analysis on the selection of user opinions and factual argument shows that for low involvement topics , there was a higher tendency to check on user opinions , however this tendency decreased with contextually relevant threat . This change could possibly be explained by the fact that when threat was perceived people became more vigilant in the information seeking process [ 24 ] , and thus might treat the issue as more “ serious ” . As a result , they put more weight on factual arguments than user opinions as they did for topics they had high involvement . Our analysis on selective exposure revealed that contextually relevant threat induced higher selective exposure to both factual arguments and user opinions , which implied that participants preferentially selected both attitude consistent factual arguments and attitude consistent peer opinions to cope with cognitive dissonance . In general , we found that participants ’ information selection was more sensitive to the influence of contextual factor when they had low involvement with the topic . In comparison , for topics users have high involvement , balanced and consistent information seeking strategy for attitude consistent and inconsistent information was adopted across different situational context and for different types of information , with a higher general preference for factual information . It was consistent with conclusions from previous research , which stated that increased level of topic involvement often leads to an “ open minded ” information seeking strategy towards competing views and a lower reliance on other people ’ s opinions [ 1 , 8 ] . CHI 2013 : Changing Perspectives , Paris , France DISCUSSION Our study showed that , even when opposing views were presented side-by-side , information seeking under perceived relevant threat led to more pronounced selective exposure to attitude consistent information . This increased level of selective exposure also leads to less attitude change due to the overall less reception of attitude challenging information . However , high topic involvement can override this tendency such that people seek relatively balanced exposure to attitude consistent and inconsistent information . Nonetheless , high involvement with the topic results in more preferential evaluation of attitude consistent information over attitude inconsistent one , and largely increases the resistance to attitude change . According to Frey [ 7 ] , when facing cognitive dissonance brought by attitude-challenging information , — the consistency of the cognitive system is maintained by either avoiding attitude-inconsistent information , or by counter arguing attitude-inconsistent information in order to find flaws in it . For topics that people have low involvement , in which people may have less knowledge and thus fewer defending arguments available , they may feel higher level of uncertainty and less motivated to counter-argue attitude- challenging information . While they may be interested in discovering attitude-challenging information otherwise , perceived threat may increase the motivation to avert themselves from confronting attitude challenging information . From a motivational account , it is also possible that for topics that people have high involvement , they have a higher motivation to learn about the truth about the topic regardless of their own position . According to [ 1,24 ] , this kind of accuracy motive is able to mitigate the tendency of selective exposure . As a result , people may be able to retain higher level of accuracy motive for topics that they have high involvement regardless of the situation . These findings suggest that selective exposure is sensitive to situational variables if they are less involved with the topic . For example , a newly diagnosed patient , who is likely to feel increasing level of anxiety , may have a higher tendency to expose himself to information about a treatment he or she prefers and fails to pay attention to different perspectives to better inform the medical decision . In this kind of situation , the system ( e.g. , search engine , recommendation system ) should provide adequate information about their preferred choice while encourage the exposure to high quality information about the alternatives [ 10 ] . On the other hand , the system should provide a balanced mix of alternative or competing views if it recognizes that the user is knowledgeable or frequently exposed to the domain or topic . While the study in [ 17 ] concluded that system designers should be aware that there exists both “ diverse-seeking ” users and “ challenge-averse ” users , our findings seem to complement their finding in suggesting that these tendencies are not fixed for each individual but are sensitive 2366 Session : Data Navigation to situational factors and dependent on the domain or topic . A person who is highly passionate about politics may seek diverse information when browsing political news . However , he may become challenge-averse when it comes to information seeking for a health related decisions . Although it is a highly challenging task to accurately predict users ’ preference for the level of diversity based on the complex interactions among personal , topic-related , and situational factors , our study provides preliminary evidence that , to design for personalized presentation of diverse information , it is helpful to take into account users ’ overall involvement with the domain/topic and the situation of the information seeking process , such as whether it is for acute information needs ( e.g. , learning about ongoing events , making time sensitive decisions ) , or whether it is about an anxiety sensitive topic ( e.g. , politics , finance , health ) . By analyzing the selection of factual arguments and user opinions separately , we found that users may have a higher tendency to seek peer users ’ opinions if they are studying a topic that they consider less involved . However , if they are facing a threatening situation , they may turn to factual arguments more often and increase their tendency of preferentially seeking both attitude consistent factual arguments and attitude consistent user opinions . These findings have interesting implications for designing systems that aggregate and present diverse information . For example , the system may provide more peer users ’ opinions as well as competing views for topics that are relatively casual ( e.g. , entertainment ) , but highlight attitude supporting information and high quality factual arguments for topics that may potentially induce threat and anxiety . Our study also suggested , to a certain extent , that information seekers ’ attitude could be moderated by exposure to diverse viewpoints , even for topics that one already had a certain level of involvement . In general , it supported the validity of promoting personal deliberation and preventing attitude extremity by exposing people to diverse opinions enabled by technology intervention as suggested by previous researchers [ 10 , 15 , 20 ] . Our finding provided further evidence that attitude moderation for low involvement topics tended to be more effective , suggesting that the exposure to diverse information may have a larger impact for low-involvement topics , as such experiences may encourage knowledge acquisition and attitude construction for these topics . During preliminary data analysis , we explored the effects of attitude extremity by comparing cases where participants had more extreme prior attitude rating ( < 3 or > 5 ) to those who were more neutral . However , we did not find any significant effect on either information selection or attitude change ( p > 0.10 ) . At first glance , it may seem somewhat counterintuitive , as people with more extreme attitude may be less likely to change . However , we observed that in our sample , there were cases where participants who held extreme attitudes actually shifted their attitude in a CHI 2013 : Changing Perspectives , Paris , France relatively large magnitude . Interestingly , most of these cases were regarding topics participants had low involvement , which again underscored the interactive effects of pre-existing attitude and personal involvement on attitude moderation . Given that our experiment used 8 controversial topics that covered a wide variety of domains that varied in their prevalence , it is unlikely that participants would have mature attitudes in all topics . This could be one reason why we found the dominating effects of topic involvement , rather than attitude extremity , on attitude change . In the experiment , the system provided 13 different aspects on either side ( pro/con ) , which could serve as an intensive educating platform that led to discoveries of new knowledge and ( re ) construction of attitude . It was possible that , for topics that one had low involvement , the processing of the larger amount of information that was new to the participants resulted in higher attitude change as they acquire more knowledge about the topics . This inference was at least partially supported by the fact that our topic involvement measure had a high correlation with participants ’ self claimed topical knowledge ( 1-0.77 ) . Another related finding was the low correlation between attitude extremity ( measured by absolute difference between prior attitude rating and neutral rating 4 ) and topic involvement ( 1=-0.06 ) , which calls attention to an important and potentially dangerous phenomenon : people could express a relatively extreme attitude even when they have neither adequate knowledge nor motivation to learn about the topic . The attitude is therefore likely to be an uninformed or even biased one . An information aggregation system that presents well-organized high quality information on multiple facets of the topic can be effective and efficient for the purpose of educating without bias . These results imply that information interfaces may need to adapt to both the levels of knowledge or familiarity of the topic and personal involvement of the users to encourage a more balanced processing of multiple viewpoints . Lastly , we should point out that the interface we used in the experiment was already an optimized design in presenting diverse information . Presenting equal numbers of pros and cons items in a well-defined layout was often considered an effective means to encourage users to check on both sides of the issues [ 18 ] . Although in the experiment , selective exposure was salient only in the condition of low topic involvement with threat , selective exposure may be even more pronounced in a loosely organized online information environment , in which users follow hyperlinks , or use simple interfaces commonly designed for many information retrieval or aggregation systems for everyday information needs . Our results provided strong support that information bubble can emerge from the interactions of multiple factors in addition to that created by personalization Web algorithms . How technology interacts with multiple personal and social factors to impact effectiveness of balanced civic discourse through the online information 2367 Session : Data Navigation environment clearly demands more research and attention from both information engineers and HCI researchers . ACKNOWLEDGMENTS We thank Arpit Agarwal for programming the interface . REFERENCES 1 . Albarracin , D. , & Mitchell , A. L. The role of defensive confidence in preference for proattitudinal information : How believing that one is strong can sometimes be a defensive weakness . Personality and Social Psychology Bulletin 30 ( 2004 ) , 1565-1584. . Case , D.O. , Andrews , J , Johnson , J , Allard , S. Avoiding versus Seeking : the Relationship of Information Seeking to Avoidance , Blunting , Coping , Dissonance , and Related Concepts . Journal of Medical Library Association 93 , 3 ( 2005 ) , 353-362 . Cronbach , L.J. , Coefficient Alpha and The Internal Structure of Tests . Psychometrika 16 , 3 ( 1951 ) , 297- 334. . Dutta-Bergman , M.J. Complementarity in Consumption of News Types Across Traditional and New Media . Journal of Broadcasting & Electronic Media 48 , 1 ( 2010 ) , 41-60 . Faridani , S. , Bitton , E. , Ryokai , K. , Goldberg , K. Opinion Space : A Scalable Tool for Browsing Online Opinions . In Proc . CHI2010 1175-1184. . Fischer P. , Kastenmuller , A. , Greitemeyer , T. , Fischer J. , Frey , D. Threat and Selective Exposure : The Moderating Role of Threat and Decision Context on Confirmatory Information Search After Decision . Journal of Experimental P sychology : General 140 , 1 ( 2011 ) . 51-62. . Fischer , P. , & Ai , A . International terrorism and mental health : Recent research and future directions . Journal of Interpersonal Violence 23 ( 2008 ) , 339-361. . Frey , D. Recent Research on Selective Exposure to Information . Advances in Experimental Social Psychology 19 ( 1986 ) , 41-80. . Garrett , R. K. Echo chambers online ? : Politically motivated selective exposure among Internet news users , ” Journal of Computer Mediated Communication 14 , 2 ( 2009 ) , 265-285 . 10 . Garrett , R. , Resnick , P. Resisting Political Fragmentation on the Internet . Daedalus 140 , 4 ( 2011 ) 108-120 . 11.Hart , W. , Albarracin , D. , Eagly , A. , Brechan , I. , Lindberg , M. , Feeling Validated Versus Being Correct : A Meta-Analysis of Selective Exposure to Information . Psychological Bulletin 135 , 4 ( 2009 ) , 555-588 . 12.Himmelfarb , S. The measurement of attitudes . In A.H. Eagly & S. Chaiken ( Eds . ) , Psychology of Attitudes ( 1993 ) , 23-88 . Thomson/Wadsworth 2368 CHI 2013 : Changing Perspectives , Paris , France 13 . Jiang , Y. , Liao , Q. , Cheng , Q. , Berlin , R. , Schatz , B . Designing and Evaluating a Clustering System for Organizing and Integrating Patient Drug Outcomes in Personal Health Messages . In Proc . AMIA 2012 14 . Johnson , B. J . & Eagly , A . Effects of Involvement on Persuasion : A Meta-Analysis . Psychological Bulletin , 106 , 2 ( 1989 ) , 290-314 . 15.Kriplean , T. , Morgan , J. , Freelon , D. , Borning , A. , Bennett , L. Supporting Reflective Public Thouht with Considerlt . In Proc . CSCW 2012 , 265-274 . 16.Mankoff , J. , Kuksenok , K , Rode , J. , Kiesler , S. , Waldman , K. Competing Online Viewpoints and Models of Chronic Illness . Jn Proc . CHI2011 , 589-597 . 17.Munson , S. & Resnick P. Presenting Diverse Political Opinions : How and How Much . In Proc . CH12010 , 1457-1466 . 18.Oh , A. , Lee , H. , Kim , Y . User Evaluation of a System for Classifying and Displaying Political Viewpoints of Weblogs . In Proc . JCWSM 2009 , 282-285 19 . Pariser , Eli . The Filter Bubble : What the Internet Is Hiding from You , Penguin Press , 2011 20.Park , S. , Kang , S. , Chung , S. , Song , J. NewsCube : Delivering Multiple Aspects of News to Mitigate Media Bias . Jn Proc . CHI2009 , 443-452 21.Petty , R-E. , & Cacioppo , J. Communication and Persuasion : Central and Peripheral Routes to Attitude Change . New York : Springer-Verlag , 1986 . 22.Petty , R-E. & Cacioppo J . Involvement and Persuasion : Tradition Versus Integration . Psychological Bulletin 107,3 ( 1990 ) , 367-374 . 23.Sunstein , C. R. Republic.com . Princeton , NJ : Princeton University Press , 2002 . 24 . Valentino , N. A. , Banks , A. , Hutchings , V. , Davis , A . Selective Exposure in the Internet Age : The Interaction between Anxiety and Information Utility . Political Psychology 30 , 4 ( 2006 ) 591-613 . 25 . Vydiswaran , V. , Zhai , C. , Roth , D. , Pirolli , P. Unbiased Learning of Controversial Topics . Jn Proc . ASIST2012 26 . Yatani , K. , Novati M. , Trusty , A. , Truong , K. Review Spotlight : A User Interface for Summarizing User Generated Reviews Using Adjective-Noun Word Pairs . In Proc . CHI2011 , 1541-1550 APPENDIX : TOPICS USED IN THE EXPERIMENT 1 . Should certain performance enhancing drugs ( such as steroids ) be accepted for sports ? . Should death penalty be allowed ? Should prescription drugs be advertised directly to consumers ? . Should euthanasia be legal ? . Do violent video games contribute to the increase of youth violence ? . Should people become vegetarian ? . Should the US have sent troops to Iraq ? . Should social security be privatized ? SIDA RWH Burst the Filter Bubble : Using Semantic Web to Enable Serendipity Valentina Maccatrozzo The Network Institute Department of Computer Science VU University Amsterdam , The Netherlands v.maccatrozzo @ vu.nl Abstract . Personalization techniques aim at helping people dealing with the ever growing amount of information by filtering it according to their interests . However , to avoid the information overload , such tech- niques often create an over-personalization effect , i.e . users are exposed only to the content systems assume they would like . To break this “ per- sonalization bubble ” we introduce the notion of serendipity as a perfor- mance measure for recommendation algorithms . For this , we first identify aspects from the user perspective , which can determine level and type of serendipity desired by users . Then , we propose a user model that can facilitate such user requirements , and enables serendipitous recommen- dations . The use case for this work focuses on TV recommender systems , however the ultimate goal is to explore the transferability of this method to different domains . This paper covers the work done in the first eight months of research and describes the plan for the entire PhD trajectory . 1 Research Problem We are living the Information Age - previously unfindable or unreachable in- formation is accessible instantly and the amount of it is constantly growing . Through personalization techniques we often get to see only the chunk that relates to our interests , preventing us from being overwhelmed . Various infor- mation providers typically gather user behavior and interests data to provide personalized recommendations , e.g . Amazorfl , Netflix . However , such informa- tion filters have downsides too . On one hand , users are constantly missing some- thing without noticing it , and , on the other , they are getting continuously the same type of recommendations . In 2011 Pariser [ TS ] coined a new concept to describe this phenomenon : the filter bubble , i.e . personalization filters are build- ing around us invisible barriers that keep away the content that does not fit completely with our profiles . Think when you buy a book in a bookstore . You browse around the shelves letting titles and covers attract your attention . How many times it happens lnttp : //www . amazon.com 2 nttp : //www.netflix.com P. Cudré-Mauroux et al . ( Eds . ) : ISWC 2012 , Part II , LNCS 7650 , pp . 391-B98 ] 2012 . © Springer-Verlag Berlin Heidelberg 2012 392 V. Maccatrozzo you found an interesting book on a shelve you look at only by chance ? This is an unexpected encounter . The ability to make fortunate discoveries by accident is called serendipity . The word was coined by Horace Walpole in a letter he exchanged with Horace Mann in 1754 [ 24 ] . He describes serendipity as “ / ... / making discoveries , by accidents and sagacity , of things which they were not in quest for [ ... ] ” . Personalization as we know it in the online bookstores does not allow this to happen anymore . It makes it difficult to discover what we did not know we were looking for . This over-personalization problem can not be solved by simply relaxing the filters , i.e . by keeping the bubble bigger , because of two reasons ( see Fig. [ ] ) . First , browsing through irrelevant results in an online system is not as pleasurable as browsing through a physical store - the amount is way too big , and a bird-eye view is usually not available . Second , such approach does not account explicitly for the serendipity effect , z.e . as serendipity is subjective , the user model has to be able to surface items that are relevant but enough novel and diverse from the standard user interests . Fig . 1 . This example shows how over-personalization harms recommendations . In ( La ) the circle indicates an over-personalized recommendation , which includes only core relevant items , ( Ib ) shows a relaxed personalized recommendation , which contains many irrelevant items and ( Id ) shows the target recommendation , which contains all relevant items including the serendipitous ones . While traditional personalization approaches focus mainly on getting results as close as possible to the user profile and do not account explicitly for the serendipity effect , more recently , a trend to focus more on approaches to get serendipitous results in recommendations [ IJT6 ) 25 ) has developed . 2 Research Context The focus of this work is on recommender systems in the TV domain ( not only movies , but more about TV programs , e.g . talk shows , live shows , particular episodes of series ) . As described above , serendipity in the context of recom- mender systems is represented by a well balanced mix of diversity , novelty and relevance of the recommended items with respect to the users ’ interests . Thus , it can be measured only with respect to a given user profile , and the challenge Burst the Filter Bubble : Using Semantic Web to Enable Serendipity 393 is how to determine the ideal distance from the user profile in a given context , that will be still relevant . Our proposal is to use Semantic Web techniques , in particular Linked Open Data ( LOD ) , as a means to induce novel and relevant concepts in the user profile and thus explicitly support serendipity in recom- mender systems . The rich link structure and the uniform representation make the LOD cloud a good candidate to explore for ‘ deep ’ and ‘ novel ’ connections between concepts . The LOD cloud can be seen as a structured knowledge space covering a multitude of different domains ( many relevant to TV , e.g . music , books , movies , art ) , where each node in the graph is a separate knowledge element and the mechanism for discovery can be applied by creating bindings between different elements . The goal of this research is to define and develop a method for an interac- tive recommendation approach , where the central novelty is the discovery and utilization of serendipitous bindings between the user profile and elements pre- viously unlinked to it . We refer to such bindings as content patterns [ TQ ] - well connected concepts in one or across LOD datasets . The requirements , as well as initial experiments with LOD patterns for this re- search have been gathered and performed during the NoTube pro ject . The next stage of this research will be performed in the context of the ViSTA-TVA Euro- pean project . The consumers anonymized viewing behavior as well as the actual video streams from broadcasters and IPTV transmitters provided by ViSTA-TV will be used as training and test data for this PhD research . The ultimate goal is to integrate the serendipity-aware recommendation strategies together with a holistic live-stream data mining analysis in a personalized electronic program guide . 3 Research Questions The central concept of this PhD research is serendipity and its utilization in serendipity-aware recommendation algorithms . Serendipity is typically an im- plicit user-subjective notion that is difficult to capture in objective terms . In order to realize it in a general recommendation approach we need to identify its objective characteristics in different user contexts , and define an explicit method to measure it . This guides our first research question : Can we define a method to measure serendipity for individual content elements , as well as for the overall result of a recommendation system considering an explicit user profile ? Which elements of this method are domain dependent and which could be generalized ? As the serendipity level and its success should be assessed from a user per- spective we use results from previous work , in the TV and cultural heritage domains , on identifying user needs and understanding of ‘ serendipity ’ as initial 3 4 http : //www.notube.tv http : //www.vista-tv.eu 394 V. Maccatrozzo input for this research question . We have also explored several LOD sources , dis- covered relevant content patterns and analyzed their statistics as possible input for the serendipity measure . Further , user surveys in the context of the concrete ViSTA-TV use cases will be performed to gather additional requirements for the definition of serendipity and for the model to assess it . A number of experiments with the serendipity-aware recommendations will be needed in order to identify the optimal serendipity level in the different use cases . Finally , similar experi- ments will be performed in a different domain to investigate the cross-validity of our model . The second challenge in this work relates to the use of LOD as a structured knowledge space to discover content patterns suitable to surface serendipitous recommendations . Considering the size of the LOD cloud and the diversity of domains , types of relationships and concepts it covers , keeping the right level of relevance in the recommendation results could be a tedious task . One way of addressing this issue could be through maintaining an up-to-date user context . Therefore , the second research question is : Can we use social networks activities to form a continuously evolving and relevant context of the user interests ? Can we map these user interests to LOD concepts in order to discover novel user interests through LOD content patterns ? Results from previous and related research on social activities as input for a user profile were studied . An initial set of requirements for the user profile were derived . This set should be extended and finalized through experiments in the ViSTA-TV use cases , i.e . applying LOD browsing procedures ( Section ) guided by a user model . The NoTube mapping of LOD concepts to user interests is used as a baseline and further extended . Experiments will be performed to determine the impact of alternative user models and their LOD mappings on the serendipity level of the recommendation results and the user satisfaction . What is serendipitous today , may not be true tomorrow , as it is with most of the user interests . In order to be sustainable over time , recommendation strate- gies need to account for the decay in user interests and changes in user context that determine the serendipity aspects . So , the third question is : How does the time affect the serendipity function of a recommender sys- tem ? What user feedback can help to determine a possible decay in the user interests ? In order to measure the influence of time we need to perform long-term user tests monitoring the evolution of individual user interests , the context switching and the corresponding user feedback in the whole process . We envision comparing user profile states in different moments of time and applying a set of content patterns to analyze the differences in the serendipity perception . In the next section we are discussing the overall approach to answering the research questions and implementing the solutions . Burst the Filter Bubble : Using Semantic Web to Enable Serendipity 395 4 Approach Our approach combines technologies from two fields , z.e . user modeling and semantic-based recommendation systems . According to André et al . [ 4j , to in- duce serendipity we need a common language model , so that barriers between different fields can be removed and novel connections can be established . In other words , we need to express all the components involved in the same way . Thus , centrally to this approach is the enrichment of our data with LOD con- cepts . This includes both user activities , user interests and program metadata . The enriched data enables the alignment of concepts between the user profile and the program descriptions , and subsequently the querying for related users and programs , for example through analogy , metaphors , synonymy , homonymy , and hierarchy . Here we reuse existing metadata enrichment experiences in other domains , such as in cultural heritage for defining semantic search paths from ex- perts behavior [ [ 4 ] , for enriching museum metadata with historical events [ 23 ] , and for recommendation-based browsing through museum collections [ 5 ] . In this project we use Web services , such as Lupedial , to realize the enrichment of the program metadata and the user activities . The next major step in the approach is to find the interesting paths in these graphs ( 7.e . content patterns ) that would lead to serendipitous recommendations . We identify three such ‘ routes ’ to serendipity , i.e . ( 1 ) variation & selection , ( 2 ) diverging & converging and ( 3 ) analogy . Variation & Selection . According to Campbell [ 8 ] , a combination of blind vari- ation and selective retention of concepts is the process at the basis of creative thinking . We can apply this rationale to the querying of LOD sources by deriv- ing new concepts from the ones that are present in the user-profile and then select those that are potentially serendipitous . The selection process needs to be trained by the feedback of the user , so that the serendipitous variations can be identified . In terms of content patterns : we select new concepts following a specific pattern , and if the feedback is positive we keep on applying it , otherwise we eliminate it . Once we have a list of serendipitous patterns , z.e . patterns that lead to serendip- itous concepts , the identification of new ones is performed on the basis of their characteristics ( e.g . same length , same predicates but different order ) . Diverging € Converging . According to Guilford [ T3 ] , divergent thinking is the capacity to consider different and original solutions to one problem and is the main component in the creativity process . Convergent thinking , instead , is the ability of bringing all the solutions together and elaborate a single one . Analogously , in querying the LOD we can first discover all possible paths starting from one node in the user profile ( diverging phase ) . Then we can identify a new node that connects all { or the most of ) these new concepts together ( converging phase ) , and use it as a serendipitous candidate . Analogy . According to Gentner [ [ 0J , an analogy is a mapping of knowledge from one domain ( the base ) into another { the target ) . In other words , a system 5 nttp : //lupedia . ontotext.com 396 V. Maccatrozzo of relations that holds among the base objects also holds for the target objects . This process , called analogical mapping , is a combination of matching existing predicate structures and importing new predicates . Following the same reason- ing , we can derive analogues LOD patterns using nodes ( starting from the user profile ) that share ( the same or similar ) predicates and exchange their predicates to define new connections . 5 Related Work Serendipity has been recognized as an important component in many fields , such as scientific research [ 9 ] , art [ 22 ] and humanistic research JO ) . The main point of study , especially in creative thinking , has been the strive for understanding how different serendipitous encounters take place [ 7 ] . The role of serendipity in recommender systems has also been studied . Abbasi et al . [ I ] examine the over-specialization problem in recommenders . Similarly to our approach , they propose a system were items are grouped in regions and recommendations are built taking items also from regions under-exposed to the user . However , contrary to our approach , they do not exploit content semantics . Oku and Hattori [ 16 ] introduce serendipity in recommendations by selecting new items mixing the features of two user-input items . This approach measures serendipity only considering past activities of the users . This differs from our approach , that does not aim necessarily at improving accuracy with respect to other recommendation techniques , but improving the overall user experience . Zhang at al . [ 2h ] present a music recommender that combines diversity , novelty and serendipity of recommendation at a slightly cost of the accuracy . On the side of semantic recommenders , Oufaida and Nouali [ I7 ] propose a multi-view recommendation engine that integrates collaborative filtering with social and semantic recommendation . They build users ’ profiles and neighbor- hoods with three dimensions : collaborative , socio-demographic and semantic . They show how semantics enhance precision and recall of collaborative filtering recommendations . However our approach aligns more with the work done in the CHIP project ] on a content-based semantic art recommender , where |5 ] explores a number of semantic relationships and patterns that allow for introducing sur- prisingly interesting results . One of the aim addressed by researchers in the field of semantic recommender systems is the reliability and precision of the recom- mended items . To tackle this issue trust network have been used . For instance , Ziegler 26 ] proposes suitable trust metrics to build trust neighborhoods , and to make collaborative filtering approaches applicable to decentralized architecture , i.e . the Semantic Web . Golbeck and Hendler [ 2 ] propose a collaborative rec- ommender system for movies , using FOAF [ 6 ] vocabulary as a base to build a social network of trust . An example of a semantic recommender for multimedia content is given by Albanese et al . that computes customized recommenda- tions using semantic contents and low-level features of multimedia objects , past behavior of individual users and behavior of the users community as a whole . The effectiveness of the approach is evaluated on the basis of user satisfaction . Burst the Filter Bubble : Using Semantic Web to Enable Serendipity 397 Semantic user models to enhance personalized semantic search have been re- searched by Jiang and Tan [ 15 ] . They propose a user ontology model that utilizes concepts , taxonomic and non-taxonomic relations in a given domain ontology to capture the users interests . Ghosh and Dekhil [ TJ ] , on the other hand , discuss ac- curate models of user profiles using Semantic Web technologies , by aggregating and sharing distributed fragments of user profile information spread over multi- ple services . Related to our proposal are also the semantic user modeling from so- cial network . Abel et al . 2 ] introduce a framework for user modeling on Twitter which enriches the semantics of Twitter messages and identifies topics and enti- ties mentioned in them and , similarly to van Aart at al . [ 21 ] , shows how semantic enrichment enhances the variety and the quality of the generated user profiles . 6 Future Work and Conclusions This PhD research is now approaching the second year . Current work involves an- alyzing specific techniques to select possible serendipitous patterns from different LOD datasets , namely LinkedMDBJ and DBpedid . We are also investigating dif ferent techniques of enrichment , exploring natural language processing methods . The plan for the near future is to start the users surveys to gather preliminary data about their serendipity perception . Afterwards , we will follow the steps presented in Section 4 Acknowledgments . This research is supported by the FP7 STREP “ ViSTA- TV ” project , as well as partially supported by the FP7 IP “ NoTube ” project and the ONR Global NICOP “ COMBINE ” project . References 1 . Abbassi , Z. , Amer-Yahia , $ . , Lakshmanan , L.V.S. , Vassilvitskii , S. , Yu , C. : Getting Recommender Systems to Think Outside the Box . In : RecSys 2009 , pp . 285-288 2009 2 . Cee , Gao , Q. , Houben , G.-J. , Tao , K. : Analyzing User Modeling on Twitter for Personalized News Recommendations . In : Konstan , J.A. , Conejo , R. , Marzo , J.L. , Oliver , N . ( eds . ) UMAP 2011 . LNCS , vol . 6787 , pp . 1-12 . Springer , Heidelberg 2011 3 . CThanese , M. , d ’ Acierno , A. , Moscato , V. , Persia , F. , Picariello , A. : A Multimedia Semantic Recommender System for Cultural Heritage Applications . In : ICSC 2011 , pp . 403-410 ( 2011 ) 4 . André , P. , schraefel , mc. , Dumais Teevan , 8.T . : Discovery Is Never by Chance : De- signing for ( Un ) Serendipity . In : C & C 2009 , pp . 305-314 ( 2009 ) 5 . Aroyo , L. , Stash , N. , Wang , Y. , Gorgels , P. , Rutledge , L. : CHIP Demonstrator : Semantics-Driven Recommendations and Museum Tour Generation . In : Aberer , K. , Choi , K.-S. , Noy , N. , Allemang , D. , Lee , K.-I. , Nixon , L.J.B. , Golbeck , J. , Mika , P. , Maynard , D. , Mizoguchi , R. , Schreiber , G. , Cudré-Mauroux , P . ( eds . ) ISWC/ASWC 2007 . LNCS , vol . 4825 , pp . 879-886 . Springer , Heidelberg ( 2007 ) Tihttp : //www.Linkedmdb.com http : //www.dbpedia.or 398 10 . 11 . 12 . 13 . 14 . 15 . 16 . 17 . 18 . 19 . 20 . 21 . 22 . 23 . 24 . 25 . 26 . V. Maccatrozzo . Brickley , D. , Miller , L. : FOAF Vocabulary Specification 0.97 . Namespace document , WSC ( January 2010 ) . Chaomei , C. : Turning Points . The Nature of Creative Thinking . Springer ( 2011 ) . Campbell , D.T . : Blind Variation and Selective Retention in Creative Thought as in Other Knowledge Processes . Psychological Review 67 , 380-400 ( 1960 ) . Garcia , P. : Discovery by Serendipity : a new context for an old riddle . Foundations of Chemistry 11 , 33-42 ( 2009 ) Gentner , D. : The mechanisms of analogical learning . In : Vosniadou , S. , Ortony , A . ( eds . ) Similarity and Analogical Reasoning , pp . 199-241 . Cambridge University Press ( 1989 ) Ghosh , R. , Dekhil , M. : Mashups for semantic user profiles . In : WWW 2008 , pp . 1229-1230 ( 2008 ) Golbeck , J. , Hendler , J. : FilmTrust : movie recommendations using trust in web- based social networks . In : CCNC 2006 , pp . 282-286 ( 2006 ) Guilford , J.P. : The Nature of Human Intelligence . McGraw-Hill , New York ( 1967 ) Hildebrand , M. , van Ossenbruggen , J.R. , Hardman , H.L. , Wielemaker , J. , Schreiber , G. : Searching In Semantically Rich Linked Data : A Case Study In Cultural Heritage . Technical Report INS-1001 , CWI ( 2010 ) Jiang , X. , Tan , A. : Learning and inferencing in user ontology for personalized Se- mantic Web search . Information Sciences 179 ( 16 ) , 2794-2808 ( 2009 ) Oku , K. , Hattori , F. : Fusion-based Recommender System for Improving Serendipity . In : DiveRS 2011 , pp . 19-26 ( 2011 ) Oufaida , H. , Nouali , O. : Exploiting Semantic Web Technologies for Recommender Systems : A Multi View Recommendation Engine . In : ITWP 2009 ( 2009 ) Pariser , E. : The Filter Bubble . What the Internet is hiding from you . Penguin Press HC ( 2011 ) Presutti , V. , Aroyo , L. , Adamou , A. , Schopman , B. , Gangemi , A. , Schreiber , G. : Extracting Core Knowledge from Linked Data . In : COLD 2011 ( 2011 ) Quan-Haase , A. , Martin , K. : Digital Humanities : the continuing role of serendipity in historical research . In : iConference 2012 , pp . 456-458 ( 2012 ) van Aart , C. , Aroyo , L. , Brickley , D. , Buser , V. , Miller , L. , Minno , M. , Mostarda , M. , Palmisano , D. , Raimond , Y. , Schreiber , G. , Siebes , R. : The NoTube Beancounter : Aggregating User Data for Television Programme Recommendation . In : SDoW 2009 ( 2009 ) van Andel , P. : Anatomy of the Unsought Finding . Serendipity : Origin , History , Do- mains , Traditions , Appearances , Patterns and Programmability . The British Jour- nal for the Philosophy of Science 45 ( 2 ) , 631-648 ( 1994 ) van Erp , M. , Oomen , J. , Segers , R. , van de Akker , C. , Aroyo , L. , Jacobs , G. , Legéne , S. , van der Meij , L. , van Ossenbruggen , J.R. , Schreiber , G. : Automatic Heritage Metadata Enrichment With Historic Events . In : MW 2011 ( 2011 ) Walpole , H. : To Mann , Monday 18 January 1754 . In : Lewis , W.S . ( ed . ) Horace Walpole ’ s Correspondence , vol . 20 , pp . 407-411 . Yale University Press ( 1960 ) Zhang , Y.C. , Séaghdha , D. , Quercia , D. , Jambor , T. : Auralist : Introducing Serendipity into Music Recommendation . In : WSDM 2012 , pp . 13-22 ( 2012 ) Ziegler , C.-N. : Semantic Web Recommender Systems . In : Lindner , W. , Fischer , F. , Turker , C. , Tzitzikas , Y. , Vakali , A.I . ( eds . ) EDBT 2004 . LNCS , vol . 3268 , pp . 78- 89 . Springer , Heidelberg ( 2004 ) The Thirty-Fourth AAAI Conference on Artificial Intelligence ( AAAI-20 ) Bursting the Filter Bubble : Fairness-Aware Network Link Prediction Farzan Masrour , Tyler Wilson , Heng Yan , Pang-Ning Tan , Abdol-Hossein Esfahanian Michigan State University { masrours , wils1270 , yanheng , ptan , esfahanian } @ msu.edu Abstract Link prediction is an important task in online social network- ing as it can be used to infer new or previously unknown rela- tionships of a network . However , due to the homophily prin- ciple , current algorithms are susceptible to promoting links that may lead to increase segregation of the network—an ef- fect known as filter bubble . In this study , we examine the fil- ter bubble problem from the perspective of algorithm fairness and introduce a dyadic-level fairness criterion based on net- work modularity measure . We show how the criterion can be utilized as a postprocessing step to generate more heteroge- neous links in order to overcome the filter bubble problem . In addition , we also present a novel framework that com- bines adversarial network representation learning with super- vised link prediction to alleviate the filter bubble problem . Experimental results conducted on several real-world datasets showed the effectiveness of the proposed methods compared to other baseline approaches , which include conventional link prediction and fairness-aware methods for i.i.d data . Introduction Online social networking sites have transformed the way in- dividuals interact and share information with each other . The wealth of social network data available also provide oppor- tunities to mine them for a variety of business applications . For example , businesses can learn about the users ’ interests , sentiment , and online behavior by analyzing the social net- work data . The insights gained from such analysis will help businesses to increase engagement with their existing cus- tomers or connect with new customers . Despite its impor- tance , recent studies have raised concerns about the poten- tial biases and unintended consequences that may arise from such automated analysis . For example , link prediction methods ( Liben-Nowell and Kleinberg 2007 ; Al Hasan et al . 2006 ; Masrour et al . 2015 ; 2018 ) are commonly employed by social networking sites to encourage users to expand their social circles . “ Suggested for you ” on Instagram and “ People you may know ” on LinkedIn are two example applications of such methods . However , the rise of link prediction systems have led to an effect known as filter bubble ( Pariser 2012 ) , which is the re- inforced segregation and narrowing diversity of information Copyright © 2020 , Association for the Advancement of Artificial Intelligence ( www.aaai.org ) . All rights reserved . 841 exposed to online users . If left unchecked , the filter bubble may introduce systematic biases in the network data and its subsequent analysis . For instance , Hofstra et al . ( Hofstra et al . 2017 ) examined the ethnic and gender diversity of social relationships on Facebook and showed that those who have ample opportunities to befriend other similar users often find themselves in highly segregated networks . This is due to the homophily principle ( McPherson , Smith-Lovin , and Cook 2001 ) , which is the tendency of individuals to form social ties with other similar individuals in a network . As current algorithms are designed to promote links between similar users , their suggested links may exacerbate the user segre- gation problem . In addition to online social networks , the filter bubble problem is also prevalent in recommender systems , which can be viewed as a link prediction task applied to a bipar- tite network of users and items . A recent study by Nguyen et al . ( Nguyen et al . 2014 ) concluded that recommender sys- tems tend to expose users to “ slightly narrowing set of items over time. ” For example , in movie recommendation , movies from a certain genre may only be recommended to users from a specific gender . By addressing the filter bubble prob- lem in network link prediction , the proposed method can potentially be used to alleviate the filter bubble problem in other types of recommender systems . This paper examines the filter bubble problem for network link prediction from algorithm fairness perspective . Specif- ically , we consider a link prediction algorithm to be unfair if it is biased towards promoting certain types of links ( e.g. , those between users with similar gender or other protected attributes ) . As a motivating example , consider the link pre- diction task on professional networking sites . Certain pro- fessions , such as software engineering , tend to be dominated by men , a fact that is likely to be reflected in the link struc- ture of the professional network . As a result , the links rec- ommended by the site may reinforce this gender-based seg- regation and primarily recommend links between individ- uals from the same gender while recommending compara- tively fewer inter-gender links . Though such a system may be able to achieve high link prediction accuracy , it may un- fairly disadvantage some users . For example , a female soft- ware engineer may be treated unfairly as they are seldom recommended to other male software engineers . Unfair practices due to the decisions generated by auto- mated systems is a problem that has been well-documented in many application domains , including criminal justice , mortgage lending , and university admission . For example , Angwin et al . ( Angwin et al . 2016 ) warned about the poten- tial biases against African Americans in the software used to predict the risk score of defendants who would likely re- offend again while O ’ Neil ( O ’ Neil 2017 ) cautioned against the manipulative marketing tactics used by for-profit col- leges in online advertising that exploit vulnerable popula- tions . These concerns have brought increasing scrutiny into the issue of fairness in machine learning algorithms . Despite their growing research , existing works are primarily focused on independent and identically distributed ( i.i.d ) data , and thus , may not be suitable for link analysis problems . For ex- ample , previous works have considered the notion of fair- ness either at individual ( Dwork et al . 2012 ) or group ( Hardt et al . 2016 ; Feldman et al . 2015 ) level . In contrast , this paper examines the notion of fairness at a dyadic-level , based on the pairwise interactions between users in a social network . Furthermore , previous approaches have considered fairness in terms of the unjust decisions against members of a spe- cific underrepresented ( protected ) group . Instead , we con- sider fairness in terms of promoting inter-group connections in a network in order to alleviate the filter bubble problem . There are four major contributions of this paper . First , we empirically assess the influence of protected attributes such as gender on the link structure of a network by mea- suring the homophily effect on several real-world network datasets . Second , we introduce modred as a fairness crite- rion for network link prediction . The metric is inspired by the well-known modularity measure ( Newman and Girvan 2004 ) developed for network community detection . We con- sider the reduction in modularity measure as a way to deter- mine whether the links predicted by an algorithm may lead to further segregation of the network . We then illustrate how the measure can be incorporated into a greedy algorithm for postprocessing the results of current link prediction al- gorithms . Finally , we present a novel Fairness-aware LInk Prediction ( FLIP ) framework that combines adversarial net- work representation learning with supervised link prediction to mitigate the filter bubble problem . Related Work Link prediction is a well studied problem in network anal- ysis with various algorithms been developed over the past two decades ( Al Hasan et al . 2006 ; Masrour et al . 2015 ) . This includes heuristics methods that consider the pairwise similarities between nodes , where similarity is defined based on the network topology ( Newman 2001 ; Liben-Nowell and Kleinberg 2007 ) or node features ( Crandall et al . 2010 ) . The main benefit of these methods is their simplicity and the fact that most of these approaches do not required train- ing . Another class of link prediction methods employ ma- chine learning methods , such as those based on probabilis- tic graphical models ( Clauset , Moore , and Newman 2008 ) , matrix factorization ( Scripps et al . 2008 ) , and supervised classification ( Al Hasan et al . 2006 ; Wang et al . ) . Despite their higher accuracy , these methods often suffer from the class imbalance problem as the number of links in a network 842 is significantly fewer than the number of non-links . Recent years have also witnessed the emergence of deep neural net- work methods for the link prediction task ( Li et al . 2014 ; ; Tian et al . 2014 ) . These methods have been shown to achieve state of the art performance . Social networks are increasingly personalizing their con- tent using automated machine learning techniques , which is a concern as the decisions may lead to adverse effects on the users . This is due to the so-called “ filter bubble ” or “ echo chamber ” effect ( Hofstra et al . 2017 ; Pariser 2012 ) in which individuals are increasingly isolated to consuming only in- formation that conform to their own belief system . In on- line social networks , the effect of filter bubble is exemplified by the recommendation decisions generated using link pre- diction algorithms . As link prediction algorithms are com- monly used to encourage users to expand their networks , this may lead to adverse consequences such as segregation of users ( Hofstra et al . 2017 ; Nguyen et al . 2014 ) . Quantifying fairness has been a subject of intense de- bate among AI and ML researchers in recent years ( Berk et al . 2018 ; Dwork et al . 2012 ; Hardt et al . 2016 ; Kus- ner et al . 2017 ) . Previous works are primarily focused on non-relational data and can be classified into two types— individual-level or group-level fairness . Fairness definition at individual level is based on the premise that similar people should be treated similarly . For example , Dwork et al . ( Dwork et al . 2012 ) defined a task-specific metric based on a probabilistic distance measure between individuals via a Lipschitz condition . The metric is used as constraints to optimize a fairness-aware classifier . In contrast , the group- level approach quantifies fairness in terms of statistical mea- sures such as demographic parity , equalized odds ( Hardt et al . 2016 ) or balanced error rate ( Feldman et al . 2015 ) with respect to the protected groups . The measures are typically computed from a confusion matrix ( Berk et al . 2018 ) and are used to ensure that the average performance do not vary significantly among different groups of a protected attribute . In addition , there has been growing literature on develop- ing fairness-aware methods . Current methods can be divided into three categories . The first category includes prepossess- ing algorithms ( Zemel et al . 2013 ; Madras et al . 2018 ) with the motivation that training data is the main cause of bias in machine learning . Zemel et al . ( Zemel et al . 2013 ) intro- duced an optimization algorithm to map data points into a new space to ensure membership in the protected group is lost . Madras and et al . ( Madras et al . 2018 ) connected group fairness concept to adversarial concept for learning fair rep- resentation . In addition , there has been some recent work on fairness in recommender systems related to the link predic- tion problem ( Zhu , Hu , and Caverlee 2018 ) . Fairness for Network Data We first review the fairness criteria for 1.i.d . data . Let Y be the target variable of interest ( true outcome ) and X be a set of input features . Conventional supervised learning algo- rithms are designed to predict the target outcome Y from X by learning a model f such that Y = f ( X ) is the predicted outcome . Existing fairness-aware methods seeks to ensure that the predictions generated by the model will not discrim- inate against one or more subgroups , defined by a protected attribute X ) such as gender , race , or sexual orientation . A widely used criterion for assessing fairness is demo- graphic parity ( Louizos et al . 2015 ; Kamishima , Akaho , and Sakuma 2011 ; Johndrow , Lum , and others 2019 ; Ed- wards and Storkey 2015 ; Calders , Kamiran , and Pechenizkiy 2009 ) , which considers the degree of independence between the model output and protected attribute . Assuming both the target outcome and protected attributes are binary-valued , demographic parity seeks to achieve : P ( Y =1|X xX ) = P ( Y =1 ) Another well known fairness criterion is equalized odds ( Hardt et al . 2016 ) , which seeks to ensure that the predic- tions are conditionally independent of the protected attribute given the true outcome : P ( Y =1X ) =0 , Y =y ) = P ( Y =1 , X =1 , Y¥ =y ) If we consider Y = 1 as advantaged outcome , a special case for this criterion is known as equal opportunity ( Hardt et al . 2016 ) , which is defined as follows : PY =1.X =0 , Y =1 ) =P ( ¥ =1|X =1 , y = ) ) , Dyadic-level Fairness In this paper , we investigate the filter bubble problem from the perspective of algorithm fairness . Specifically , a dyadic- level fairness criterion can be defined based on the protected group membership of individuals participating in the links . Below , we consider two such criteria : e Subgroup dyadic-level protection , where fairness is as- sessed in terms of how representative each protected sub- group is in the formation of the links . For example , in ap- plications such as link-based recommender systems , the fairness criteria could be to ensure that the recommended links do not favor certain subgroups in the population at the expense of other subgroups . e Mixed dyadic-level protection , where fairness is deter- mined based on homogeneity of the nodes involved in each link . Specifically , a link is considered to be an intra- group link if it relates a pair of nodes with the same pro- tected attribute values . Otherwise , it is known as an inter- group link . To prevent effects such as filter bubble , inter- group or mixed links should be favored to prevent segre- gation of the users . In principle , the subgroup dyadic-level protected can be im- plemented using existing group-level fairness criteria for iid . data by applying them to the links instead of individual nodes in the network . For mixed dyadic-level protected , we introduce the network modularity measure to be described in the next section . Network Modularity Homophily ( McPherson , Smith-Lovin , and Cook 2001 ) , which is the tendency of individuals to form relations with others similar to them , is an important characteristic of many social networks . Such relationship can be quantified using 843 the well-known network modularity ( or assortative mixing ) measure ( Newman and Girvan 2004 ; Newman 2006 ) . The measure , which was originally developed for community de- tection in networks , is based on the idea that a random graph is not expected to contain any clustering structure . Any com- munity structure in a given network can thus be validated by comparing its link density against its expected density if the link structure of the network is completely random . The modularity measure is defined as follows ( Newman and Gir- van 2004 ) : 1 did ; Q= Sm De ( 4s ~ Go ) Alen en ) qd ) ij where A is the adjacency matrix representation of the net- work , 5 ( c ; , cj ) is the Kronecker delta function , c ; is the com- munity of node 2 , d , is its corresponding degree and m is to- tal number of links . Intuitively , a network is said to be assor- tative if a significant portion of its links are between nodes that belong to the same community . The modularity measure can be used to determine whether a network is unfair in terms of mixed dyadic- level protection by replacing 5 ( c ; , c ; ) in Equation ( 1 ) with 5 ( xl ? x ie ) ) , where X ’ ( p ) ig the protected attribute value for node 2 . The @ value is thus influenced by only those pairs of nodes belonging to the same protected class . Val- ues of Q close to one would indicate high unfairness due to the strong alignment between the link structure and the pro- tected attribute while values close to zero indicate high fair- ness . For numeric-valued protected attributes such as age or income level , it can be modified as follows : Dade d ar — dedi / 2m ) XW ? ) X } P ) 1 ifi=j where oi = { i o.w This is also known as assortativity coefficient of the network . To illustrate the use of modularity as a measure of un- fairness , consider the networks shown in Figure 1 . The data correspond to friendship relations among freshman at a sec- ondary school in the Netherlands from 2003-2004 ( Snijders , Van de Bunt , and Steglich 2010 ) . Using gender as protected attribute , the modularity value for the first network shown in Figure 1 ( A ) is equal to 0.3033 while the value for the second network is 0.0179 . Note that the network with higher mod- ularity has more links between students of the same gender compared to the one with lower value , and thus , is unfair from the perspective of mixed dyadic-level protection . Our proposed fairness-aware framework evaluates the re- duction in the modularity measure to determine whether the modified network obtained from the link prediction results is biased towards creating more inter-group or intra-group links . Specifically , we define the following metric : > ref modred = ( 2 ) where Qyer is the modularity measure of a reference net- work ( e.g. , the ground truth network when evaluating link ( b ) Snapshot taken in 2004 . Modularity = 0.0179 . Figure 1 : Snapshots of friendship relation among students at a Dutch school taken 2003 and 2004 along with their modu- larity values . The node color represents the student ’ s gender . Darker dashed lines correspond to links between students of different gender while the solid ones correspond to links be- tween students of the same gender . prediction algorithms ) and Qpreq is the modularity of the pre- dicted network , i.e. , the network obtained by augmenting the predicted links to the original network . A positive modred value indicates that the link prediction algorithm predicts more inter-group links than the ground truth network while a negative value suggests that the algorithm is predicting more intra-group links than the ground truth network . Greedy Post-Processing One approach to promoting fairness in link prediction is to post-process the prediction results . To this end , we pro- pose a greedy algorithm for reducing modularity of the pre- dicted network . It takes as input a set of binarized link pre- dictions , { € , , , } and calculates the change in modularity re- sulting from flipping the prediction of each node pair . The change in modularity for flipping link é , , , is : ( =1 ) 8Ee0 ) 2m » vEV , X§P ) zx ) vFY _ da +dy —1 ( p ) yl ) ( -1 4 SEER ) aca x » vEV.X\\P ZX ) ode score ( €xy ) = 4 ( dy + di ) /Am ? ( 3 ) where the value of ( —1 ) °= ) is —1 if € , , , is 1 and +1 oth- erwise , d , and d , , are the degrees of nodes x and y respec- tively . After computing this score for each predicted link we 844 C Link Prediction Mtdesiace ) Tale ) ahs Representation Learning Prediction Random Weis Peers mele Were Z ( learned eect } PAGuos ac ) Pol litcs pair type ) Adversarial Learning D Figure 2 : FLIP architecture flip the edges with the lowest scores . This is another approx- imation since the score for edge should be recomputed after each edge is flipped due to changes in the value of d , and d , , . The number of link predictions to flip is a hyper-parameter that can be varied depending on the importance of accuracy versus modularity . Adversarial Learning for Fair Link Prediction Consider an attributed network NV = ( V , E , X ) , where V is the set of nodes , fF C V x V is the set of links , and X € RI 1 * 4 is a matrix corresponding to the set of attribute values associated with the nodes in V. Assume X can be partitioned into submatrices [ X * ) , X ] , which correspond to the protected and unprotected features of the nodes . Here we only consider a binary value X ” ) . Our goal is to accu- rately infer new links in the network without being biased against the formation of inter-group links . Our proposed framework , known as FLIP ( Fairness-aware Link Prediction ) , employs an adversarial learning approach to ensure that inter-group links are well-represented among the predicted links . The framework consists of the following 3 components , as illustrated in Figure 2 : 1 . A generator , G , that takes the attributed network as input and learns a representation G ( v ) for each node v € V. We use DeepWalk ( Perozzi , Al-Rfou , and Skiena ) as the generator , though in principle , the framework can be ap- plied to other network representation learning methods . 2 . A discriminator , D , that takes the representations for each pair of nodes produced by the generator as input and at- tempts to predict if it is an intra-group or inter-group node pair . The discriminator ’ s predicted probability that a pair of nodes has the same protected attribute value is denoted as D ( G ( v ; ) , G ( v ; ) ) 3 . A link prediction component , £ , which tries to infer new links given node representation learned by the generator . The predicted probability that a link exists between a pair of vertices is L ( G ( v ; ) , G ( v ; ) ) . To understand the rationale behind the framework , note that a good feature representation learned by the generator will enable the link prediction component to infer correctly whether a node pair is connected . If the link structure of the network is biased towards intra-group links , so will the link prediction component as well as the generator . The discrim- inator plays the role of an adversary who attempts to predict whether a node pair involves nodes from the same group or from different groups . By making the generator and discrim- inator to work against each other , this would lead to a situa- tion in which the generator produces a feature representation that is good enough for link prediction yet unbiased enough to prevent the discriminator from inferring whether it is an inter-group or intra-group node pair . In networks with ho- mophily property , this will help to discourage the prediction of intra-group links and promotes more inter-group links . Discriminator In recent years , adversarial networks have been used to achieve different fairness criteria for independent and iden- tically distributed ( i.i.d ) data ( Beutel et al . 2017 ; Madras et al . 2018 ) . The shared idea between these methods is an ad- versarial component that attempts to predict the protected attribute value X , , , . A naive approach to achieving fairness in network data is to follow same path and design an ad- versarial component that predicts the protected attribute of a node using the following cross entropy cost function : pod mie [ xP oat ) + ( 1 — X { ? ) ) log ( 1 — g ) vEeVv Here # , , = D ( G ( u ) ) is the prediction of the discriminator of the binary protected value of node wu . However this will not necessarily result in mixed dyadic level protection because intra-group links may still be fa- vored in a homophilic network . To solve this challenge we propose the following adversarial loss : JP = Fi S- pualou ( Pan ) ( uvyeET + ( 1 _ Duv ) log ( 1 _ Puv ) ( 4 ) where 7 C V xV is the set of node pairs in the training data , Pu » is the actual type of node pair ( u , v ) with respect to a given protected attribute ( i.e . intra-group vs inter-group ) and Puy is the discriminator ’ s prediction . Instead of inferring the node ’ s protected attribute , the discriminator receives a pair of node representations , which it passes to a two layer fully connected network with leaky ReLU activation to determine the probability that it is an intra-group node pair . Generator In contrast to the original GAN framework proposed by ( Goodfellow et al . 2014 ) where the generator seeks to gen- erate samples of data points that seem real , the generator in our framework tries to learn node representation that will preserve important structural information of the network without implicit usage of the protected attribute informa- tion . For the generator , we utilized Deep Walk ( Perozzi , Al- Rfou , and Skiena ) which is a network representation learn- ing method inspired by the Skip-gram ( Mikolov et al . 2013 ) model from natural language processing . Deep Walk consists of two steps : the first step is to extract sequences of nodes 845 from the network by performing a series of truncated ran- dom walks starting from each node in the input network . In the second step , the node sequences generated from the random walk process are used to learn the feature represen- tation of each node . This is accomplished as follows . A slid- ing window of width w scans the generated node sequences to generate all the node pairs ( u , v ) in which node v appears in the sliding window centered at node u . A fully connected neural network with a single hidden layer predicts the prob- ability of the occurrence of node v given the one hot en- coding , t , of node u . Specifically , the network attempts to predict p ( v|u ) for each u as follows : exp ( f '' ( v ) ' f ( u ) ) Vevev exp fv ! ) f ( u ) ) where f ( v ) = Wo , f ' ( u ) = Zu , W is the weight matrix between the input and hidden layers of the network , and Z is the weight matrix between the hidden and output layers of the network . The rows of matrix W are the node rep- resentations generated by the skip-gram model so we have G ( u ) = fu ) . The parameters of DeepWalk are trained using the maxi- mum likelihood estimation approach , with the following loss function : skip = _ | - log ( S > exp ( f '' ( v ' ) '' f ( u ) ) p ( u|u ) = ( 5 ) ueVv weVv + SD eapls ( v ) '' 7u ) ) | vw ’ EQ ( 4 ) Here 2 , , ( u ) represent the set of all nodes that appears in the neighborhood of node u in the given random walk sequence with window size of width w. Link prediction This component takes a pair of node embeddings as input to predict whether their nodes should be linked or not . This is accomplished by adding a two-layer link prediction network to the GAN model . During the training phase the link pre- diction component receives pairs of node embeddings and concatenates them into a feature vector , which is then passed to a two-layer fully connected network with leaky ReLU ac- tivation . The output of the network corresponds to the like- lihood of a link to exist between the node pair . Here we de- ployed the standard cross entropy cost function as follows : 1 Th = S- lewstog ( éxe ) + ( 1 en ) 10g ( 1 ~ ) ( w , vjeT ( 6 ) where é , , , is output of the link prediction component for node pair ( u , v ) and e , , , is the binary ground truth link label . Putting everything together , the overall loss function for the proposed framework is given as follows : JF = ( 1— ay sSP ? — ay ? + prt ( 7 ) where is a hyperparameter . The generator , discriminator , and link prediction network are all trained end to end us- ing Adam ( Kingma and Ba 2014 ) . The generator and link Table 1 : data sets network # nodes | # edges | protected feature Dutch school 26 221 gender Facebook 1,034 26,749 gender Google+ 4,938 | 547,923 gender Table 2 : Proximity based link prediction algorithms . For each node v , N ( v ) is the set of its immediate neighbors . Method | Definition CY fi Tat Adamic/Adar DEN ( WAN ( 0 ) Toads ) Preferential attachment ody | p ( link ) | p ( link|intra ) | prob ( link|inter ) Dutch School | 0.3662 0.5406 0.1699 Facebook 0.050 0.053 0.047 Googlet+ 0.045 0.061 0.0316 Table 3 : Homophily effect prediction network are trained on the same batches but ev- ery other batch is used to train the discriminator only so that training alternates between updating the link predictor and generator together on one batch and updating the discrimi- nator on the next batch . Experimental Evaluation This section describes the experiments performed to evalu- ate the efficacy of our proposed methods to address the filter bubble problem in network link prediction . Experiment Setup We first discuss the experimental setup , including data sets , baselines and evaluation metrics used in our experiment . Datasets We evaluated our methods on three real world social network data sets . Table 1 summarizes the main prop- erties of these data sets . The first data set is a Facebook ego network ( Leskovec and Mcauley 2012 ) , which con- tains 1,034 nodes , and 26,749 friendship links . The second data set is Google+ , which has 4,938 nodes and more than 500,000 links . ( Leskovec and Mcauley 2012 ) , The third data set is Dutch school network ( Snijders , Van de Bunt , and Steglich 2010 ) , which corresponds to friendship relations among 26 freshmen at a secondary school in the Nether- lands . For all three datasets , we use gender as the protected attribute for inferring intra-group and inter-group links . Baseline Algorithms We considered 4 state-of-art link prediction algorithms as baselines . Three of them are well known classical proximity based methods which use neigh- borhoods structural information . The first baseline is based on the well known Jaccard ’ s ( Jac ) coefficient similarity met- ric which is deployed in the context of network link predic- tion by calculating the portion of common neighbors for a 846 given nodes pair . The second baseline is Adamic/Adar ( Ad- Ad ) , a similar measure that assigns less weight to more connected common neighbors . The third proximity based algorithm is preferential attachment ( Pr-At ) ( Mitzenmacher 2001 ) which sets the probability of a connection between two pair of such that it is correlated with the product of the their degrees ( Newman 2001 ) . Table 2 summarized the for- mal definition of these algorithms . We also considered the more recent DeepWalk ( DW ) algorithm ( Perozzi , Al-Rfou , and Skiena ) which learns d-dimensional feature representa- tions of nodes by simulating uniform random walks and pro- vides latent features for nodes at the first step and then , simi- lar to proposed approach in ( Grover and Leskovec ) , we con- struct the edge embedding by applying binary Hadammard product operation to the given node pair and train a logistic regression to do link prediction . For evaluation , we use the settings suggested in the original DW paper for both the DW baseline and the proposed method ’ s skip gram model . These settings are : latent feature dimension ( 128 ) , length of ran- dom walks ( 80 ) , and number of random walks ( 10 ) and win- dow size ( 10 ) on all data sets . We also consider a traditional fairness algorithm based on equalized odds which we use to post-process our 4 base- lines . As previously mentioned , imposing an equalized odds constraint on the predictions of a model is a popular way of ensuring fair predictions . For our task , we use a generalized version of equalized odds proposed in ( Pleiss et al . 2017 ) to post-process each of the baseline algorithm predictions . To make the generalized equalized odds constraint compatible to network data setting we treat link type , intra-group ver- sus inter-group , as each link ’ s binary protected attribute . We refer to this post processing algorithm as ( PEO ) . Sampling process and training A big challenge for link prediction algorithms is the sparsity of real world network data . In other words , since the number of existing links are significantly smaller than non-existing links , training a model which is not biased toward negative examples is dif- ficult . Given a graph N = ( V , E , X ) we generate a train- ing set with equal number of negative and positive examples < N ’ , E * , E~ > . Here N ’ is the remaining sub-graph after removing all sampled positive links , E+ , and EF isa set of randomly sampled non-links such that || = || . Sam- pling positive links from N is random with the restriction that N ’ remains connected . For each data set we generating 10 examples of < N ’ , E * + , E~ > by deleting 80 % of all links in NV . For FLIP and DW we learn node representations by performing random walks on graph N ’ and train the link prediction using 10 % of the generated positive and negative samples . For the other baselines we used all the 30 % of ET and £~ for calculating the proximity measures . We used re- maining 70 % for test . Evaluation Metric We evaluate the quality of link pre- dictions with two metrics , accuracy and the area under the ROC curve ( AUC ) which represents the trade-off between true and false positives with respect to different thresholds . For the fairness subgroup dyadic-level metric we consider modred measure given in equation 2 . Table 4 : Performance comparison between baseline and proposed algorithms on 3 real-world datasets . Results are reported based on the average AUC and modred scores after repeating the sampling process 10 times . Method Dutch school Facebook Google+ AUC modred AUC modred AUC modred Jac 0.6500 +/- 0.0008 | -0.5030 +/- 0.0046 0.8305 +/- 0.0 -0.1494 +/- 0.0396 0.7932 +/- 0.0 0.0932 +/- 0.0297 Ad-Ad 0.6571 +/- 0.0006 | -0.3761 +/- 0.0044 0.836 +/- 0.0 0.2224 +/- 0.0089 0.8692 +/- 0.0 -0.3048 +/- 0.0015 Pr-At 0.6023 +/- 0.0016 | 0.4431 +/- 0.0022 0.8068 +/- 0.0 0.4601 +/- 0.0015 0.9047 +/- 0.0 -2.9354 +/- 0.0106 DW 0.5287 +/- 0.0074 | -0.0471 +/- 0.2423 0.951 +/- 0.0 0.0889 +/- 0.0022 | } 0.7708 +/- 0.0006 | 0.1663 +/- 0.0386 Jac+PEO 0.5356 +/- 0.003 | 0.0325 +/- 0.0521 || 0.7992 +/- 0.0001 | -0.5575 +/- 0.2353 0.7500 +/- 0.0 3.4696 +/- 0.048 Ad-Ad+PEO | ] 0.5275 +/- 0.0024 | -0.2337 +/- 0.052 || 0.7992 +/- 0.0001 | 0.0132 +/- 0.0599 0.8292 +/- 0.0 3.2193 +/- 0.0133 Pr-At+PEO | } 0.5054 +/- 0.0003 | 0.0219 +/- 0.1091 || 0.6822 +/- 0.0004 | -0.208 +/- 0.2277 0.8584 +/- 0.0 3.8539 +/- 0.1538 DW+PEO 0.4908 +/- 0.0055 | -0.1209 +/- 0.2133 0.9489 +/- 0.0 0.0142 +/- 0.0204 | ] 0.7354 +/- 0.0008 | 3.546 +/- 2.6518 Jac+GM 0.6571 +/- 0.0289 | -0.2179 +/- 0.0840 || 0.8421 +/- 0.0018 | 0.6613 +/- 0.0501 || 0.7399 +/- 0.0013 | 0.9657 +/- 0.0405 Ad-Ad+GM _ || 0.6528 +/- 0.0265 | -0.2110 +/- 0.0882 | ) 0.8421 +/- 0.0018 | 0.6613 +/- 0.0501 || 0.8179 +/- 0.0009 | 1.3693 +/- 0.0383 Pr-At+GM 0.5827 +/- 0.0440 | 0.1795 +/- 0.1654 | ] 0.7400 +/- 0.0036 | 0.9190 +/ 0.0597 || 0.8422 +/- 0.0004 | 1.7478 +/- 0.0960 DW+GM 0.5363 +/- 0.0560 | 0.1335 +/- 0.0907 | ] 0.9013 +/- 0.0045 | 0.4972 +/- 0.0617 || 0.7254 +/- 0.0295 | 1.5062 +/- 0.5906 FLIP 0.6576 +/- 0.0039 | 0.3592 +/- 0.0089 || 0.8601 +/- 0.0001 | 0.3483 +/- 0.0039 0.8575 +/- 0.0 0.2071 +/- 0.0088 Experimental Results In the following subsection we investigate the general per- formance of the proposed framework . Homophily property Table 3 summarizes our evaluation on the homophily prop- erty of the three networks . The first column is the probability a node pair is linked . The second column shows the condi- tional probability a node pair is linked given that it is an intra-group node pair , while the third column corresponds to the conditional probability of a link between an inter-group node pair . These probabilities indicate that all three networks have homophily property because they are more likely to have intra-group links than inter-groups links . Performance Comparison We summarize our results for link prediction in Table 4 . For FLIP we report the result for a = 0.1 and £ = 0.2 . For greedy post-processing we chose to invert 3 % of the predictions that reduces the modularity the most . Based on these results we can make several ob- servations . First , there is generally a trade off between AUC and modred so higher modred scores are only achievable by sacrificing accuracy . Second , none of the baseline algorithms achieve con- sistently high modred scores . In particular , equalized odds post-processing provides highly inconsistent gains in modred that are heavily dependant on the data set . It pro- vides significant gains on the Google+ data set , but on the Dutch school data set it provides only moderate gains . It is also a moderate impediment on the Facebook data set . However , greedy post-processing and FLIP always achieve high modred scores and provide a good balance between AUC and modred . This is unsurprising since FLIP and greedy post-processing were the only two techniques specif- ically designed for promoting fairness in link prediction . This demonstrates the importance of developing algorithms tailored specifically for network data and link prediction . Third , among the baselines , preferential attachment does the best job in terms of balancing the tradeoff between accu- racy and modred . One possible explanation for this is that all other baselines make predictions based on the neighbor- 847 hood structure of nodes . In a network that is homophillic with respect to a protected attribute , nodes with the same protected attribute value are likely to have similar neighbor- hood structure . Since all of our networks are homophillic with respect to the protected attribute , link prediction meth- ods based on neighborhood structure are more likely to rein- force the existing homophilly and create intra-group links . In contrast , preferential attachment ignores the neighborhood structure of nodes when making predictions so it less af- fected by pre-existing network homophilly . Conclusions This paper presents novel fairness-aware methods to alle- viate the filter bubble problem in network link prediction . First , we present a fairness criterion based on network mod- ularity measure to determine whether inter-group links are well-represented in the predicted output of a link prediction algorithm . We then consider two approaches to overcome the filter bubble problem—one based on a greedy postpro- cessing approach using the modred measure while the other based on an adversarial learning framework . Experimental results showed that the proposed methods are promising as they can reduce modularity of the predicted network without degrading prediction accuracy significantly . References Al Hasan , M. ; Chaoji , V. ; Salem , S. ; and Zaki , M. 2006 . Link prediction using supervised learning . In SDMO06 : work- shop on link analysis , counter-terrorism and security . Angwin , J. ; Larson , J. ; Mattu , S. ; and Kirchner , L. 2016 . Machine bias . ProPublica , May 23 . Berk , R. ; Heidari , H. ; Jabbari , S. ; Kearns , M. ; and Roth , A . 2018 . Fairness in criminal justice risk assessments : The state of the art . Sociological Methods & Research . Beutel , A. ; Chen , J. ; Zhao , Z. ; and Chi , E. H. 2017 . Data decisions and theoretical implications when adver- sarially learning fair representations . arXiv preprint arXiv:1707.00075 . Calders , T. ; Kamiran , F. ; and Pechenizkiy , M. 2009 . Build- ing classifiers with independency constraints . In 2009 IEEE International Conference on Data Mining Workshops . Clauset , A. ; Moore , C. ; and Newman , M. E. 2008 . Hier- archical structure and the prediction of missing links in net- works . arXiv preprint arXiv:081 1.0484 . Crandall , D. J. ; Backstrom , L. ; Cosley , D. ; Suri , S. ; Hutten- locher , D. ; and Kleinberg , J . 2010 . Inferring social ties from geographic coincidences . PNAS 107 ( 52 ) :22436-22441 . Dwork , C. ; Hardt , M. ; Pitassi , T. ; Reingold , O. ; and Zemel , R. 2012 . Fairness through awareness . In Proceedings of the 3rd innovations in theoretical computer science conference . Edwards , H. , and Storkey , A . 2015 . Censoring representa- tions with an adversary . arXiv preprint arXiv:1511.05897 . Feldman , M. ; Friedler , S. A. ; Moeller , J. ; Scheidegger , C. ; and Venkatasubramanian , S. 2015 . Certifying and removing disparate impact . In Proc . of KDD . ACM . Goodfellow , I. ; Pouget-Abadie , J. ; Mirza , M. ; Xu , B. ; Warde-Farley , D. ; Ozair , S. ; Courville , A. ; and Bengio , Y . 2014 . Generative adversarial nets . In NeurIPS , 2672-2680 . Grover , A. , and Leskovec , J. node2vec : Scalable feature learning for networks . In Proc . of KDD . Hardt , M. ; Price , E. ; Srebro , N. ; et al . 2016 . Equality of opportunity in supervised learning . In NeurIPS , 3315-3323 . Hofstra , B. ; Corten , R. ; Van Tubergen , F. ; and Ellison , N. B . 2017 . Sources of segregation in social networks : A novel approach using facebook . American Sociological Review 82 ( 3 ) :625-656 . Johndrow , J. E. ; Lum , K. ; et al . 2019 . An algorithm for removing sensitive information : application to race- independent recidivism prediction . The Annals of Applied Statistics 13 ( 1 ) :189-220 . Kamishima , T. ; Akaho , S. ; and Sakuma , J . 2011 . Fairness- aware learning through regularization approach . In [ CDM Workshops , 643-650 . IEEE . Kingma , D. P. , , and Ba , J . 2014 . Adam : A method for stochastic optimization . arXiv preprint arXiv:1412.6980 . Kusner , M. J. ; Loftus , J. ; Russell , C. ; and Silva , R. 2017 . Counterfactual fairness . In NeurfPS , 4066-4076 . Leskovec , J. , and Mcauley , J. J . 2012 . Learning to discover social circles in ego networks . In NeurIPS , 539-547 . Li , Y. ; Tarlow , D. ; Brockschmidt , M. ; and Zemel , R. Gated graph sequence neural networks . Li , X. ; Du , N. ; Li , H. ; Li , K. ; Gao , J. ; and Zhang , A . 2014 . A deep learning approach to link prediction in dynamic net- works . In SDM . SIAM . Liben-Nowell , D. , and Kleinberg , J . 2007 . The link- prediction problem for social networks . journal of the Asso- ciation for Information Science and Technology 58 ( 7 ) :1019- 1031 . Louizos , C. ; Swersky , K. ; Li , Y. ; Welling , M. ; and Zemel , R. 2015 . The variational fair autoencoder . arXiv preprint arXiv : 1511.00830 . 848 Madras , D. ; Creager , E. ; Pitassi , T. ; and Zemel , R. 2018 . Learning adversarially fair and transferable representations . arXiv preprint arXiv : 1802.06309 . Masrour , F. ; Barjesteh , I. ; Forsati , R. ; Esfahanian , A.-H. ; and Radha , H. 2015 . Network completion with node similarity : A matrix completion approach with provable guarantees . In ASONAM , 302-307 . TEEE . Masrour , F. ; Tan , P.-N. ; Esfahanian , A.-H. ; and VanDam , C. 2018 . Attributed network representation learning ap- proaches for link prediction . In ASONAM , 560-563 . IEEE . McPherson , M. ; Smith-Lovin , L. ; and Cook , J. M. 2001 . Birds of a feather : Homophily in social networks . Annual review of sociology 27 ( 1 ) :415—-444 . Mikolov , T. ; Chen , K. ; Corrado , G. ; and Dean , J . 2013 . Ef- ficient estimation of word representations in vector space . arXiv preprint arXiv : 1301.3781 . Mitzenmacher , M. 2001 . A brief history of lognormal and power law distributions . In Proceedings of the Allerton con- ference on communication , control , and computing . Newman , M. E. , and Girvan , M. 2004 . Finding and evalu- ating community structure in networks . Physical review E 69 ( 2 ) :026113 . Newman , M. E. 2001 . Clustering and preferential attach- ment in growing networks . Physical review E 64 ( 2 ) :025102 . Newman , M. E. 2006 . Modularity and community structure in networks . PNAS 103 ( 23 ) :8577-8582 . Nguyen , T. T. ; Hui , P.-M. ; Harper , F M. ; Terveen , L. ; and Konstan , J . A . 2014 . Exploring the filter bubble : the effect of using recommender systems on content diversity . In WWW . O'Neil , C. 2017 . Weapons of math destruction : How big data increases inequality and threatens democracy . Broad- way Books . Pariser , E. 2012 . The filter bubble : What the internet is hiding . Perozzi , B. ; Al-Rfou , R. ; and Skiena , S. Deepwalk : Online learning of social representations . In Proc . of KDD . Pleiss , G. ; Raghavan , M. ; Wu , F : ; Kleinberg , J. ; and Wein- berger , K. Q . 2017 . On fairness and calibration . In NeurIPS . Scripps , J. ; Tan , P.-N. ; Chen , F. ; and Esfahanian , A.-H. 2008 . A matrix alignment approach for link prediction . In Proc of ICPR . Snijders , T. A. ; Van de Bunt , G. G. ; and Steglich , C. E. 2010 . Introduction to stochastic actor-based models for network dynamics . Social networks 32 ( 1 ) :44-60 . Tian , F. ; Gao , B. ; Cui , Q. ; Chen , E. ; and Liu , T.-Y . 2014 . Learning deep representations for graph clustering . In AAAI . Wang , D. ; Pedreschi , D. ; Song , C. ; Giannotti , F ; and Barabasi , A.-L. Human mobility , social ties , and link pre- diction . In Proc . of KDD . Zemel , R. ; Wu , Y. ; Swersky , K. ; Pitassi , T. ; and Dwork , C. 2013 . Learning fair representations . In JCML , 325-333 . Zhu , Z. ; Hu , X. ; and Caverlee , J . 2018 . Fairness-aware tensor-based recommendation . In Proceedings of the 27th ACM International Conference on Information and Knowl- edge Management . ACM . Running Head : BURSTING THE FILTER BUBBLE Bursting the filter bubble : The mediating effect of discussion frequency on network heterogeneity BURSTING THE FILTER BUBBLE 2 Structured Abstract Purpose : The purpose of this study is to identify the structural processes that lead citizens to escape their common social circles when talking about politics and public affairs ( e.g. , ‘ filter bubbles ' ) . To do so , this study tests to what extent political attitudes , political behavior , news media consumption and discussion frequency affect discussion network heterogeneity among U.S. citizens . Methodology/approach : Supported by the polling group Nielsen , this study uses a two-wave panel online survey to study the antecedents and mechanisms of discussion network heterogeneity among U.S. citizens . To test the hypotheses and answer the research questions , OLS regressions ( cross-sectional , lagged , autoregressive ) and mediation analyses were conducted . Findings : The findings imply that political discussion frequency functions as the key element in explaining the mechanism that leads politically interested and participatory citizens ( online ) as well as news consumers of traditional and online media to seek a more heterogencous discussion network , disrupting the so-called “ filter bubbles. ’ However , mediation analyses also showed that discussion frequency can lead to more homogenous discussion networks if people score high on political knowledge , possibly reflecting the formation of a close network of political savvy individuals . Originality/value : The survey data gives important insights into the 2016 pre-election situation , trying to explain why US citizens were more likely to remain in homogenous discussion networks when talking about politics and public affairs . By using two-wave panel data , the analyses allow to draw tentative conclusions about the influential and inhibiting factors and mechanisms that lead individuals to seek/avoid a more heterogenous discussion network . Keywords : network heterogeneity , discussion frequency , political interest , news use , filter bubble BURSTING THE FILTER BUBBLE 3 Bursting the filter bubble : The mediating effect of discussion frequency on network heterogeneity The US Presidential Election 2016 and the pervasive partisan flow of information about the presidential candidates online have revived the notion of ‘ filter bubbles ’ ( Pariser , 2011 ) and ‘ information cocoons ’ ( Sunstein , 2006 ) . Journalists , critics and opinion makers were quick in identifying the scapegoats of the surprising turnout of the election , blaming social media for spreading false information ( Baer , 2016 ; El-Bermawy , 2016 ) and creating an information environment that has reinforced existing beliefs and strengthened political polarization ( cf. , Stroud , 2010 ; Knobloch-Westerwick and Meng , 2011 ) . What is more , European politicians and advisors have expressed their concerns about increased personalized media content and its danger for a healthy democracy ( Vike-Freiberga et al. , 2013 ) . It is in this vein that social media and personalized algorithms ( e.g. , on Twitter , Facebook ) have been suspected of enforcing people ’ s tendency to solely reside in information environments and social circles that affirm their personal opinions , attitudes and points of views ( cf . Pariser , 2011 ) . However , not only has recent research casted doubt on the so-called ‘ filter bubble ’ ( Nelson and Webster , 2017 ; Zuiderveen Borgesius et al. , 2016 ) , part of the theoretical rational is also imperfect : citizens and voters are not active on the Internet or social media 24/7 . Surely , recent figures show that 77 % of Americans go online every day and 26 % of Americans are online almost constantly ( Perrin and Jiang , 2018 ) . Yet these findings do not rule out that American citizens also get exposed to views and opinions about politics and current affairs when interacting with their peers in real-life settings . After all , the majority of people goes online for leisure and entertaining purposes rather than for political reasons ( Park et al. , 2009 ; Quan-Haase and Young , 2010 ) . And political beliefs , attitudes and voting choices are still vastly influenced by face-to-face conversations with family members , friends and neighbors ( Berger et al. , 2008 ; Huckfeldt and Sprague , 1995 ) . BURSTING THE FILTER BUBBLE 4 Thus , the discussion about the prevalence of like-minded information cocoons ( Sunstein , 2006 ) needs to better incorporate the offline scenery theoretically and empirically . Furthermore , research needs to better explain why and under what circumstances people are more likely to encounter opinions and viewpoints that differ from their own—both online and offline ( cf . Choi and Lee , 2015 ; Lee et al. , 2014 ; Sunstein , 2018 ) . What we know from past research is that social media and the Internet , just as the offline scenery , offers information and exchange opportunities for both : people who seek information that reaffirms their existing beliefs ; and people who seck a more diverse and heterogenous information environment ( Festinger , 1957 ; Knobloch-Westerwick and Meng , 2009 ; 2011 ; Sears and Freedman , 1967 ) . Facing an age with information ubiquity both offline and online , the question therefore remains : What are the structural processes that lead citizens to escape their common social circles when talking about politics and public affairs ? Using a two-wave panel survey among U.S. citizens in 2013/2014 , we find that political discussion frequency functions as the key mediator in explaining the mechanism that leads politically interested and participatory citizens ( online ) as well as news consumers of traditional and online media to seek a more heterogencous discussion network . However , discussion frequency can also lead to more homogenous discussion networks if people score high on political knowledge , possibly reflecting the formation of a political-savvy elite . Literature Review Network Heterogeneity and Democracy We are currently living in a political environment that is characterized by political polarizations , extremism , and violent rioting ( ¢.g. , Charlottesville 2017 , Gunter and Hughes , 2018 ) . All around the world , but particularly in the U.S. , we have witnessed clashes among society and politics with regards to controversial topics ( e.g. , climate change , refugee policy , vaccines ) . Although political debates and disagreement are necessary and useful aspects of a well-functioning democracy ( Sorensen , 2018 ; Chadwick et al. , 2017 ) , it has been reported that BURSTING THE FILTER BUBBLE 5 not only political debates have become more hostile , disrespectful and polemic over time ( Sood and Iyengar , 2016 ) , the strong divide between ideological political stances has also made reconciliations between parties more difficult ( Iyengar et al. , 2019 ; Davis and Dunaway , 2016 ) . Given these recent developments , it becomes of paramount interest to study the underlying mechanisms that foster a citizenship that is open-minded and willing to listen to opinions and voices that differ from their own , opening up possibilities for fruitful compromises that create solutions for a harmonious life together . In fact , it has long been argued by sociologists , political scientists and communication scholars that being exposed to a diverse set of viewpoints is the nucleus for deliberative democracies ( Habermas , 1989 ; Price et al. , 2002 ) and democratic citizenship ( e.g. , Gil de Zufiiga and Valenzuela , 2011 ; Mutz , 2006 ; Sunstein , 2002 ) . However , recent detrimental societal movements , such as the rise of the political right around the globe ( e.g. , Berlet and Lyons , 2018 ) as well as hate speech and discrimination on the net ( e.g. , Gerstenfeld et al. , 2003 ) , show that our democratic societies are far away from enacting deliberative discourses . Moreover , the increasing fragmentation and polarization within societies pose a real threat for the functioning of democracies . Individuals have become less likely to identify common ground and understanding with the ‘ other group ’ ( Sunstein , 2001 ) . It is in this vein that human interactions and discussions between individuals who differ in their ideas , viewpoints as well as ethnical and social backgrounds gain increasing relevance . Scholars in communication science have identified the discussion among people with diverse viewpoints and political attitudes as discussion network heterogeneity ( Kwak et al. , 2005 ; Mutz , 2002 ; Scheufele et al. , 2006 ; Scheufele et al. , 2004 ) . These unfamiliar encounters are believed to increase the identification of shared experiences , and thereby the likeliness of acceptance and tolerance which work as “ social glue ” ( Sunstein , 2002 , p. 9 ; Mutz and Mondak , 2006 ; Price et al. , 2002 ) for diverse democratic societies . As Sunstein ( 2018 ) contends , “ in a democracy ... lives—including digital ones—should be BURSTING THE FILTER BUBBLE 6 structured so that people frequently come across views and topics that they have not specifically selected ” ( p. 7 ) Network Heterogeneity and Endogeneity Problems However , the vast majority of research on discussion network heterogeneity has concentrated on the concept as a direct or indirect antecedent for political behavior such as political participation , political knowledge or civic engagement ( e.g. , Choi et al. , 2017 ; Kim and Chen , 2015 ; McLeod et al. , 1999b ; Mutz , 2002 ; Scheufele et al. , 2004 ; 2006 ) . Thus , rather than providing another study that aims at testing the positive outcomes of political discussions among a diverse network of people for democracy , we strive for empirical evidence that informs us about the underlying mechanisms that explain why individuals are more likely to expose themselves to a heterogeneous discussion network . Reviewing previous research on network heterogeneity , we have identified various behavioral and attitudinal variables that can be hypothesized to contribute to individuals ’ likeliness to reside in non-like- minded discussion networks . These include political participation , political efficacy , political interest , political knowledge , ideology and news use . What is more , we position discussion Jrequency about politics and public affairs—which has so far been mostly considered as a control variable—at the center of our analysis , arguing that it works as a conduit between political attitudes , political behavior , news use and discussion network heterogeneity . See Figure | for the conceptual model . [ Figure 1 about here ] Political Behavior , Attitudes and Network Heterogeneity Political Participation . Although the conceptualization of network heterogeneity differs quite substantially among scholars ( Eveland and Hively , 2009 ) , the main focus of previous research has lied on the role of network heterogeneity for political participation ( c.g. , Choi et al. , 2017 ; Lu et al. , 2018 ) . Two camps have emerged in this field of research . Representative of the first camp posit that individuals embedded in a heterogenous social BURSTING THE FILTER BUBBLE 7 network are more likely to retreat from political activity due to so-called “ cross-cutting pressures ” and the need for harmony with their social relationships ( Lazarsfeld et al. , 1944 ; Mutz , 2002 ; Nir , 2005 ) . It has been argued that individuals belonging to social groups , characterized by conflicting interests and opinions , have difficulties in making up their political mind , resulting in delayed participation or no participation in elections at all . However , research that has tried to replicate the findings could not find evidence for the cross-pressure hypothesis , pointing to methodological errors and theoretical misconceptions ( Eveland and Hively , 2009 ; Horan , 1971 ; Knoke , 1990 ) . In fact , more recent work ( second camp ) suggests that heterogeneous discussion networks lead to positive effects in terms of political engagement , civic citizenship and deliberative democracy overall ( Cappella et al. , 2002 ; Choi et al. , 2017 ; Kim and Chen , 2015 ; Lu et al. , 2018 ; McLeod et al. , 1999b ; Scheufele et al. , 2004 ; 2006 ) . For example , individuals who are embedded in a heterogeneous network are not only more knowledgeable in politics ( e.g. , Scheufele et al. , 2004 ) , they are also reported to be more likely to increase political tolerance ( Mutz and Mondak , 2006 ; Price et al. , 2002 ) and decrease polarization ( e.g. , Lee and Choi , 2020 ) . Furthermore , previous research that has shown that network heterogeneity is positively related to political participation ( McLeod et al. , 1999b ; Scheufele et al. , 2004 ; 2006 ) , has been confirmed by a current stream of research on online social networks that has found positive effects of network heterogeneity on political participation ( Choi et al. , 2017 ; Kim and Chen , 2015 ; Lu et al. , 2018 ) , particularly when news use is involved ( e.g. , Kim , 2018 ) . Despite the plethora of research on the relation between network heterogeneity and political participation , none of the research cited above has focused on the reversed direction . Hence , to get more insights into what determines the constitution of heterogeneous networks , we want to inquire : ( RQ1 ) : How does political participation ( offline , online , social media ) relate to discussion network heterogeneity ? BURSTING THE FILTER BUBBLE 8 Political Efficacy . Given that political efficacy is an important predecessor for political participation ( Hayes et al. , 2006 ) and voting ( Verba and Nie , 1972 ) , it might also play a crucial role for discussion network heterogeneity . However , as Eveland and Hively ( 2009 ) have pointed out , there is a lack of research that has investigated the potential influence of political efficacy on diverse networks . Even up to now , research on discussion network heterogeneity has forgone to include political efficacy in conceptual and analytical models , or only used it as a control variable ( Kim et al. , 2013 ) . However , reversely , research has shown that political efficacy is positively influenced by the frequency of political talk and the orientation toward common understandings within political conversations ( Rojas , 2008 ) . Hence , citizens who encounter more political talk are more likely to believe they have a good understanding of politics and feel qualified to participate in politics ( cf . internal efficacy : Niemi et al. , 1991 ) . Likewise , citizens might also perceive themselves to be more politically efficacious if they get regularly exposed to a broad range of political ideas , arguments and issues that can be considered representative of the electorate . Reversely , it is also likely that individuals who are exposed to diverse political attitudes become disillusioned about their own ability to participate in politics and more skeptical with regards to their perception about their understanding of the political sphere ( cf . Eveland and Hively , 2009 ) . The sheer diversity of viewpoints , argumentations and positions that are difficult to understand—and maybe even to tolerate for some—might discourage individuals to feel politically efficacious . Given the scarce body of research on this matter , we pose the following research question : ( RQ2 ) : How is political efficacy related to individuals ’ discussion network heterogeneity ? Political Interest . The fact that motivation and interest in politics play crucial roles in explaining political behavior has long been accepted in the academic community , but particularly since the publication of Prior ’ s work on media choice and inequality in political involvement and elections ( 2007 ) . Focusing on network heterogeneity , Kwak et al . ( 2005 ) BURSTING THE FILTER BUBBLE 9 have shown that attention paid to discussions is a crucial factor in explaining the positive relationship between network heterogeneity and political participation . In other words , individuals who are entrenched in a heterogeneous discussion network , and who are attentive to what their discussion partners have to contribute to the conversation , are more likely to become politically engaged . Thus , the extent to which somebody is interested in politics might also be strongly linked to the extent to which individuals seek diverse discussion networks . However , political interest has mostly been ignored ( e.g. , McLeod et al. , 1999b ; Scheufele et al. , 2004 ; 2006 ) or simply been treated as a control variable in past research about discussion network heterogeneity ( e.g. , Kwak et al. , 2005 ) . Investigating disagreement within communication networks , Huckfeldt and Morehouse Mendez ( 2008 ) concluded that political interest , knowledge and the education of individuals are strong predictors for discussion frequency . A more recent paper by Choi and Lee ( 2015 ) has studied the reverse relationships and provided evidence that political interest moderates the relationship between news sharing online and network heterogeneity . Thus , we hypothesize ( H1 ) : Individuals who have a strong interest in politics are more likely to be exposed to a heterogeneous discussion network . Political Knowledge . Long ago , political interest has already been found to be strongly linked to political knowledge ( Seeman , 1966 ) . Since then , a wide range of research has highlighted that the more people know about politics , the more likely they are to actively participate in politics ( e.g. , Bennett , 1986 ; McLeod et al. , 1999a ; Neuman , 1986 ) . At the same time , it has been argued that this relationship might also be triggered by other intervening factors , such as the frequency of political discussions or with whom people actually discuss politics . Scheufele et al . ( 2006 ) , for example , found evidence that network heterogeneity is positively related to political participation , but mediated through political knowledge . Hence , BURSTING THE FILTER BUBBLE 10 how political knowledge contributes to political participation ( in various forms ) might also depend on the diversity of political opinions and viewpoints individuals encounter . In fact , previous research has shown that network heterogeneity enhances political knowledge ( Huckfeldt et al. , 2004 ; McLeod et al. , 1999b ; Scheufele et al. , 2004 ) . More specifically , it has been argued that individuals exposed to disagreement and opposing views have to use more cognitive activity to reflect upon new arguments they encounter , and in order to find ( new ) ways to defend their position—possibly also revising their own opinion ( Levine and Russo , 1995 ) . More recent studies support this mechanism . Eveland and Hively ( 2009 ) , distinguishing between issue stance knowledge and knowledge structure density , found that both dangerous and diverse discussion networks are positively related with knowledge structure density . Hence , when considering the reverse direction , it might also be possible that individuals with strong political knowledge are more likely to seek various political viewpoints to maintain their knowledge and get to know to various perspectives towards an issue . Given the absence of evidence for the reversed relationship between political knowledge and discussion network heterogeneity , we assume : ( H2 ) : The more individuals know about politics , the more they are exposed to a heterogeneous discussion network . Political Ideology . A related stream of research investigating information selection in a diverse information environment has focused on the phenomenon of selective exposure and how it reinforces or alters political ideologies and attitudes . Grounded in cognitive dissonance theory ( Festinger , 1957 ) and motivated reasoning ( Kraft et al. , 2015 ) , scholars argue that people are likely to avoid media content that is not in line with their own beliefs and tend to consume information that confirms their already existing opinions and ideologies ( Taber and Lodge , 2006 ) , albeit not necessarily avoiding counter-attitudinal information ( Garrett et al. , 2013 ) . Scholars in political science have found evidence that exposure to diverse political views and ideologies indeed brings about detrimental effects , such as the reinforcement of BURSTING THE FILTER BUBBLE 11 pre-existing political attitudes and opinions , thus leading to even more extreme positions ( c.g. , on gun control : Taber and Lodge , 2006 ; same-sex marriage and sexual minority rights : Wojcieszak and Price , 2010 ; or attitude toward political candidates : Meffert et al. , 2006 ) . At the same time , empirical findings have also casted doubt on the black/white news and information consumption behavior ( e.g. , Nelson and Webster , 2017 ) , pointing to various underlying factors that influence the extent to which people expose themselves to opposing views and ideologies . Lee et al . ( 2014 ) have shown , for example , that individuals with a more heterogeneous network on social network services are more polarized in ideology , but only if they discuss politics with others more often . Similarly , a more recent study suggests that the effect of heterogeneous discussion networks on opinion polarization might be moderated by political orientation such that more liberal individuals ( i.e . South Koreans ) show higher levels of polarization when being exposed to opposing opinions than individuals with lower liberal attitudes ( Lee and Choi , 2020 ) . To the best of our knowledge , Lee and colleagues ( 2014 ) have provided the only study that has investigated the reversed direction , and they found that political ideology is positively related to network heterogeneity . Given that previous research about network heterogeneity has only controlled for political ideology ( Brundidge , 2010 ) or strength of partisanship respectively ( e.g. , Kim et al. , 2013 ) , we hypothesize based on Lee et al. ’ s ( 2014 ) findings : ( H3 ) : The stronger individuals ’ political ideology , the more they are exposed to a heterogeneous discussion network . News Use and Network Heterogeneity Scholars disagree whether being embedded in a heterogeneous discussion network leads individuals to consume more ( hard ) news media in order to learn about diverse viewpoints , political arguments and topics ( McLeod et al. , 1998 ; Nisbet et al. , 2003 ) , or whether the consumption of news and the encountering of various positions and issues in the news lead people to seek a more diverse social network ( Brundidge , 2010 ) . It has been argued based on the uses and gratifications theory that individuals will pay more attention to diverse BURSTING THE FILTER BUBBLE 12 topics in the news if they also anticipate to interacting with a heterogeneous pool of individuals with a variety of interests , backgrounds and viewpoints ( Eveland , 2004 ; Scheufele et al. , 2004 ) . McLeod et al . ( 1999b ) , for example , concluded that discussions about politics in heterogeneous networks may enhance reflective thinking about issues . And Scheufele et al . ( 2004 ) , indeed , found that individuals who have reported to have a more diverse discussion network were more likely to use hard news content in newspapers and television—news formats that demand more cognitive effort when processing information compared to soft news . Brundidge ( 2010 ) has confirmed the reversed hypothesis , showing that online news use is positively related with a heterogenous political discussion network , albeit the relationship was rather small . Looking at news sharing activities but not consumption directly , Choi and Lee ( 2015 ) have shown that news sharing mediates the relationship between social networking services and network heterogeneity . Similarly , Choi et al . ( 2017 ) provided evidence that news sharing positively moderates the relationship between network heterogeneity and political participation . However , given that previous research has not differentiated between traditional , online or social media news use or did not measure active news consumption per se ( cf . Choi and Lee , 2015 ) , the relationship between news use and network heterogeneity is still unclear . We thus pose the third research question : ( RQ3 ) : How is news use ( RO3a : traditional , RO3b : online , RO3c : social media ) related to discussion network heterogeneity ? The Mediating Role of Discussion Frequency The more citizens talk about politics and public affairs , the more they become politically informed and the more likely they take responsibility as participatory democratic citizens ( e.g. , Scheufele et al. , 2004 ; Wyatt et al. , 2000 ) . A wide range of research has shown that political discussion is a determining factor for political participation in various forms ( e.g. , Gastil et al. , 2002 ; McLeod et al. , 1999a ; Scheufele et al. , 2004 ; Wyatt et al. , 2000 ) . BURSTING THE FILTER BUBBLE 13 Furthermore , more political discussion has been found to enhance understanding for political topics ( e.g. , Scheufele et al. , 2002 ) and the integration into a community ( Stamm et al. , 1997 ) . In addition , scholars have identified political discussion as a crucial moderator in strengthening political efficacy when being exposed to political campaigns , either in the newspapers or on the Internet ( Nisbet and Scheufele , 2004 ) . However , the findings reported above solely focus on the uni-directional effect of discussion frequency on political behavior , but not on mediation processes that are indicative for a deliberative democracy , such as the extent to which people discuss politics with a diverse network of opinions and attitudes . What is more , the seminal studies ( Choi et al. , 2017 ; Kim and Chen , 2015 ; Kwak et al. , 2005 ; Mutz , 2002 ; Scheufele et al. , 2004 ) in the field of discussion network heterogeneity have not consistently considered discussion frequency as a key variable that affects network heterogeneity . While Choi et al . ( 2017 ) , Mutz ( 2002 ) and Scheufele et al . ( 2004 ; 2006 ) simply controlled for the variable when predicting political participation , Kim and Chen ( 2015 ) and Kwak et al . ( 2005 ) did not even include discussion frequency in their analyses . Thus , there is a conceptual and empirical lack of research that investigates the pivotal role that discussion frequency might play with regard to network heterogeneity . As follows , this study seeks to investigate the mediating effect of discussion frequency by posing the final research question : ( RQ4 ) : To what extent is the relationship between political behavior , political attitudes , news use and network heterogeneity mediated by discussion frequency ? Method Sample and Data The data for this study are based on a two-wave panel online survey which was administered in the United States . The distribution of the survey was supported by the media polling group Nielsen . Nielsen uses a stratified quota-sampling method to recruit respondents from a pool of over 200,000 pre-registered US citizens to reach a sample that is most likely to BURSTING THE FILTER BUBBLE 14 resemble the demographic distribution as reported by the US Census . Wave 1 of the survey was carried out in December 2013 . From an initial sample of 5000 participants , 2060 individuals responded , resulting in a relatively high response rate of 34.6 % . Data for Wave 2 were collected in March 2014 . 1024 respondents filled out the survey , which indicates an acceptable retention rate of 57 % ( Watson and Wooden , 2006 ) . The resulting sample of the panel survey is diverse and comparable with the US national population as well as similar surveys that use random sampling strategies ( ¢.g. , Pew Research Center for the People and the Press , 2013 ) . Respondents varied demographically regarding age ( mean [ A/ ] =52.71 , standard deviation [ SD ] = 14.77 ) , education ( range of scale : 1-8 , Af = 3.61 , SD = 1.44 , median [ Mdn ] = some college ) , income ( ranger of scale 1-8 , Af = 4.46 , SD = 1.44 , Mdn = US $ 50,000 — US $ 59,000 ) , sex ( 49.9 % female ) , and race ( 78,1 % white ) . However , slight differences compared to the US Census were prevalent . The sample of this study is slightly younger , more educated and includes fewer Hispanics . See the appendix for the formulation of the following measures . Measures Discussion network heterogeneity . Discussion network heterogeneity has been conceptualized and measured in various ways in past research ( Eveland and Hively , 2009 ) . We followed Moy and Gastil ’ s ( 2006 ) approach in considering network heterogeneity as a multifaceted concept ( i.e. , ethnic , social , political ) , using four distinct items for the measurement ( see also Dichl et al. , 2016 ) . Respondents were asked how often ( 1 = never , 10 = all the time ) they talk about politics and public affairs online and offline with people a ) who disagree with [ them ] , b ) whose political views are different from [ theirs ] , c ) from a different race or ethnicity , and d ) from a different social class ( Wave 1 : Cronbach ’ s alpha= .94 , A= 3.58 , SD = 2.45 ; Wave 2 : Cronbach ’ s alpha = .93 , Af = 3.41 , SD = 2.36 ) . Discussion Frequency . Discussion frequency was measured by using nine items that asked respondents how often ( 1 = never , 10 = all the time ) they talk about politics or public BURSTING THE FILTER BUBBLE 15 affairs online and offline with their spouse or partner , family relatives , friends , acquaintances , strangers , neighbors they know well and don ’ t know well , and co-workers they know well and don ’ t know well ( Cronbach ’ s alpha = .87 , Mf = 3.27 , SD = 1.74 ) . Political participation . Political participation was differentiated between offline , online and social media . For offline political participation , respondents were asked to indicate on a 10-point Likert scale ( 1 = never , 10 = all the time ) , how often [ they ] have a ) contacted an elected public official , b ) attended a political rally , c ) participated in any demonstrations , protests , or marches , d ) donated money to a campaign or political cause , ¢ ) participated in groups that took any location action for social or political reform , and f ) been involved in public interest groups , political action groups , political clubs , political campaigns , or political party committees ( Cronbach ’ s alpha= .89 , Af = 2.15 , SD = 1.78 ) . Regarding online political participation , respondents were questioned how often [ they ] a ) signed or shared an online petition , b ) participated in online polls , c ) participated in an online question and answer session with a politician or public official , d ) created an online petition , and e ) signed up online to volunteer to help with a political cause ( Cronbach ’ s alpha = .78 , Af = 2.29 , SD = 1.70 ) . Finally , social media participation was gauged by inquiring how often [ they ] a ) joined a political or cause-related group on a social media site , and b ) started a political or cause- related group on a social media site ( Pearson =.66 , 14 = 1.56 , SD = 1.46 ) . Political efficacy ( internal ) . Internal political efficacy was measured by using three items derived from previous research ( Niemi et al. , 1991 ) . Ranging on a 10-point Likert scale ( 1 = strongly disagree , 10 = strongly agree ) , respondents had to indicate to what extent they think a ) “ People like me can influence government ” , b ) “ I consider myself well qualified to participate in politics ” , and c ) “ I have a good understanding of the important political issues facing our country ” ( Cronbach ’ s alpha = .78 , Mf = 5.17 , SD = 2.24 ) . Political interest . Political interest was measured by asking respondents two questions , following prior research ( Niemi et al. , 1991 ) . Respondents had to indicate on a 10- BURSTING THE FILTER BUBBLE 16 point scale ( 1 = not at all , 10 = a great deal ) a ) how interested [ they ] are in information about what ’ s going on in politics and public affairs and b ) how closely [ they ] pay attention to information about what ’ s going on in politics and public affairs ( Pearson = .93 , Af = 6.67 , SD = 2.70 ) . Political knowledge . To measure political knowledge , the respondents were asked eight questions regarding politics in the US . After recoding night and wrong answers ( 1=right , 0=wrong ) , the eight items were averaged ( Cronbach ’ s alpha : .75 , ( f= 0.57 , SD = 0.27 ) . Political ideology . To measure political ideology , respondents were asked to place themselves on 11-point scales ( 0 = strong conservative , 11 = strong liberal ) for a ) social issues and b ) economic issues . The two items were recoded to form a 4-point scale ( 1 = neutral , 4 = strong ideology ) ( Pearson =.75 ; M = 2.36 , SD = 1.00 ) . News use . News use was distinguished between traditional news media , online news media and social media news . Traditional news use ( e.g. , Gil de Zufiiga et al. , 2010 ) was captured by asking respondents nine items that asked how often they get news ( 1 = never , 10 = all the time ) from network TV news ( e.g. , ABC , CBS , NBC ) , local television news ( local affiliate stations ) , national newspapers ( e.g . New York Times , Washington Post , US Today ) , local newspapers ( e.g. , Oregonian , Houston Chronicle , Miami Herald ) , cable news ( c.g. , CNN , Fox News , MSNBC ) , radio news ( e.g. , NPR , talk shows ) , print media , television media , and radio ( Cronbach ’ s alpha = .77 , Af = 5.26 , SD = 1.86 ) . Online news use was measured using eight items , asking respondents how often they get news ( 1 = never , 10 = all the time ) from online news sites ( e.g. , Gawker , Politico , BuzzFeed ) , citizen journalism sites ( e.g. , CNN ’ s iReport , Examiner.com ) , hyperlocal news sites ( e.g. , Patch.com or other sites dedicated to news in [ their ] local community ) , computer web browser ( laptop or desktop ) , tablet app or browser ( iPad , 7 inches or larger ) , smartphone app or browser ( handheld mobile device smaller than 7 inches ) , news aggregators ( c.g. , BURSTING THE FILTER BUBBLE 17 Google News , etc . ) and sites and apps that collect news ( e.g. , Flipboard or Pulse ) ( Cronbach ’ s alpha =.78 , Af = 2.97 , SD = 1.55 ) . The variable for social media news use was constructed based on four items ( e.g. , Gil de Zufiiga et al. , 2010 ) , asking respondents how often they use Facebook for getting news , Twitter for getting news , use social media to stay informed about current events and public affairs , and use social media to get news from mainstream media . Answer categories ranged on a 10-point scale ( 1 = never , 10 = all the time , Cronbach ’ s alpha = .82 , f= 2.67 , SD = 2.06 ) . Controls . Following previous research on network heterogeneity ( e.g. , Lee et al. , 2014 ) , we also controlled for daily social media use by asking respondents how often ( 1 = never , 10 = all the time ) they use social media on a typical day ( Af = 4.13 , SD = 2.99 ) , Furthermore , following Mutz ( 2002 ) and others ( ¢.g. , Eveland and Hively , 2009 ) , we measured network size to control for the amount of people with whom respondents usually have political discussions . We asked respondents about how many people they would say they have talked to a ) face-to-face or over the phone about politics or public affairs , and b ) via the Internet , including e-mail , chat rooms , social network sites and micro-blogging sites . Given the highly skewed variable when averaged , a constant ( 1 ) was added before applying a log transformation to the variable ( Af = 0.89 , SD = 0.99 , min = 0.00 , max = 5.62 ) . As for demographics , we included age , gender ( 1 = male ) , race ( 1= white ) , annual household income , and education in our analyses . Analyses To answer the research questions and test the hypotheses , including the mediating effect of discussion frequency , we conducted a series of ordinary least squares regression analyses , and causal mediation analyses ( Baron and Kenny , 1986 ) with the computing software R. To control for non-normal data , the mediation analyses were conducted with 1,000 bootstrap samples . What is more , the two-wave survey design allowed us to test for BURSTING THE FILTER BUBBLE 18 tentative causal directions of the assumed relationships . To do so , we estimated three OLS regression models ( cross-sectional , lagged , autoregressive ) . It is particularly the autoregressive model that allows for more confident causal assumptions as it regresses the independent variable ( IV ) from wave one on the dependent variable ( DV ) from wave two while , at the same time , controlling for the DV from wave one ( Finkel , 1995 ) . Results The first research question dealt with the relationship between political participation and network heterogeneity . The OLS results ( see Table 1 ) indicate that none of the forms of political participation ( offline , online , social media ) is significantly related to network heterogeneity . In the second research question we inquired how political efficacy is associated with network heterogeneity . We equally find no significant relationship in the OLS models . The first hypothesis posed in this study assumed that individuals who have a strong interest in politics are more likely to be exposed to a heterogeneous discussion network . The results show that there is a direct significant positive relationships between political interest and discussion network heterogeneity in the cross-sectional model ( OLS : B = .082 , p < .05 ) . Hence , the more people are interested in politics and public affairs , the more likely they seek a heterogeneous discussion network . In the second hypotheses we asserted that individuals who know more about politics , are more likely to be exposed to a heterogeneous discussion network . However , we did not find support for this assumption in the OLS models . [ Table 1 ] The third hypothesis dealt with the positive relationship between political ideology and network heterogeneity . Here , no significant correlations were detected in the OLS models either . In addition , we inquired how news media consumption relates to network heterogeneity ( RQ3 ) . The results reveal that traditional news use is positively related with network heterogeneity , both in the lagged and autoregressive OLS model ( lagged : 2 = .077 , p < .05 ; autoregressive : B = .089 , p < .05 ) . Thus , the more people consume traditional news BURSTING THE FILTER BUBBLE 19 ( e.g. , newspapers , TV , radio ) , the more likely they reside in heterogeneous networks . However , no other form of news media use has been found to be related with discussion network heterogeneity . The final research question dealt with the mediating effect of discussion frequency for the relationship between political attitudes , behavior , news use and discussion network heterogeneity . The causal mediation analyses have revealed that the positive effect of political participation online on discussion network heterogeneity is largely dependent on discussion frequency . Accordingly , when frequently discussing politics , the relationship between online political participation and network heterogeneity becomes apparent for individuals . Second , political interest can also lead to a more diverse discussion network over time , but only if politics is discussed more frequently . Third , while there was no direct effect of political knowledge on network heterogeneity in the OLS models , discussion frequency works as a negative mediator ; hence decreasing discussion network heterogeneity . Eventually , the positive effects of traditional news consumption on network heterogeneity were found to be largely contingent on whether individuals frequently talk to other people about politics and public affairs . Positive mediation effects were also detected for online news consumption . For social media news use , the mediation effect was absent , however . [ Table 2 about here ] Discussion Having recently faced widely debated issues around “ information cocoons ’ , ‘ echo chambers ’ , and ‘ filter bubbles ’ , this study aimed at shedding light on what political attitudes , political behavior as well as news consumption behaviors are indicative for US citizens to talk to people from diverse backgrounds ( e.g. , social , ethnical , political ) . What scholars in political science and communication science have called “ discussion network heterogeneity ” ( Mutz , 2002 ; Scheufele et al. , 2004 ; 2006 ) , and which has been ascribed a pivotal role for deliberative democracies ( Habermas , 1989 ) , has so-far been mainly considered as an BURSTING THE FILTER BUBBLE 20 exogenous variable in theoretical and empirical models ( except : Brundidge , 2010 ; Lee et al. , 2014 ; Choi and Lee , 2015 ) . However , in this study we sought out to identify the major antecedents for network heterogeneity , while at the same time , also accounting for the mediating role of discussion frequency . Findings revealed that the most important factors that lead people to seek a heterogeneous discussion network are political interest , political participation online as well as news use ( traditional , online ) . Political knowledge , on the other hand , has been found to rather attenuate network heterogeneity . However , while the direct relationship between these factors were found to be limited ( ¢.g. , only present for political interest and traditional news use ) , it became clear that citizens need to foster frequent talks about politics and public affairs in order to get exposed to counter-attitudinal political opinions . Hence , the more politically interested individuals talk to others about politics and public affairs , the more likely they are to encounter alternative viewpoints and explanations . Research on selective exposure has indeed shown that politically interested individuals are not dismissive about opinions and attitudes that differ from theirs , but that they seek opposing arguments in order to construct counter-arguments and become prepared for political discussions with the opposition ( e.g. , Garrett , 2009 , Valentino et al. , 2009 ) . While this mechanism seems to be at work for politically interested citizens , political intelligence combined with discussion frequency might function as a damper . The results have shown that politically savvy people are less likely to encounter heterogeneous discussion networks if they talk about politics and public affairs frequently . Rather , it seems that politically knowledgeable people—especially if they talk with others about politics and public affairs more often—amight be less inclined to listening to counter-attitudinal viewpoints . These findings point to a dangerous formation of a politically sophisticated elite that becomes increasingly delineated from the broader , average political forum ( cf . Putnam , 1976 ) . BURSTING THE FILTER BUBBLE 21 What is more , having researched news media effects for a variety of news platforms ( traditional , online , social media ) , it became apparent that traditional news use can be considered the strongest predictor for discussion network heterogeneity—and even over time . Furthermore , the mediation analyses showed that frequent discussions with others about politics and public affairs do not only mediate the positive effect of traditional news use on network heterogeneity , it also enhances citizens who consume online news to talk more often with people from diverse backgrounds . In other words , the more individuals consume news via traditional and online media outlets and discuss politics with others , the more likely they are to seek out conversation partners that differ from themselves socially , politically , and/or ethnically . These findings are not only in line with Brundidge ( 2010 ) , who has shown that online news consumption leads to network heterogeneity through discussion frequency ; the results also provide evidence that the previously identified uni-directional relationship between traditional news use and network heterogeneity ( Scheufele et al. , 2004 ; 2006 ) also holds in the reverse order . Eventually , the reason that we do not find a mediation effect of discussion frequency for the relationship between social media news use and network heterogeneity can be well-reasoned . Given that consuming news via social media already implies that people have a large network and frequent discussions in the online sphere ( in most cases ) , it is plausible that the mediating effect of discussion frequency seems to become obsolete in our analyses . Lastly , we found that discussion frequency works as a positive mediator for political participation online affecting network heterogeneity positively . Hence , while political participation on social media and offline might not necessarily increase the likeliness to be exposed to different viewpoints , online political participation ( e.g. , signing online petitions or participating in a Q & A with politicians online ) might represent actions that could help to burst the so-called ‘ filter bubble. ’ Explanations for this finding can be found when BURSTING THE FILTER BUBBLE 22 considering the nature of the different forms of political participation . Offline political participation ( e.g. , participation in rallies , demonstrations or political interest groups ) oftentimes take place within a common social community ( e.g. , political party , friends , social circles who stand up for a shared cause ) . The same can be said about political participation on social media . Here , the activity remains in the social media sphere , such as starting or joining a cause-related group but does not extend beyond the familiar social online circles . Yet , online political participation , which includes creating , sharing , signing a petition or signing up to volunteer for a political cause , implies that one does not necessarily need to be exposed to the same group of people . Petitions can take various forms and can focus on a diversity of topics . What is more , online tools nowadays enable people to become exposed to a variety of political opinions and backgrounds that one would not have necessarily encountered offline or on social media ( e.g. , emails , newsletters , forums , What ’ s App groups ) . Limitations Although this study has given new insights into the antecedents and mechanisms of discussion network heterogeneity , there are certain limitations that need to be taken into account . First , the data could be considered outdated as the surveys were conducted back in 2013 and 2014 respectively . However , as we are still facing many questions regarding the outcome of the US elections in 2016 , the findings of this study can be deemed indicative for why US citizens have turned away from secking alternative political views and rather resided in social circles that ( re- ) confirmed their existing political beliefs . Second , we had to rely on survey data which are widely known in the field to be prone to social desirability , untrustworthy answers , and missing values ( cf . decreases the sample for final analyses ) . However , rather than relying on a small dataset that might be less generalizable , we opted for a large-scale , representative survey in order to make more compelling conclusions about the U.S. population . Future research should , however , focus on tracking-data and survey- techniques that use smartphone and other intrusive online techniques . BURSTING THE FILTER BUBBLE 23 Thirdly , and lastly , we were only able to identify a direct relationship between traditional news use , political interest and discussion network heterogeneity respectively . All other variables that measured political attitude and behavior as well as news use did not yield positive results , albeit the mediation effects revealed more interesting insights . It is in this vein that we reason that network heterogeneity is part of a recursive process in which political attitudes , behavior and news consumption mutually influence and reinforce each other . As a result , this study has given useful insights into the antecedents and mechanisms of network heterogeneity when considered as an endogenous construct . What is more , follow-up studies should investigate discussion network heterogeneity as a social constructive process . More specifically , future research could take a look at the individual , cognitive processes that take place when citizens encounter counter-attitudinal political viewpoints , and how these conversations affect their political attitudes and behaviors ( over time ) . Another possibility could be an intervention study , focusing on the micro-level processes of promoting network heterogeneity . A prime example in this regard is the initiative by the Germany newspaper ZEIT “ Deutschland spricht ” ! since 2017 . A similar project could be conducted in the US , engaging citizens to meet and talk about politics with fellow citizens who differ in their political ideas . The results of the personal exchange , the regular meetings and conversations could be scientifically accompanied by means of follow-up interviews and surveys , providing insights into the effects of heterogencous discussion networks on beliefs and attitudes toward democratic principles . Conclusion All in all , the findings of this study lend support that political discussion can be considered the “ social glue ” ( Sunstein , 2002 , p. 9 ) that keeps democratic societies together and that might lead to the “ bursting ” of the alleged ‘ filter bubbles ’ and ‘ information cocoons ’ these days . Thus , there is a need to create platforms in societies to talk about politics and public affairs more frequently—either privately , at home , in the public sector , in schools , at BURSTING THE FILTER BUBBLE 24 universities , or at work . Furthermore , educational institutions and lecturers are in demand to arouse interest among pupils and students to become engaged with politics and public affairs . Reading the news regularly ( e.g. , in the newspapers or online ) is part of the process to stay informed and equip oneself with the necessary tools to participate in political discussions . In short , the results of this study have shown that strengthening political interest , political participation online and news media consumption , coupled with more political talks , is key to ensure a thriving democracy that is based on citizens who seek to encounter diverse opinions , show interest in various standpoints , and are open to listen to alternative viewpoints . References Baer , D. ( 2016 ) , “ The ‘ filter bubble ’ explains why trump won and you didn ’ t see it coming ” , The Cut , available at : https : //www.thecut.com/2016/1 1/how-facebook-and-the-filter- bubble-pushed-trump-to-victory.html ( accessed 4 November 2019 ) . Baron , R.M . and Kenny , D.A . ( 1986 ) , “ The moderator-mediator variable distinction in social psychological research : Conceptual , strategic , and statistical considerations ” , Journal of Personality and Social Psychology , Vol . 51 No . 6 , pp . 1173-1182 . Bennett , S.E . ( 1986 ) , Apathy in America 1960-1984 : Causes and Consequences of Citizen Political Indifference , Transnational Publishers , Dobbs Ferry , NY . Berlet , C. and Lyons , M. N. ( 2018 ) , Right-Wing Populism in America : Too Close for Comfort . The Guilford Press , New York , NY . Berger , J. , Meredith , M. and Wheeler , C. ( 2008 ) , “ Contextual priming : Where people vote affects how they vote ” , in Proceedings of the National Academy of Sciences , June 2008 . Brundidge , J . ( 2010 ) , “ Political discussion and news use in the contemporary public sphere : The “ ‘ accessibility ’ ’ and ‘ “ traversability ’ ’ of the Internet ” , Javnost—The Public , Vol . 17 No . 2 , pp . 63-82 . BURSTING THE FILTER BUBBLE 25 Cappella , J.N. , Price , V. and Nir , L. ( 2002 ) , “ Argument repertoire as a reliable and valid measure of opinion quality : Electronic dialogue during campaign 2000 ” , Political Communication , Vol . 19 No . 1 , pp . 73-93 . Chadwick , A. , O ’ Loughlin , B. , and Vaccari , C. ( 2017 ) , “ Why people dual screen political debates and why it matters for democratic engagement ” . Journal of Broadcasting & Electronic Media , Vol . 61 No . 2 , pp . 220-239 . Choi , J. , Lee , J.K. , and Metzger , E. ( 2017 ) , “ Investigating effects of social media newssharing on the relationship between network heterogeneity and political participation ’ , Computers in Human Behavior , No 75 , pp . 25-31 . Choi , J. and Lee , J.K. ( 2015 ) , “ Investigating the effects of news sharing and political interest on social media network heterogeneity ” , Computers in Human Behavior , Vol . 44 , pp . 258-266 . Davis , N.T. , and Dunaway , J.L . ( 2016 ) , “ Party polarization , media choice , and mass partisan- ideological sorting ” . Public Opinion Quarterly , Vol . 80 No . 1 , pp . 272-297 . Diehl , T. , Weeks , B.E . and Gil de Zufiiga , H. ( 2016 ) , “ Political persuasion on social media : Tracing direct and indirect effects of news use and social interaction ” , New Media & Society , Vol . 18 No . 9 , pp . 1875-1895 . El-Bermawy , M.M . ( 2016 ) , “ Your filter bubble is destroying democracy ” , Wired , available at : https : //www.wired.com/2016/1 1/filter-bubble-destroying-democracy/ ( accessed 4 November 2019 ) . Eveland , W.P. , Jr. ( 2004 ) , “ The effect of political discussion in producing informed citizens : The roles of information , motivation and elaboration ” , Political Communication , Vol . 21 No . 2 , pp . 177-193 . Eveland W.P.Jr . and Hively M.H . ( 2009 ) , “ Political discussion frequency , network size , and “ heterogeneity ” of discussion as predictors of political knowledge and participation ” , Journal of Communication , Vol . 59 No . 2 , pp . 205-224 . BURSTING THE FILTER BUBBLE 26 Festinger , L. ( 1957 ) , A Theory of Cognitive Dissonance . Stanford University Press , Stanford , CA . Finkel , 8.E . ( 1995 ) , Causal Analysis with Panel Data , Sage , Thousand Oaks , CA . Garrett , K. ( 2009 ) , “ Politically motivated reinforcement seeking : Reframing the selective exposure debate ” , Journal of Communication , Vol . 59 No . 4 , pp . 676-699 . Garrett , R.K. , Carnahan , D. and Lynch , E.K . ( 2013 ) , “ A turn toward avoidance ? Selective exposure to online political information , 2004-2008 ” , Political Behavior , Vol . 35 No . 1 , pp . 113-134 . Gastil , J. , Deess , E.P . and Weiser , P. ( 2002 ) , “ Civic awakening in the jury room : A test of the connection between jury deliberation and political participation ’ , Journal of Politics , Vol . 64 No . 2 , pp . 585-595 . Gerstenfeld , P.B. , Grant , D. and Chiang , C.-P. ( 2003 ) , “ Hate online : A content analysis of extremist internet sites ” , Analyses of Social Issues and Public Policy , Vol . 3 No . 1 , pp . 29-44 . Gil de Zufiiga , H. and Valenzuela , 8 . ( 2011 ) , “ The mediating path to a stronger citizenship : Online and offline networks , weak ties , and civic engagement ” , Communication Research , Vol . 38 No . 3 , pp . 397-421 . Gil de Zurfiiga , H. , Veenstra , A. , Vraga , E. and Shah , D. ( 2010 ) , “ Digital democracy : Reimagining pathways to political participation ” , Journal of Information Technology & Politics , Vol . 7 No . 1 , pp . 36-51 . Gunter , J. and Hughes , R. ( 2018 ) , “ Charlottesville remembered : ‘ A battle for the soul of America ’ ” , BBC , available at : https : //www.bbc.com/news/world-us-canada-446 19374 ( accessed 4 November 2019 ) , Habermas , J . ( 1989 ) , The Structural Transformation of the Public Sphere : An Inquiry into a Category of Bourgeois Society , MIT Press , Cambridge , MA . BURSTING THE FILTER BUBBLE 27 Hayes , A.F. , Scheufele , D.A . and Huge , M.E . ( 2006 ) , “ Nonparticipation as self-censorship : Publicly observable political activity in a polarized opinion climate ” , Political Behavior , Vol . 28 No . 3 , pp . 259-283 . Horan , P.M. ( 1971 ) , “ Social positions and political cross-pressures : A re-examination ’ , American Sociological Review , Vol . 36 No . 4 , pp . 650-660 . Huckfeldt , R. and Morehouse Mendez , J . ( 2008 ) , “ Moths , flames , and political engagement : Managing disagreement within communication networks ” , The Journal of Politics , Vol . 70 No . 1 , pp . 83-96 . Huckfeldt , R. and Sprague , J. D. ( 1995 ) , Citizens , Politics , and Social Communication : Information and Influence in an Election Campaign , Cambridge University , Cambridge , U.K. Huckfeldt , R. , Morehouse Mendez , J. and Osborn , T. ( 2004 ) , “ Disagreement , ambivalence , and engagement : The political consequences of heterogeneous networks ” , Political Psychology , Vol . 25 No . 1 , pp . 65-95 . Iyengar , S. , Lelkes , Y. , Levendusky , M. , Malhotra , N. , and Westwood , S.J . ( 2019 ) , “ The origins and consequences of affective polarization in the United States ” . Annual Review of Political Science , Vol . 22 , pp . 129-146 . Kim , M. ( 2018 ) , “ How does Facebook news use lead to actions in South Korea ? The role of Facebook discussion network heterogeneity , political interest , and conflict avoidance in predicting political participation ” , Telematics and Informatics , Vol . 35 , No 5 , pp . 1373-1381 . Kim , Y. , and Chen , H.T . ( 2015 ) , “ Discussion network heterogeneity matters : Examining a moderated mediation model of social media use and civic engagement ” , /nternational Journal of Communication , No . 9 , pp . 2344-2365 . BURSTING THE FILTER BUBBLE 28 Kim , Y. , Hsu , $ .H . and Gil de Zifiiga , H. ( 2013 ) , “ Influence of social media use on discussion network heterogeneity and civic engagement : The moderating role of personality traits ” , Journal of Communication , Vol . 63 No . 3 , pp . 498-516 . Knobloch-Westerwick , S. and Meng , J . ( 2011 ) , “ Reinforcement of the political self through selective exposure to political messages ” , Journal of Communication , Vol . 61 No . 2 , pp . 349-368 . Knobloch-Westerwick , S. and Meng , J . ( 2009 ) , “ Looking the other way : Selective exposure to attitude-consistent and counterattitudinal political information ” , Communication Research , Vol . 36 No . 3 , pp . 426-448 . Knoke , D. ( 1990 ) , Political Networks : The Structuralist Perspective . Cambridge University Press , New York , NY . Kraft , P.W. , Lodge , M. and Taber , C.S . ( 2015 ) , “ Why people “ don ’ t trust the evidence ” : Motivated reasoning and scientific beliefs ” , The ANNALS of the American Academy of Political and Social Science , Vol . 658 , pp . 121-133 . Kwak , N. , Williams , A.E. , Wang , X. and Lee , H. ( 2005 ) , “ Talking politics and engaging politics : An examination of the interactive relationships between structural features of political talk and discussion engagement ” , Communication Research , Vol . 32 No . 1 , pp . 87-111 . Lazarsfeld , P.F. , Berelson , B. and Gaudet , H. ( 1944 ) , The People ’ s Choice : How the Voter Makes up His Mind in a Presidential Campaign , Columbia University Press , New York , NY . Lee , J. , and Choi , Y . ( 2020 ) , “ Effects of network heterogeneity on social media on opinion polarization among South Koreans : Focusing on fear and political orientation ” , International Communication Gazette , Vol . 82 No . 2 , pp . 119-139 . Lee , J.K. , Choi , J. , Kim , C. and Kim , Y . ( 2014 ) , “ Social media , network heterogeneity , and opinion polarization ” , Journal of communication , Vol . 64 No . 4 , pp . 702-722 . BURSTING THE FILTER BUBBLE 29 Levine , J.M . and Russo , E. ( 1995 ) , “ Impact of anticipated interaction on information acquisition ’ , Social Cognition , Vol . 13 No . 3 , pp . 293-317 . Lu , Y. , Lee , J. and Kim , E. ( 2018 ) , `` Network characteristics matter in politics on Facebook : evidence from a US national survey '' , Online Information Review , Vol . 42 No . 3 , pp . 372-386 . McLeod , J.M. , Scheufele , D.A . and Moy , P. ( 1999a ) , “ Community , communication , and participation : The role of mass media and interpersonal discussion in local political participation ” , Political Communication , Vol . 16 No . 3 , pp . 315-336 . McLeod , J.M. , Scheufele , D.A. , Moy , P. , Horowitz , E.M. , Holbert , R.L. , Zhang , W. , Zubric , S. and Zubric , J . ( 1999b ) , “ Understanding deliberation . The effects of discussion networks on participation in a public forum ” , Communication Research , Vol . 26 No . 6 , pp . 743-774 . McLeod , J.M. , Sotirovic , M. and Holbert , R.L . ( 1998 ) , “ Values as sociotropic judgments influencing communication patterns ” , Communication Research , Vol . 25 No . 5 , pp . 254-480 . Meffert , M.F. , Chung , S. , Joiner , A.J. , Waks , L. and Garst , J . ( 2006 ) , “ The effects of negativity and motivated information processing during a political campaign ” , Journal of Communication , Vol . 56 No . 1 , pp . 27-51 . Moy P. and Gastil , J . ( 2006 ) , “ Predicting deliberative conversation : The impact of discussion networks , media use , and political cognitions ” , Political Communication , Vol . 23 No . 4 , pp . 443-460 . Mutz , D.C. ( 2006 ) , Hearing the Other Side : Deliberative Versus Participatory Democracy . Cambridge University Press , New York , NY . Mutz , D.C. ( 2002 ) , “ The consequences of cross-cutting networks for political participation ” , American Journal of Political Science , Vol . 46 No . 4 , pp . 848-855 . BURSTING THE FILTER BUBBLE 30 Mutz , D.C. and Mondak , J.J. ( 2006 ) , “ The workplace as a context for cross-cutting political discourse ” , Journal of Politics , Vol . 68 No . 1 , pp . 140-155 . Nelson , J.L . and Webster , J.G . ( 2017 ) , “ The Myth of Partisan Selective Exposure : A Portrait of the Online Political News Audience ” , Social Media + Society , Vol . 3 No . 3 . Neuman , W.R. ( 1986 ) , The Paradox of Mass Politics : Knowledge and Opinion in the American Electorate , Harvard University Press , Cambridge , MA . Niemi , R.G. , Craig , 8.C . and Mattei , F. ( 1991 ) , “ Measuring internal political efficacy in the 1988 National Election Study ” , American Political Science Review , Vol . 85 No . 4 , pp . 1407-1413 . Nir , L. ( 2005 ) , “ Ambivalent social networks and their consequences for participation ” , International Journal of Public Opinion Research , Vol . 17 No . 4 , pp . 422-442 . Nisbet , M.C . and Scheufele , D.A . ( 2004 ) , “ Political talk as a catalyst for online citizenship ” , Journalism & Mass Communication Quarterly , Vol . 81 No . 4 , pp . 877-896 . Nisbet , M.C. , Moy , P. and Scheufele , D.A . ( 2003 ) , “ Religion , communication , and social capital ” , paper presented to the Political Communication Division of the International Communication Association ( ICA ) , May , San Diego , USA . Pariser , E. ( 2011 ) , The filter bubble : What the Internet is hiding from you , Penguin , New York , NY . Park , N. , Kee , K. F. and Valenzuela , S. ( 2009 ) , “ Being immersed in social networking environment ” , Cyberpsychology & Behavior , Vol . 12 No . 6 , pp . 729-733 . Perrin , A. , & Jiang , J . ( 2018 ) . Almost a quarter of US adults say they are ‘ almost constantly ’ online . World Economic Forum , available at : https : //www.weforum.org/agenda/20 18/03/about-a-quarter-of-u-s-adults-say -they- are-almost-constantly-online/ ( accessed 4 November 2019 ) . BURSTING THE FILTER BUBBLE 31 Pew Research Center for the People and the Press ( 2018 ) , Mfethodology . The American Trends Panel survey methodology , available at : http : //www.people- press.org/2018/10/15/methodology-207/ ( accessed 4 November 2019 ) . Price , V. , Cappella , J. N. and Nir , L. ( 2002 ) , “ Does more disagreement contribute to more deliberative opinion ? ” , Political Communication , Vol . 19 No . 1 , pp . 95-112 . Prior , M. ( 2007 ) , Post-broadcast democracy : How media choice increases inequality in political involvement and polarizes elections , Cambridge University Press , New York , NY . Putnam , R.D . ( 1976 ) , The comparative study of political elites , Prentice Hall , New Jersey , NJ . Quan-Haase , A. and Young , A. L. ( 2010 ) , “ Uses and gratifications of social media ” , Bulletin of Science , Technology & Society , Vol . 30 No . 5 , pp . 350-361 . Rojas , H. ( 2008 ) , “ Strategy versus understanding : How orientations toward political conversation influence political engagement ” , Communication Research , Vol . 35 No . 4 , pp . 452-480 . Scheufele , D.A. , Hardy , B.W. , Brossard , D. , Waismel-Manor , I.S . and Nisbet , E.C . ( 2006 ) , “ Democracy based on difference : Examining the links between structural heterogeneity , heterogeneity of discussion networks , and democratic citizenship ” , Journal of Communication , Vol . 56 No . 4 , pp . 728-753 . Scheufele , D.A. , Nisbet , M.C. , Brossard , D. and Nisbet , E.C . ( 2004 ) , “ Social structure and citizenship : Examining the impact of social setting , network heterogeneity , and informational variables on political participation ” , Political Communication , Vol . 21 No . 3 , pp . 315-338 . Scheufele , D.A. , Shanahan , J. and Kim , 8 . ( 2002 ) , “ Who cares about local politics ? Media influences on local political involvement , issue awareness , and attitude strength ” , Journalism and Mass Communication Quarterly , Vol . 79 No . 2 , pp . 427-444 . BURSTING THE FILTER BUBBLE 32 Sears , D.O . and Freedman , J.L . ( 1967 ) , “ Selective exposure to information : A critical review ” , Public Opinion Quarterly , Vol . 31 No . 2 , pp . 194-213 . Seeman , M. ( 1966 ) , “ Alienation , membership , and political knowledge : A comparative study ” , Public Opinion Quarterly , Vol . 30 No . 3 , pp . 353-367 . Sood , G. and Iyengar , 8 . ( 2016 ) , “ Coming to Dislike Your Opponents : The Polarizing Impact of Political Campaigns ” , Stanford University , available at : https : //ssm.com/abstract=2840225 ( accessed 10 May 2020 ) . Sorensen , G. ( 2018 ) , Democracy and democratization : processes and prospects in a changing world , Routledge , New York , NY . Stamm , K.R. , Emig , A.G. and Hesse , M.B . ( 1997 ) , ’ The contribution of local media to community involvement ” , Journalism and Mass Communication Quarterly , Vol . 74 No . 1 , pp . 97-107 . Stroud , N.J. ( 2010 ) , “ Polarization and partisan selective exposure ” , Journal of Communication , Vol . 60 No . 3 , pp . 556-576 . Sunstein , C.R . ( 2018 ) , # Republic : Divided democracy in the age of social media . Princeton University Press , Princeton , NJ . Sunstein , C.R . ( 2006 ) , /nfotopia : How many minds produce knowledge . Oxford University Press , New York , NY . Sunstein , C.R . ( 2002 ) , “ The law of group polarization ” , Journal of political philosophy , Vol . 10 No . 2 , pp . 175-195 . Sunstein , C.R . ( 2001 ) , Republic.com . Princeton University , Princeton , NJ . Taber , C.S . and Lodge , M. ( 2006 ) , “ Motivated skepticism in the evaluation of political beliefs ” , American Journal of Political Science , Vol . 50 No . 3 , pp . 755-769 . Valentino , N.A. , Hutchings , V.L. , Banks , A.J . and Davis , A.K . ( 2009 ) , “ Selective exposure in the Internet age : The interaction between anxiety and information utility ” , Political Psychology , Vol . 30 No . 4 , pp . 591-613 . BURSTING THE FILTER BUBBLE 33 Verba , S. and Nie , N.H. ( 1972 ) , ’ Participation in America : Political democracy and social equality ” , University of Chicago Press , Chicago , IL . Vike-Freiberga , V. , Daubler-Gmelin , H. , Hammersley , B. and Pessoa Maduro , L.M.P . ( 2013 ) , “ A free and pluralistic media to sustain European democracy ” , Report , High Level Group on Media Freedom and Media Pluralism , available at : http : //static.eu20 13 .It/uploads/documents/Programos/Discussion % .20documents/Free % 20and % 20Pluralistic % 20Media % 20to % 20Sustain % 20European™20Democracy.pdf ( accessed 4 November , 2019 ) . Watson , N. and Wooden , M. ( 2006 ) , “ Modelling longitudinal survey response : The experience of the HILDA survey ” , in ACSPRI social science methodology conference , pp . 10-13 . Wojcieszak , M. and Price , V. ( 2010 ) , “ Bridging the divide or intensifying the conflict ? How disagreement affects strong predilections about sexual minorities ” , Political Psychology , Vol . 31 No . 3 , pp . 315-339 . Wyatt , R. O. , Katz , E. and Kim J . ( 2000 ) , “ Bridging the spheres : Political and personal conversation in public and private spaces ” , Journal of Communication , Vol . 50 No . 1 , pp . 71-92 . Zuiderveen Borgesius , F. , Trilling , D. , Moller , J. , Bod , B. , de Vreese , C. and Helberger , N. ( 2016 ) , “ Should we worry about filter bubbles ? ” , Znternet Policy Review , Vol . 5 No . 1 . Footnotes 1 More information on the project ( in German ) : https : //www.zeit.de/serie/deutschland-spricht BURSTING THE FILTER BUBBLE Table 1 34 OLS Regression Models Predicting Discussion Frequency and Network Heterogeneity ( Cross-Sectional , Lagged , Autoregressive ) Discussion Frequency Network Heterogeneity Network Heterogeneity Network Heterogeneity Cross-Sectional™ ? Cross-Sectional™ ? Lagged * ? Autoregressive ? B B B B Block 1 : Autoregressive Term Network Heterogeneity™ ! - - - A34 * * * ( 533 ) Constant .000 ( .372 ) .000 ( .489 ) .000 ( 570 ) .000 ( .533 ) Block 2 : Demographics & Controls Age -.059 ( .004 ) .015 ( .005 ) -.024 ( .006 ) -.030 ( .005 ) Gender ( 1=male ) -.011 ( .097 ) -.029 ( .123 ) .007 ( .149 ) .020 ( .139 ) Race ( 1=white ) .014 ( .122 ) .024 ( .160 ) .022 ( .187 ) .011 ( 175 ) Income .080 * * ( .034 ) -.057 * ( .046 ) -.063 ( .053 ) -.038 ( .050 ) Education .030 ( .034 ) .026 ( .044 ) .067 ( .052 ) .056 ( .048 ) Social Media Use -.019 ( .021 ) .053 ( .027 ) .089 * ( .032 ) .066 ( .030 ) Network Size ( log ) .385 * * * ( .056 ) .126 * * * ( .081 ) .213 * * * ( 094 ) 158 * * * ( 089 ) Block 3 : Political Antecedents Political Participation Offline .045 ( .049 ) .039 ( .064 ) .093 ( .075 ) .076 ( .070 ) Political Participation Online .144 * * ( .051 ) .062 ( .068 ) .107 ( .079 ) .080 ( .074 ) Political Participation Social Media .058 ( .049 ) -.033 ( .064 ) -.074 ( .075 ) -.060 ( .070 ) Political Efficacy Internal .050 ( .029 ) .015 ( .038 ) .074 ( .045 ) .068 ( .042 ) Political Interest .182 * * * ( 028 ) .082 * ( .037 ) .084 ( .043 ) .049 ( .040 ) Political Knowledge -.098 * * ( 232 ) .067 ( .306 ) -.019 ( .357 ) -.048 ( .334 ) Political Ideology .030 ( .050 ) -.012 ( .065 ) -.019 ( .076 ) -.014 ( 071 ) Block 4 : News Media Use Traditional News .135 * * * ( .030 ) -.029 ( .040 ) .077 * ( .047 ) .089 * ( .044 ) Online News .095 * * ( 039 ) .004 ( .052 ) -.014 ( .060 ) -.016 ( .056 ) Social Media News .037 ( .034 ) -.053 ( .045 ) .020 ( .052 ) .043 ( .049 ) Block 5 : Mediator Discussion Frequency = 596 * * * ( 053 ) .286 * * * ( 061 ) .028 ( .069 ) Total R ? 549 629 A57 526 Observations 641 641 641 641 Note . Cell entries are final-entry ordinary least squares ( OLS ) , standardized Beta ( f ) coefficients , standard errors in parentheses ; * p < .05 , * * pn < 01 , * * * p < 001 BURSTING THE FILTER BUBBLE 35 Table 2 Causal Mediation Analyses Discussion Frequency Network Heterogeneity Cross-sectional ” ! Lagged * ? Autoregressive ” B B B Political Attitudes Political Participation Offline 039 .018 002 Political Participation Online .128 * * .059 * * .006 Political Participation Social Media 064 .030 .003 Political Efficacy Internal .033 015 001 Political Interest .096 * * * 046 * * * .004 Political Knowledge -.522 * -.241 * -.023 Political Ideology 044 .020 002 News Media Use Traditional News 104 * * * 048 * * * .005 Online News .093 * .043 * .004 Social Media News 026 012 001 Note . Cell entries are unstandardized coefficients of the Average Causal Mediation Effect ( ACME , indirect effect ) ; nonparametric bootstrap confidence intervals with 1,000 iterations ; * p < .05 , * * p < .01 , * * * p < .001 Political Participation Offline Political Participation Online Political Participation Social Media Political Efficacy ( internal ) Political Interest Political Knowledge Political Ideology Traditional News Use Online News Use Social Media News Use N A Discussion Frequency Network Heterogeneity Figure 1 . Conceptual mediation model of network heterogeneity . ResearchGate See discussions , stats , and author profiles for this publication at : https : //www.researchgate.net/pu blication/36 1264034 Can we blame social media for polarization ? Counter-evidence against filter bubble claims during the COVID-19 pandemic Article in New Media & Society « June 2022 DOL : 10.1177/14614448221099591 CITATIONS READS 0 158 2 authors : aN 4 Mo Jones - Jang Myojung Chung ‘ eh ’ Boston College , USA Northeastern University 56 PUBLICATIONS 2,007 CITATIONS 17 PUBLICATIONS 183 CITATIONS SEE PROFILE SEE PROFILE Some of the authors of this publication are also working on these related projects : Project Nature Climate Change View project Project NEH grant : Evolution in digital discourse : Toward a computational tool for identifying patterns of language change in social media View project All content following this page was uploaded by Mo Jones - Jang on 13 June 2022 . The user has requested enhancement of the downloaded file . ® Check for updates Article new media & society e e 1-20 Can we blame social media © The Author ( s ) 2022 ° ° Article reuse guidelines : for polarization ? Counter- sagepub comvjournals-permission e e DOI : 10.1177/146 1444822109959 | evi d ence agal n st fi Ite r journals.sagepub.com/home/nms @ SAGE bubble claims during the COVID-19 pandemic S Mo Jones-Jang @ ® Boston College , USA Myojung Chung Northeastern University , USA Abstract Although collective efforts are essential to fight COVID-19 , public opinion in the United States is sharply divided by partisan attitudes and health beliefs . Addressing the concern that media use facilitates polarization , this study investigated whether social and traditional media use for COVID-19 information attenuates or reinforces existing disparities . This article focuses on two important areas where the public is highly polarized : partisan affect and vaccine attitudes . Contradicting the filter bubble claim , our survey ( n= 1106 ) revealed that social media use made people less polarized in both partisan affect and vaccine hesitancy . In contrast , traditional media use made people more polarized in partisan affect . These findings corroborate the growing evidence that social media provide diverse viewpoints and incidental learning . Keywords Affective partisan polarization , COVID-19 , polarization , social media , vaccine hesitancy Corresponding author : S Mo Jones-Jang , Department of Communication , Boston College , RM474 , Saint Mary ’ s Hall , Chestnut Hill , MA 02467 , USA . Email : jangsr @ be.edu 2 new media & society 00 ( 0 ) Polarization has been a defining social concern in the United States and other countries for the past several decades ( Iyengar et al. , 2019 ) . Under the COVID-19 crisis , concerns about polarization grow , noting that the pandemic is often politicized and thus exacer- bates group conflicts as well as reinforces existing beliefs ( Bird and Ritter , 2021 ; Green et al. , 2020 ; Hart et al. , 2020 ) . Given that a society ’ s ability to effectively respond to a health crisis depends on citizens ’ united minds and collective behavioral efforts ( Kahan et al. , 2011 ) , partisan conflicts and sharp divisions in health beliefs raise extra hurdles to combat the pandemic ( Pew Research Center , 2020a ) . Some media scholars and social commentators have pointed out that emerging media systems have accelerated opinion polarization , and such concerns are amplified during the COVID-19 pandemic . Amid a rapidly changing novel crisis , people increasingly turn to media outlets for up-to-date information ( Dixon and Clarke , 2013 ) . A recent study found that individuals get information about COVID-19 from fragmented media sources and such different media uses led to divergent perceptions and behaviors related to the pandemic ( Chung and Jones-Jang , 2021 ) . Among the diverse media sources , we have a particular interest in the role of social media in polarization during the COVID-19 pandemic . The literature has presented con- tinuous concerns about the link between social media use and polarization ( Bakshy et al. , 2015 ; Pariser , 2011 ; Stroud , 2011 ) . For instance , earlier research has suggested that homogeneous networks or algorithmic decisions based on past online activities may cre- ate filter bubbles or echo chambers where citizens ’ existing attitudes tend to be rein- forced without hearing the other side ( Bennett and Iyengar , 2008 ; Pariser , 2011 ; Stroud , 2011 ) . While these earlier concerns still stand during the COVID-19 pandemic where politicized and unverified misinformation about health issues spreads among like- minded networks , researchers began to call for a more nuanced approach . For example , recent empirical evidence suggests that social media allow users to learn diverse view- points through incidental exposure and that algorithm-driven filter bubble claims are somewhat exaggerated ( Bakshy et al. , 2015 ; Beam et al. , 2018 ; Lee and Xenos , 2022 ; Lu and Lee , 2019 ; Nanz and Matthes , 2020 ; Weeks et al. , 2017 ) . Other studies also ques- tioned the differential role of diverse social media platforms in contributing to polariza- tion ( e.g . Cinelli et al. , 2020 ; Yarchi et al. , 2021 ) . As such inconsistent views warrant further investigation in this line of research , the current study aims to clarify whether social media use indeed amplifies polarization dur- ing the COVID-19 pandemic . To set a comparison point for the role of social media use in polarization , this study also examines the ( de ) polarizing role of traditional media . Traditional media outlets such as TV , cable channels , radio , and newspapers may convey more politically tinged , one-sided views than social media where at least some friends and followers display diverse political spectrums . By exploring these two media plat- forms , we can elucidate the unique role of different information sources . This article addresses this matter in two contexts : affective partisan polarization and vaccine hesi- tancy . Note that the former embraces more long-standing and abstract-level attitudes , but the latter taps into more concrete and behavior-oriented attitudes that are constructed responding to the specific social situation . By looking at two related but distinct-level realms , we seek to provide increasing confidence in the interpretation of our reported findings . In addition , two areas suffer from growing public divide . Defined as Jones-Jang and Chung 3 the tendency of partisans to dislike , distrust , and discriminate against people from the opposite party , affective partisan polarization poses a significant threat to collective pub- lic health efforts , including the response to the COVID-19 ( Druckman et al. , 2020 ) . At the same time , citizens ’ attitudes toward the COVID-19 vaccines are also severely divided ( Grenier , 2020 ) , presenting impending challenges to vaccination programs . Using a national survey in the United States ( 1 =1106 ) , this article contributes to the literature in several aspects . First , we provide meaningful evidence that can speak to the hotly debated topic—whether social media use adds more to the ongoing opinion polari- zation . Second , this article distinguishes the roles of social media and traditional media in polarization over the COVID-19 crisis . By investigating these two media separately , we attribute our findings to the unique role of each media , not to the increasing exposure to information about COVID-19 in general . Third , while prior studies have focused on a single issue to examine polarization ( Druckman et al. , 2020 ; Hart et al. , 2020 ) , we aim to increase confidence in the interpretation of our findings by presenting two analyses in different domains , affective partisan polarization and vaccine attitudes , both of which suffer from deepening public cleavage during COVID-19 . Literature review Attitude reinforcement hypothesis versus counterclaims As the digital media environment has increased the audience ’ s control and choice over media content , selective exposure research has garnered enormous attention over the past two decades . Some researchers declared a new era of minimal effects ( Bennett and Iyengar , 2008 ) , indicating that selective media exposure to agreeable views will lead to attitude reinforcement without producing sizable attitude change . Research indicates that exposure to like-minded views reinforces existing attitudes , resulting in greater polariza- tion ( Dylko et al. , 2018 ; Stroud , 2011 ) . Concerns have suggested that such an imbal- anced media diet harms deliberative democracy , facilitating lack of tolerance and open minds at the individual level as well as polarization and fragmentation at the society level ( Bennett and Iyegnar , 2008 ; Shin , 2020 ; Stroud , 2011 ) . Analyzing large-scale Facebook digital trace data , Facebook researchers ( Bakshy et al. , 2015 ) examined the extent to which users encounter attitude-consistent or counter- attitudinal views . The study identified three mechanisms that facilitate selective expo- sure , including individual choice , homogeneous networks , and algorithmic decisions . However , there have been contrasting views regarding each mechanism ; while many scholars supported the attitude reinforcement hypothesis , other media researchers have pushed back against the notion of echo chambers and filter bubbles , calling for a more sophisticated approach to examine the role social media plays in terms of polarization . The first point of debate is whether people make conscious choices for pro-attitu- dinal content . Some studies suggest that individuals selectively choose attitude-con- sistent content to avoid potential cognitive discomfort and to maintain self-esteem or social identities Jang , 2014 ; Knobloch-Westerwick , 2012 ) . The reinforcing spirals model proposes that media effects and selection mutually influence each other and create reinforcing spirals over time ( Slater , 2015 ) . The model suggests that the 4 new media & society 00 ( 0 ) reinforcing processes are notably accelerated in the presence of social change , con- flict , and salient identity cues . However , other studies argued that users do not always avoid counter-attitudinal information ( e.g . Garrett et al. , 2013 ) . Evidence also suggests that the selection of media content is determined by many other factors besides the similarity between users ’ exist- ing views and media content . Survey data from 12 countries show that digital informa- tion consumption is not primarily driven by ideological consistency but by other historical , economic , and political factors ( Fletcher et al. , 2020 ) . In a similar vein , users obtaining news from Facebook were more likely to be exposed to both pro- and counter- attitudinal information , eventually resulting in decreased polarization ( Beam et al. , 2018 ) . Moreover , other content features such as social metrics ( i.e . number of likes or shares ) or information utility are known to function as powerful cues that override ideo- logical preferences ( Chung , 2017 ; Messing and Westwood , 2014 ) . The next competing arguments are about whether people compose largely homogene- ous networks on social media . Research found that the user network is the most powerful driver limiting cross-cutting exposure ( Bakshy et al. , 2015 ) . According to this study , the likelihood of cross-cutting exposure on social media is substantially reduced from 45 % to 24 % ( liberals ) and from 40 % to 35 % ( conservatives ) due to their homogeneous net- works compared to random networks . Another line of research indicated that to maintain popularity on social media , users tend to engage in politically safe discussions with like- minded individuals ( Miller et al. , 2015 ) . However , a different line of research indicates that users in the current informa- tion environment are afforded increasing opportunities to encounter diverse view- points ( Beam et al. , 2018 ; Kobayashi , 2020 ; Lu and Lee , 2019 ) . Studies found that Facebook users do not typically choose friends based on their political similarity ( Kim and Lee , 2016 ) , and at least 20 % of users ’ networks display opposite political identities ( Bakshy et al. , 2015 ) . Given that social media users often have hundreds of friends online , it is hard to assume that their social networks fully consist of ideo- logically homogeneous users . Furthermore , other scholars posited that social media platforms are distinct in their features/affordances and thus may facilitate or inhibit cross-cutting exposure to varying degrees . For instance , Facebook may offer fewer opportunities for cross-cutting expo- sure than other social media platforms given its heavy reliance on users ’ self-curated social networks and the algorithm that prioritizes congenial content ( Nahon , 2016 ) . Proposing the “ expression , news , and discussion ( END ) ” model , Settle ( 2018 ) explained how specific affordances of Facebook ( e.g . political content presentation , identity main- tenance design , social feedback ) are associated with political polarization . In contrast , on Twitter or YouTube , users can follow accounts without joining a community and interact with users who are not in their network of friends and peers ( Yarchi et al. , 2021 ) . The third debated point is whether social media algorithms exclude counter-attitudinal information . With the advent of social media , some researchers provide platform-driven explanations for the mechanism of selective exposure . For example , a recent experiment found that YouTube algorithms recommend videos that reinforce viewers ’ existing politi- cal opinion ( Cho et al. , 2020 ) . This approach stresses the role of social and algorithmic filters through which social media curates information to users . Overall , this approach Jones-Jang and Chung 5 views the current media environment as fostering polarization by creating a filter bubble where people live in their own personalized world without having to interact with people with different views ( Pariser , 2011 ) . In contrast , other studies suggest that algorithms may present a broader range of per- spectives as compared to when users actively select information ( Bakshy et al. , 2015 ) . This view highlights the possibility of incidental learning , whereby social media users happen to be exposed to fresh or opposite ideas posted by other users or fed by algorith- mic filters ( Nelson and Webster , 2017 ; Yamamoto and Morey , 2019 ) . Exposure to a wider range of opinions is related to weaker attitudes or attitudinal ambivalence ( Hmielowski et al. , 2017 ) . The mechanism of incidental learning largely relies on social media users ’ passive information consumption . One report on social media use indicates that users often obtain information not through active information-seeking but through clicks while “ doing other things ” online ( Gottfried and Shearer , 2016 ) . Similarly , researchers suggest that the multitasking nature of online behavior fosters passive infor- mation consumption . Evidence shows that multitaskers do not have sufficient cognitive resources to selectively seek out attitude-consistent information and avoid attitude- challenging information ( Jang , 2014 ) . Affective partisan polarization Affective partisan polarization , commonly referred to as hostility toward political out- groups , 1s conceptually rooted in social identity theory . The theory posits that individuals consider themselves representative members of broad social , cultural , and political groups ( Tajfel et al. , 1979 ) . Party identification , typically categorized as Democrat or Republican in the United States , has functioned as a key group identity associated with a host of attitudinal and behavioral consequences ( Iyengar et al. , 2019 ; Mason , 2018 ) . When citizens identify with a party , they automatically categorize people , values , and ideas into us ( in-group ) against them ( out-group ) , accompanied by positive or negative feelings . Affective partisan polarization is commonly conceptualized and operational- ized as the gap between positive feelings toward individuals ’ preferred parties and nega- tive feelings toward their opposing party ( Druckman et al. , 2020 ) . Before our primary investigation regarding the role of the media , we hypothesize that the degree of affective partisan polarization depends on individuals ’ political identities . Thus , this study antici- pates that those with stronger liberal ( conservative ) views are more likely to exhibit stronger favoritism toward Democrats ( Republicans ) and hostility toward Republicans ( Democrats ) . H1 : Political identities will lead to in-group and out-group partisan bias ( affective polarization ) . Although antagonism between the two political groups in the United States is nothing new , concerns have mounted that affective polarization worsened during the COVID-19 pandemic ( Druckman et al. , 2020 ; Iyengar et al. , 2019 ) . Prior research showed that when feeling threatened by emerging rival ideologies or conflicting external events , partisans 6 new media & society 00 ( 0 ) tend to consolidate their collective identity through selective exposure ( Esses et al. , 2002 ; Slater , 2015 ) . Some scholars assert that social media in particular have become a battleground for such partisan echo chambers during this pandemic ( Uscinski et al. , 2020 ) . For example , a series of conspiracy theories such as COVID-19 being a ploy to defeat Donald Trump in the 2020 presidential election or to control society have been widely circulated among conservative social media users . In such a setting , social media use may reinforce existing partisan sentiment and thus amplify hostility toward political opponents . However , other scholars argue that greater use of social media is not necessarily associated with faster growth in partisan polarization . For instance , Boxell et al . ( 2017 ) found a greater increase in polarization among the groups who are less likely to use social media ( e.g . older than 65 ) , implying a limited role of social media in explaining political polarization . Furthermore , a recent experimental study found that social information exchange in an egalitarian network makes partisans /ess polarized ( Becker et al. , 2019 ) . The finding suggests that in an egalitarian social network where new ideas and opinions can emerge from anyone in the group , partisans tend to adopt a moderate opinion . Other research also showed that users relying on Facebook for news tended to be exposed to cross-cutting views and show less extreme views ( Beam et al. , 2018 ) . Here , social media provide users with opportunities for incidental learn- ing ( Nelson and Webster , 2017 ) . In this light , we focus on the moderating role of social media use in affective polariza- tion by investigating whether the proposed relationship in H1 between political identities and affective polarization becomes strengthened or weakened as social media use increases . As the literature provides strong theoretical reasonings for both arguments , we present two competing hypotheses as H2a and H2b . H2a : Social media use for COVID-19 information will reinforce the relationship between political identities and affective partisan polarization ( H1 ) . H2b : Social media use for COVID-19 information will weaken the relationship between political identities and affective partisan polarization ( H1 ) . To set a comparison point for the role of social media use in affective polarization , this study also examines the ( de ) polarizing role of traditional media . Without examining the role of traditional media , it is difficult to disentangle whether social media use or the quantity of information about COVID-19 is the factor that facilitates affective polarization . Some argue that traditional media would not trigger affective polarization because the content selection and publication would show a less partisan slant due to the journalistic norm of objectivity ( Harcup and O ’ Neill , 2017 ; Phillips , 2015 ) . However , others claim that such journalistic values are less pronounced in the current media landscape where partisan content is known to attract a larger audience ( Hamilton , 2004 ) . A recent study found that conservative media reported numerous rumors and conspiracy theories about COVID-19 in an attempt to underestimate the pandemic and undermine efforts to prop- erly address the risk ( Jamieson and Albarracin , 2020 ) . As these contrasting views about Jones-Jang and Chung 7 the role of traditional media have relatively insufficient theoretical frameworks , we ask the following research question : RQI1 : Does traditional media use for COVID-19 information strengthen or weaken the relationship between political identities and affective polarization ? Divides in vaccine attitudes Citizens ’ attitudes toward the COVID-19 vaccines have been severely polarized , with growing divisions between those who long for the vaccines and those who do not ( Grenier , 2020 ) . What mainly drives such divides is antivaccine sentiments that have been around since the UK doctor Andrew Wakefield proposed links between MMR ( measles , mumps , and rubella ) vaccinations and autism in the 1990s . Extending their existing distrust in MMR vaccines , anti-vaxxers have promulgated various rumors and conspiracy theories about COVID-19 vaccines ( Wallis , 2020 ) . False claims such as COVID-19 vaccination being used to implant a microchip to track people or that RNA- based vaccines will alter a recipient ’ s DNA are just a few examples . Antivaccine senti- ments could have lethal consequences , as the efficacy of the vaccine is contingent on widespread and timely vaccination . As in the case of affective polarization , we aim to examine how divided vaccine atti- tudes are reinforced or weakened depending on the use of social and traditional media . To do so , we need to establish a reasonable cognitive link as a baseline relationship in the vaccine context . While there could be a variety of factors contributing to vaccine atti- tudes , a central tenet of antivaccine sentiments has long been a misguided belief that MMR vaccinations cause autism ( Salmon et al. , 2015 ; Smith and Graham , 2019 ) . Thus , we decided to use the cognitive link between prior misguided vaccine beliefs and cur- rent/future vaccine hesitancy as a target relationship . One thing to note is that we did not make the link specifically about COVID-19 ( e.g . misbeliefs about COVID-19 vaccines ) for a reason . Although numerous false claims about COVID-19 vaccines have emerged , most of them remain as mere misinformation or rumors . There has been no empirical evidence that misbeliefs about COVID-19 vac- cines shape vaccine hesitancy . Rather , scholars have indicated that a misguided belief about MMR vaccinations and autism has served as one of the most visible causes of vaccine hesitancy ( McKeever et al. , 2016 ; Salmon et al. , 2015 ; Smith and Graham , 2019 ) . Taken together , we expect that those who hold stronger misbeliefs about the link between vaccines and autism are more likely to show vaccine hesitancy in general . This cognitive link will serve as a baseline relationship that is either strengthened or weak- ened through media use during the pandemic . H3 : Misbeliefs about the link between vaccines and autism lead to vaccine hesitancy . Supposing that existing vaccine misbeliefs are an important factor in predicting COVID-19 vaccine hesitancy ( Reynolds , 2020 ) , two opposite predictions can emerge 8 new media & society 00 ( 0 ) concerning how people ’ s attitudes toward vaccines change when confronting the circum- stances of the pandemic . On the one hand , the unprecedented timescale of vaccine devel- opment and production may further fuel vaccine hesitancy among those who already hold mistrust in vaccines . Anti-vaxxers assert that a rushed vaccine would be improperly tested and thus have safety issues ( Riviére , 2020 ) . On the other hand , as public fear has grown with increasing death tolls of COVID-19 and vaccines have been eagerly antici- pated as the most effective way to end the pandemic , those who once rejected vaccines may reconsider their stance ( Reynolds , 2020 ) . Admitting these two possible scenarios , we focus on how social and traditional media play different roles in the processes . Vaccine opponents have an outsized presence on social media ( Jang et al. , 2019 ; Smith and Graham , 2019 ) and actively spread fears about COVID- 19 vaccines . For example , soon after the approval of Pfizer/BioNTech ’ s COVID-19 vac- cine in the United Kingdom , anti-vaxxers on social media paralleled the vaccine to thalidomide , which resulted in thousands of birth defects in the 1960s ( Dupuy , 2020 ) . Such antivaccine arguments can be amplified by bots and state-sponsored trolls ( Broniatowski etal. , 2018 ) . This may place vaccine opponents in an echo chamber , leading them to believe ina false consensus and reinforcing their pre-existing vaccine attitudes . However , another notable trend is the movement of provaccine counterparts on social media . For example , on Twitter , many people are putting energy into debunking or refut- ing antivaccine claims ( Burki , 2020 ) , if not directly promoting COVID-19 vaccines . These actions are distinguishable from previous vaccine debates in which vaccine propo- nents were not visible on social media ( McKeever et al. , 2016 ) . The balance between antivaccine and provaccine information on social media may help anti-vaxxers correct their misunderstanding about the vaccine and be less concerned about it . As in the con- text of affective partisan polarization , contrasting views about the role of social media show strong theoretical claims . Hence , we present two competing hypotheses . H4a : Social media use for COVID-19 information will reinforce the relationship between misguided vaccine beliefs and vaccine hesitancy ( H3 ) . H4b : Social media use for COVID-19 information will weaken the relationship between misguided vaccine beliefs and vaccine hesitancy ( H3 ) . There could be similar contrasting expectations for the role of traditional media . On the one hand , media coverage of COVID-19 vaccines may not be particularly polarized given the important role of the vaccine in ending the pandemic . For instance , although antivaccine sentiments are often associated with conservative stances ( Jamison et al. , 2020 ) , major conservative media covered leading Republican figures ’ ( e.g . Mike Pence ) COVID-19 vaccination , which was aimed to boost public confidence in the safety of vaccines . On the other hand , conservative media have consistently created doubts about the vaccine and frequently spotlighted isolated adverse reactions to the vaccine without much context ( Darcy , 2020 ) . In this light , we propose the following research question : RQ2 : Does traditional media use for COVID-19 information strengthen or weaken the relationship between misguided vaccine beliefs and vaccine hesitancy ? Jones-Jang and Chung 9 Method Participants This study relied on a national survey conducted in the United States . A total of 1106 online panels from the research company Dynata participated in the survey . Using the stratified quota , this study sample mirrors the US population as reported by the 2017 American Community Survey ( ACS ; American Community Survey , 2017 ) . The median age was 44.4 in this study and 46.7 in the 2017 ACS . Our sample included 52.9 % female participants , while 51.4 % of the ACS sample was female . The median income category in this study was US $ 50,000-US $ 74,999 , and the 2017 ACS reported US $ 57,652 as the median income . The median education level in our study was “ 2-year college degree including current students , ” which was similar to the “ some college , no degree ” in the ACS survey . Although the debate about nonprobability national sampling is still underway , the literature indicates that survey results are largely identical in nonprobability panel data and representative population samples ( for a review of the validity of online panels , see Callegaro et al. , 2014 ) . The respondents were asked to complete an online questionnaire to measure their media use for COVID-19 information , in-group/out-group affect , politi- cal identities , vaccine beliefs , vaccine hesitancy , and demographic information . The sur- vey and sampling procedure was approved by the Institutional Review Board of the researcher ’ s institute . Measures Affective polarization . We used an established measure of affective polarization , which was calculated as the difference between the feeling thermometer scales for Republicans and Democrats ( see Haddock et al. , 1993 ) . Respondents were asked to rate their overall feelings toward Republicans and Democrats on a scale ranging from 0 to 100 . We then subtracted the thermometer score for Republicans from that for Democrats ( Af=6.30 , SD=56.40 , range=—100 to 100 ) . It should be noted that high levels of polarization should be represented by the values close to —100 and close to 100 , whereas values around 0 should indicate low levels of polarization . Political identities . Political identities were assessed on a 7-point scale ranging from 1=Fery conservative , 7 = Very liberal , M=3.78 , SD=1.74 ) . Vaccine hesitancy . We measured vaccine hesitancy through two Likert-type scale items : “ T am concerned about serious adverse effects about vaccines , ” “ I intend to receive any vaccination that my health care provider recommends in the future ” ( reverse coded ; 1=Strongly disagree , 5=Strongly agree ; M=2.60 , SD=1.17 , r=.65 ) . Misguided vaccine beliefs . We measured respondents ’ pre-existing vaccine beliefs about vaccine and autism using two items adapted from the literature ( Jones-Jang and Noland , 2022 ) . As most anti-vaxxers before the COVID-19 pandemic have focused on child vac- cine risks related to autism , we assessed respondents ’ perceived vaccine risks about 10 new media & society 00 ( 0 ) autism ( Salmon et al. , 2015 ) “ Vaccines can cause autism ” and “ Vaccines can increase the risk of developing autism ” ( 1 =Strongly disagree , 5 = Strongly agree ; M=2.21 , SD=1.21 , r=.84 ) . Social media use . Respondents were asked , “ How often have you used social media ( e.g . Facebook , Twitter , Instagram , and YouTube ) to get information about Coronavirus ? ” ( 1=Never , 5= Very often ; M=2.75 , SD=1.52 ) . We also measured the use of individual social media platforms ( Facebook , Twitter , Instagram , and YouTube ) separately and ran analyses with them . Since the results of our moderation analyses were almost identical across platforms , we did not include individual results in this article . Traditional media use for COVID-19 . Respondents were asked , “ How often have you used national TV , radio , and/or newspapers to get information about Coronavirus ? ” ( 1 =Never , 5=Very often ; M=3.43 , SD=1.36 ) . Results Analytic approach This study employed a bootstrapping approach with the PROCESS macro for our pri- mary investigations ( Hayes , 2017 ) . As we tested the model with two moderating varia- bles , we employed Model 2 for our moderation analyses . As our investigation tapped into two domains , we ran separate analyses for each . Political identity and vaccine beliefs were entered as independent variables , and affective polarization and vaccine hesitancy were entered as outcome variables . Media use variables ( 1.e . social media and traditional media use for COVID-19 information ) were included as two moderators . We are particu- larly interested in whether the slope of existing links ( e.g . relationship between political identity and affective polarization ) becomes steeper or flattened among heavy social/ traditional media users . Steeper slopes indicate the reinforcement of existing cognitive links , and flattened slopes indicate moderated cognitive links . The analysis controlled for age , gender , education , household income ( for all hypotheses and RQs ) , and political identities ( only for H3 , H4a-b , and RQ2 ) . Hypothesis tests This study first hypothesized that individuals show affective polarization based on their political identities ( H1 ) . That is , those with stronger liberal ( conservative ) views are more likely to exhibit stronger favoritism toward Democrats ( Republicans ) and hostility toward Republicans ( Democrats ) . We then examine whether these partisan biases are strengthened or weakened through social media and traditional media use for COVID-19 information ( H2a , H2b , and RQ1 ) . We also hypothesized that individuals ’ existing mis- guided vaccine beliefs predict their vaccine hesitancy ( H3 ) and explored whether social media and traditional media uses reinforce or weaken the link ( H4a , H4b , and RQ2 ) . The results are summarized in Table 1 . Jones-Jang and Chung II Table I . Predicting affective polarization and vaccine hesitancy Affective polarization Vaccine hesitancy Predictors b SE pvalue b SE p value Age -0.12 0.09 A9 -0.00 0.00 06 Gender ( Female= high ) 542 2.73 04 0.05 0.06 36 Education 2.69 1.35 04 0.03 0.03 36 Household income 2.21 0.76 .00 -0.02 0.02 24 Social media use 13.21 2.27 .00 0.15 0.04 .00 Traditional media use 2.44 2.35 30 -0.04 0.04 36 Political identity ( Liberal = high ) 22.57 2.27 .00 -0.04 0.02 02 Political identity < social media 3.37 ) 0.51 .00 Political identity < traditional media 162 0.54 .00 Vaccine belief 0.61 0.07 .00 Vaccine belief X social media -0.03 0.02 .04 Vaccine belief X traditional media 0.01 0.02 9 R ? = 40 R ? =.42 The dependent variable ( affective polarization ) was calculated by the difference of feeling thermometers ( subtraction of Republicans from Democrats ) . Thus , higher scores in DV indicate a greater amount of favor- itism of Democrats over Republicans . SE : standard error . Confirming our expectation ( H1 ) , the results show that individuals show strong affec- tive polarization based on their political identities after controlling for age , gender , edu- cation , and household income . In a nutshell , the stronger individuals ’ political identities , the greater their in-group/out-group affect differences ( i.e . affective polarization , b=22.57 , SE=2.27 , p < .001 ) . Next , in addressing the polarizing or depolarizing role of media use on COVID-19 , we investigated the statistical significance of two interaction terms , political identities < social media use and political identities < traditional media use . The results indicate that both interaction terms were significant but in opposite directions . Supporting H2b but rejecting H2a , social media use for the COVID-19 weak- ens the relationship between political identities and affective partisan polarization ( b=-3.37 , SE=0.51 , p < .001 ) . Figure 1 on the left illustrates this pattern , showing that the slope is significantly steeper among light social media users than among heavy social media users for COVID-19 . In contrast , traditional media use amplifies the relationship ( b=1.62 , SE=0.54 , p=.003 ) . As seen in Figure | on the right , heavy traditional media users display more affective partisan polarization based on their political identities than light traditional media users . We found similar results for the vaccine data . The results show that individuals express vaccine hesitancy based on their pre-existing vaccine beliefs after controlling for age , gender , education , household income , and political identities . The stronger one ’ s belief in the link between vaccination and autism , the stronger one ’ s resistance to vac- cines ( b=.61 , SE=.07 , p < .001 ) . Thus , H3 was supported . In exploring the moderating role of social media ( H4a and H4b ) , the results suggest that the interaction term of vac- cine belief and social media is significant ( 6=~—.03 , SE=.02 , p=.04 ) , which supported 12 new media & society 00 ( 0 ) —lLowSM ——Medium SM High SM —LowTM —Medium TM High TM Affective Partisan Polarization Affective Partisan Polarization Conservative Liberal Conservative Liberal ( M- SD ) ( M+ SD ) ( M- SD ) ( M+ SD ) Figure I . Predicting affective polarization by social media ( SM ) and traditional media ( TM ) . Steep slopes indicate the reinforcement of existing cognitive bias , but flattened slopes indicate the weak- ened cognitive link . For example , slopes grow steeper among low social media ( left ) and high traditional media use ( right ) . Low , medium , and high media use was classified based on the Mean , Mean - | SD , and Mean + | SD . —LowSM -——MediumSM High SM —LowTM —MediumTM -High TM 3.5 358 3 3 E g £ £ = 25 mB 25 wo vo = = £2 2 2 & - 15 bal 15 1 1 Low ( M - SD ) High ( M + SD ) Low ( M - SD ) High ( M + SD ) Vaccine Belief About Autism Vaccine Belief About Autism Figure 2 . Predicting vaccine hesitancy by social media ( SM ) and traditional media ( TM ) . H4b but rejected H4a . Figure 2 on the left illustrates this relationship . In contrast , as shown in Figure 2 on the right , the interaction term with vaccine belief and traditional media ( b=.01 , SE=.02 , p=.49 ) was not significant . Discussion In light of heightened concern that social media use during the COVID-19 pandemic is further sharpening public division ( Druckman et al. , 2020 ; Hart et al. , 2020 ; Pew Research Center , 2020a ) , this study examined whether social media use is associated with the polarization process by strengthening individuals ’ existing cognitive links . We Jones-Jang and Chung 13 also examined the role of traditional media in making it comparable to the role of social media . We used two existing cognitive links as baseline tendencies that could be related to media use . The first link indicates the well-known political tendency that individuals discriminate against outgroups based on their political identities ( affective partisan polarization ) . Another link is that individuals with misguided beliefs about the effect of MMR vaccines on autism are more likely to show vaccine hesitancy . While these two links represent baseline tendencies based on pre-existing beliefs , the domains have prac- tical importance . The public divide in the two domains can significantly harm efforts against the current pandemic . We then examined the moderating role of social media in these relationships . Contrary to prior claims that social media should be blamed for polarization in society ( Pariser , 2011 ; Stroud , 2011 ) , our results show that the link between political identities and affec- tive partisan polarization weakens as social media use for COVID-19 information increases . Similarly , the link between misguided beliefs about child vaccines and vaccine hesitancy weakens as social media use for COVID-19 information increases . These find- ings highlight the positive aspect of social media use , supporting the claim that ideologi- cal segregation on social media is “ overestimated ” ( Barbera et al. , 2015 : 1531 ) . Although our survey data did not allow us to specify the mechanism through which social media weaken the existing cognitive link , it is worth addressing possible mecha- nisms for future research . The extant literature offers three possible explanations . First , incidental exposure to diverse information on social media alleviates attitude reinforce- ment and polarization in online communication ( Lu and Lee , 2019 ; Nelson and Webster , 2017 ) . Studies indicate that social media users come across news incidentally while “ online doing other things ” ( Gottfried and Shearer , 2016 : 6 ) . Recent research shows that users report significant learning outcomes through incidental exposure to political news ( Nanz and Matthes , 2020 ) . The findings suggest that once incidentally encountered information is found to be relevant , users engage in effortful information processing . Incidental exposure to unexpected information may thus have depolarizing outcomes . Second , in deciding to click and learn information on social media , users may prior- itize other information over the ( mis ) match between media content and users ’ existing beliefs . For example , research has shown that social media users rely more on social cues , such as the number of likes and comments than the political affinity of information ( Chung , 2017 ; Messing and Westwood , 2014 ) . In addition , other researchers theorize that individuals are hardwired to pay attention to information that challenges rather than supports their views when evaluating potential risk ( Jang , 2014 ; Shoemaker , 1996 ) . Hence , individuals may be significantly attracted to new , unusual information in select- ing information about COVID-19 or vaccines . Even when the new information conflicts with their existing beliefs about ideologies or vaccines , individuals may seek wider exposure out of a need to reassess the present danger . Finally , it is likely that information presented by algorithms provides a wider range of viewpoints than information actively selected by users ( Bakshy et al. , 2015 ) . A large- scale study using Facebook digital trace data concludes that like-minded exposure occurs mostly due to users ’ psychological orientation to avoid different views , but cross-cutting exposure is widely available through algorithms ( Bakshy et al. , 2015 ) . This study also l4 new media & society 00 ( 0 ) suggests that users ’ social networks are not as homogeneous as we think . Although our findings can not further explicate the underlying mechanism of how social media use mitigates polarization , these possibilities deserve further investigation for a better under- standing of the depolarizing effect of social media during the COVID-19 pandemic . Although our results in both the political and health domains consistently showed the potential depolarizing role of social media , some may argue that this is not because peo- ple get information about COVID-19 from social media , but because they receive more information about COVID-19 regardless of the media platforms . To reject this possibil- ity , we also examined the ( de ) polarizing role of traditional media . If the amount of infor- mation matters , not the platforms , both social and traditional media uses regarding COVID-19 should have shown the same directional pattern . However , we found oppo- site roles in the two media . According to our analyses , social media weakened the cogni- tive link in both domains , but traditional media either strengthened the link ( in affective partisan polarization ) or had no impact ( in vaccine hesitancy ) . It is worth noting that the use of traditional media for COVID-19 information acceler- ates affective partisan polarization . It is possible that traditional media users tend to be frequent customers of specific partisan news outlets . As these partisan media outlets increasingly convey politically tinged information and opinions , the habitual use of these outlets may reinforce in-group favoritism and out-group hostility ( Lelkes et al. , 2017 ; Stroud , 2011 ) . In media use practice , social media users may encounter diverse views more easily on one media platform , but it could be more difficult for traditional media users to obtain information across multiple channels representing a wide range of politi- cal spectrum . Nevertheless , we did not find a polarizing role of traditional media in the context of vaccine hesitancy . This nonfinding in the vaccine context may be attributed to the pos- sibility that traditional media or even partisan sources do not promote consistent posi- tions on vaccines . For example , while liberals in general tend to be more favorable toward vaccination than conservatives , Vice President-Elect Kamala Harris questioned vaccine safety during the presidential campaign ( Kelly , 2020 ) . As political elites and partisan media do not signal crystallized , consistent opinions about vaccine issues , it may be difficult to expect to see the significant role of traditional media one way or the other . This study offers important practical implications for combating the pandemic . While the partisan division and polemic views on vaccines pose substantial obstacles to efforts to end the pandemic , our findings suggest that social media may function as an effective tool to mitigate such divisions ( Centers for Disease Control and Prevention [ CDC ] , 2021 ; Pew Research Center , 2020a ) . The message to take away from this study is thus positive , particularly given citizens ’ increasing reliance on social media for political and health information ( Pew Research Center , 2016 ) . Taking advantage of this finding , governments , health organizations , and social media practitioners should consider how their social media agendas ( e.g . vaccination programs ) can attract dis- senters ’ attention . As social media exposure typically occurs through spontaneous and incidental clicking behaviors , it may be helpful to use social and recommendation cues that increase the perceived credibility of the message ( Chung , 2017 ; Messing and Westwood , 2014 ) . Jones-Jang and Chung 15 Several limitations of this study should be noted . First , although the consistent results of the social media ’ s depolarizing role in the two domains increase the generalizability of the findings , it is still questionable whether the findings are generalizable to contexts outside the United States . Some expressed concerns that the United States may be an extreme case where media and public opinion are overly polarized ( Bos et al. , 2016 ; Kubin and von Sikorski , 2021 ) . Second , although we review possible explanations of social media ’ s ( de ) polarizing role , our survey data did not allow us to pinpoint specific working mechanisms . Previously , Bakshy et al . ( 2015 ) who had access to Facebook big data reported that the Facebook algorithm was not the primary factor of echo chamber . Similarly , Yarchi et al. ’ s ( 2021 ) research looked at the degree of polarization across social media platforms and unexpectedly found that Twitter showed a greater level of polarization than Facebook . However , the study was not able to disentangle the primary causal mechanism of such polarization as well . As it is challenging to distinctively measure incidental exposure and exposure based on algorithms through self-reported data , future research using digital trace data should examine this issue . Third , although we believe that our findings illustrate important snapshots about the ( de ) polarizing role of social media , the cross-sectional analysis does not allow us to rule out the possibility of a reverse-direction influence such that the reinforcement of exist- ing relationships ( e.g . deepening affective partisan polarization ) may decrease the moti- vation to use social media . While we do not rule out this possibility , there has been little research or theory to support this claim so far . On the contrary , arecent work ( Osmundsen et al. , 2021 ) , which analyzed both social media behavioral data and self-reported data , concluded that partisan polarization ( in the United States ) was the primary psychologi- cal motivation behind information sharing ( both real and fake news ) on social media . Thus , although our data can not directly demonstrate causal directions , our findings combined with other literature may suggest that one way is more plausible than the other way round . Future efforts should include long-term data to draw increasing causal inferences . Finally , we measured pre-existing vaccine beliefs related to autism as an anchor point to test our second set of hypotheses , because most prior anti-vaccine movements have been rooted in such misguided beliefs . However , some people , especially nonparents , may possess misguided vaccine beliefs not based on child vaccines but from something else . Future research should incorporate broader factors that shape vaccine beliefs . Conclusion While partisan polarization has reached high-level records ( Pew Research Center , 2019 ) , there are concerns that media use and presentation of the COVID-19 pandemic may aggravate polarization . Responding to this concern , this study examined the role of media in strengthening or weakening existing cognitive links . The findings indicate that social media do not aggravate but alleviate polarization in both contexts , including par- tisan polarization and vaccine hesitancy . These are at odds with earlier filter bubbles or echo chamber claims that social media exacerbate intergroup relations and attitude rein- forcement ( Pariser , 2011 ; Stroud , 2011 ) . Given that social media outlets function as 16 new media & society 00 ( 0 ) important channels through which many people get information about COVID-19 ( Pew Research Center , 2020b ) or future health crises , these findings offer some relief to those concerned with increasing polarization surrounding public health issues . This study also has practical implications : If managed well , social media could be an effective tool for government or health organizations to reach a wide range of audiences for unbiased edu- cation or communication during health crisis . Declaration of conflicting interests The author ( s ) declared no potential conflicts of interest with respect to the research , authorship , and/or publication of this article . Funding The author ( s ) received no financial support for the research , authorship , and/or publication of this article . ORCID iD S Mo Jones-Jang ( [ 5 ) https : //orcid.org/0000-0003-3935-7421 References American Community Survey ( 2017 ) Comparing 2017 American community survey data . Available at : https : //www.census.gov/programs-surveys/acs/guidance/comparing-acs- data/2017.html Bakshy E , Messing S and Adamic LA ( 2015 ) Exposure to ideologically diverse news and opinion on Facebook . Science 348 ( 6239 ) : 1130-1132 . Barbera P , Jost JT , Nagler J , et al . ( 2015 ) Tweeting from left to right . Psychological Science 26 ( 10 ) : 1531-1542 . Beam MA , Hutchens MJ and Hmielowski JD ( 2018 ) Facebook news and ( de ) polarization : reinforcing spirals in the 2016 US election . Information , Communication & Society 21 ( 7 ) : 940-958 . Becker J , Porter E and Centola D ( 2019 ) The wisdom of partisan crowds . Proceedings of the National Academy of Sciences 116 ( 22 ) : 10717-10722 . Bennett WL and Iyengar S ( 2008 ) A new era of minimal effects ? The changing foundations of political communication . Journal of Communication 58 : 707-731 . Bird R and Ritter Z ( 2021 ) Is the media creating division on Covid-19 health practices ? Gallup . Available at : https : //news.gallup.com/poll/3 12749/media-creating-division-covid-health- practices.aspx Bos L , Kruikemeier S and De Vreese C ( 2016 ) Nation binding : how public service broadcasting mitigates political selective exposure . PLoS ONE 11 ( 5 ) : 0155112 . Boxell L , Gentzkow M and Shapiro JM ( 2017 ) Greater Internet use is not associated with faster growth in political polarization among US demographic groups . Proceedings of the National Academy of Sciences 114 ( 40 ) : 10612-10617 . Broniatowski DA , Jamison AM , Qi S , et al . ( 2018 ) Weaponized health communication : Twitter bots and Russian trolls amplify the vaccine debate . American Journal of Public Health 108 ( 10 ) : 1378-1384 . Burki T ( 2020 ) The online anti-vaccine movement in the age of COVID-19 . The Lancet Digital Health 2 ( 10 ) : e504—e505 . Jones-Jang and Chung \\7 Callegaro M , Baker RP , Bethlehem J , et al . ( Eds ) ( 2014 ) Online Panel Research : A Data Quality Perspective . John Wiley & Sons . Centers for Disease Control and Prevention ( 2021 ) Measles cases and outbreaks . Available at : https : //www.cdc.gov/measles/cases-outbreaks . html Cho J , Ahmed S , Hilbert M , et al . ( 2020 ) Do search algorithms endanger democracy ? An experi- mental investigation of algorithm effects on political polarization . Journal of Broadcasting & Electronic Media 64 ( 2 ) : 150-172 . Chung M ( 2017 ) Not just numbers : the role of social media metrics in online news evaluations . Computers in Human Behavior 75 : 949-957 . Chung M and Jones-Jang SM ( 2021 ) Red media , blue media , Trump briefings , and COVID-19 : examining how information sources predict risk preventive behaviors via threat and efficacy . Health Communication . Epub ahead of print 23 April . DOT : 10.1080/10410236.2021.1914386 . Cinelli M , Quattrociocchi W , Galeazzi A , et al . ( 2020 ) The COVID-19 social media infodemic . Scientific Reports 10 ( 1 ) : 1-10 . Darcy O ( 2020 ) Tucker Carlson fans flames of vaccine skepticism , telling Fox news viewers to be nervous about “ glitzy ” rollout . CNN . Available at : https : //edition.cnn.com/2020/12/17/ media/tucker-carlson-fox-news-vaccine/index.html Dixon GN and Clarke CE ( 2013 ) Heightening uncertainty around certain science . Science Communication 35 ( 3 ) : 358-382 . Druckman JN , Klar S , Krupnikov Y , et al . ( 2020 ) How affective polarization shapes Americans ’ political beliefs : a study of response to the COVID-19 pandemic . Journal of Experimental Political Science . Epub ahead of print 24 August . DOI : 10.1017/XPS.2020.28 . Dupuy B ( 2020 ) Vaccine testing falsely equated with thalidomide development decades ago . AP News . Available at : https : //apnews.com/article/fact-checking-afs : Content:9802969269 Dylko I , Dolgov I , Hoffman W , et al . ( 2018 ) Impact of customizability technology on political polarization . Journal of Information Technology & Politics 15 : 19-33 . Esses VM , Dovidio JF and Hodson G ( 2002 ) Public attitudes toward immigration in the United States and Canada in response to the September 11 , 2001 “ attack on America. ” Analyses of Social Issues and Public Policy 2 : 69-85 . Fletcher R , Cornia A and Nielsen RK ( 2020 ) How polarized are online and offline news audi- ences ? A comparative analysis of twelve countries . The International Journal of Press/ Politics 25 ( 2 ) : 169-195 . Garrett RK , Carnahan D and Lynch EK ( 2013 ) A tum toward avoidance ? Selective exposure to online political information , 2004-2008 . Political Behavior 35 : 113-134 . Gottfried J and Shearer E ( 2016 ) News use across social media platforms 2016 . Available at : http : //www.journalism.org/2016/05/26/news-use-across-social-media-platforms-2016/ Green J , Edgerton J , Naftel D , et al . ( 2020 ) Elusive consensus : polarization in elite communication on the COVID-19 pandemic . Science Advances 6 ( 28 ) : eabc2717 . Grenier E ( 2020 ) The pandemic was already polarizing—now vaccines have become partisan as well . CBC News . Available at : https : //www.cbc.ca/news/politics/grenier-vaccines- polls-1.5823870 Haddock G , Zanna MP and Esses VM ( 1993 ) Assessing the structure of prejudicial attitudes : the case of attitudes toward homosexuals . Journal of Personality and Social Psychology 65 ( 6 ) : 1105-1118 . Hamilton J ( 2004 ) All the News That ’ s Fit to Sell How the Market Transforms Information into News . Princeton , NJ : Princeton University Press . Hareup T and O ’ Neill D ( 2017 ) What is news ? Journalism Studies 18 ( 12 ) : 1470-1488 . Hart PS , Chinn S and Soroka S ( 2020 ) Politicization and polarization in COVID-19 news cover- age . Science Communication 42 ( 5 ) : 679-697 . 18 new media & society 00 ( 0 ) Hayes AF ( 2017 ) Introduction to Mediation , Moderation , and Conditional Process Analysis : A Regression-based Approach . New York : Guilford . Hmielowski JD , Beam MA and Hutchens MJ ( 2017 ) Bridging the partisan divide ? Exploring ambivalence and information seeking over time in the 2012 U.S. presidential election . Mass Communication & Society 20 ( 3 ) : 336-357 . Iyengar S , Lelkes Y , Levendusky M , et al . ( 2019 ) The origins and consequences of affective polarization in the United States . Annual Review of Political Science 22 : 129-146 . Jamieson KH and Albarracin D ( 2020 ) The relation between media consumption and misinfor- mation at the outset of the SARS-CoV-2 pandemic in the US . Harvard Kennedy School Misinformation Review 1 : 1-22 . Jamison AM , Broniatowski DA , Dredze M , et al . ( 2020 ) Not just conspiracy theories : vaccine opponents and proponents add to the COVID-19 “ infodemic ” on Twitter . Harvard Kennedy School Misinformation Review 1 ( 3 ) : 1-22 . Jang SM ( 2014 ) Challenges to selective exposure : selective seeking and avoidance in a multitask- ing media environment . Mass Communication & Society 17 ( 5 ) : 665-688 . Jang SM , Mckeever BW , Mckeever R , et al . ( 2019 ) From social media to mainstream news : the information flow of the vaccine-autism controversy in the US , Canada , and the UK . Health Communication 34 : 110-117 . Jones-Jang SM and Noland C ( 2022 ) The politicization of health and science : role of politi- cal cues in shaping the beliefs of the vaccine-autism link . Health Communication 37 : 608-616 . Kahan DM , Jenkins-Smith H and Braman D ( 2011 ) Cultural cognition of scientific consensus . Journal of Risk Research 14 ( 2 ) : 147-174 . Kelly C ( 2020 ) “ I will not take his word for it ” : Kamala Harris says she would not trust Trump alone on a coronavirus vaccine . CNN . Available at : https : //www.cnn.com/2020/09/05/poli- tics/kamala-harris-not-trust-trump-vaccine-cnntv/index.html Kim C and Lee JK ( 2016 ) Social media type matters : investigating the relationship between moti- vation and online social network heterogeneity . Journal of Broadcasting & Electronic Media 60 ( 4 ) : 676-693 . Knobloch-Westerwick § ( 2012 ) Selective exposure and reinforcement of attitudes and partisan- ship before a presidential election . Journal of Communication 62 ( 4 ) : 628-642 . Kobayashi T ( 2020 ) Depolarization through social media use : evidence from dual identifiers in Hong Kong . New Media & Society 22 ( 8 ) : 1339-1358 . Kubin E and von Sikorski C ( 2021 ) The role of ( social ) media in political polarization : a systematic review . Annals of the International Communication Association 45 ( 3 ) : 188-206 . Lee S and Xenos M ( 2022 ) Incidental news exposure via social media and political participation : evidence of reciprocal effects . New Media & Society 24 : 178-201 . Lelkes Y , Gaurav S and Shanto I ( 2017 ) The hostile audience : the effect of access to broadband Internet on partisan affect . American Journal of Political Science 61 : 5-20 . Lu Y and Lee JK ( 2019 ) Stumbling upon the other side : incidental learning of counter-attitudinal political information on Facebook . New Media & Society 21 ( 1 ) : 248-265 . McKeever BW , McKeever R , Holton AE , et al . ( 2016 ) Silent majority : childhood vaccina- tions and antecedents to communicative action . Mass Communication & Society 19 ( 4 ) : 476-498 . Mason L ( 2018 ) Uncivil Agreement : How Politics Became Our Identity . Chicago , IL : University of Chicago Press . Messing S and Westwood SJ ( 2014 ) Selective exposure in the age of social media . Communication Research 41 ( 8 ) : 1042-1063 . Jones-Jang and Chung 19 Miller PR , Bobkowski PS , Maliniak D , et al . ( 2015 ) Talking politics on Facebook : network cen- trality and political discussion practices in social media . Political Research Quarterly 68 ( 2 ) : 377-391 . Nahon K ( 2016 ) Where there is social media there is politics . In : Bruns A , Enli G , Skogerbo E , et al . ( eds ) Companion to Social Media and Politics . New York : Routledge , pp . 39-55 . Nanz A and Matthes J ( 2020 ) Learning from incidental exposure to political information in online environments . Journal of Communication 70 ( 6 ) : 769-793 . Nelson JL and Webster JG ( 2017 ) The myth of partisan selective exposure : a portrait of the online political news audience . Social Media + Society 3 ( 3 ) : 205630511772931 . Osmundsen M , Bor A , Vahlstrup PB , et al . ( 2021 ) Partisan polarization is the primary psycho- logical motivation behind political fake news sharing on Twitter . American Political Science Review 115 ( 3 ) : 999-1015 . Pariser E ( 2011 ) The Filter Bubble : How the New Personalized Web Is Changing What We Read and How We Think . London : Penguin Books . Pew Research Center ( 2016 ) News use across social media platforms 2016 . Available at : https : // www.journalism.org/2016/05/26/news-use-across-social-media-platforms-2016/ Pew Research Center ( 2019 ) Partisan antipathy : more intense , more personal . Available at : https : // www.pewresearch.org/politics/2019/10/10/partisan-antipathy-more-intense-more-personal/ Pew Research Center ( 2020a ) Republicans , Democrats move even further apart in coronavirus concerns . Available at : https : //www.pewresearch.org/politics/2020/06/25/republicans-demo- crats-move-even-further-apart-in-coronavirus-concerns/ Pew Research Center ( 2020b ) Social media outpaces print newspapers in the U.S. as a news source . Available at : https : / ( www.pewresearch.org/fact-tank/2018/12/10/social-media-out- paces-print-newspapers-in-the-u-s-as-a-news-source/ Phillips A ( 2015 ) Journalism in Context : Practice and Theory for the Digital Age . New York : Routledge . Reynolds E ( 2020 ) Some anti-vaxxers are changing their minds because of the coronavirus pan- demic . CNN . Available at : https : //edition.cnn.com/2020/04/20/health/anti-vaxxers-coronavi- rus-intl/index.html Riviére E ( 2020 ) COVID-19 vaccine faces an increasingly hesitant public . Kantar . Available at : https : //www.kantar.com/inspiration/coronavirus/covid-19-vaccine-faces-an-increasingly- hesitant-public Salmon DA , Dudley MZ , Glanz JM , et al . ( 2015 ) Vaccine hesitancy : causes , consequences , and a call to action . Vaccine 33 : D66—D71 . Settle JE ( 2018 ) Frenemies : How Social Media Polarizes America . Cambridge : Cambridge University Press . Shin J ( 2020 ) How do partisans consume news on social media ? A comparison of self-reports with digital trace measures among Twitter users . Social Media+ Society 6 ( 4 ) : 1-12 . Shoemaker PJ ( 1996 ) Hardwired for news : using biological and cultural evolution to explain the surveillance function . Journal of Communication 46 ( 3 ) : 32-47 . Slater MD ( 2015 ) Reinforcing spirals model : conceptualizing the relationship between media con- tent exposure and the development and maintenance of attitudes . Media Psychology 18 ( 3 ) : 370-395 . Smith N and Graham T ( 2019 ) Mapping the anti-vaccination movement on Facebook . Information , Communication & Society 22 ( 9 ) : 1310-1327 . Stroud NJ ( 2011 ) Niche News : The Politics of News Choice . Oxford : Oxford University Press . Tajfel H , Turner JC , Austin WG , et al . ( 1979 ) An integrative theory of intergroup conflict . In : Hatch MJ and Schultz M ( eds ) Organizational Identity : A Reader . Oxford : Oxford University Press , pp . 56-65 . 20 new media & society 00 ( 0 ) Uscinski JE , Enders AM , Klofstad C , et al . ( 2020 ) Why do people believe COVID-19 conspiracy theories ? Harvard Kennedy School Misinformation Review 1 : 1-12 . Wallis W ( 2020 ) How anti-vaxxers are threatening the UK ’ s Covid programme . The Financial Times . Available at : https : //www.ft.com/content/f84746af-9a7 f-4cc8-a3b5-434d4c085 56¢e Weeks BE , Lane DS , Kim DH , et al . ( 2017 ) Incidental exposure , selective exposure , and political information sharing : integrating online exposure patterns and expression on social media . Journal of Computer-Mediated Communication 22 ( 6 ) : 363-379 . Yamamoto M and Morey AC ( 2019 ) Incidental news exposure on social media : a campaign com- munication mediation approach . Social Mediat+ Society 5 ( 2 ) : 1-12 . Yarchi M , Baden C and Kligler-Vilenchik N ( 2021 ) Political polarization on the digital sphere : a cross-platform , over-time analysis of interactional , positional , and affective polarization on social media . Political Communication 38 ( 1—2 ) : 98-139 . Author biographies S Mo Jones-Jang ( PhD , University of Michigan ) is an Associate Professor in the Department of Communication at Boston College . His recent research examines the partisan use of misinforma- tion and opinion polarization in the new media environment . Myojung Chung ( PhD , Syracuse University ) is an assistant professor in the School of Journalism at Northeastern University . Her research focuses on ( mis ) information processing in digital media contexts . 1904.10527v3 [ cs.CY ] 24 Jul 2020 arXiv Deconstructing the Filter Bubble : User Decision-Making and Recommender Systems GUY ARIDOR , Columbia University DUARTE GONCALVES , Columbia University SHAN SIKDAR , Everquote We study a model of user decision-making in the context of recommender systems via numerical simulation . Our model provides an explanation for the findings of Nguyen , et . al ( 2014 ) , where , in environments where recommender systems are typically deployed , users consume increasingly similar items over time even without recommendation . We find that recommendation alleviates these natural filter-bubble effects , but that it also leads to an increase in homogeneity across users , resulting in a trade-off between homogenizing across-user consumption and diversifying within-user consumption . Finally , we discuss how our model highlights the importance of collecting data on user beliefs and their evolution over time both to design better recommendations and to further understand their impact . CCS Concepts : - Applied computing — Economics ; - Information systems — Recommender systems . Additional Key Words and Phrases : Filter Bubbles , Recommender Systems , Similarity-based Generalization 1 INTRODUCTION Recommender systems ( RS ) have become critical for assisting users in navigating the large choice sets that they face on many online platforms . For instance , users have to choose from thousands of movies on Netflix , millions of products on Amazon , and billions of videos on YouTube . Users in many cases are not aware of most items , let alone have full information about their preferences over them . To make matters worse , the items in these contexts are usually experience goods whose true value for users can only be learned after consumption . RS have driven a significant fraction of consumer choice on these platforms with 75 % of movies watched on Netflix and 35 % of page-views on Amazon coming from recommendations. ! While there are many positive effects from these systems , there is an increasing worry about their unintended side-effects . There have been claims that personalized RS lead users into filter bubbles where they effectively get isolated from a diversity of viewpoints or content [ 25 ] , and that personalized RS may also lead users to become increasingly homogenized at the same time [ 6 , 15 ] . Understanding how RS influence user behavior is important not only for characterizing the broader consequences of such systems but also for guiding their design . In this paper , we develop a theoretical model of user decision-making in contexts where RS are traditionally deployed . We utilize previous empirical studies that characterize how RS influence user choice as a benchmark and our theoretical model provides an intuitive mechanism that can explain these empirical results . The key insight of our model is that user beliefs drive the consumption choices of users and that recommendations provide them with information that leads them to update their beliefs and alter their choices . A crucial component of our model is that users ’ beliefs about items are driven not only by recommendations , but also from their previous 'MacKenzie et al . ( 2013 , Oct. ) , How retailers can keep up with consumers . https : //www-.mckinsey.com/industries/retail /our-insights/how- retailers- can- keep-up-with-consumers . Retrieved on October 3 , 2019 . Authors ’ addresses : Guy Aridor , Columbia University , New York , NY , g.aridor @ columbia.edu ; Duarte Goncalves , Columbia University , New York , NY , duarte.goncalves @ columbia.edu ; Shan Sikdar , Everquote , Cambridge , MA , shan.sikdar @ gmail.com . 2 Guy Aridor , Duarte Goncalves , and Shan Sikdar experiences with similar items . We use these insights to provide guidance for RS design , highlighting that understanding users ’ beliefs about the quality of the available items is essential to design recommendations and evaluate their impact . Our Model . We analyze a model of user choice with four central components . The first component of our model is that users sequentially consume items and face large choice sets . In our setting of interest , users are long-lived , but they only consume a small fraction of this choice set over their lifetime . This is traditionally the case on online platforms that have thousands or millions of options for users . The second component is that , prior to consuming them , users are uncertain about how much they value the different items . This is motivated both by the fact that recommender systems are traditionally deployed in contexts with experience goods , whose true value can only be learned after consumption , and the fact that such uncertainty is why RS exist in the first place . Thus , users face a sequential decision-making problem under uncertainty . The third , and most crucial , element is that consumption of an item reveals information that changes user beliefs about their valuation of similar items . Unlike in standard sequential decision-making problems , once an item is consumed all uncertainty about its valuation is resolved and provides information that enables users to update their beliefs about similar items . This exploits the fact that the valuations of similar items are correlated which assists users in navigating the vast product space . The idea that users make similarity-based assessments to guide their choice has grounding in empirical evidence on how users navigate large choice sets [ 27 ] . Finally , in our model recommendation provides users with information about the true valuations . We model the realized valuations as being a weighted sum of a common-value and an idiosyncratic component . This formulation gives a stylized notion of predictability of user preferences where the idiosyncratic component is inherently unpredictable given other users ’ preferences and the common-value component is what the recommender can learn from previous users ’ data . We suppose that the recommender knows the common-value component for each item and combines it with users ’ beliefs over the product space when designing personalized recommendation . Our Contributions . We provide a clear mechanism that explains the empirical results in [ 24 ] who show that , in the context of movie consumption , user behavior is consistent with filter-bubble effects even without recommendation and that recommendation leads to users being less likely to fall into such filter bubbles . In this context , filter-bubble effects are defined as users consuming items in an increasingly narrow portion of the product space over time . The simple and intuitive driving force of this is that preferences for similar items are correlated , which implies that when an item is consumed and the user learns its value , it provides information about similar items . Crucially , this not only impacts the underlying belief about the expected value of similar items , but also how uncertain the user is about their valuation of them . Consequently , this learning spillover induces users to consume items similar to those they consumed before that had high realized value , leading to an increasing narrowing of consumption towards these regions of the product space . This effect is further amplified when users are risk-averse , a concept from decision theory where all else being equal , users have a preference for items with lower uncertainty to those with higher uncertainty . However , by providing information to users , recommendation leads users to be more likely to explore other portions of the product space , limiting the filter bubble effect . We find that , while recommendation leads a single user to be more likely to explore diverse portions of the product space , it also coordinates consumption choices across users . This leads to an increase in homogeneity across users , resulting in a trade-off between homogenizing across-user consumption and diversifying within-user consumption . We explore the relationship between the overall diversity of consumed items and user welfare and find that more diverse sets of consumed items do not always correspond to higher user welfare . Deconstructing the Filter Bubble 3 Lastly , we discuss how our model and findings can be used to inform the design and evaluation of RS as well as the data that is traditionally collected for them . This highlights the importance of user beliefs in determining user consumption choices and how both recommendation and informational spillovers determine how these beliefs change over time . By collecting information on user beliefs , RS designers can understand what items a user would consume without recommendation and then predict how providing information to the user would change her beliefs and resulting consumption decisions . Thus , our evaluation measure determines the value of a recommendation based on the marginal welfare gain associated with providing a user with a recommendation over what the user would do without it . We discuss how this provides an additional rationale as to why “ accurate ” recommendations are not always good recommendations . 2 RELATED WORK . The first set of related works studies the extent and implications of filter bubbles . [ 25 ] first informally described the idea of the “ filter bubble ” which is that online personalization services would lead users down paths of increasingly narrower content so that they would effectively be isolated from a diversity of viewpoints or content . Following this , a number of empirical studies in various disciplines , have since studied the extent to which this phenomenon exists in a wide range of contexts [ 9 , 15 , 23 , 24 ] . The most relevant to our study is [ 24 ] who study whether this effect exists in the context of movie consumption . They find that even users whose consumption choices are not guided by recommendations exhibit behavior consistent with “ filter bubbles ” and that RS can actually increase the diversity of the content that users consume . To our knowledge there are no theoretical models that rationalize these empirical findings and we provide a theoretical framework through which to view this problem . Moreover , we provide a clear mechanism that drives such effects and how recommendation interacts with them . Another set of papers has examined whether RS can lead users to become increasingly homogenized . [ 4 , 29 ] show that incorporating content popularity into RS can lead to increased user homogenization . [ 6 ] shows how user homogenization may arise from training RS on data from users exposed to algorithmic recommendations . [ 10 ] show that homogenization can increase due to a popularity recommendation bias that arises from lack of information about items with limited consumption histories . We show similar results as previous work where RS lead to increased user homogenization . However , the mechanisms behind this differ from existing work as homogenization arises due to the fact that recommendation leads users to coordinate their consumption decisions in certain portions of the product space . A third strand in the literature studies the impact of human decision-making on the design and evaluation of RS . [ 7 ] surveys the literature on the relationship between human decision making and RS . The closest set of papers pointed out in this survey are those related to preference construction [ 2 , 19 ] whereby users develop preferences over time through the context of a decision process . We point out that the true underlying preferences of users may be stable over time , but , due to the nature of items in contexts where RS are deployed , they have incomplete information of their valuations and both consumption and recommendation provide them with information to reduce their uncertainty . Thus , the primary insight of our paper is that user beliefs and how users update their beliefs about similar items after consumption are important and previously unconsidered elements of human decision making that are critical for ‘ understanding the design and consequences of RS . Within this literature , [ 5 , 8 , 26 ] focus on “ user-centric ” approaches to recommendation whereby user evaluation of the usefulness of recommendation is a key evaluation measure . Our evaluation measure is similar , but , unlike previous approaches , emphasizes the importance of user beliefs . Finally , [ 14 ] considers a similar model as ours where users engage in “ spatial learning ” and exploit the correlation of their preferences in the environment , but consider it in the context of search for a single item . 4 Guy Aridor , Duarte Goncalves , and Shan Sikdar 3 . OUR MODEL AND PRELIMINARIES 3.1 Preliminaries on Expected Utility Theory For every item n in the product space J , we assume that each user i assigns a monetary equivalent x ; , n € R to the experience of consuming it . Each user can value the same item differently . However , we assume that users have the same utility over money , given by a utility function u : R > R , strictly increasing and continuous . So , ex-post , the value of item n for user i is given by u ( x ; , , ) . Before consuming the item , the user does not know exactly how she will value it . In particular , even users that will end up having the same ex-post valuation of item n may differ in their ex-ante valuation because they hold different beliefs about it . We denote by p ; the beliefs user i has about how she will value each of the items in the product space . Note that this implies that consuming item n is the same as taking a gamble . Each user evaluates the item according to the expected utility associated with the item , ie . Uj ( n ) = Ep , [ u @ n ) ] - Risk aversion captures how different users react to the risk associated to a particular consumption opportunity . It is formalized as follows : a given gamble x takes real values and follows distribution p. Then , for every gamble x , there is a certain amount of money that makes the user indifferent between taking the gamble or taking the sure amount of money . This sure amount of money is called the certainty equivalent of gamble x and is denoted as 5 ( x ) . A user i is more risk-averse than another user j if whenever user j prefers a sure thing to the gamble , then user i does too . Therefore , a more risk-averse user is more willing to avoid the risk of taking the gamble . We assume that the utility function takes a flexible functional form u ( x ) = 1 - exp ( —yx ) for y # 0 and u ( x ) = x for y > 0 - known as constant absolute risk-aversion preferences ( from hereon CARA ) . Higher y implies higher risk-aversion , with y — 0 corresponding to the risk-neutral case and y > 0 to the risk-averse one . Our formulations here follow standard economic consumer theory ( see [ 21 ] for a textbook treatment of these topics ) . 3.2 . Model Users . We consider a set of users I where each user i € I faces the same finite set of N items J = { 0,1 , ... , N —1 } . For simplicity , we assume that users only derive pleasure from item n € J the first time they consume it . We denote by xj , user i 's realized value from consuming item n. In particular , we consider that the realized value derived from a given item can be decomposed in the following manner : x ; , , = Vj , n + PUn , where v ; , , denotes an idiosyncratic component — ie . user i ’ s idiosyncratic taste for item n - and vp , a common-value component . One can interpret vp as a measure of how much item n is valued in society in general and , in a sense , v ; , , denotes how i diverges from this overall ranking . The scalar f € Ry denotes the degree to which valuations are idiosyncratic to each user or common across users . If / = 0 , it is impossible to generate meaningful predictions of any one ’ s individual preferences based on others , while if f is large , every individual has similar preferences . Stacking values in vector-form , we get the vector of values associated with each item ( inne g = Xi = Vi + BV , where V ; = ( Cm neg and V = ( n ) ne g- User Decision-Making . We assume the user makes T choices and therefore can only consume up to T items , where T is a small fraction of N. This captures the idea that users are faced with an immense choice set , but that ultimately they end up experiencing ( and learning ) about just a small fraction of it . For tractability , we impose that users are myopic and every period consume the item that they have not yet tried ( n ' ) that gives them the highest expected utility given the information from past consumption ( ci = ( nj , tee nj ) and their initial beliefs . Deconstructing the Filter Bubble 5 User Beliefs . We assume that all the true realized values are drawn at t = 0 . However , users do not know the realized values before consuming an item , but rather have beliefs over them . Formally , user i starts with some beliefs about X ; , namely that the idiosyncratic and common-value parts of the valuations are independent - Vj tL V - and that each is multivariate normal : ( 1 ) Vi ~ N ( Wi. % i ) s and ( 2 ) V ~ N ( V , > ) with V = 0 . We impose the normality assumption for two reasons . The first is that this allows for simple and tractable belief updating . The second is that it allows us to incorporate an easily interpretable correlation structure between the items . The precise formulation of = and X ; that we consider is defined below when we discuss user learning . Recalling that Vj represents idiosyncratic deviations from V , we assume that , on the population level , prior beliefs Vi= ( 7i , n ) ne g are drawn independently from a jointly normal distribution , where Dj , » ~ N ( 0 , ’ ) are independent and identically distributed . These 0 ; , n denote the prior belief that individual i holds about her valuation over item n. As people are exposed to different backgrounds , their beliefs about how much they value a given item also varies and Uj , n denotes this idiosyncrasy at the level of prior beliefs . We assume users are expected utility maximizers . User i ’ s certainty equivalent for item n , the sure value that makes user i indifferent between it and consuming the item n , conditional on the consumption history , is given by di ( m ) | crt = fin - $ Y2nn , where fin and Enn are the expected value and variance for item n that the user has given their initial beliefs and consumption history up until time ¢ . Note that this expression is known to be the certainty equivalent for CARA preferences in a Gaussian environment [ 21 ] . As it is immediate from this expression , the user assigns greater value to items for which the expected monetary equivalent , i , is higher , but penalizes those about which there is greater uncertainty =p » , the more so the greater the user ’ s degree of risk aversion y . User Learning . When a user consumes an item n she learns the realized value for that item . We consider the case where learning about the value of item n reveals more about the value associated to items that are closer to it , which captures the idea that trying an item provides more information about similar items than about dissimilar ones. ” In order to have a well-defined notion of similarity we need to define a distance function between items , which we define as d ( n , m ) : = min { |m —n| , N — |m —n| } where m and n are indices of items in .f . This distance function is not intended to model the intricacies of a realistic product space , but instead to provide a stylized product space to help us understand the effects of informational spillovers on user behavior . The basic intuition , in the context of movie consumption , is that a user ’ s valuation of John Wick ( item n ) provides more information about how much she will like John Wick : Chapter Two { item m ) than Titanic ( item q ) since d ( n , m ) < d ( n , q ) . We consider that the entry of n-th row and the ( m ) -th column of ¥ ; is given by a ? ptr , ™ ) and that of © is given by o2p % * ™ ) , The scalar p € [ 0,1 ] therefore impacts the covariance structure : a higher p implies that learning the utility of n is more informative about items nearby and , for p € ( 0 , 1 ) , this effect is decreasing in distance . The particular distance function that we rely on leads to a simple covariance structure , where the ( n , n + 1 ) -th entry in the covariance matrix is op , the ( n , n + 2 ) -th entry is op ’ , etc ? The precise updating rule is as follows . Recall that at time ¢ the user ’ s consumption history is given by Cc and we denote the utility realizations of these items as cy . We denote ji ; as the initial mean beliefs the user has over the items in 2 [ 27 ] empirically studies how individuals solve sequential decision-making problems under uncertainty in large choice sets in the context of mobile food delivery orders . They find that individuals engage in similarity-based generalizations where learning about the realized value of a particular item provides them with information about similar items . We incorporate this finding into our model in a stylized manner . 5This exponential decay correlation structure can be related to the tenet of case-based similarity of [ 12 ] - see [ 3 ] for an axiomatization of exponential similarity . 6 Guy Aridor , Duarte Goncalves , and Shan Sikdar Cc and jin ; as the initial mean beliefs the user has over the remaining N —¢ items , J \\ Cc . We partition the covariance matrix as follows : = 2 ( N-t , N-2 ) Diw-t , t ) 2 ( t , N-2 ) Deer ) , After consuming the items in Ch , the resulting beliefs over the remaining items are given by N ( fi , © ) where ji and © are > as follows : Hl er = HN + Sent . ) 2 ep ( Ce — He ) ; EL er = Zey-pn—n ) ~ Ze ) , 2 ) ZC N-1 ) ° An Illustrative Example . We illustrate the main intuitions of our model with a simple example . Suppose that there are four items : 0 , 1 , 2 , 3 . The items are in different places of the product space , where 0 is close to 1 and 3 but more distant from 2 . For the sake of expositional clarity , suppose that the initial mean beliefs are given by p = ( ElxnD } 9 = ( 0 ) 3 9 . In period 1 , every item is ex-ante identical since they have the same mean and variance and so suppose that the user breaks the tie arbitrarily and consumes item 0 . The underlying correlation structure implies that upon observing that xo = y the user will update beliefs about the remaining three items according to the previously specified updating rule . For concreteness , we suppose that o = 1 and p = 0.5 , but the intuitions hold for any value of o and p > 0 . First , we consider the case when the realization of y > 0 and , specifically , y = 0.5 - though the general intuitions hold for any y > 0 . The resulting beliefs after observing y are then as follows : Elx , | xo = y ] py ; 7 3 0 f= ( elxo=y ) =| Ele lao=yl [ =| ey f= ] 4 | , 2= @ leooaey= ] z BR 3 Elx3 | xo = y ] py i 0 3 3 Thus , upon learning xo = y , the user updates beliefs about the remaining items . Note that Ex | xo = y ] = Elx3 | xo = y ] > Elxe | xo = y ] since item 0 ’ s value is more informative about similar items ’ values , items 1 and 3 , than items further away in the product space such as item 2 . Moreover , 511 = ¥33 < Yzg2 as the uncertainty about items 1 and 3 is further reduced compared to item 2 . Thus , since y > 0 , the user in the next period will consume items nearby to item 0 since , even though initially she believed that all items had the same mean , the spillover from consuming item 0 leads her to believe that items 1 and 3 have higher expected valuations . Since both the mean is higher for these items and the variance is lower , the user will consume items 1 and 3 regardless of her risk aversion level . Now we consider the case when item 0 ends up having a negative valuation so that y = —0.5 < 0 . This results in Elx1 | xo = y ] = Elx3 | xo = y ] = -4 < - $ = Elxe | xo = y ] with © remaining the same as when y = 0.5 . In this case the risk-aversion levels of the user determine the choice in the next period . If the user is risk-neutral ( y = 0 ) , then she will go across the product space to consume item 2 in the next period since it has a higher expected value . However , if she is sufficiently risk-averse then she may still consume item 1 or 3 since her uncertainty about these items is lower than item 2 . In particular , this will happen when 1 . 9 1 . 5 ( 3 ) = 5 ) = py = Sy > pty — SyBa2 = 52 ) Given the aforementioned parametrization and y = —0.5 , the user will consume item 1 or 3 when y > 4 and will consume item 2 when y < 4 , Thus if the user is risk averse enough , then she might be willing to trade-off ex-ante lower expected values for lower risk and stick to consuming nearby items just because these items have lower uncertainty . Deconstructing the Filter Bubble 7 This example illustrates the main mechanisms that can lead to excessive consumption of similar items . Once the user finds items in the product space with high valuations she will update her beliefs positively about items in this portion of the product space and continue consuming these items regardless of her level of risk aversion . However , this sarne updating leads to a reduction in uncertainty of these items and so , if she is sufficiently risk-averse , she still may continue consuming items in this portion of the product space , even if she has bad experiences with them , since they are perceived to be less risky . Recommendation . Our model of recommendation is stylized in order to provide qualitative insights into how rec- ommendation shapes behavior , instead of focusing on the details of how RS are implemented in practice . We model recommendation as giving users information about the valuation of the items . We will consider three cases . The case of primary interest is recommendation where the recommender observes values accrued and knows V but does not know V ; .4 However , the recommender does know the users ’ beliefs V ; . Thus , at any given period , the recommender provides a personalized recommendation that combines the knowledge of the common value component V with the user beliefs V ; . Knowing the user ’ s beliefs about her valuation of each item become crucial in this case : just providing the user with information about V may change the user ’ s original ranking , but , without considering the user ’ s beliefs , she will not necessarily follow the recommendation.° We further consider two cases that serve mainly as benchmarks . The first is no recommendation , where users get no additional information and make consumption choices based on their beliefs and consumption history . This gives us a benchmark as to how users would behave without recommendation so that we can analyze what changes with the introduction of recommendation . The second is the oracle recommendation where the recommender knows the true realized utility of each item for each user and can therefore recommend the best remaining item in every period . This gives us a full information benchmark , which is the optimal consumption path for a user if all uncertainty about their preferences was resolved . Comparison to the oracle regime benchmark provides an analog to the standard regret measures utilized in the multi-armed bandit literature , which look at the difference in the expected value of the ex-post optimal action and the expected value of actions that were taken . Simulation Details . We analyze our model using numerical simulation since the sequential decision-making component paired with the rich covariance structure between the items make it difficult to characterize optimal user behavior analytically.® We explore how consumption patterns differ as we consider different recommendation regimes and report represen- tative results from our simulations . We run this simulation over 100 populations of users with 100 users per population for each combination of parameters . A given set of parameters and a user are a single data point in our dataset . We simulate over risk-aversion parameters y € { 0 , 0.3 , 0.6 , 1,5 } , standard-deviation o € { 0.25 , 0.5 , 1.0 , 2.0 , 4.0 } , corre- lation parameters p € { 0 , 0.1 , 0.3 , 0.5 , 0.7 , 0.9 } and degree of idiosyncrasy of individual valuations f € { 0 , 0.4 , 0.8 , 1 , 2 , 5 } . The range of considered parameter values cover the relevant portions of the parameter space in order to provide full insight into the behavior of the model . When we consider results varying a single parameter , we group the results over 4We do not consider the acquisition of information for the recommender to know V and suppose that she has sufficient data to learn V with arbitrary precision at t = 0 . > The notion of recommendation that we consider is idealized where the recommendation does the Bayesian updating for users , but the results are equivalent to if the users did the updating themselves . ®The Gaussian assumption allows for closed form belief updating which enables us to simulate our model but does not provide much help in analytical characterizations . 8 Guy Aridor , Duarte Goncalves , and Shan Sikdar the other parameters and provide reports varying only the parameter of interest . We report results for a relatively small consumption history T = 20 with a product space size N = 200. ” 4 RESULTS 4.1 Local Consumption and Filter Bubbles We characterize “ filter bubble ” effects as the degree to which users engage in local consumption . We define local consumption in terms of the average consumption distance between the items consumed by the users at time t — 1 and t. Thus , in the context of our model , filter-bubble effects arise when the average consumption distance decreases over time and , across regimes , when the levels are lower for a given recommendation regime compared to another . Our first finding can be summarized as follows : FInDINnG 1 . The impact of recommendation on local consumption : ( 1 ) When p = 0 , there is no difference in consumption distance between the three recommendation regimes . ( 2 ) When p > 0 , no recommendation induces more local consumption than both recommendation and oracle regimes . This effect is amplified as p increases as well as when users are more risk averse ( y increases ) . First , the right panel of Figure 1 shows that , when p = 0 , there is no difference in consumption distance between the three regimes . This is due to the fact that when p = 0 , there is no reason that items that are close in the product space should have similar values and so the optimal consumption path does not depend on the similarity of the items . However this also means that users do not learn anything about neighboring items and so there is limited path-dependence in consumption . Not only is there no difference in the levels between the three regimes , but they all have the same , flat , average consumption distance path . This underscores the fact that if there were no correlation between the realized utilities then there would be no reason for users to consume similar items and thus no narrowing effect , regardless of the information on the true utility of the items that users had . The left panel of Figure 1 shows that , when p € ( 0,1 ) , both recommendation and no recommendation lead to increasingly local consumption compared to the oracle benchmark case . Moreover , the average consumption path between periods is decreasing for the no recommendation case whereas it is increasing for the oracle case . The recommendation regime decreases the degree of local consumption , but not as much as the oracle benchmark . Due to the correlation of values , the oracle consumption path exploits this and leads to the consumption of more similar items than in the case when p = 0 . However , since these spillovers also impact user learning in the no recommendation case , users over-exploit these and increasingly consume items similar to high value items that they have consumed before . This is also illustrated in the top row of Figure 2 , which shows how the consumption paths in the oracle and no-recommendation regimes vary as p increases and is in line with this intuition . As shown in the bottom row of Figure 2 , this effect is further amplified as the level of risk aversion increases : the degree of local consumption drastically increases as y increases . This is due to the fact that the spillovers not only impact the mean expected belief about quality but also the degree of uncertainty . Local consumption therefore leads to users having less uncertainty about certain areas of the product space and risk aversion may lead them to increasingly consume nearby items . In sum , filter-bubble effects only arise when there is an inherent correlation between the realized utilities of the items in the product space . When there is a correlation between the realized utilities then filter bubbles can naturally '' Due to space constraints , we only report the values for N = 200 . However , we further conducted the same exercises for N = 100 and N = 500 and the results are qualitatively similar to those reported here . Deconstructing the Filter Bubble 9 Fig . 1 . Local Consumption and Correlation g 50 BO c oo c 40 40 a etree neers Ree a QO 30 ; \\ . Q 30 & 20 & 20 s s > 10 > 10 < < °o 2 4 6 8 10 12 14 16 18 20 °S-s a4 € 8 10 12 14 16 18 20 t t —— No Recommendation —— Oracle —— No Recommendation —— Oracle —— Recommendation —— Recommendation Notes : The figure shows the consecutive consumption path difference between the no recommendation , recommendation , and oracle regime . The figure on the left displays the average consecutive consumption distance aggregating over simulations where p € ( 0 , 1 ) and the figure on the right displays the average consecutive consumption distance aggregating over simulations where p = 0 . The shaded area represents the 95 % confidence interval . arise due to the nature of how individuals acquire additional information about the remaining items . We have shown that , unless users are provided with additional information to guide their consumption choices , then these information spillovers and user risk-aversion can lead users into filter bubbles . When users consume high valued items , they exploit the underlying correlation across different items ’ values , stronger for similar items , which leads them to increasingly consume items in narrower and narrower portions of the product space . Risk aversion may lead users into performing local consumption even when they have a low valuation of nearby items just because they know what to expect from the item . Recommendation leads to these effects being mitigated by providing users with additional information on items outside the already explored portions of the product space . Logically , if all uncertainty were resolved as in the oracle regime , then such behavior is not present . 4.2 User Welfare and Item Diversity In this section we primarily focus on the impact of recommendation on user welfare and the overall diversity of the items that they consume . While in the previous section we looked at the distance between consecutive items , in this section we focus on a diversity measure that considers the entire consumed set of items . The diversity measure we utilize is common in RS literature ( e.g . [ 33 ] ) which is the average normalized pairwise distance between the consumed 1 1 i= SAG » d ( n , m ) items : n , meC ? intm Finding 2 summarizes the main results on item diversity : FinvinG 2 . The impact of recommendation on item diversity : ( 1 ) When p = 0 , item diversity is the same across all three recommendation regimes ; ( 2 ) When p € ( 0,1 ) , item diversity decreases across all recommendation regimes but decreases the most in the no- recommendation regime . This effect is amplified as p increases as well as when users become more risk-averse . As before , when there is no correlation between valuations , item diversity is the same across different recommendation regimes . The over-exploitation of information spillovers when p € ( 0 , 1 ) leads to item diversity being lowest in the no-recommendation regime . As a result , this effect gets amplified as p increases , which leads to the gap in diversity 10 Guy Aridor , Duarte Goncalves , and Shan Sikdar Fig . 2 . Relationship between Local Consumption and Correlation ( p ) , Risk Aversion ( y ) No Recommendation Recommendation Oracle g 50 zm 08 g 50 08 8 9 08 5 4 % QW 0.7 5 40 0.7 Bw a 07 2 x i 0.5 2 x 05 B x » C—O 0.5 o ao ao a g 2 Xx 0.3 g 2 0.3 g 2 0.3 2 19 0.1 2 19 o1 2 19 0.1 °F 5 10 py 0 °F 5 10 py 0 e 5 10 py 0 t t t No Recommendation Recommendation Oracle 5 5 5 50 50 50 g * . 23 . £ig- | 3 3 3 a x a x a x ® 06 > @ 06 > 0.6 > 2 2 2 $ : 0.3 $ . 0.3 3 > 03 190 ‘ 190 . 10 . < < < oo 5 to 0 oo 5 to 0 e 5 10 15 0 t t t Notes : Each figure plots the average consecutive consumption distance across time as the inherent correlation between the valuation of the items , p , varies ( top row ) and the level of risk-aversion , y , varies ( bottom row ) . In both rows , the left displays the no-recommendation regime , the center displays the recommendation regime , and the right displays the oracle regime . between the regimes to increase as p increases . The top row of Figure 2 shows how diversity varies as p increases across the three regimes that we consider . There is a similar increasing diversity gap as y , or the level of risk-aversion , increases as can be seen in the bottom row of Figure 2 . The mechanisms behind these effects directly parallels those discussed in the previous section since low average sequential consumption distance directly leads to low diversity . We now study how recommendation impacts user welfare . In our model users make consumption decisions that maximize their current period ex-ante utility that depends on their beliefs in that period . Thus , from an ex-ante perspective , they make optimal decisions , but our primary interest is in understanding how the ex-post , or realized , utility varies across regimes and parameter values . We define user ’ s ex-post welfare as the average of the realized values , Wi : z » Xin nec ? controlling for the effect of T : Finding 3 states our main findings of the impact of recommendation on ex-post welfare , which can be seen in the rightmost plot of Figure 3 : FINDING 3 . The impact of recommendation on consumer welfare is as follows : ( 1 ) Under oracle recommendation , welfare is invariant with respect to p. ( 2 ) Under no recommendation , welfare is increasing in p. ( 3 ) Recommendation introduces welfare gains relative to no recommendation , but these gains are decreasing as p increases . The most interesting observation is that the value of recommendation decreases as p decreases . While welfare in the recommendation regime is flat as we increase p , it is increasing in the no-recommendation regime and thus the welfare gap between the two shrinks as p increases . The intuition is clear as recommendation provides users with Deconstructing the Filter Bubble 11 Fig . 3 . Relationship between User Welfare , Diversity and Correlation ( p ) , Risk Aversion ( y ) 0.25 4 0.22 ee 2 0.20 = gf 3 B g 0.20 £ D > = 2 oa Z 0.18 = 2 0.16 1 eee 0.10 0.0 0.2 0.4 0.6 08 0 2 4 0.0 0.2 0.4 0.6 0.8 e ¥ ep —_ Ne Recommendation — Oracle _ No Recommensation — Oracle — No Recommendation — Oracle mmendation mmendation —— Recommendation Notes : The figures on the left and center display the relationship between p and overall consumed item diversity ( left ) as well as y and overall consumed item diversity ( center ) . The figure on the right displays the relationship between p and overall welfare . The shaded area represents the 95 % confidence interval . Fig . 4 . Diversity vs . Welfare Diversity 0.3 0.9 0.9 a9 = 2 02 = 0.7 3 0.7 3 0.7 3 05 2 05 2 o1 05 2 ao ao ® ado 0.3 0.3 03 0.0 o1 o1 0.1 0 Welfare 0 Welfare 0 tana weeentemaiereenen —— 8 teen wee meinen —— 8 tore wee emeteomeen —— O18 tae ve etemaiereenen —— 8 Notes : The figure plots the relationship between diversity and welfare under no recommendation , with y = 0 ( first ) and y = 5 ( second ) , and under recommendation , with Y = 0 ( third ) and y = 5 ( fourth ) . information that allows them to better guide their decisions and increase welfare . However , as p increases users get increasingly more information from consuming items since the realized utility is now more informative about the utility of nearby items . Thus , since consumption decisions themselves yield valuable information , the information provided by recommendation is less valuable to the user . One striking observation is that the decrease in diversity does not appear to be associated with a decline in welfare . Indeed , it appears that the opposite is the case - that low diversity is associated with higher welfare and vice versa . We next explore the relationship between welfare and diversity . Finding 4 summarizes our findings on the relationship between diversity and welfare : Finpinc 4 . In the no-recommendation regime , diversity and welfare are : ( 1 ) Negatively correlated when users have no risk-aversion ; ( 2 ) Uncorrelated when users have high levels of risk-aversion . In the recommendation regime , diversity and welfare are : ( 1 ) Uncorrelated when users have no risk-aversion ; ( 2 ) Positively correlated when users have high levels of risk-aversion . In the oracle regime , diversity and welfare are always uncorrelated . 12 Guy Aridor , Duarte Goncalves , and Shan Sikdar Figure 4 shows how diversity and welfare correlate for the no recommendation case as we vary the degree of risk aversion . When there is no risk-aversion then there is a negative correlation between welfare and diversity . This is since , with no risk-aversion , a user will select the item that she currently believes has the highest expected value . High item diversity in this case can arise from a user who consumes an item she disliked and updates her beliefs about nearby items negatively . As a result , in the following period she will pick an item far away in the product space from the item that was previously consumed . If instead the user valued highly the item that she had consumed , then she is more likely to pick a nearby item . The information spillovers therefore lead to high item diversity being negatively correlated with welfare . This only happens since y = 0 leads to users only caring about the expected value of the item . However , as we saw in Findings 1 and 2 , increasing y can lead to lower diversity and increasingly local consumption due to the fact that the degree of uncertainty now impacts users ’ choices . This weakens the negative relationship between diversity and welfare since both negative and positive experiences with an item reduce uncertainty about surrounding items . This leads to the inverted-U shape found in Figure 4 when y is relatively large ( e.g . y = 5 ) though diversity and welfare are virtually uncorrelated in the data . In the recommendation and oracle regimes , under risk neutrality ( y = 0 ) , welfare and diversity are uncorrelated , while under risk aversion ( y = 5 ) , it is possible to observe an actual positive relation between diversity and welfare as recommendations are able to reduce uncertainty and facilitate exploration of the product space . 4.3 . User Homogenization In this section , we focus on comparisons across users and investigate how the consumed set of items across users varies across different recommendation regimes and parameter values . In particular we look at the degree of homogenization between users . Similar to other papers that study the degree of homogenization in RS ( e.g . [ 6 ] ) we measure homogeneity via the Jaccard index between the consumption sets of users : 1 T AT His ——— J '' dj ( C } .c7 ) n= ) , 44,7 89 CLIFT where d ; denotes the Jaccard index and H € [ 0 , 1 ] . Finding 5 summarizes our findings on the impact of recommendation on user homogeneity : Finpinc 5 . The impact of recommendation on homogeneity is as follows : ( 1 ) Highest under recommendation and lowest under no recommendation ; ( 2 ) Increasing in f , or the weight of the common-value component ; ( 3 ) Decreasing in p for partial recommendation , but weakly increasing in p for no recommendation . First , we study how the degree of homogenization varies as we increase f , the weight of the common value component . As f increases we expect that users should become increasingly homogeneous as the realized utilities of the items are now increasingly similar . Figure 5 confirms that as the weight of the common-value component / increases , users consume increasingly similar sets of items . The homogenization effect is strongest under the recommendation regime since the revelation of the common-value component induces users to consume items in similar areas of the product space . As f increases , some amount of homogenization is optimal as can be seen from the oracle case . However , since users in the no-recommendation regime do not know the common-value component they engage in local consumption in different areas of the product space which leads to less than optimal homogeneity . Deconstructing the Filter Bubble 13 Fig . 5 . Relationship between Homogeneity and Common-Value Strength ( / ) , Correlation ( p ) 0.25 2 2 3 0.20 3 % 0.15 3 € 0.10 — ° ° = s0.05 = 0.00 0 2 4 B e —— No Recommendation —— Oracle —— NoRecommendaton —— Oracle —— Recommendation —— Recommendation Notes : This figure displays the value of the homogeneity measure as we vary the weight of the common value component , f ( left ) and correlation between valuations , p ( right ) . Each line represents this plot for a single recommendation regime . The shaded area represents the 95 % confidence interval . We next study how the degree of homogeneity varies with p. Figure 5 shows how homogeneity decreases as p increases in the recommendation regime . As was highlighted in Findings 1 and 2 , the degree of local consumption increases with p. Even though the revelation of the common-value component induces them to search in similar parts of the product space , their idiosyncratic components induce them to consume items in a more localized area of the product space as p increases which leads to a decline in homogeneity . 5 RECOMMENDER SYSTEM EVALUATION In this section we discuss how the insights from our model of user decision-making can inform the evaluation and design of recommender systems . The classic approach to evaluation is to predict user ratings for items and to compare how accurate this prediction is to recorded ratings data , either explicitly given by users or inferred from behavioral data . The RS should then recommend the items with the highest predicted ratings [ 1 ] . There has been a recent movement away from such evaluation measures due to the observation that accurate recommendations are not necessarily useful recommendations [ 22 ] . Our model illustrates a mechanism behind this observation . Consider the domain of movie recommendation and suppose a user has just watched the movie John Wick and rated it highly . A RS attempting to predict user ratings may then predict that this user is very likely to enjoy the sequel , John Wick : Chapter Two , as well . However , the user herself may also have made this inference since the two movies are very similar to each other . Thus , recommending this movie would not be not useful since the recommendation gives the user little information that she did not already know . The key insight is it is not useful since it ignores the inference the user themselves made and their updated beliefs . The user may watch John Wick : Chapter Two , then , even without recommendation , and the value of the recommendation was small . This intuition implies that RS should collect additional data beyond that which is traditionally recorded . The first and most crucial type of data to collect is individual user beliefs about items that they have not yet consumed . As illustrated by our model , these beliefs are what drive the future consumption decisions of users and understanding these beliefs is crucial for determining the value of recommending certain items.® The second type of data that is relevant for RS designers to collect is how user beliefs change over time and , in particular , not just how individuals value the item they § Additionally , user beliefs contain information that may not have been observed by the recommender that only observes user choices on the platform . 14 Guy Aridor , Duarte Goncalves , and Shan Sikdar just consumed , but also how it impacts their beliefs about the quality of similar items. ’ The third type of data is the risk-aversion levels of users as our model illustrates that the risk preferences of users are important for understanding what information RS can provide that materially leads users to alter their consumption patterns . A natural follow-up question is how this additional data should be utilized in the design of good recommendations . Our model posits that recommendation provides value to users by providing them with information about the true valuation of an item if they were to consume it . Thus , the prediction problem for the recommender becomes predicting what item the user would choose with no recommendation and , correspondingly , what would be the most useful information to provide to the user that would lead her to consume a better item than she would without recommendation . This links back to the intuition our model provided for the John Wick example whereby collecting user beliefs and measuring how the user updated beliefs about similar items would lead the recommender to understand that the user would consume John Wick : Chapter Two . Our approach would therefore imply that , with this as a starting point , the recommender ’ s problem would be to predict what is the most useful information to give the user leading them to change the item that they eventually consume . There have been a number of alternative recommendation evaluation metrics proposed in the literature with the aim of providing more useful recommendations than those provided by accuracy metrics , such as serendipity [ 18 ] , calibration [ 28 ] , coverage [ 11 ] , novelty [ 30 ] , and many others . Our approach most closely follows the set of proposed serendipity measures which are surveyed in [ 18 ] . As discussed by [ 20 ] , serendipitous recommendations are said to “ have the quality of being both unexpected and useful ” which is in line with the primary intuition behind our approach . The primary difference between our proposed approach and those existing in the literature is that ours crucially hinges on understanding user beliefs and the risk-preferences of users . For instance , [ 16 , 30 ] propose unexpectedness metrics that look at the dissimilarity of the proposed recommended items compared to what the recommender already knows the user likes . This metric depends only on the proposed item-set and not necessarily on the user ’ s beliefs or how such a recommendation will change the item that the user consumes . [ 17 ] provide a comprehensive overview of possible definitions of serendipity and ours is closest to their “ motivational novelty '' definition , which is that the user was persuaded to consume an item as a result of recommendation . Indeed , our approach allows us to give precise definitions for what it means for a recommendation to be unexpected and useful in the spirit of serendipitous recommendations . Our evaluation measure leads to useful recommendations since it leads users towards better items than they would consume without recommendation . It further results in “ unexpected ” recommendations since it explicitly incorporates user beliefs and thus allows the RS to understand how “ unexpected ” a recommendation would be from the perspective of a user . Finally , such a measure may lead to a perceived broadening of user preferences as has been discussed in [ 13 , 32 ] . However , under our interpretation , it may be that their underlying preferences are unchanged and , instead , that recommendation and consumption themselves provides information that encourages users to explore different portions of the product space . °Characterizing the similarity between items has been an important goal of designing content-based recommendations , though as noted by [ 31 ] , how users perceive similarity between items is not always in line with how similarity is computed in content-based RS . Understanding how this impacts which items users update their beliefs about is an important direction for future work . Deconstructing the Filter Bubble 15 REFERENCES ( 4 ) [ 2 ] ( 3 [ 4 ] [ 3 ] [ 9 ] [ 10 ] ( 11 ] [ 12 ] [ 13 ] [ 14 ] [ 15 ] [ 16 ] [ 17 ] [ 18 ] [ 19 ] [ 20 ] ( 21 ] [ 22 ] [ 23 ] [ 24 ] [ 25 ] [ 26 ] ( 27 ] [ 28 ] [ 29 ] Gediminas Adomavicius and Alexander Tuzhilin . 2005 . Toward the next generation of recommender systems : A survey of the state-of-the-art and possible extensions . IEEE Transactions on Knowledge & Data Engineering 6 ( 2005 ) , 734-749 . James R Bettman , Mary Frances Luce , and John W Payne . 1998 . Constructive consumer choice processes . Journal of consumer research 25 , 3 ( 1998 ) , 187-217 . Antoine Billot , Itzhak Gilboa , and David Schmeidler . 2008 . Axiomatization of an exponential similarity function . Mathematical Social Sciences 55 , 2 ( 2008 ) , 107-115 . Oscar Celma and Pedro Cano . 2008 . From hits to niches ? : or how popular artists can bias music recommendation and discovery . In Proceedings of the 2nd KDD Workshop on Large-Scale Recommender Systems and the Netflix Prize Competition . ACM , 5 . Oscar Celma and Perfecto Herrera . 2008 . A new approach to evaluating novel recommendations . In Proceedings of the 2008 ACM conference on Recommender systems . 179-186 . Allison JB Chaney , Brandon M Stewart , and Barbara E Engelhardt . 2018 . How algorithmic confounding in recommendation systems increases homogeneity and decreases utility . In Proceedings of the 12th ACM Conference on Recommender Systems . ACM , 224-232 . Li Chen , Marco De Gemmis , Alexander Felfernig , Pasquale Lops , Francesco Ricci , and Giovanni Semeraro . 2013 . Human decision making and recommender systems . ACM Transactions on Interactive Intelligent Systems ( TiiS ) 3 , 3 ( 2013 ) , 1-7 . Paolo Cremonesi , Franca Garzotto , and Roberto Turrin . 2013 . User-centric vs. system-centric evaluation of recommender systems . In IFIP Conference on Human-Computer Interaction . Springer , 334-351 . Seth Flaxman , Sharad Goel , and Justin M Rao . 2016 . Filter bubbles , echo chambers , and online news consumption . Public opinion quarterly 80 , S1 ( 2016 ) , 298-320 . Daniel Fleder and Kartik Hosanagar . 2009 . Blockbuster culture ’ s next rise or fall : The impact of recommender systems on sales diversity . Management science 55 , 5 ( 2009 ) , 697-712 . Mouzhi Ge , Carla Delgado-Battenfeld , and Dietmar Jannach . 2010 . Beyond accuracy : evaluating recommender systems by coverage and serendipity . In Proceedings of the fourth ACM conference on Recommender systems . ACM , 257-260 . Itzhak Gilboa and David Schmeidler . 1995 . Case-based decision theory . The quarterly Journal of economics 110 , 3 ( 1995 ) , 605-639 . Jonathan L Herlocker , Joseph A Konstan , Loren G Terveen , and John T Riedl . 2004 . Evaluating collaborative filtering recommender systems . ACM Transactions on Information Systems ( TOIS ) 22 , 1 ( 2004 ) , 5-53 . Charles Hodgson and Gregory Lewis . 2019 . You Can Lead a Horse to Water : Spatial Learning and Path Dependence in Consumer Search . In Proceedings of the 2019 ACM Conference on Economics and Computation ( EC 4AZ19 ) . Association for Computing Machinery , New York , NY , USA , 215. https : //doi.org/10.1145/3328526.3329595 Kartik Hosanagar , Daniel Fleder , Dokyun Lee , and Andreas Buja . 2013 . Will the global village fracture into tribes ? Recommender systems and their effects on consumer fragmentation . Management Science 60 , 4 ( 2013 ) , 805-823 . Marius Kaminskas and Derek Bridge . 2014 . Measuring surprise in recommender systems . In Proceedings of the workshop on recommender systems evaluation : dimensions and design ( Workshop programme of the 8th ACM conference on recommender systems ) . Citeseer . Denis Kotkov , Joseph A Konstan , Qian Zhao , and Jari Veijalainen . 2018 . Investigating serendipity in recommender systems based on real user feedback . In Proceedings of the 33rd Annual ACM Symposium on Applied Computing . 1341-1350 . Denis Kotkov , Shuaiqiang Wang , and Jari Veijalainen . 2016 . A survey of serendipity in recommender systems . Knowledge-Based Systems 111 ( 2016 ) , 180-192 . Sarah Lichtenstein and Paul Slovic . 2006 . The construction of preference . Cambridge University Press . Andrii Maksai , Florent Garcin , and Boi Faltings . 2015 . Predicting online performance of news recommender systems through richer evaluation metrics . In Proceedings of the 9th ACM Conference on Recommender Systems . ACM , 179-186 . Andreu Mas-Colell , Michael Dennis Whinston , Jerry R Green , et al . 1995 . Microeconomic theory . Vol . 1 . Oxford university press New York . Sean M McNee , John Riedl , and Joseph A Konstan . 2006 . Being accurate is not enough : how accuracy metrics have hurt recommender systems . In CHI ’ 06 extended abstracts on Human factors in computing systems . ACM , 1097-1101 . Judith MAtller , Damian Trilling , Natali Helberger , and Bram van Es . 2018 . Do not blame it on the algorithm : an empirical assessment of multiple recommender systems and their impact on content diversity . Information , Communication & Society 21 , 7 ( 2018 ) , 959-977 . Tien T Nguyen , Pik-Mai Hui , F Maxwell Harper , Loren Terveen , and Joseph A Konstan . 2014 . Exploring the filter bubble : the effect of using recommender systems on content diversity . In Proceedings of the 23rd international conference on World wide web . ACM , 677-686 . Eli Pariser . 2011 . The filter bubble : How the new personalized web is changing what we read and how we think . Penguin . Pearl Pu , Li Chen , and Rong Hu . 2011 . A user-centric evaluation framework for recommender systems . In Proceedings of the fifth ACM conference on Recommender systems . 157-164 . Eric Schulz , Rahul Bhui , Bradley C Love , Bastien Brier , Michael T Todd , and Samuel J Gershman . 2019 . Structured , uncertainty-driven exploration in real-world consumer choice . Proceedings of the National Academy of Sciences ( 2019 ) , 201821028 . Harald Steck . 2018 . Calibrated recommendations . In Proceedings of the 12th ACM conference on recommender systems . 154-162 . Jutta Treviranus and Stephen Hockema . 2009 . The value of the unpopular : Counteracting the popularity echo-chamber on the Web . In 2009 IEEE Toronto International Conference Science and Technology for Humanity ( TIC-STH ) . IEEE . https : //doi.org/10.1109/tic-sth.2009.5444430 16 Guy Aridor , Duarte Goncalves , and Shan Sikdar [ 30 ] Saul Vargas and Pablo Castells . 2011 . Rank and relevance in novelty and diversity metrics for recommender systems . In Proceedings of the fifth ACM conference on Recommender systems . ACM , 109-116 . ( 31 ] Amy A Winecoff , Florin Brasoveanu , Bryce Casavant , Pearce Washabaugh , and Matthew Graham . 2019 . Users in the loop : a psychologically-informed approach to similar item retrieval . In Proceedings of the 13th ACM Conference on Recommender Systems . 52-59 . [ 32 ] Yuan Cao Zhang , Diarmuid © Séaghdha , Daniele Quercia , and Tamas Jambor . 2012 . Auralist : introducing serendipity into music recommendation . In Proceedings of the fifth ACM international conference on Web search and data mining . 13-22 . [ 33 ] Cai-Nicolas Ziegler , Sean M McNee , Joseph A Konstan , and Georg Lausen . 2005 . Improving recommendation lists through topic diversification . In Proceedings of the 14th international conference on World Wide Web . ACM , 22-32 . 1406.7438v1 [ cs.SI ] 28 Jun 2014 arXiv Does Offline Political Segregation Affect the Filter Bubble ? An Empirical Analysis of Information Diversity for Dutch and Turkish Twitter Users E. Bozdag * * , Q. Gao ’ , G.J . Houben® , M.E . Warnier® * Deift University of Technology , Department Values and Technology , P.O . Box 5015 2600 GA Delft , The Netherlands > Philips Research , Eindhoven , the Netherlands “ Delft University of Technology , Web Information Systems Group , Delft , the Netherlands 4 Delft University of Technology , Section of System Engineering . Delft , the Netherlands Abstract From a liberal perspective , pluralism and viewpoint diversity are seen as a necessary condition for a well-functioning democracy . Recently , there have been claims that viewpoint diversity is diminishing in online social networks , putting users in a “ bubble ” , where they receive political information which they agree with . The contributions from our in- vestigations are fivefold : ( 1 ) we introduce different dimensions of the highly complex value viewpoint diversity using political theory ; ( 2 ) we provide an overview of the metrics used in the literature of viewpoint diversity analysis ; ( 3 ) we operationalize new metrics using the theory and provide a framework to analyze viewpoint diversity in Twitter for different political cultures ; ( 4 ) we share our results for a case study on minorities we performed for Turkish and Dutch Twitter users ; ( 5 ) we show that minority users can not reach a large percentage of Turkish Twitter users . With the last of these contributions , using theory from communication scholars and philosophers , we show how minority access is missing from the typical dimensions of viewpoint diversity studied by computer scientists and the impact it has on viewpoint diversity analysis . Keywords : Twitter , diversity , polarization , politics , Turkey , Netherlands 1 . Introduction It is well known that traditional media have a bias in selecting what to report and in choosing a perspective on a particular topic . Individual factors such as personal judg- ment can play a role during the selection of news for a newspaper . Selection bias , organizational factors , adver- tiser and government influences can all affect which items will become news ( Bozdag , 2013 ) . About 37 % of Ameri- cans see a great deal of political bias in news coverage and 68 % percent prefer to get political news from sources that have no particular point of view ( Pew Research , 2012 ) . Similarly , in a survey performed before the general elec- tions in the UK , 96 % of the population said they believe they have seen clear bias within the UK media ( Wei et al. , 2013 ) . Evidence of bias ranges from the topic choice of the New York Times to the choice of think-tanks that the media refer to ( DellaVigna & Kaplan , 2007 ) . Many democracy theorists claim that modern delibera- tive democracy requires citizens to have socially validated and justifiable preferences . Citizens must be exposed to opposed preferences and viewpoints and should be able to defend their views ( Held , 2006 ; Offe & Preuss , 1990 ; * Corresponding author Email addresses : v.e.bozdag @ tudelft.nl ( E. Bozdag ) , q. gao @ philips.com ( Q. Gao ) , g.j.p.m.houben @ tudelft.nl ( G.J . Houben ) , m.e.warnier @ tudelft.nl ( M.E . Warnier ) Preprint submitted to Computers in Human Behavior ( forthcoming ) Dryzek , 1994 ) . Exposure to biased news information can foster intolerance to opposing viewpoints , lead to ideolog- ical segregation and antagonisms in major political and social issues ( Glynn et al. , 2004 ; An et al. , 2012 ; Saez- Trumper et al. , 2013 ) . Being aware of and overcoming bias in news reporting is essential for a fair society , as me- dia has the power to shape voting behavior ( Saez-Trumper et al. , 2013 ) . Social information streams , i.e. , status updates from social networking sites , have emerged as a popular means of information sharing . Political discussions on these plat- forms are becoming an increasingly relevant source of po- litical information , often also used as a source of quotes for media outlets ( Jiirgens et al. , 2011 ) . Traditional me- dia are declining in their gatekeeping role to determine the agenda and select which issues and viewpoints reach their audiences ( Bruns , 2011 ) . Internet users have moved from scanning traditional media such as newspapers and televi- sion to using the Internet , in particular social networking sites ( An et al. , 2012 ) . Social networking sites are thus now acting as gatekeepers ( Bozdag , 2013 ) . Communication theorists argue that the traditional me- dia are declining in their gatekeeping role to determine what is “ newsworthy ” and select which issues and view- points will reach their audiences Bruns ( 2011 ) . It is often argued that the Internet , by promoting equal access to diverging preferences and opinions in society , actually in- August 16 , 2018 creases information diversity . Many scholars characterize the online media landscape as the “ age of plenty , with an almost infinite choice and unparalleled pluralization of voices that have access to the public sphere ( Karppinen , 2009 ) . Some argue that social media will disrupt the tra- ditional elite control of media and amplify the political voice of non-elites and minorities ( Castells , 2011 ) .Still oth- ers claim that tools such as Twitter are neutral spaces for collaborative news coverage operated by third parties out- side the journalism industry . As a result , the information curated through collaborative action on such social media platforms should be expected to be drawn from a diverse , multi-perspectival range of sources ( Bruns , 2011 ) . Some further claim that platforms such as Twitter are neutral communication spaces , and offer a unique environment in which journalists are free to communicate virtually any- thing to anyone , beyond many of the natural constraints posed by organizational norms that are existing in tradi- tional media ( Lasorsa et al. , 2012 ) . On the other hand , there are skeptical voices that argue that the Internet has not fundamentally changed the con- centrated structure typical of mass media , but reflects the previously recognized inequalities ( Karppinen , 2009 ) . It is also argued that it has brought about new forms of exclu- sion and hierarchy ( Suoranta & Vadén , 2009 ) . While it has increased some sort of political participation , it has em- powered a small set of elites and they still strongly shape how political material is presented and accessed ( Hindman , 2008 ) . Others have pointed out the danger of “ cyberbalka- nization ” ” caused by the Internet ( Sunstein , 2002 ; Pariser , 2011 ) . They argue that the filters we choose on the Inter- net , or the filters that are imposed upon us will weaken the democratic process . This is because it will allow citizens to join into groups that share their own views and values , and cut themselves off from any information that might chal- lenge their beliefs . Group deliberation among like-minded people can create polarization ; individuals may lead each other in the direction of error and falsehood , simply be- cause of the limited argument pool and the operation of social influences . It is thus very important to verify whether viewpoint diversity is diminishing in social media and whether cyber- balkanization indeed occurs . There are empirical studies that have observed a high level of information diversity in Twitter and Facebook , mainly due to retweets and weak- ties ( Bakshy et al. , 2012 ; An et al. , 2011 ; Sun et al. , 2013 ) . While being very valuable contributions to the literature , these studies often focus on American users and they de- fine information diversity either as “ novelty ” , or “ source diversity ” . However , as we will show below , novel infor- mation does not necessarily contribute to information di- versity and highly competitive media markets with many sources may still result in excessive sameness of media con- tents . As we will argue , marginalized members of segre- gated groups , structurally underprivileged actors and mi- norities must receive special attention and just measuring number of available sources will not guarantee viewpoint diversity . In this paper , we contribute with a framework to an- alyze and understand the impact of political culture in Twitter . Rather than reducing the concept viewpoint di- versity to a single quantity or metric , we introduce differ- ent dimensions of viewpoint diversity , based on previous studies and the theory from communication studies and political philosophy . In addition , we provide a set of new metrics and operationalize them . Finally , we present the result of a case study we performed for Dutch and Turkish Twitter users using this framework . We show that minor- ity users can not reach a large percentage of the studied Turkish Twitter users and political culture is making a difference . 2 . Empirical Studies of Information Diversity in Social Media An empirical study performed by Facebook suggests that online social networks may increase the spread of novel information and of diverse viewpoints . According to Bakshy ( 2012 ) , even though people are more likely to consume and share information that comes from close con- tacts that they interact with frequently , the vast major- ity of information comes from contacts that they interact with infrequently . These so-called “ weak-ties ” ( Granovet- ter , 1981 ) are also more likely to share novel information . However , there are some concerns with this study . First , Facebook does not provide open access to everyone , thus we can not repeat or reproduce the results using Facebook data . Second , our weak ties give us access to new stories that we would not otherwise have seen , but these stories might not be different ideologically from our own general worldview . They might be novel information , but not par- ticularly diverse . The concepts serendipity , diversity and novelty are different from each other ( Sun et al. , 2013 ) . The Facebook research does not indicate whether we en- counter and engage with news that opposes our own beliefs through “ weak-links ” . Twitter , with its API , provides an excellent environ- ment for information diversity research . An et al . ( 2012 ) observe extreme polarization among media sources in Twit- ter . In another study , they found that , when direct sub- scription is considered alone , most Twitter users receive only biased political views they agree with ( An et al. , 2011 ) . However , they note that the news media land- scape changes dramatically under the influence of retweets , broadening the opportunity for users to receive updates from politically diverse media outlets . Sun et al . ( 2013 ) performed an empirical study using statistical models to identify serendipity in Twitter and Weibo . Using like- lihood ratio test and by measuring unexpectedness and relevance , they observe high levels of serendipity in in- formation diffusion in microblogging communities . Saez- Trumper et al . ( 2013 ) found that political bias is evident in social media , in terms of the distribution of tweets that dif- ferent stories receive . Further , statement bias is evident in social media ; a more opinionated and negative language is used than the one used in traditional media . Twitter users are more interested in what is happening directly around them and what is happening to those around them . While communities talk about a broad range of news , Twitter users dedicate most of their tweets to a few of them ( Saez- Trumper et al. , 2013 ) . Wei et al . ( 2013 ) found that indi- vidual journalists have the strongest influence on Twitter for UK users . Further , they observed that all influential British Twitter users ( mainstream media , journalists and celebrities ) display some kind of bias towards a particular political party in their tweets . Jurgens et al . ( 2011 ) show that certain individual German Twitter users act as gate- keepers , especially in the distribution of political informa- tion . Those users are also not neutral hubs . They tend to curate political information and post messages that they find important ( Jiirgens et al. , 2011 ) . 3 . Theory In this section , we first give a short overview “ infor- mation diversity ” and explain why it is a vital value for a democratic society . Later , we show different dimensions of this value and show how it can be defined . 3.1 . Information Diversity A cyberbalkanized Internet or “ filter bubble ” is not acceptable in different models of modern democracy . Ag- gregative versions of democracy hold that legitimacy lies in the fair counting of votes casted by informed voters Held ( 2006 ) . Deliberative democrats on the other hand hold that a decision is only legitimate if it is determined by fair , informed deliberations ( Fishkin , 1993 ; Cohen , 2009 ) . Because no set of values or preferences can claim to be correct by themselves , they must be justified and tested through social encounters which take the point of view of others into account ( Held , 2006 ) . In addition to the nor- mative value of discussion , information-sharing is required for many of the practical benefits that proponents of de- liberation hope deliberative institutions will provide , such as higher quality policy , greater appreciation of the views of the opposing side , cultural pluralism and citizen wel- fare ( Napoli , 1999 ) . According to deliberative democrats , we must focus on why and how we come to adopt our views , and whether they can be defended in a complex social setting with people with opposed preferences . This will complement voting , the necessary mode of participa- tion , by a “ conscious confrontation of one ’ s own point of view with an opposing point of view , or of the multiplicity of diverse viewpoints that the citizen , upon reflection , is likely to discover within his or her own self ” ( Offe & Preuss , 1990 ) . Under conditions of ideal deliberation , ‘ no force ex- cept that of the better argument is exercised ’ ( Habermas , 1975 ) . Information diversity is also an important concept in communication studies . The freedom of media , a multi- plicity of opinions and the good of society are inextricably connected ( Napoli , 1999 ) . Free Press theory , a theory of media diversity , states that we establish and preserve con- ditions that provide many alternative voices , regardless of intrinsic merit or truth , with the condition that they emerge from those whom society is supposed to benefit its individual members and constituent groups ( van Cuilen- burg & McQuail , 2003 ) . What is good for the members of the society can only be discovered by the free expres- sion of alternative goals and solutions to problems , often disseminated through media ( Napoli , 1999 ) . While many scholars from different disciplines agree that information diversity is an important value that we should include in the design of institutions , policies and online services , this value is often reduced to a single defi- nition , such as “ source diversity ” , or “ hearing the opinion of the other side ” . In the next subsections , we explain that just having a deliberation is not enough , and that a bias against arguments made by deliberators who are in the minority in terms of their interests in the decision being made can exist . 3.2 . Dimension of Information Diversity Following Napoli ( 1999 ) , we may distinguish three dif ferent dimensions of information diversity . The first di- mension is source diversity , which is diversity in terms of outlets ( cables and channel owners ) or program produc- ers ( content owners ) . Content diversity consists of diver- sity in format ( program-type ) , demographic ( in terms of racial , ethnic , and gender ) , and idea-viewpoint ( of social , political and cultural perspectives ) . The third dimension , exposure diversity , deals with audience reach and whether users have actually consumed a diverse set of items . In US media policy , with the “ free marketplace of ideas ” theory , it is assumed that increasing source diversity will increase content diversity and exposure diversity will fol- low these two . American media policy consequently fo- cuses on source diversity by way of competition and an- titrust regulation ( van Cuilenburg , 2002 ) . However , whether more media competition ( more sources ) really brings about more media variety is highly debated and research address- ing this relationship has not provided definitive evidence of a systematic relationship ( Napoli , 1999 ; van Cuilenburg , 1999 ; McQuail & van Cuilenburg , 1983 ; Karppinen , 2013 ) . Highly competitive media markets may still have low con- tent diversity and media monopolies can produce highly diverse supply of media content ( van Cuilenburg , 2002 ) . It has also been argued that to fulfill the objectives of the marketplace of ideas metaphor , policymakers need to focus on exposure diversity . So , one should not look at availabil- ity of different sources or content , but whether the public consumes a diverse set of items ( Napoli , 1999 ) . 3.3 . Minorities and Openness Karppinen ( 2009 ) argues that the aim of media diver- sity should not be the multiplication of genre , sources or markets , but giving voice to different members of the soci- ety . We should not see diversity as something that can be measured through the number of organizations or channels or just “ having two parties reach all citizens ” . Karppinen holds that we should focus on democratic distribution of communicative power in the public sphere and whether everyone has the chance and resources to get their voices heard . Karppinen argues : “ the key task for media pol- icy from the radical pluralist perspective is to support and enlarge the opportunities for structurally underprivileged actors and to create space for the critical voices and so- cial perspectives excluded from the systematic structures of the market or state bureaucracy ” ( Karppinen , 2009 ) . If democratic processes and public policies exclude and marginalize members of segregated groups from political influence to the extent that privileged groups often domi- nate the public policy process , they will magnify the harms of segregation . These “ minorities ” must be politically mo- bilized and included as equals in a process of discussing issues ( Young , 2002 ) . McQuail and van Cuilenburg ( 1983 ) propose to assess media diversity by introducing two normative frameworks . The norm of reflection checks whether “ media content pro- portionally reflects differences in politics , religion , culture and social conditions in a more or less proportional way . The norm of openness checks whether media “ provide per- fectly equal access to their channels for all people and all ideas in society . If the population preferences were uni- formly distributed over society , then satisfying the first condition ( reflection ) would also satisfy the second condi- tion ( equal access ) . However , this is seldom the case ( van Cuilenburg , 1999 ) . Often population preferences tend to- ward the middle and mainstreams . In such cases , the media will not satisfy the openness norm , and the pref- erences of the minorities will not reach a larger public . This is undesirable , because “ social change usually be- gins with minority views and movements ( ... ) asymmetric media provision of content may challenge majority prefer- ences and eventually may open up majority preferences for cultural change in one direction or another ” ( van Cuilen- burg , 1999 ) . Van Cuilenburg ( 1999 ) argues that the Inter- net has to be assessed in terms of its ability to give open access to new and creative ideas , opinions and knowledge that the old media do not cover yet . Otherwise it will only be “ more of the same ” . 4 . Polarization in the Netherlands and Turkey Before discussing methods and the results of our em- pirical study that focused on Dutch and Turkish users , we give a short overview of political diversity for those two countries and explain why they are interesting for a case study on information diversity . 4.1. the Netherlands Pillarization ( Dutch : “ verzuiling ” ) is a process that occurred in the Netherlands and reached its highest point in 1950s . During this period , several ideological groups making up Dutch society were systematically organized as parallel complexes that were mutually segregated and polarized ( van Doorn , 1956 ; Post , 1989 ) . As part of this social apartheid dividing the population into subcultures , political parties were used for political mobilization of the ideologically and religiously defined groups and social ac- tivities were concentrated within the particular categori- cal group ( Steininger , 1977 ) . Few contact existed between the different groups and internally the groups were tightly organized ( Lijphart , 1968 ) . Elites at the ‘ top ’ level com- municated , while the ones at the ‘ bottom ’ did not . Pillar- ization had an effect on parental choice of an elementary school for children , the voting for political parties and the choice on which daily newspaper to read ( Kruijt , 1962 ) . People belonging to a pillar retreated into their own orga- nizations and entered into a ‘ voluntary ’ isolation , because they perceive that values important to them were threat- ened ( Marsman , 1967 ) . Depillarization ( Dutch : “ ontzuiling ” ) started in mid 1960 ’ s as a democratization process and pillarization has lost much of its significance since the 1960 ’ s as a result of secularization and individualization . Even though depil- larization has started , many institutional legacies in present- day Netherlands still reflect its pillarized past , for example in its public broadcasting system or in the school system ( Vink , 2007 ) . The Netherlands continues to be a country of minorities , which may be a main reason that consensus seems so ingrained in the Dutch political culture ( Peter van der Hoek , 2000 ) . The Dutch parliament currently has 12 political parties . Due to the very low chance of any party gaining power alone , parties often form coalitions . The Netherlands has created several media policies to implement diversity in the media . The Media Monitor , an independent institution , measures ownership concen- tration , editorial concentration and audience preferences ( Aslama et al. , 2007 ) . It also measures diversity of televi- sion programming on the basis of a content classification system , by categorizing program output in categories like news and information , education , drama , sports , etc . ( Me- diamonitor , 2013 ; van Cuilenburg , 2002 ) . 4.2 . Turkey Turkey has regularly held free and competitive elec- tions since 1946 . The country has alternated between a two-party political system and a multi-party system . Elec- toral politics has often been dominated by highly ideolog- ical rival parties and military inventions changed the po- litical landscape several times ( Tessler & Altinoglu , 2004 ) . Elections in 2002 led to a two-party parliament , partially due to a ten per cent threshold . The Justice and Develop- ment Party ? ( AKP ) won the elections and still is the ruling party , having an absolute majority . The parliament is cur- rently formed by 4 political parties . While AKP has 59 % 1 Adalet ve Kalkinma Partisi of the MP ’ s , secular Republican People ’ s Party ? ( CHP ) has 24 % . AKP ’ s dominance and the despair and sense of marginal ization felt by its opponents threaten to create a polit- ical polarization . Muftuler-Bas and Keyman ( 2012 ) ar- gue that “ many other polarizing social and political strug- gles remain unresolved in Turkey , and mutually antago- nistic groups remain unreconciled . This social and po- litical polarization remains potentially explosive and re- duces the capacity for social consensus and political com- promise ” . Similarly Unver ( 2011 , p.2 ) claims that “ the so- ciety is pushed towards two extremes that are independent of party politics . ( ... ) Competing narratives and ‘ realities ’ clash with each other so intensely , that the resultant effect is one of alienation and ‘ otherness ’ within the society. ” Some scholars argue that , the top-down imposition of concepts such as democracy , political parties and parlia- ment as part of westernization efforts is causing the socio- political polarization in Turkey ( Altintas , 2003 ) . Agirdir ( 2010 ) argues that “ the system does not breed from the diverse interests and demands of the society , but around the values and interests of a party leader and the nar- row crew around her ” . Economic voting behavior , religios- ity , and modern versus traditional orientation seem to be the strongest drivers of polarization ( Yilmaz et al. , 2012 ) . Some argue that , after 2011 polarization has increased and reached its highest points in Turkish history ( Ozturk , 2013 ) . The difference of opinion between different clus- ters about secularity , tolerance and political change issues in total contradiction of each other , therefore a danger of absolute social polarization is imminent ( Agirdir , 2010 ) . Kiris ( 2011 ) observes an identity-based polarization , be- tween secularists and islamists , between Turkish national- ists and Kurdish Ethnic Nationalists , and between Alevis and Sunnis ( different sects of Islam ) . Turkish Radio Television Supreme Council ( RTUK ) was established in order to control whether Turkish lan- guage , Turkish history , historical values , Turkish way of life , thoughts and feelings are being given a significant place in broadcasting programs ( Acar , 2004 ) . RTUK is sometimes referred as “ the Censure Board ” ( Miiftiiler Bac , 2005 ) and its decisions of penalizing the broadcasters have been criticized domestically and internationally ( Baris , 2007 ; Demir & Ben-Zadok , 2007 ) . RTUK does not have a diver- sity policy and the lack of diversity in programme-making is said to undermine the quality of the audio-visual media ( Baris , 2007 ) . 4.3 . Conclusion In short , The Netherlands and Turkey are two differ- ent countries in terms of political landscape and diversity policy . The Dutch society is less polarized than it was half a century ago , while the Turkish society is thought to be heavily polarized . The Dutch Parliament contains many 2Cumbhuriyet Halk Partisi political parties , no party has absolute power to govern alone . Turkey , on the other hand has few political parties represented in the government and the ruling party has almost 60 % of all the seats . Further , the Dutch media is regulated with a diversity policy . While Turkey has a sim- ilar institution , it acts more as a censor board and does not employ an active diversity policy . If the social net- working platforms mirror the society , then we can expect the Dutch users to receive more diverse content , while the Turkish users to be more polarized and have a less diverse newsfeed . 5 . Method In this section we provide our method of data collec- tion , present our research model and the metrics we oper- ationalized to measure information diversity . 5.1 . Data collection In January 2013 , over a period of more than one month we crawled microblogging data via the Twitter ’ s REST and streaming APIs * . We started from a seed set of Dutch and Turkish Twitter users U , , who mainly publish news- related tweets . We have selected different types of users including mainstream news media , journalists , individual bloggers and politicians . The list of these “ influential ” users were picked up from different ranking sites . For the Dutch ranking , we used Peerreach * , Twittergids® and Haagse Twitter-stolp® . For Turkish ranking , we used Twit- terTurk ’ and TwitterTakip® . This resulted in two lists for Turkey and the Nether- lands , both containing seed users categorized in political groups , which differed per country . We mapped the polit- ical leaning of Dutch seed users into five groups and the political leaning of Turkish seed users into nine groups . We did this using a number of public sources ( Krouwel , 2008 ; van der Eijk , 2000 ; Trendlight , 2012 ; Carkoglu & Kalay- cioglu , 2007 ) . Later , we defined some of the seed users as a “ minority ” . We did this by selecting seed users who belong to a political party that is either not represented in the parliament , or is represented with few MP ’ s . We also included MP ’ s of a large political party who belong to an ethnic minority . That makes for instance the Kur- dish Party BDP and its MP ’ s a minority in Turkey , while we consider the Greens as a minority in the Netherlands . See Appendix A for a list of minorities . Both user groups defined as minorities create about 15 % of the all observed tweets for both countries . 3https : //dev.twitter.com/ “ http : //peerreach.com/lists/politics/nl Shttp : //twittergids.nl/ Shttp : //alleplanten.net/twitter/site/de-resultaten/belangrijke- personen/ Thttp : //twitturk.com/twituser/users/turk Shttp : //www.twittertakip.com/ By monitoring the Twitter streams of U , , we were able to add another set of users U , , , who followed and retweeted at least 5 items from users in U , . After removing users who were involved in spam , we had 1981 Dutch users and 1746 Turkish users . After crawling seed user tweets and identify the retweets made by their followers , we operationalized various metrics . In the following subsections , we explain the translation of research questions into metrics . 5.2 . Research questions The main question in this research is the following : “ Does offline political segregation affect information di- versity in Twitter ? ” . To answer this question , we have provided some sub-questions . 1 . Q1- Seed User Interaction : Do seed users from one end of the political spectrum ever tweet links from another category ? Do they reply to each other ? The results of this question is relevant to the previ- ously conducted studies that studied media bias on Twitter , such as Wei et al . ( 2013 ) 2 . Q2 - Source Diversity : Is the newsfeed of so- cial media users diverse ? Are they receiving updates from a diverse set of users ? Does indirect exposure ( e.g. , via retweets or weak-links ) increase diversity marginally ? Result of these questions are relevant to the previously conducted studies , such as An et al. ’ s ( 2011 ) . 3 . Q3- Output Diversity : Do users share items from a diverse set of users or mainly from the same politi- cal category ? This question is relevant to the frame- work provided by Napoli , which we have mentioned in Section 3.2 . 4 . Q4 - Openness/Minority Diversity : Can mi- norities reach the social media users , so that “ equal access ” principle is satisfied ? Or can only the ” popu- lar ” reach a bigger public ? This question is relevant to the normative theory of McQuail & van Cuilen- burg ( 1983 ) and Karppinen ( 2013 ) , which we dis- cussed in Section 3.3 . 5 . Q5 - Input-Output Correlation : Do users post political messages whose political position reflects the political position of those messages that the users receive ? Or do the messages they choose to retweet show a political position significantly skewed from the political position of the messages which they re- ceive ? Result of this question is relevant to the pre- viously conducted studies such as Jurgens et al. ’ s ( 2011 ) . 5.3 . Entropy While translating the concepts introduced in the pre- vious subsection into metrics , we apply the following en- tropy formula used by van Cuilenburg ( 2007 ) to measure traditional media diversity , which is based on the work of Shannon ( 1948 ) : — ( 2 ( pi log pi ) /log ( n ) ) ( 1 ) In van Cuilenburg & van der Wurff ( 2007 ) , p ; repre- sents the proportion of items of content type category 7. n represents the number of content type categories . We use this formula for calculating source diversity and exposure diversity in our Twitter study . For instance in source di- versity , p ; represents incoming tweets from seed users with a specific political stance , while n represents all possible categories . As a result of this formula , the user will have a diversity between 0 and 1 , where 0 represents minimum diversity and 1 represents maximum diversity . Figure 1 shows a user that receives equal amount of tweets ( 20 ) from all political categories and has an incoming diversity of 1 . The user only retweets from one political category ( 10 from Category 1 ) , therefore she/he has an outgoing diversity of 0 . Political Political category 1 category 1 “ ai 0 Political Political category 2 category 2 category 3 category 3 Figure 1 : Applying entropy 5.4 . Translating Research Questions into Metrics Source Diversity : For each user , we used Equation 1 to calculate his/her source diversity . For a user A , we compare the tweets published by A ’ s direct followees ( people A follows ) from different groups of which the political leanings have been categorized as discussed above ( See Figure 2 ) . This gives us a user ’ s direct input entropy . We then also added the tweets A gets through retweets and investigated if A receives more diverse information through indirect media exposure ( See Figure 3 ) . This provides us a user ’ s indirect input entropy . In both of figures , arrows show the information flow . Output Diversity : To measure what the user is sharing after she/he was exposed to different incoming infor- mation , we used Equation 1 to compare the retweets and replies she/he makes for each political category . Political category 1 Political category 2 Political Political category 1 Political category 2 Political category n Figure 3 : Indirect source diversity User A category n ( ) Figure 2 : Direct source diversity O- O- UserB Minority news source tweets ¥ UserA “ a User B retweets tweets Minority news source Figure 4 : Minority access Political Political category 1 20 category 1 5 Or } Political it ] User te Political category 2 ‘ category 2 \\ Political 5 Political category 3 category 3 Figure 5 : Input-Output Correlation Openness/Minority Diversity : For this definition of di- versity , we first defined all seed users who belong to a political party that is either not represented in the parliament , or is represented with few MP ’ s . We also included MP ’ s of a large political party who be- long to an ethnic minority . That makes for instance the Kurdish Party BDP and its MP ’ s a minority in Turkey , while we consider the Greens as a minor- ity in the Netherlands . See Appendix A for a list of minorities . Both users defined as minorities cre- ate about 15 % of the all observed tweets for both countries . We then looked whether the user is receiving mi- nority tweets directly or indirectly . For instance , in Figure 4 , User A is receiving minority tweets by di- rect subscription , but also indirectly via User B . We defined two metrics to measure minority access . We first look at the ratio of minority tweets a user gets out of all minority tweets : # received minority tweets ror ™1 '' ” .s oaeeeer ” 2 # all published minority tweets ( 2 ) We later calculate the ratio of minority tweets in a users ’ timeline # received minority tweets ( 3 ) # received tweets from seeds Input-Output Correlation : For each user in our sam- ple we look whether the maximum number of the po- litical position of the messages retweeted by a user is significantly skewed from the political position of the messages that she/he receives . max ( incoming political category ) == max ( outgoing political ca ( 4 ) For instance , Figure 5 shows a biased user which re- ceives most items from category 1 , and also retweets mainly from category 1 . 6 . Results This section shows the results for the defined metrics . We tested statistical significance of our results with a two- tailed t-Test where the significance level was set to a = 0.01 unless otherwise noted . Figures 6 and 7 show the distribution of the seed users for both countries . Figures 8 and 9 show the distribution of regular users . We see that our selection of popular users covers the political spectrum and it is not concentrated on a single political category . We have used several sources to do the seed user categorization ( Krouwel , 2008 ; van der Eijk , 2000 ; Trendlight , 2012 ; Krouwel , 2012 , 2008 ; Baris , 2007 ) . We used the retweet behavior of the users to as- sign them to a political category to identify their political stance . 6.1 . Seed User Interaction To answer research question Q1 , Tables la and 1b show the retweet and reply behavior of seed users . Each row shows the category of users who retweet an item or reply to another user . The columns show the source of their retweet or the user they interact with . We observe that 73 % of the left seed users retweet only from left users and reply to left users , while 72 % of the right users do the same . The situation is more extreme for Turkish seed users : 93 % of left seed users only retweet from and reply to left users , while 94 % of the right seed users show the same behavior . 6.2 . Source and Output Diversity Table 2a shows the results for research questions Q2 and Q3 . Here we see that on a scale of 0 to 1 , the di- versity of the incoming tweets for an average user is ap- proximately 0.6 and the results are not very different for both countries . While diversity is not perfect , we do not observe a true cyberbalkanization and we do not observe a significant difference between two countries . We observe that indirect communication ( retweets ) does increase di- versity , but not dramatically . Figure 10 and Figure 11 show the distribution of source diversity among users . We observe that , indirect communication decreases the num- ber of users who have a diversity approaching 0 for both countries . Approximately 27 % of the Dutch and 29 % of the Turkish users have an indirect diversity less than 0.5. neutral 10 % ~ center-left 15 % center- right 3 % Figure 6 : Dutch seed user distribution nationalist socially 6 % liberal 16 % > + 8 % 9 % 56 Figure 7 : Turkish seed user distribution center- right 5 % neutral 1 % Figure 8 : Dutch user distribution Social Liberals — 19 % conservati Neutrals 9 % Nationalis ts 3 % Kemalists 11 % Figure 9 : Turkish user distribution However , if we look at the diversity of an average user ’ s output , we see much lower numbers . As Table 2b shows , on a scale of 0 to 1 , retweet diversity is 0.43 for the Dutch and 0.40 for the Turkish users . If we look at reply diversity , it is 0.42 for the Dutch and 0.29 for the Turkish users . Figures 12 and 13 show the distribution of output ( retweet and reply ) diversity among the population . About 55 % of the Dutch and 66 % of the Turkish users have a retweet diversity lower than 0.5 , and about 17 % of the Dutch and 12 % of the Turkish users have a retweet diversity lower than 0.01 ( p < 0.001 ) . About 61 % of the Dutch and 77 % of the Turkish users have a reply diversity lower than 0.5 , and about 24 % of the Dutch and 26 % of the Turkish users have a reply diversity lower than 0.01 ( p < 0.001 ) . This means that the users show bias for both their retweet and reply preferences and especially the Turkish reply diversity is quite low . 6.3 . Opennes/Minority Diversity Table 2d shows the results for the research question Q4 . First row , which we call “ minority reach ” shows the result for Equation 2 and the second row , which we call “ minority exposure ” shows the result for Equation 3 . Minority reach measures how many percent of all the produced tweets by minorities reach an average user . Minority exposure checks the ratio of minority tweets in a user ’ s newsfeed . We observe that an average Dutch Twitter users will re- ceive 15 % of the produced minority tweets , whereas an average Turkish user will only receive 2 % of them . Later , we observe that minority tweets make up 23 % of an av- erage Dutch users ’ incoming tweets from seed users , while it only makes up 2 % for a Turkish user . Figures 14 and 15 show the distribution of users for this metric . Here we observe a significant difference between two countries ( p < 0.001 ) . About 55 % of the Turkish users have a minor- ity exposure under 0.05 and 57 % of them have a minority reach under 0.05 . The percentages are much lower for the Dutch users : 14 % and 23 % respectively . This means that more than half of the Turkish users are missing almost all the updates produced by the minorities and their newsfeed contains almost no minority tweets at all . This includes indirect minority tweets thanks to retweets done by their friends . 6.4 . Input-Output Correlation Table 2c shows the results for the research question Q5 . The first row shows the number of users whose out- put correlates with their input . Such users make up 33 % of the Dutch and 47 % of the Turkish userbase . Further , if we only consider a bias towards a certain political cate- gory that is higher than 15 % ( for both input and output ) , 26 % of the Dutch and 36 % of the Turkish users show this behavior . Table 1 : Seed user bias ( a ) Netherlands User / Source | Left | Right Left 73 % | 27 % Right 28 % | 72 % ( b ) Turkey User / Source | Left | Right Left 93 % | 7 % Right 6 % | 94 % Table 2 : Different dimensions of diversity . NL = the Netherlands , TR = Turkey . ( a ) Source Diversity ( on a scale of 0 to 1 ) NL | TR Direct 0.63 | 0.58 Indirect | 0.68 | 0.62 ( b } Output Diversity ( on a scale of 0 to 1 ) NL | TR Retweet | 0.43 | 0.40 Reply 0.42 | 0.29 ( c } Input-Output Correlation NL | TR # users | 657 | 828 % users | 33 % | 47 % ( d } Openness/Minority Diversity NL | TR minority reach 15 % | 2 % minority exposure 23 % | 2 % % users under < 0.05 reach 14 % | 57 % % users under < 0.05 exposure | 23 % | 55 % 1 > | = Dutch 20.8F 5 Turkish = Tf WwW 0.6F 5 ft a L £04 S [ o | Q 0.27 Oks 1 1 1 1 1 L 1 1 L 1 1 1 L 0 % 25 % 50 % 75 % 100 % Users Figure 10 : Direct source diversity If ost 7 Dutch > | Turkish Qa | = 0.6F 5 L uw L 2 0.47 & L 0.25 0 Ca 1 L L L 0 % 25 % 50 % 75 % 100 % Users Figure 11 : Indirect source diversity 10 Ouput Entropy Ouput Entropy 1T t = Dutch 0.8 [ Turkish 0.6F 0.4+ 0.2 7 Ort 1 = 1 1 1 L 1 1 1 1 1 L 0 % 25 % 50 % 75 % 100 % Users Figure 12 : Output diversity ( retweet diversity ) 1F : oak = '' Dutch Turkish 0.6+ 0.4+ 0.2+ 0 C L = 1 L L 0 % 25 % 50 % 75 % 100 % Users Figure 13 : Output diversity ( reply diversity ) o 9 oO ow o iB Minority reach o nD So Figure 14 : Minority Reach 4 o © 4 o o o is Minority exposure o nO 2 : Minority Exposure 7 . Discussion In this study we have shown different dimensions of diversity and discussed an additional dimension , namely minority access . This dimension has not been previously been subjected to large-scale quantitative validation . How- ever , as many communication scholars and philosophers have argued , while the media should reflect the preferences present in the society , it should also allow equal access to everyone , including those whose common social location tends to exclude them from political participation . Public life needs to include differently situated voices , not just the majority . We have shown that different definitions of diversity can be operationalized in different metrics and the ques- tion whether “ the filter bubble exists in social media ” will have different answers depending on the metric and po- litical segregation of the observed country . For instance , according to the results of our study , source diversity does not differ much for Turkish and Dutch users and we cer- tainly can not observe a bubble . However , if we consider output , then we see that the diversity is much lower . Fur- ther , if we consider the minority access as a diversity met- ric , we see that minorities can not reach a large percentage of the Turkish population . Twitter , with its 140 character limitation , is not the ideal platform for deliberation . However , having a diverse information stream in Twitter is still important , as it can serve as an input for deliberation elsewhere . Information intermediaries such as Twitter could have a considerable influence in nudging people towards more valuable and di- verse choices ( Helberger , 2011 ) . Media diversity has been an important policy objective for the regulation of tradi- tional media ( van Cuilenburg & McQuail , 2003 ) . Journal- ism ethics requires the newspapers to have a balanced and fair coverage of news and opinions and editors and jour- nalists to minimize bias in their filtering decisions . In the abundance of digital online information and algorithmic filters to deal with information overload , bias should also be minimized and ideas and opinions of minorities should not be lost . Design choices in software codes and other forms of information politics still largely determine the way infor- mation is made available and who can speak to whom under what condition ( Karppinen , 2009 ) . According to Karppinen ( 2009 ) , it is important to make decisions about standards , because those “ can have lasting influence on media pluralism , even if they are not necessarily recog- nized as sites of media policy as such ” . However , making minority voices reach a wider public is no easy matter . While identifying minorities and their valuable tweets is no easy task , showing these items to “ challenge averse ” users is a real challenge ( Munson & Resnick , 2010 ) . For instance Munson et al . ( 2013 ) provided people with feed- back about the political lean of their reading behaviors and found that such feedback had only a small effect on nudging people to read more diversely . More research is needed to understand how users ’ reading behavior change and to determine the conditions that would allow such a change . Further , normative questions arise while making de- sign decisions . When designing diverse recommendation systems , it is definitely a challenge to determine which view is “ valid ” . For instance , should a recommendation system show all viewpoints in the climate change debate , if some viewpoints are not empirically validated or simply seen as false by the majority of the experts ? Should a viewpoint get equal attention even if it provides no infor- mation or only contains arguments with fallacies ? These questions would need to be addressed by a good ethical analysis before design decisions of such systems are made . 8 . Limitations This study has several limitations . First of all , next to the accounts of traditional media outlets on Twitter , we also selected politicians and bloggers . While they mainly tweet political matters , it is possible that they have shared personal and non political matters as well . Second , while the results give us an idea on the polit- ical landscape of the studied countries , Twitter does not represent ‘ all people ’ . As boyd and Crawford ( 2011 ) have stated , “ many journalists and researchers refer to ‘ peo- ple ’ and ‘ Twitter users ’ as synonymous ( ... ) Some users have multiple accounts . Some accounts are used by mul- tiple people . Some people never establish an account , and simply access Twitter via the web ” . Therefore we can not conclude that our sample represent the real population of the studied countries . Third , input-output correlation does not always impli- cate that the volume of the content affects the items users share . Users might already be biased before they select their sources and can therefore follow more from certain sources and share from certain categories . Fourth , users will make different uses of Twitter . Some might use it as its primary news source , therefore following mainstream items , while others will use it to be informed of the opposing political view or to find items missing in the traditional media . Therefore , we do not know why some users only follow sources from a specific political category . More qualitative studies are needed . Fifth , retweets in Twitter can be made for different purposes . There is a difference between endorsement retweets ( created by pushing the retweet button ) and informal tweets ( where users include most of the same text often prefixed by ‘ RT ’ or similar but also add their own comments before or after the tweet ) . These two actions measure a different interaction . Informal retweets and replies could also ex- press disagreement and show us deliberation . In order to make a distinction between these two types of tweets , we need semantic analysis . We are not aware of the availabil- ity of such tools for the Turkish language , therefore we were unable to perform such an analysis . While informa- tion diversity is important not only for deliberative models 12 of democracy , it would be very useful to study deliberation on Twitter by using such tools in the future . Sixth , users could retweet or reply with bad intentions , such as trolling . For retweets , we only measured users ’ retweets to original tweets created by seed users . We as- sume that , those powerful political actors would not take part in trolling . Users can retweet a seed user ’ s tweet ran- domly or for trolling purposes . Same issue can manifest itself in replies . Since we did not perform a semantic anal- ysis , this remains a limitation . 9 . Conclusion and Future Work In this paper , we have introduced a framework that lists metrics used in the previous social media analytics studies and added new ones using the theory from other fields . As one of the outcomes of the results from the pre- vious section , we showed how minority access is missing from the typical dimensions of viewpoint diversity studied by computer scientists and the impact it has on viewpoint diversity analysis . To our knowledge , this is the first work that provides an overview of all the used metrics in so- cial media analytics literature and the first study to apply an “ openness ” metric . Building on this framework , new studies can be performed for different countries and po- litical cultures . For instance , Belgium , a country where different languages are spoken in different regions is an an interesting case to apply our framework . In the recent months , Turkey experienced several po- litical protests that spontaneously erupted against the de- struction of trees and the building of a shopping mall at Gezi Park in Taksim Square and large scale corruptions within the government . Twitter and Facebook played a vi- tal role during these movements and became the only com- munication medium when traditional media performed self- censorship ( Dorsey , 2013 ; Hammond & Angell , 2013 ; Ok- tem , 2013 ) . It would be very useful to see whether the political stance of our observed users have changed . It is also challenging to identify the opinion leaders during these movements and find whether they communicate with each other or form their own “ bubbles ” . It is further valuable to see if minorities were able to reach a wider public during those protests . A hashtag based political communication or an extension of our methodology could bring new in- sights . Our study was focused on Twitter and studied whether users have put themselves in bubbles by following indi- viduals from only one end of the political spectrum and showed a biased sharing behavior . Twitter itself does not employ a personalization algorithm in a user ’ s timeline . However other social networking platforms , such as Face- book , do use a personalization algorithm and filter cer- tain information on user ’ s behalf ( Bozdag , 2013 ) . Future studies can perform black-box testing techniques to deter- mine whether filters used by these platforms lead to bub- bles ( See Jiirgens ( 2013 ) ) . Creating multiple profiles while modifying certain factors , such as political affiliation , age , location , etc . can help us detect bubbles , if they exist . Appendix A : List of Minorities Dutch minorities : Keklik Yucel , SGP , Khadija Arib , Vera Bergkamp , Sadet Karabulut , Farshad Bashir , Tanja Jadnanansing , Piratenpartij NLD , Partij van de Dieren , Fatma Koser Kaya , ChristenUnie , Groenlinks , Marianne Thieme , Femke Halsema . Turkish minorities : Ayca Soylemez , Evrensel , Aydin- lik , Ozgur Gundem , Pinar Ogunc , Bianet , Sebahat Tun- cel , Sol Haber Portali , Halkin Gazetesi Birgun Yildirim Turker , BDPGenelMerkez , Ufuk Uras , Selahattin Demir- tas , Sirri Sureyya Onder , Sinan Ogan , Hasip Kaplan . Note that both minorities create about 15 % of all tweets produced by seed users . References Acar , K. ( 2004 ) . Globalization And Language : English In Turkey . Sosyal Bilimler , 2 . Agirdir , B . ( 2010 ) . Polarization in Politics and the Society . Tech- nical Report Konda Research Istanbul . Altintas , H. ( 2003 ) . The Impact of Political Parties and Urbanisation on the Process of Polarisation in the Political System . Akdeniz ktisadi ve dari Bilimler Faktiltesi Dergisi , , 3 , 1-31 . An , J. , Cha , M. , & Gummadi , K. ( 2012 ) . Visualizing media bias through Twitter . AAAI Technical Report WS-12-01 The Poten- tial of Social Media Tools and Data for Journalists in the News Media Industry , . An , J. , Cha , M. , Gummadi , K. , & Crowcroft , J . ( 2011 ) . Media Landscape in Twitter : A World of New Conventions and Polit- ical Diversity . In Proceedings of the Fifth International AAAI Conference on Weblogs and Social Media ( pp . 18-25 ) . Aslama , M. , de Bens , E. , van Cuilenburg , J. , Nordenstreng , K. , Schulz , W. , & van der Wurff , R. ( 2007 ) . Measuring and assessing empirical media diversity : Some European cases . In E. de Bens ( Ed . } , Media between Culture and Commerce ( pp . 55-98 ) . Bristol : Intellect . Bakshy , E. , Rosenn , I. , Marlow , C. , & Adamic , L. ( 2012 ) . The role of social networks in information diffusion . Proceedings of the 21st international conference on World Wide Web , ( pp . 519-528 ) . URL : http : //dl.acm . org/citation . cfm ? id=2187907 . Baris , R. ( 2007 ) . The Turkish Media Landscape . In G. Terzis ( Ed . ) } , European Media Governance : National and Regional Dimensions ( pp . 289-301 ) . Intellect . Books . Boyd , D. , & Crawford , K. ( 2011 ) . Six Provocations for Big Data . In A Decade in Internet Time : Symposium on the Dynamics of the Internet and Society . Oxford . doi:10.2139/ssrn . 1926431 . Bozdag , E. ( 2013 ) . An Algorithmic Gatekeeping Model for the Social Web , Bias in Algorithmic Filtering and Personalization . Ethics and Information Technology , 15 , 209-227 . Bruns , A . ( 2011 } . Gatekeeping , Gatewatching , Real-time Feedback . Brazilian Journalism Research , 7 , 117-136 . Carkoglu , A. , & Kalaycioglu , E. ( 2007 } . Turkish Democracy Today : Elections , Protest and Stability in an Islamie Society . New York : I.B.Tauris . Castells , M. ( 2011 ) . Press , USA . Cohen , J . ( 2009 ) . Reflections on Deliberative Democracy . In T. Christiano , & J. Christman ( Eds . ) , Contemporary Debates in Political Philosophy chapter 14 . West-Sussex , UK : Blackwell . van Cuilenburg , J . ( 1999 ) . On Competition , Access and Diversity in Media , Old and New Some Remarks for Communications Policy in the Information Age . New media & society , 1 , 183-207 . Communication Power . Oxford University 13 van Cuilenburg , J . ( 2002 } . The media diversity concept and Euro- pean Perspectives . In Media Economics , Content and Diversity Seminar Finnish Academy of Sciences . Helsinki . van Cuilenburg , J. , & McQuail , D. ( 2003 ) . Media Policy Paradigm Shifts : Towards a New Communications Policy Paradigm . Euro- pean Journal of Communication , 18 , 181-207. van Cuilenburg , J. , & van der Wurff , R. ( 2007 } . Toward Easy-to- Measure Media Diversity Indicators . In E. D. Bens ( Ed . ) , Media Between Culture and Commerce ( p. 258 ) . Intellect . Books . DellaVigna , S. , & Kaplan , E. ( 2007 ) . The Fox News Effect : Media Bias and Voting . The Quarterly Journal of Economics , . Demir , T. , & Ben-Zadok , E. ( 2007 } . Politically Driven Regulations and Enforcement : Monitoring Kurd and Fundamentalist Broad- casts in Turkey . Administration & Society , 39 , 262-293. van Doorn , J . ( 1956 } . Verzuiling : een eigentijds systeem van social controle . Sociologische Gids , 3 , 41-49 . Dorsey , S. ( 2013 } . Turkey ’ s Social Media And Smartphones Key To ’ Occupy Gezi ’ Protests . Dryzek , J. S. ( 1994 ) . Diseursive Democracy : Politics , Policy , and Political Science . Cambridge University Press . van der Eijk , C. ( 2000 ) . The Netherlands : Media and Politics be- tween Segmented Pluralism and Market Forces . In Richard Gun- ther , & Anthony Mughan ( Eds . ) } , Democracy and the Media : A Comparative Perspective ( p. 510 ) . Cambridge University Press . Fishkin , J. S. ( 1993 } . Democracy and Deliberation : New Directions for Democratic Reform . Yale University Press . Glynn , C. J. , Herbst , S. , O ’ Keefe , G. J. , Shapiro , R. Y. , & Lindeman , M. ( 2004 ) . Public Opinion . Westview Press . Granovetter , M. S. ( 1981 ) . The strength of weak ties : a network theory revisited . State University of New York , Department of Sociology . Habermas , J . ( 1975 ) . Legitimation Crisis . Beacon Press . Hammond , T. , & Angell , E. ( 2013 ) . Is Everywhere Tak- sim ? : Public Space and Possible Publics . Jadaliyya , URL : http : //www . jadaliyya.com/pages/index/12143/ is-everywhere-taksim_public-space-and-possible-pub . Helberger , N. ( 2011 ) . Diversity by Design . Journal of Informa- tion Policy , 1 . URL : http : //jip.vmhost.psu.edu/ojs/index . php/ jip/article/viewArticle/59 . Held , D. ( 2006 ) . Models of Democracy , 3rd Edition . Stanford Uni- versity Press . Hindman , M. ( 2008 } . The Myth of Digital Democracy . Princeton University Press . Jiirgens , P. ( 2013 ) . Measuring Personalization : An Experimental Framework for Testing Technological Black Boxes . In Society of the Query . URL : http : //networkcultures.org/wpmu/query/ tag/pascal- jurgens/ . Jiirgens , P. , Jungherr , A. , & Schoen , H. ( 2011 ) . Small worlds with a difference : New gatekeepers and the filtering of political informa- tion on twitter . In WebSei 711 . Karppinen , K. ( 2009 ) . Rethinking media pluralism and communica- tive abundance . Observatorio ( OBS * ) , 3 . Karppinen , K. ( 2013 ) . Rethinking Media Pluralism . ( onald mcga ed. ) . Fordham University Press . Kiris , H. M. ( 2011 ) . Parti Sisteminde Kutuplasma ve Tiirk Parti Ornegi . Amme Idaresi Dergisi , 44 , 33-67 . Krouwel , A . ( 2008 ) . Zo links zijn de kranten niet . Technical Report Dag . Krouwel , A . ( 2012 ) . Regeerakkoord analyse Kieskompas 2012 . URL : http : //www . kieskompas .nl/page/Home/1/nl1/content.html . Kruijt , J . ( 1962 ) . De begrippen verzuiling en ontzuiling . Socialisme en Democratie , ( pp . 791-797 ) . Lasorsa , D. , Lewis , S. , & Holton , A . ( 2012 ) . Normalizing Twitter- Journalism practice in an emerging communication space . Jour- nalism Studies , 13 , 19-36 . Lijphart , A . ( 1968 ) . The politics of Accommodation : Pluralism and Democracy in the Netherlands . University of California Press . Marsman , G. ( 1967 ) . De katholieke dagbladpers in sociologisch per- spectief . Nimegue : Van Gorcum . McQuail , D. , & van Cuilenburg , J. J . ( 1983 ) . Diversity as a Media Policy Goal : a Strategy for Evaluative Research and a Netherlands Case Study . International Communication Gazette , 31 , 145-162 . Mediamonitor ( 2013 ) . The concept of pluralism : me- dia diversity . URL : http : //www.mediamonitor.nl/english/ the- concept-of-pluralism-media-diversity/ . Miiftiiler Bac , M. ( 2005 ) . Turkey ’ s Political Reforms and the Impact of the European Union . South European Society and Politics , 10 , 17-31 . Muftuler-Bas , M. , & Keyman , F. E. ( 2012 ) . Turkey Under the AKP . Journal of Democracy , 23 , 85-99 . Munson , 8. , & Resnick , P. ( 2010 ) . Presenting diverse political opin- ions : how and how much . In Proceedings of the SIGCHI Confer- ence on Human Factors in Computing Systems , CHI 2010 ( pp . 1457-1466 ) . New York , New York , USA . Munson , S. A. , Lee , 8 . Y. , & Resnick , P. ( 2013 } . Encouraging Read- ing of Diverse Political Viewpoints with a Browser Widget . In In- ternational Conference on Weblogs and Social Media ( ICWSM ) . Boston . Napoli , P. ( 1999 ) . Deconstructing the diversity principle . Journal of Communication , 49 , 7-34. doi:10.1111/j.1460-2466.1999 . tb02815.x . Offe , C. , & Preuss , U. K. ( 1990 ) . Democratic Institutions and Moral Resources . Oktem , K. ( 2013 ) . Why Turkey ’ s mainstream media chose to show penguins rather than protests . Guardian , . URL : http : //www . theguardian.com/commentisfree/2013/jun/09/ turkey-mainstream-media-penguins-protests . Ozturk , M. ( 2013 ) . Agirdir : Bugunku kutuplasma 1970 ’ lerdekinden daha vahim . Aksiyon , URL : http : //t24.com.tr/haber/ agirdir-bugunku-kutuplasma-1970lerdekinden-daha-vahimn/ 241939 , Pariser , E. ( 2011 ) . The Filter Bubble : What the Internet Is Hiding from You . New York : Penguin Press . Peter van der Hoek , M. ( 2000 ) . Does the dutch model really ex- ist ? International Advances in Economic Research , 6 , 387-403. doi:10 . 1007/BF02294959 . Pew Research ( 2012 ) . Bias Perceived in News Cover- age . URL : http : //www.pewresearch.org/daily-number/ bias-perceived-in-news-coverage/ . Post , H. ( 1989 ) . Pillarization : an analysis of Dutch and Belgian society . Vermont : Gower Publishing Company . Saez-Trumper , D. , Castillo , C. , & Lalmas , M. ( 2013 ) . Social media news communities : gatekeeping , coverage , and statement bias . In Proceedings of the 22nd ACM international conference on Confer- ence on information & knowledge management ( pp . 1679-1684 ) . New York , NY , USA : ACM . Shannon , C. ( 1948 ) . A Mathematical Theory of Communication . Bell System Technical Journal , 27 , 379 — 423 . Steininger , R. ( 1977 ) . Pillarization and Political Parties . Sociologis- che Gids , ( pp . 242-257 ) . Sun , T. , Zhang , M. , & Mei , Q . ( 2013 ) . Unexpected Relevance : An Empirical Study of Serendipity in Retweets . In Seventh International AAAI Conference on Weblogs and Social Media ( ICWSM ’ 13 ) . Sunstein , C. R. ( 2002 ) . Republic.com . Princeton University Press . Suoranta , J. , & Vadén , T. ( 2009 ) . Wikiworld . Pluto Press . Tessler , M. , & Altinoglu , E. ( 2004 ) . Political culture in Turkey : Connections among attitudes toward democracy , the military and Islam . Democratization , 11 , 22-51 . Trendlight ( 2012 ) . AD is de krant voor Henk en In- grid TrendLight . URL : = http : //trendlight.eu/ ad-is-de-krant-voor-henk-en-ingrid/ . Unver , A . ( 2011 ) . Clash of Communities : Turkey ’ s Dormant Domes- tic Cold War . Political Reflection Quarterly Journal 1 , 2 . Vink , M. ( 2007 ) . Dutch Multiculturalism Beyond the Pillarisation Myth . Political Studies Review , 5 , 337-350 . Wei , Z. , He , Y. , Gao , W. , Li , B. , Zhou , L. , & Wong , K. ( 2013 ) . Mainstream media behavior analysis on Twitter : a case study on UK general election . Labour , ( pp . 174-178 ) . Yilmaz , C. , Aygoren , O. , & Ozdemir , O . ( 2012 } . Tiurkiyede siyasi kutuplasmayi olusturan unsurlar : Secmen tercihlerinde ekonomik oy verme davranisindan toplumsal travma kuramina kadar bir dizi 14 etkenin gorece etkileri . [ ktisat Isletme ve Finans , 27 , 09-39 . Young , I. M. ( 2002 } . Inclusion and Democracy ( Oxford Political Theory ) . Oxford University Press , USA . Downloaded from https : //royalsocietypublishing.org/ on 09 November 2022 ROYAL SOCIETY OPEN SCIENCE royalsocietypublishing.org/journal/rsos 6 Check for updates Cite this article : Min Y , Jiang T , Jin C , Li Q , Jin X . 2019 Endogenetic structure of filter bubble in social networks . R. Soc . open sci . 6 : 190868. http : //dx.doi.org/10.1098/rsos.190868 Research Received : 18 May 2019 Accepted : 7 October 2019 Subject Category : Computer science Subject Areas : behaviour/hybrid computing/complexity Keywords : social network , polarization , echo chamber , controlled experiment , privacy protection Author for correspondence : Yong Min e-mail : myong @ zjut.edu.cn Electronic supplementary material is available online at https : //doi.org/10.6084/m9.figshare.c . 4721477 . THE ROYAL SOCIETY PUBLISHING Endogenetic structure of filter bubble in social networks Yong Min ' , Tingjun Jiang ' , Cheng Jin2 , Qu Li ! and Xiaogang Jin ? `` College of Computer Science and Technology , Zhejiang University of Technology , Hangzhou , People ’ s Republic of China “ Tencent Corporation , Shenzhen , People ’ s Republic of China “ Zhejiang University , Hangzhou , People ’ s Republic of China @ ® YM , 0000-0002-9387-3921 The filter bubble is an intermediate structure to provoke polarization and echo chambers in social networks , and it has become one of today ’ s most urgent issues for social media . Previous studies usually equated filter bubbles with community structures and emphasized this exogenous isolation effect , but there is a lack of full discussion of the internal organization of filter bubbles . Here , we design an experiment for analysing filter bubbles taking advantage of social bots . We deployed 128 bots to Weibo ( the largest microblogging network in China ) , and each bot consumed a specific topic ( entertainment or sci-tech ) and ran for at least two months . In total , we recorded about 1.3 million messages exposed to these bots and their social networks . By analysing the text received by the bots and motifs in their social networks , we found that a filter bubble is not only a dense community of users with the same preferences but also presents an endogenetic unidirectional star-like structure . The structure could spontaneously exclude non-preferred information and cause polarization . Moreover , our work proved that the felicitous use of artificial intelligence technology could provide a useful experimental approach that combines privacy protection and controllability in studying social media . 1 . Introduction With the growing popularity of social media , especially microblogging platforms , the way people obtain information and form opinions has undergone substantial change . A recent study found that social media has become the primary source for over 60 % of users to obtain news [ 1 ] . These users are selectively exposed to more personalized information , which is considered to limit the diversity of content they consume and give rise to filter bubbles [ 2-4 ] . News consumption on social media has been extensively studied to determine what factors lead to © 2019 The Authors . Published by the Royal Society under the terms of the Creative Commons Attribution License http : //creativecommons.org/licenses/by/4.0/ , which permits unrestricted use , provided the original author and source are credited . Downloaded from https : //royalsocietypublishing.org/ on 09 November 2022 polarization [ 5,6 ] . Recent works suggest that confirmation bias or selective exposure plays a significant role in online social dynamics [ 5,7 ] . That is , online users tend to select messages or information sources supporting their existing beliefs or cohering with their preferences and hence to form filter bubbles [ 4 ] . However , the polarization process , especially the features of filter bubbles , still needs further clarification . In collective and individual levels , the term ‘ polarization ’ has two possible meanings . One is that like- minded people form exclusive clubs sharing similar opinions and ignoring dissenting views , i.e . opinion polarization [ 5 ] ; the other is that an individual is exposed to less diverse content and is limited by a narrow set of information , i.e . information polarization [ 6 ] . For this paper , we focus on information polarization on social media . The formation mechanism of polarization and the method of restraining polarization are the most pressing issues in the field of information polarization [ 2,4,7,8 ] . Many studies have suggested that selective exposure , both self-selection , and pre-selection , limits people ’ s exposure to diverse content ( ie . filter bubble ) and increases polarization [ 9 ] . Self-selection is the tendency for users to consume content or build new relationships that confirm their existing beliefs and preferences . Pre-selection depends on computer algorithms to personalize content for users without any conscious user choice . The present research generally agrees that self-selection is the primary cause of information polarization [ 7 ] . In the chain from selective exposure to information polarization , the formation and evolution of filter bubbles play as critical a role as the amplifier [ 3,10 ] . Therefore , quantifying and measuring filter bubbles has become a central issue in studying polarization [ 11,12 ] . From the perspective of opinion polarization , filter bubbles are usually considered equivalent to the community structure ( densely connected internally ) and are measured by modularity coefficient or community boundaries [ 10,13 ] . However , the community structure reflects more of a relationship between a filter bubble and the external network , rather than the internal organization of the filter bubble . By analysing news consumption on Facebook , the internal structural features of filter bubbles have been discovered , for example , users in filter bubbles are usually only concerned with a few information sources [ 6 ] . However , the details of filter bubbles still need further research . At present , research about online social networks relies mainly on observational methods [ 6,7 ] , which means that researchers can not intervene in the study object but can only process and analyse the passively acquired data . However , the big open data contains great noise [ 14 ] and the risk of revealing privacy [ 15 ] . To overcome the shortcomings of a purely observational study , some researchers have ingeniously adopted the method of natural experiments or quasi-experiments to make comparative analyses and causal inferences from the available datasets [ 14,16-18 ] . Nevertheless , the uncontrolled approach limits the freedom of research . Recently , controlled experiments on social networks have deepened our understanding about information sharing and diffusion , behaviour spreading , voting and political mobilization , and cooperation [ 14,19-23 ] . Moreover , compared to the big data approach , controlled experiments can effectively control the impact factors , resulting in a causal relationship using a relatively small set of samples . Performing experiments on real-world social networks , while actively promoting innovation of sociology and communication studies , also brings about some serious problems [ 24 ] . For instance , the political voter mobilization experiment conducted by Robert ef al . on Facebook was sharply criticized by a considerable number of scholars , who argued that scientific research should not interfere with national politics or users ’ voting behaviour [ 22 ] . Therefore , the inappropriate design of actual large- scale social networks is likely to cause social injustice or infringe on the privacy of users . In this paper , we report an experimental approach for studying the polarization process by using social bots [ 25 ] . We deploy 128 social bots to Weibo ( NASDAQ : WB , the most famous Chinese Twitter-like service , with 430 million active monthly users ) . By analysing the data generated by these bots , we try to clarify the route from selective exposure to polarization , especially the structure and effect of filter bubbles . Most importantly , our approach is limited to using the data generated by the bots themselves , without any data about the actual person ; therefore it is a privacy-friendly approach . 2 . Method 2.1 . Social bot design A social bot is a computer algorithm that automatically interacts with the social network environment [ 25 ] . Social bots are generally considered to be harmful , although some of them are benign and , in principle , innocuous or even helpful . Therefore , social bots are often the subject of research that needs '' 998061 :9 “ DS Uado 305 y¥ sosi/feunol/biorbuysygndiaposero : Downloaded from https : //royalsocietypublishing.org/ on 09 November 2022 composing area initializing social bot HRY reading exposed news operations eS reposter Ge directed source gna ‘ original weibo y selecting preferred news selecting a reposted news I I | I manually waiting for I checking random time ! A l i legal ? yes ~ follow adding j gal : tree a new follow I no l A 4 removing , + ) illegal follow ie 4 I . i MN tid I `` closure © l Figure 1 . Design of neutral social bot . Based on the operating interface of Weibo ( left ) , we use the flowchart ( middle ) and the schematic diagram ( right ) to illustrate the main workflow of the social robot , including the automated process ( 1-4 ) and the manual assistant process ( 5 ) . to be eliminated [ 26 ] , but researchers have yet to recognize their potential value as a powerful tool in social network analysis [ 25,27 ] . The social bot in our experiment is designed to imitate similarity- based relationship formation , which reflects the selective exposure of information and relationships depending on one ’ s preferred topics . The social bot is based on two well-known hypotheses . The first is triadic closure [ 28 ] . Triadic closure suggests that among three people , A , B , and C , if a link exists between A and B , and A and C , then there is a high probability of a link between B and C. The hypothesis reflects the tendency of a friend of a friend to become a friend and is a useful simplification of reality that can be used to understand and predict the evolution of social networks . Because the relationships embedded in Weibo should be modelled by a directed graph , the bots use directed triadic closure to expand their followings ( figure 1 ) [ 29 ] . The second hypothesis is homophily [ 5 ] , ie . people who are similar have a higher chance of becoming connected . In online social networks , for example , an individual creating her new homepage tends to link it to sites that are close to her interests ( i.e . preferences ) . Based on the two hypotheses , the workflow of the bots includes five steps ( figure 1 ) . ( 1 ) Initially , each bot is assigned 2 or 3 default followings , who mostly post or repost messages consistent with the topic of the bot . ( 2 ) A bot will periodically awaken from idleness at a uniformly random time interval . When the bot awakens , it can view the latest messages posted or reposted by its followings . As is well known , not all unread information can be exposed to users of social networks . A bot can assess only the latest 50 messages ( i.e . the maximum amount in the one page on Weibo ) after waking up . Please note that we exclude the influence of algorithmic ranking and recommendation systems on the information exposure by re-ranking all possible messages according to the descending order of posting time . ( 3 ) After viewing the exposed messages , the bot selects only the messages consistent with the topic . In this step , we first run the FastText text classification algorithm [ 30 ] to get preliminary classification results . To ensure the accuracy and correctness of classification , the results from the FastText algorithm were further voted by at least three experimenters . Although manual supervision is required , this algorithm can help us filter out a large number of inconsistent messages . ( 4 ) If there are reposted messages in selected messages , according to directed triadic closure , the bot randomly selects '' 998061 :9 “ DS Uado 305 y¥ sosi/feunol/biorbuysygndtaposero : Downloaded from https : //royalsocietypublishing.org/ on 09 November 2022 a reposted message and follows the direct source of the reposted message . Please note that Weibo limits direct access to the information about the followings and followers of a user ; thus , bots must find new followings through reposting behaviour . ( 5 ) If the following number reaches the upper limit , the bot stops running ; otherwise , the bot becomes idle and waits to wake up again . The upper limit of followings for each bot is 150 , according to the Dunbar number , which is a suggested cognitive limit to the number of people with whom one can maintain stable social relationships [ 31 ] . To avoid legal and moral hazards , the bots in the experiment do not produce , modify , or repost any information . 2.2 . Experiment design We are interested in exploring the following overarching question : how does selective exposure lead to polarization ? Based on the above neutral social bots , we designed a controlled experiment to help us observe the news consumption and the evolution of personal social networks of the bots with a specific topic . For each bot , we mainly measured the following response variables : V1 : The probability that the bot is exposed to the preferred topic . For a given time t , the probability can be quantified by the preferred topic ratio ( R ) , which is the ratio of the amount of information matching the topic to the total amount of information from 0 to t. Since the running of each bot is not completely synchronized , we normalize the time scale from 0 to 1 , where t =0 represents the initial state after being given the initial user , and t = 1 represents the time when the bot ends the running . V2 : The distribution of word frequency in the preferred topic . For a word i , the word frequency ( F ) is defined as the ratio of the number of messages that contain the word ( N , ) to all exposed preferred messages of the bot ( N , ) : N ; Rar . 2.1 N , ( 2.1 ) V3 : The proportion of followings with the same preferred topic ( P ) . The preference of followers is judged according to their nickname as well as the user tags and content of their microblogs . V4 : The structure of the personal social network ( G ( n , m ) , where n is the number of nodes and m is the number of directed arcs ) of a bot , including : V4.1 : in- and out-degree distribution . V4.2 : directed clustering coefficient ( C ) [ 32 ] : x 5 ( 2.2 ) deg ’ ( x ) ( deg ' * ' ( x ) — 1 ) — 2deg™ ( x ) and C=C , for all node x , ( 2.3 ) where T ( x ) is the number of directed triangles involved node x , deg ' * ( x ) is the sum of in- degree ( deg ) and out-degree ( deg * ” ) of x and deg * ( x ) is the reciprocal degree of x. V4.3 : Connection density ( D ) : m D= Mant ) ’ ( 2.4 ) V4.4 : The dyadic and triadic motifs . Motifs are the special sub-structures indicating connecting patterns and functions in complex networks [ 33,34 ] . Motif has been applied to detect and measure controversy on Twitter [ 35 ] . In calculating motifs , we also consider the centrality ( i.e . deg™ ) of nodes in personal social networks . For V1 to V3 , we can quantify the extent of the diversity of new consumption . For V4 , we can detect the structure of filter bubbles for causing polarization . We consider two most active ‘ soft ’ topics in Weibo : entertainment and science/technology ( sci-tech ) . The entertainment topic includes celebrity gossip , fashion , movies , TV shows , music , etc . and the sci-tech topic involves nature , scientific theory , engineering , technological advances , digital products , the Internet , and so on . Compared with other topics , the two topics can be freely diffused in Weibo , have low overlap in content , and possess different user characteristics ( gender , age , education level , etc . ) [ 36,37 ] . For each topic , we designed two experimental treatments : topic group and random group . In '' 998061 :9 “ DS Uado 305 y¥ sosi/feunol/bio-buusygndhaposero Downloaded from https : //royalsocietypublishing.org/ on 09 November 2022 Table 1 . An example of a table . NEN CCelMans decal accept ( 1 ) celebrity gossip , fashion , movies , TV shows , ( 1 ) nature , scientific theory , engineering , and pop music ; ( 2 ) explicitly containing the technological advances , digital products , and name , account or abbreviation of Internet ; ( 2 ) technical company and university entertainers common reject ( 1 ) commercial advertisement ; ( 2 ) less than 5 * specific reject ( 1 ) ACG content ( i.e . animation , comic , and ( 1 ) financial or business report of technical or digital game ) ; ( 2 ) art , literature , and Internet company ; ( 2 ) price of digital products ; personal feeling ; ( 3 ) simple lyrics and lines ; ( 3 ) military equipment ; ( 4 ) daily skills ; ( 4 ) personal leisure activities ( 5 ) constellations and divination ; ( 6 ) weather forecast ; ( 7 ) environmental conservation ; ( 8 ) documentary with irrelevant content the topic group , bots select preferred content to expand their social networks , but in the random group , bots randomly choose new information sources in all exposed content disregarding the preferred topic . As a result , we have four experimental bot groups : topic environment group ( EG ) , topic sci-tech group ( STG ) , random entertainment group ( REG ) , and random sci-tech group ( RSTG ) . Each treatment contained 30-34 bots who operated on Weibo between 13 March and 28 September 2018 . The initial followings come from a large enough user pool , which contained at least 100 candidates for each preference . For each topic , all bots in the topic and the random group have the same initial followings . The idle period of all bots was 2h . Compared with the conventional method , our design is characterized by using social bots as the agents to conduct experiments in real online social media . The approach can be seen as a Monte Carlo simulation in a real-world environment by adopting an artificial intelligence algorithm . These bots act entirely on predefined hypotheses and algorithms . Therefore , our experiment can be regarded as a type of randomized assignment . 2.3 . Standard for preference classification The most significant feature of the social bots is that they can autonomously identify whether information matches their preferred topic . Therefore , the criteria of text classification are fundamental . We defined a classification standard for the two topics in our experiment ( table 1 ) . The classification criteria shown in table 1 were used to select initial followings , prepare the training corpus of the FastText classifier , manually verify , and result analysis . The unified standard can ensure consistency in the judgement of topic and the classification of text . 3 . Results and discussion 3.1 . Topic drives polarization In social media , selective exposure of information source and information has been considered the primary mechanism of polarization . By comparing the preferred topic ratio in four experimental treatments , we can reveal the link between selective exposure and information polarization . For two topics , since the initial users have been set as the users who mainly post or repost the corresponding topic , the initial ( ( =0 ) preferred topic ratio can be as high as Ro . = 76.77 % for EG and REG and R & , , . = 50.00 % for STG and RSTG on average ( figure 2a ) . Because the topic group and the random group have the same initial followings , they also have the same initial R for each topic . That is , most of the messages exposed to four groups are concentrated in the corresponding topics . Even so , the entertainment topic is more polarized than the sci-tech topic initially . The Roo is higher than 50 % ofR3 , . ( p < 0.01 , two-sided Mann-Whitney U test , 34 bots ) . Importantly , no matter how many different topics are exposed to them after a random wake-up , the bots in topic groups only '' 998061 9 “ DS Uado 305 `` y¥ sosi/feunoljbiorbuwysygndiaposero : Downloaded from https : //royalsocietypublishing.org/ on 09 November 2022 ( a ) ) © ) tof = + 2 08 G 5 rs : ” 1 1 oT + z 0 . A ~ 0.2 0 ~ T=6 Hs REG/EG RSTG/STG EG REG STG RSTG EG REG STG RSTG Figure 2 . The polarization of exposed content and followings . ( a ) The preferred topic ratio in the initial state ( 2° ) . Because the topic group and the random group have the same initial followings , they also have the same R° for each topic . ( 6 ) The preferred topic ratio in the final state R ' . ( 0 Proportion of followings with the same preferred topic ( P ) in four treatments . select a message consistent with its preference and follow the direct source of the selected news . It means that the initial ( t= 0 ) preferred topic ratio does not affect the primary experimental process of choosing messages and following users of the bots . Finally , the initial difference between EG and STG provides a baseline for our further analysis . Compared to the initial state , we are more concerned about the diversity of messages consumed by social bots after their social networks have formed ( figure 2b ) . First , at the end of the bots ( f = 1 ) , Rig declines only slightly from Roa = 76.77 % to 63.78 % , but is significantly larger than Ri , = 19.23 % . The results suggests that selective exposure is important but not sufficient for the polarization . By contrast , Rigg and Rher is similar , but greatly less than R & , ( p < 0.01 , two-sided Mann-Whitney U test , 34 bots ) . The difference between the two topics suggests whether selective exposure causes polarization to be dependent on the topic . The followings of a bot are the direct source of its news consumption . Our results showed that for the entertainment topic , the average proportion of nodes with the preferred topic Peg = 85.32 % ( up to 92.14 % and down to 73.47 % ) ( figure 2c ) ; however , Pre is only 15.27 % without selective exposure . The large difference between Pag and Prrg suggests that selective exposure can effectively filter the information source , making most of the information sources consistent with the preferred topic and thus resulting in a filter bubble . For the sci-tech topic , however , Psta = 35.33 % ( up to 47.86 % and down to 23.12 % ) , and Prstg = 14.51 % ( figure 2d ) . Based on the information diffusion mechanism of Weibo and the design of social bots , a low proportion indicates that users preferring the sci-tech topic have a high possibility of following users liking other topics , and diverse users diffuse the sci-tech content . The overlap of topics can suppress the effect of selective exposure in forming filter bubbles . The polarization is also reflected on the semantic level . In both EG and STG treatments , the word frequency of the preferred topic exposed to the social bots presents a power-law distribution ( figure 3a ) . The power-law distribution ( y~x~ * ) indicates that there are some dominant words with high word frequency in the text . Moreover , the dominance of a few words is more severe in EG than in STG ( @ = 2.23 for EG and a=4.74 for STG ) . In the EG treatment , the maximum frequency of a word can be up to 0.4 on average , which means that the same word can be found in 40 % of messages on average . However , in the STG treatment , the maximum word frequency is no more than 0.15 ( figure 3b ) . Even among the top 10 words of EG , the first and second words are more dominant than other words . By analysing the top 10 high-frequency words of the two treatments , we find that the high-frequency words of EG are usually the names of certain entertainment celebrities and related specific words , while the high-frequency words of STG are some common words , such as ‘ China ’ , ‘ America ’ , ‘ technology ’ , ‘ market ’ and ‘ company ’ ( figure 3c ) . 3.2 . The personal social networks From the results in the previous section , we found that EG and STG treatments exhibit different levels of polarization . Therefore , by comparing the differences between EG and STG personal social networks , the structural characteristics of the filter bubbles can be found , which may be one of the mechanisms that cause polarization . 3.2.1 . Statistical properties of networks By roughly comparing the in- and out-degree distributions of EG and STG ’ s personal social networks , we find that both present power-law distributions ( a = 1.766 for in-degrees and a @ = 1.847 for out-degrees ) and '' 998061 :9 “ DS Uado 305 y¥ Sosi/feunol/biorbuwysygndiaposrero : Downloaded from https : //royalsocietypublishing.org/ on 09 November 2022 ( a ) 1 ( c ) EG03 top ! 0 words 01 ) Wa , Yifan ( name ) = 10° 02 ) Mr BR Mr Ss EG 03 ) Hip hop 2 weeny e x02-23 04 ) Music 5 io4 y 05 ) Lu , Han ( name ) Fane HIB | » STG sy 06 ) China ao eey~x 474 3 07 ) SKR Sa 10-6 4 08 ) Diss FBS o 09 ) Intemet SKR 10+ 10-3 10-7 107 ! 0.8 | 10 ) Movie word rank -AE wats Diss ( ) 0.8 . MR seg 0.6 aa STGO7 top ! 0 words > an | 04 ) Sci-Tech < _ 05 ) Market 3 0.4 xe trig SPR 06 ) Mobile phone 3 BR 07 ) US dollar = 01 ) China 08 ) Global 0.2 4 02 ) Corporation 09 ) Technology 03 ) US 10 ) Intelligence 4 606606 123 45 7 8 9 10 Figure 3 . Semantic analysis of exposed contents . ( @ ) Inverse cumulative distribution of word frequency F ( log-log plot ) . The EG has a longer tail than the STG ; i.e . EG has more higher-frequency words . ( 6 ) Box plots of the frequency of the top 10 words in both the EG and STG . ( c ) Demonstration of the top 10 words in exposing messages from EG 03 bot and STG 07 bot . The size of the bubble indicates F. ( a ) ( b ) 10 ! & B 107 s 4 —EG 3 | —STG 10 weyex lt * . = yn 85 ‘ 1 10 10 ? 1 10 10 ? in-degree out-degree ( c ) 0.2 ( d ) 0.5 - T —_— - ! + | Boa } 1 Fy a ‘ S a T g 01 a z 1 < 3S 03 I +L 0 0.2 EG STG EG STG Figure 4 . Structural features of personal social networks . ( @ ) Mean of the inverse cumulative distribution of in-degree ( log-log plot ) . ( 6 ) Mean of the inverse cumulative distribution of out-degree ( log-log plot ) . ( c ) Connection density D. ( ¢ ) Clustering coefficient C. are almost identical ( figure 4a , b ) . Moreover , the two groups of networks also have similar connection densities ( figure 4c ) . Interestingly , figure 4d shows that the average clustering coefficient of STG networks is 35 % higher than that of EG networks ( p < 0.01 , two-sided Mann-Whitney U Test , 34 networks ) . Given the low level of information polarization in STG , this is a counterintuitive result , as a dense community spreads diverse information . 3.2.2 . Motifs The previous counterintuitive phenomenon can be attributed to differences in the connection pattern of personal social networks . First , we consider all possible motifs between two nodes ( ie . followings of bots ) in the networks . By considering the in-degree centrality of nodes ( ie . the number of followers of the node ) , there are five possible configurations , which are shown in figure 5a . Figure 5b GOR061 ‘ 9 ‘ DS uado 0s “ y sosijeuinol/b1o-bulysyqndfeposjeco A Downloaded from https : //royalsocietypublishing.org/ on 09 November 2022 ( a ) central 2A Q—— > ® _| 2BO < —_ @ __ 2c O00 peripheral 2D O < > ® _| 2EO < —0 ( b ) 0.7 1 + + : : - EG 0.67 [ __ ] STG | 05+ 5 O4F - T ot Beg ag 0.15 ae Ss mot . 2A mot . 2B mot . 2C mot . 2D mot . 2E aa ° 3B ° 3C 3D 3E 3F 3G 9 % over all dyadic motifs ( d ) T T T T T T T 2 10F 7+ + ++ + + 4 2 osk | Qg | Tt uF I 4 | + I = 0.64 7 | +44 = 1 oy + iT T Ss 04+ I _ 4 5 i lt + i > & o2b Pe A & 4 + o Lt ! ! + , ! ! ! mot.3A mot.3B mot.3C mot.3D mot.3E mot.3F mot.3G Figure 5 . Motifs of personal social networks . For dyadic motifs , we distinguish between the central and the peripheral node . The boxes indicate the key motifs to distinguish filter bubbles . shows the frequency distribution of dyadic motifs in EG and STG treatments . For two nodes of a directed arc , if the difference between centralities is larger than a threshold T = 10 , we distinguish two nodes into a peripheral node and a central node , such as motif 2A and 2B in figure 5a . Note that motifs are mutually exclusive ; therefore , a reciprocal arc will not be double-counted as two unidirectional arcs . The primary difference between EG and STG networks is the frequency of motif 2A and 2D . According to figure 5b , EG networks contain more non-reciprocal arcs from peripheral nodes to central nodes , but STG networks have more reciprocal arcs between peripheral and central nodes . Second , we also consider 3-node motifs , in particular closed triangles ( figure 5c ) . Due to the high number of possible motifs , we do not distinguish centrality in calculating triadic motifs . Figure 5d shows that , compared with EG networks , STG networks contain more closed triangles with at least two reciprocal arcs . The abundance of motifs 2D , 3F and 3G confirm the counterintuitive result derived from the statistical properties of the network , that is , the STG network is more clustering but less polarized . The form of motifs explains this result . In STG networks , if each peripheral node consumes only a small number of messages on other topics , the information has a relatively high probability of exposure to the central nodes . Consequently , the preference of central nodes may be affected , and broadcast the diverse messages to its followers , making various information more widely spread within the whole community . `` $ 98061 :9 “ DS Uado 305 y¥ Sosi/feunol/biorbuysygndiaposjero : Downloaded from https : //royalsocietypublishing.org/ on 09 November 2022 EGO05 T STG02 L 1 eae i 20 % 50 % end ( 100 % ) reciprocal edges only 1 initialized ( 0 % ) Figure 6 . Visualization of the evolution of personal social networks . In this demonstration , Social bot 05 in EG ( EGO5 ) and bot 02 in STG ( STGO2 ) display a similar growth process from initialized two followings to the end of running . However , STGO2 obtains more reciprocal edges than EGOS . The triangles represent the nodes with high in-degree , that is , the corresponding users have a large number of followers . The visualization is based on the radial layout with in-degree centrality ; thus the node with higher in-degree is closer to the centre of the plot . 3.2.3 . Visualization The visualization analysis also shows similar results . If all non-reciprocal arcs are removed , we find that the STG networks still have a high connection density , and the original central nodes are still maintained , while EG networks are the opposite , with the sparse connection , and the original central nodes degenerate into peripheral nodes ( figure 6 ) . Based on the above results , an EG network tends to be a unidirectional star-like structure with a few high-degree nodes , while an STG network tends to be a bidirectional clustering structure . The unidirectional star-like structure means selecting one or several central nodes to play the role of broadcasters to send information to all other nodes with few interactions between them . However , the diffusion path of this structure is mainly dependent on the selected central node . If the central nodes in the star-like structure produce only a narrow set of news , the others will be limited to a lower diversity of content . This selection effect of central nodes tends to enlarge the polarization of the content [ 38 ] . In the bidirectional clustering structure , all nodes are placed in a clustering group , and most connections are bidirectional . Those nodes can efficiently exchange information and realize a complementary effect with their friends with distinct preferences . The complementary effect can promote the diversity of information [ 38 ] . Furthermore , our results may confirm the basic structure and behaviour of the scientific community . The bidirectional scale-free structure of scientific collaboration networks has long been recognized [ 39,40 ] . Our results show that the scientific community forms a similar interactive centre-periphery structure , both in formal collaborations and in daily life ( even in a unidirectional relationship- based social environments , e.g . microblogging ) . In Wu et al . [ 41 ] , the researchers found an interactive pattern of large teams at the centre of the scientific community and small teams at the periphery of the scientific community . In the pattern , small teams make disruptive innovation , while large teams further develop and spread such innovation . The pattern has a similar connotation to the bidirectional structure we found . Peripheric users in the scientific community are responsible for providing novel information , while the central user is responsible for further disseminating the information . As a result , the coupling of the scale-free structure and bidirectional information dissemination forms a positive feedback loop that stimulates scientific innovation . At the same time , the bidirectional structure of the scientific community can promote communication between users and limit the spread of misinformation compared to the star-like structure of the entertainment community . In sum , the controlled experiments based on neutral social bots help us to reveal the two basic structural characteristics of the filter bubbles in microblogging platforms . First , the filter bubble contains a high proportion of users preferring an exclusive topic . Second , filter bubbles have a unidirectional star-like social structure , in which the central nodes play only the role of the information source , and rarely receives information from other nodes . The combination of two characteristics leads to the emergence of information polarization . `` 998061 :9 “ DS Uado 305 y sosi/feunoljbiorbuysygndiaposero : J Downloaded from https : //royalsocietypublishing.org/ on 09 November 2022 4 , Conclusion In this paper , we report a new controlled experiment approach to study polarization in social media . This method can be seen as a real-time Monte Carlo simulation on real-world social networks using the computer and artificial intelligence technology . ( 1 ) Compared with the experimental method based on volunteers [ 42 ] , social bots use artificial intelligence technologies ( e.g . natural language processing ) to simulate specific actions ( e.g . selective exposure ) . The approach not only improves the freedom of the experimenters but also reduces the cost of the experiments on real-world social networks . Unlike volunteers , the behaviour of social bots can be effectively controlled ; therefore , the consistency and randomness of experiment processes can be ensured , such as activity frequency and content judgement criteria . ( 2 ) Compared with the experimental method based on artificial social networks [ 19,20 ] , social bots can work directly on real-world social networks and acquire timely feedback with the instantaneous online environment . ( 3 ) Compared with the experimental method of directly altering the real-world social network [ 22 ] , this method can limit the interference to real-world social networks to a lower level . In our experiment , all social bots we deploy have no direct interaction with the existing users except following on them . The bots do not produce , forward , or modify any news content , and all data collected is directly exposed to them and publicly accessible . All network connections are restricted within bots and their direct followings , and we do not use the entire social relationship of all followings . That is , our experiment does not interfere with users ’ behaviour or disturb information dissemination , and all the data used is publicly visible . Therefore , the approach avoids the risk of violating the privacy of users . However , limited by the current technical conditions , this method can intelligently simulate only relatively simple actions . How to simulate complex user behaviours ( especially initiative feedback such as comment and chatting ) is still a technical challenge . Taking advantage of the approach , we can compare the consumption of different topics . Previous studies focused on the dissemination of different opinions in response to particular content , such as political news [ 6,10,43,44 ] . In this case , users were actually in the same media environment , and the differences in topics could be ignored . Second , the rise of pre-selection technologies ( e.g . recommendation systems ) makes people more attentive to the comparison of pre-selection and self-selection than to the impact of the media environment [ 7 ] . However , our research uses the same benchmark to compare the consumption of different news topics , thus revealing the internal structure of filter bubbles in microblogging platforms . We found that the inside of the filter bubble exhibits a power-law distribution ( both in- and out-degree ) , which is consistent with previous research results , that is , users in the filter bubble usually pay attention to a few sources of information . For the directed graph structure of microblogs , we find that the reciprocal link between the central nodes and the peripheral nodes plays an important role in the polarization process . For filter bubbles , peripheral nodes usually unidirectionally follow the central node , while for non-polarized communities , the central nodes tend to interact with others bidirectionally . The difference can be quantified by particular dyadic and triadic motifs ( figure 5 ) . The result provides an alternative way to measure and minimize polarization in social media . Data accessibility . The Java code to repeat the experiment and the Weibo data involved in this paper can be found in the electronic supplementary material or downloaded from our website : www.socialbot.top . Authors ’ contributions . Y.M . designed the experiment , coded the social bots , and drafted the manuscript ; T.J. carried out the statistical analyses ; C.J . participated in experiment design and critically revised the manuscript ; Q.L . and X.J . helped draft the manuscript . All authors gave final approval for publication and agree to be held accountable for the work performed therein . Competing interests . We declare we have no competing interest . Funding . This work was supported by the National Natural Science Foundation of China ( grant nos . 71303217 , 31370354 and 31270377 ) and the Zhejiang Provincial Natural Science Foundation of China ( grant nos . LY17G030030 , LGF18D010001 and LGF18D010002 } . Acknowledgements . We thank Prof. Jie Chang and Prof. Ying Ge ( Zhejiang University ) for their guidance on the diversity theory . We thank Haidan Yang for her introduction to the theory of communication . We thank Aizhu Liu , Chenyi Fang , Conger Yuan , Fan Li , Hao Li , Hao Wu , Haochen Hou , Hengji Wang , Jian Zhou , Jiaye Zhang , Jinmeng Wang , Junhao Xu , Lingjian Jin , Longzhong Lu , Lu Chen , Luchen Zhang , Qiuhai Zheng , Qiuya Ji , Renyuan Yao , Ruonan Zhang , Shang Gao , Shicong Han , Songyi Huang , Ting Xu , Wei Fang , Wei Zhang , Xingfan Zhang , Yijing Wang , Yingjie Feng , Yinting Chen , Yiqi Ning , Yujie Bao , Yuying Zhou , Zheyu Li , Ziyu Liu for their contribution to the manual text classification . `` 998061 :9 “ DS Uado 305 y¥ sosi/feunol/biorbuysygndiaposero : Downloaded from https : //royalsocietypublishing.org/ on 09 November 2022 References Newman N , Levy D , Nielsen RK . 2015 Reuters institute digital news report 2015 . SSRN Scholarly Paper ID 2619576 Social Sdence Research Network Rochester , NY . Pariser E. 2011 The filter bubble : how the new personalized web is changing what we read and how we think . New York , NY : Penguin . Flaxman S , Goel S , Rao JM . 2016 Filter bubbles , echo chambers , and online news consumption . Public Opin . Q . 80 , 298-320 . ( doi:10.1093/poq/ nfw006 ) Zuiderveen Borgesius F , Trilling D , Moller J , Bodo B , de Vreese C , Helberger N. 2016 Should we worty about filter bubbles ? /nternet Policy Rev . 5 . Dandekar P , Goel A , Lee DT . 2013 Biased assimilation , homophily , and the dynamics of polarization . Proc . Nat ! Acad . Sci , USA 110 , 5791-5796 . ( doi:10.1073/pnas . 1217220110 ) Schmidt AL , Zollo F , Vicario MD , Bessi A , Scala A , Caldarelli G , Stanley HE , Quattrodocchi W. 2017 Anatomy of news consumption on Facebook . Proc . Natt Acad . Sd . USA 114 , 3035-3039 . ( doi:10.1073/pnas . 1617052114 ) Bakshy E , Messing S , Adamic LA . 2015 Exposure to ideologically diverse news and opinion on Facebook . Sdence 348 , 1130-1132 . ( doi:10 . 1126/science.aaa1 160 ) Stroud NJ . 2010 Polarization and partisan selective exposure . J. Commun . 60 , 556-576 . ( doi:10.1111/ ) .1460-2466.2010.01497.x ) Kakiuchi K , Toriumi F , Takano M , Wada K , Fukuda | . 2018 Influence of selective exposure to viewing contents diversity . ( https : //arviv.org/ abs/1807.08744 ) . Conover MD , Ratkiewicz J , Francisco M , Goncalves B , Menczer F , Flammini A . 2011 Political polarization on Twitter . In Fifth fnt . AAAI Conf . on Weblogs and Soda ! Media . Esteban JM , Ray D. 1994 On the measurement of polarization . Econometrica 62 , 819-851 . ( doi:10.2307/2951734 ) Nikoloy D , Oliveira DF , Flammini A , Menczer F. 2015 Measuring online social bubbles . Peers Comput . Sci . 1 , €38 . ( doi:10.7717/peerj-cs.38 ) Guerra PHC Meira Jr W , Cardie C , Kleinberg R. 2013 A measure of polarization on sodal media networks based on community boundaries . In ICWSM . Aral S , Walker D. 2014 Tie strength , embeddedness , and social influence : a large- scale networked experiment . Manage . Sci . 60 , 1352-1370 . ( doi:10.1287/mnsc.2014.1936 ) Xu L , Jiang C , Wang J , Yuan J , Ren Y . 2014 Information security in big data : privacy and 20 . 21 . 22 . 23 . 24 , 25 . 26 . 27 . 28 . 29. data mining . fEEE Access 2 , 1149-1176 . ( doi:10 . 1109/ACCESS.2014.2362522 ) Chen Y , Wang Q , Xie J . 2011 Online sodal interactions : a natural experiment on word of mouth versus observational learning . J . Mark . Res . 48 , 238-254 . ( doi:10.1509/jmkr.48.2.238 ) Phan 1Q , Airoldi EM . 2015 A natural experiment of social network formation and dynamics . Proc . Natl Acad . Sci . USA 112 , 6595-6600 . ( doi:10 . 1073/pnas.1404770112 ) Vosoughi S , Roy D , Aral $ . 2018 The spread of true and false news online . Science 359 , 1146-1151 . ( doi:10.1126/science.aap9559 ) Centola D. 2010 The spread of behavior in an online sodal network experiment . Science 329 , 1194-1197 . ( doi:10.1126/science.1185231 ) Centola D. 2011 An experimental study of homophily in the adoption of health behavior . Sdence 334 , 1269-1272 . ( doi:10.1126/sdence . 1207055 ) Rand DG , Arbesman S , Christakis NA . 2011 Dynamic sodal networks promote cooperation in experiments with humans . Proc . Nat ! Acad . Sd . USA 108 , 19 193-19 198 . ( doi:10.1073/ pnas.1108243108 ) Bond RM , Kramer ADI , Marlow C , Fariss CJ , Settle JE , Fowler JH , Jones JJ . 2012 A 61- million-person experiment in social influence and political mobilization . Nature 489 , 295-298 . ( doi:10.1038/nature11421 ) Kramer ADI , Guillory JE , Hancock JT . 2014 Experimental evidence of massive-scale emotional contagion through social networks . Proc . Natl Acad . Sd . USA 111 , 8788-8790 . ( doi:10.1073/pnas.1320040111 ) Reips UD . 2002 Standards for internet-based experimenting . Exp . Psychol . 49 , 243-256 . ( doi:10.1026//1618-3169.49.4.243 ) Ferrara E , Varol 0 , Davis C , Menczer F , Flammini A . 2016 The tise of sodal bots . Commun . ACM 59 , 96-104 . ( doi:10.1145/2818717 ) Paradise A , Puzis R , Shabtai A . 2014 Anti- reconnaissance tools : detecting targeted socialbots . /EEE fnternet Comput . 18 , 11-19 . ( doi:10.1109/MIC.2014.81 ) Abokhodair N , Yoo D , McDonald DW . 2015 Dissecting a social botnet : growth , content and influence in Twitter . In Proc . of the 78th ACM Conf . on Computer Supported Cooperative Work and Social Computing , pp . 839-851 . ACM . Bianconi G , Darst RK , lacovacd J , Fortunato S. 2014 Triadic closure as a basic generating mechanism of communities in complex networks . Phys . Rev . £ 90 , 042806 . ( doi:10 . 1103/PhysRevE.90.042806 ) Romero DM , Kleinberg JM . 2010 The directed closure process in hybrid sodal-information 30 . 31 . 32 . 33 . 34 , 35 . 36 . 37 . 38 . 39 . 40 . Al . 42 . 43. networks , with an analysis of link formation on Twitter . In Proc . of the Fourth int . AAAI Conf . on Weblogs and Social Media . Joulin A , Grave E , Bojanowski P , Mikolov T. 2016 Bag of tricks for efficient text classification . ( http : //arxiv.org/abs/1607.01759 ) Dunbar R , Dunbar RIM . 1998 Grooming , gossip , and the evolution of language . Cambridge , MA : Harvard University Press . Fagiolo G. 2007 Clustering in complex directed networks . Phys . Rev . £ 76 , 026107 . ( doi:10 . 1103/PhysRevE.76.026107 ) Milo R , Shen-Orr S , Itzkovitz S , Kashtan N , Chklovskii D , Alon U . 2002 Network motifs : simple building blocks of complex networks . Sdence 298 , 824-827 . ( doi:10.1126/science . 298.5594.824 ) Benson AR , Gleich DF , Leskovec J . 2016 Higher- order organization of complex networks . Science 353 , 163-166 . ( doi:10.1126/science.aad 9029 ) Coletto M , Garimella K , Gionis A , Lucchese C. 2017 Automatic controversy detection in sodal media : a content-independent motif-based approach . Online Soc . Netw . Media 3 , 22-31 . ( doi:10.1016/j.osnem.2017.10.001 ) 2010 Analysis of user characteristics of Sina ’ s main channel . Technical Report . 2019 Weibo user development report 2018 . Technical Report . Loreau M , Hector A . 2001 Partitioning section and complementarity in biodiversity experiments . Nature 412 , 72-76 . ( doi:10.1038/35083573 ) Barabasi AL , Jeong H , Neda Z , Ravasz E , Schubert A , Vicsek T. 2002 Evolution of the social network of scientific collaborations . Physica A 311 , 590-614 . ( doi:10.1016/S0378- 4371 ( 02 ) 00736-7 ) Newman MEJ . 2004 Coauthorship networks and patterns of scientific collaboration . Proc . Nat ! Acad . Sd . USA 101 , 5200-5205 . ( doi:10.1073/ pnas.0307545100 ) Wu L , Wang D , Evans JA . 2019 Large teams develop and small teams disrupt science and technology . Nature 566 , 378-382 . ( doi:10 . 1038/s41586-019-0941-9 ) Haim M , Graefe A , Brosius HB . 2018 Burst of the filter bubble ? Effects of personalization on the diversity of Google news . Digit . 1 . 6 , 330-343 . ( doi:10.1080/21670811.2017.1338145 ) Prior M. 2013 Media and political polarization . Annu . Rev . Pol . Sd . 16 , 101-127 . ( doi:10.1146/ annurev-polisci-100711-135242 ) Narayanan V , Barash Y , Kelly J , Kollanyi B , Neudert LM , Howard PN . 2018 Polarization , partisanship and junk news consumption over social media in the US . ( http : //arxiv.org/abs/ 1803.01845 ) s0s1/jewsnol/b10 '' bur ‘ ps uado ‘ 205 * y 898061 ‘ 9 ResearchGate See discussions , stats , and author profiles for this publication at : https : //www.researchgate.net/publication/272723200 Escaping from the Filter Bubble ? The Effects of Novelty and Serendipity on Users ’ Evaluations of Online Recommendations Conference Paper : December 2014 CITATIONS READS 34 1,124 4 authors , including : Christian Matt Alexander Benlian @ Universitat Bern Technische Universitat Darmstadt 104 PUBLICATIONS 3,613 CITATIONS 255 PUBLICATIONS 8,156 CITATIONS SEE PROFILE SEE PROFILE Thomas Hess Ludwig-Maximilians-University of Munich 555 PUBLICATIONS 11,152 CITATIONS SEE PROFILE Some of the authors of this publication are also working on these related projects : Project Research on Interaction Dynamics on Software Platform Ecosystems View project Project Research Project on Digital Transformation of Corporations View project All content following this page was uploaded by Thomas Hess on 05 January 2019 . The user has requested enhancement of the downloaded file . Escaping from the Filter Bubble ? The Effects of Novelty and Serendipity on Users ’ Evaluations of Online Recommendations Completed Research Paper Christian Matt Alexander Benlian LMU Munich TU Darmstadt Ludwigstr . 28 , Hochschulstr . 1 80539 Munich , Germany 64289 Darmstadt , Germany matt @ bwl.lmu.de benlian @ ise.tu-darmstadt.de Thomas Hess Christian WeiB LMU Munich LMU Munich Ludwigstr . 28 , Ludwigstr . 28 , 80539 Munich , Germany 80539 Munich , Germany thess @ bwl.lmu.de weiss.christian @ campus.|mu.de Abstract Recommender systems aim to support users in identifying the most relevant items . However , there are concerns that recommenders may imprison users in a “ filter bubble ” by recommending items predominantly known to them . On the other hand , providing unconventional items may increase risks of not meeting users ’ taste . Given this trade-off , we analyze the effects of consumers ’ perceived levels of recommendation novelty and serendipity on perceived preference fit and enjoyment . We find that merely increasing the level of novel recommendations is disadvantageous . Instead , recommenders should provide more serendipitous recommendations as this leads to higher perceived preference fit and enjoyment . In addition , market and recommender technology characteristics must be taken into account , since they partially determine the level of novel and serendipitous recommendations . Our findings have significant implications for research as they add additional insights on users ’ evaluations of recommender systems . For practice , our results support online retailers in developing better recommenders . Keywords : Online recommendations , user preferences , recommendation novelty , recommendation serendipity , recommender systems Thirty Fifth International Conference on Information Systems , Auckland 2014 1 Human Behavior and IS Introduction Recommender systems have become prevalent on the Internet . Based on statistical patterns they aim to suggest the most relevant products , information or actions for users and thus can also affect users ’ life besides online shopping ( Hess et al . 2014 ; Hosanagar et al . 2014 ) . This has become even more important , since there are numerous online stores that carry vast numbers of different products and it is practically impossible for consumers to manually browse through the whole product range ( Hinz and Eckert 2010 ; Veit et al . 2014 ) . Compared to the pre-internet era , many online stores now focus profitably on the so called “ long tail ” , i.e . these are niche products which are sold only rarely , but can still amount to a substantial revenue ( Anderson 2006 ; Brynjolfsson et al . 2011 ) . For online stores , efficient reeommender systems are essential and can help to increase sales ( Pathak et al . 2010 ) . The performance of recommender systems can be measured in terms of users ’ acceptance and the perceived quality of the recommendations , which in turn has an influence on users ’ intention to repurchase ( Zhang et al . 2011 ) . It is known that the perceived quality of online reeommendations differs across different recommender technologies . In particular , computer science research has invested significant efforts in increasing the precision of anticipations of future purchases based on previous purchases ( Adamopoulos and Tuzhilin 2011 ; Bell et al . 2009 ) . Despite substantial progress in improving recommendation accuracy , there have been concerns that the increasing usage of recommender systems can create a “ filter bubble ” ( Pariser 2011 ) . Following this , users mostly receive recommendations which match their pre-stated implicit or explicit preferences very closely , and thus restrict them from finding something new ( McNee et al . 2006 ; Zhou et al . 2010 ) . When providing online reeommendations that match previous purchases , there is a higher chance that users will also like other recommended items . However , sticking too close to their own comfort zone is not always desirable for users , as sometimes it takes looking beyond the obvious to discover different , but highly valued items . So , when browsing through different websites and also in traditional retail , users may discover interesting items they were originally not looking for . There are concerns that current recommender systems do not sufficiently account for niche products , and that retailers focusing on niche products may suffer from this ( Zhou et al . 2010 ) . However , tuning recommender systems to more novel and serendipitous recommendations instead of accuracy can increase the risk of deviations from users ’ taste and may , as a consequence , lead users to stop following recommendations in the future . Therefore , a good balance between novelty , serendipity , as well as accuracy of recommendations seems to be necessary . Most research related to this stems from computer science and focuses on altering existing recommendation algorithms to provide more diverse recommendations ( e.g. , Zhang et al . 2012 ; Zhou et al . 2010 ) , and on effects on the popularity of recommended items ( Adomavicius and Kwon 2012 ) . However , apart from technical specifications , the user ’ s side remains mostly unexplored . Research in IS and e-commerce has recently discussed this issue from a different angle and has shown that a more diverse product offer can increase customer retention rates ( Park and Han 2013 ) . Consequently , the authors suggest that vendors should optimize their recommender systems for more diversity . However , there is still an evident lack of knowledge on how users perceive recommendations on items that are different from what they are already familiar with . Using a web-based field experiment with high ecological validity , we assess whether consumers really want to “ escape from the filter bubble ” , i.e . whether they prefer recommendations of items that are close to their previously stated taste preferences . We draw on concepts of recommendation novelty and recommendation serendipity and address the following research questions : e What is the effect of perceived recommendation novelty and perceived recommendation serendipity on the evaluation of online product recommendations ? e Do the effects of perceived recommendation novelty and perceived recommendation serendipity differ between recommender technologies and underlying markets ? Our research aims to close research gaps concerning users ’ acceptance and evaluation of recommender systems by providing a more accurate picture of antecedents that constitute , whether a reeommendation is relevant for users or not . We expect these results to provide a better basis for optimizing current 2 Thirty Fifth International Conference on Information Systems , Auckland 2014 Escaping from the Filter Bubble ? recommender systems as well as the development of new ones . In addition , we believe that our results have implications for any kind of decision support in general . The rest of the paper is organized as follows : In the next section we present the conceptual foundations of the effects of recommender systems on users and markets , as well as the focal concepts of recommendation novelty and serendipity . Next , we introduce our research model and develop the underlying hypotheses , followed by a description of the experimental layout . The results of this study are presented and discussed thereafter . Finally , we provide further implications and a summary of the results as well as the limitations of the paper . Conceptual Foundations Effects of Recommender Systems on Markets and Users Due to their ability to reduce information overload by filtering the most relevant products for different users , recommender systems have become ubiquitous in e-commerce ( Hinz and Eckert 2010 ; Xiao and Benbasat 2007 ) . Their usage has had an effect both on aggregated markets as well as on individual consumers . For the former , their role has mostly been analyzed in respect of the long-tail-phenomenon and associated changes in the distribution of sales diversity ( Anderson 2006 ; Brynjolfsson et al . 2011 ) . In contrast to many physical stores and physical markets , for which few bestseller products typically account for large shares of the overall revenue , online stores can easily carry a large number of niche products at little cost ( Fleder and Hosanagar 2009 ; Ho et al . 2011 ) . However , there is still conflicting evidence on the impact of recommender technologies on this long-tail phenomenon and whether recommenders lead to a fragmentation or homogenization of consumers in respect of common purchases ( Brynjolfsson et al . 2011 ; Brynjolfsson et al . 2006 ; Hosanagar et al . 2014 ) . While some authors argue that recommender systems enable consumers to better find niche products , others hold that they increase the popularity of already popular items ( Fleder and Hosanagar 2009 ) . However , more recent research indicates that to answer this question a further differentiation between recommender technologies is necessary ( Matt et al . 2013 ) . In comparison to this , numerous other studies have investigated the influence of recommender systems on individual users . It has been shown that recommender systems influence consumers ’ purchases ( e.g. , Senecal and Nantel 2004 ) and that they can boost sales , which is why they are often used to sell additional or higher-priced products ( Ahn 2006 ) . However , there are different factors which can influence users ’ perceptions of online recommendations , including the source of the recommendation . Online recommendations can have a higher influence on consumer decisions than social recommendations from the user ’ s environment ( Fleder and Hosanagar 2009 ) . It has also been shown that users perceive provider and user generated product recommendations differently with regard to the perceived usefulness , but also related to their trustworthiness ( Benlian et al . 2012 ) . The potential effect of recommender systems is therefore a cause of how users evaluate recommendations and how they perceive their quality . Accuracy of Recommender Systems For a long time , improving recommendation accuracy has been seen as the key to increasing the perceived quality of recommender systems . Accuracy is mostly measured by comparing the underlying recommender algorithm ’ s prediction against user ’ s rating of a product ( MecNee et al . 2006 ) . Both research and practice have invested significant effort to increase the accuracy of recommender systems ( Adamopoulos and Tuzhilin 2011 ; Hurley 2011 ) . The underlying reasoning is that more information about products and users enables a better basis for future decisions and helps online stores to create a stronger link between previous purchases and future recommendations ( Bechwati and Xia 2003 ) . However , there have been concerns that high recommendation accuracy does not necessarily correlate with providing the most relevant recommendations for users ( Adomavicius and Kwon 2011 ; Zhou et al . 2010 ) . When users receive very accurate recommendations ( i.e . the recommended items match their preferences well ) , they are likely to receive reeommendations which are within a narrow scope of products already familiar to them . Since the number of recommendations and users ’ cognitive capacity is limited , they are therefore more likely to miss opportunities to see different products ( Hosanagar et al . 2014 ; MeNee et al . 2006 ) . Thirty Fifth International Conference on Information Systems , Auckland 2014 3 Human Behavior and IS Although Internet technologies have led to a “ world full of niches ” ( Anderson 2006 ) most current recommender systems are not able to provide unexpected recommendations to users ( Ahn 2006 ) . This phenomenon is known as the “ filter bubble ” and describes “ that users could be trapped in a self- reinforcing cycle of opinion , never being pushed to discover alternative genres or viewpoints “ ( Zhang et al . 2012 ) . Thus , many researchers argue that other characteristics should be taken into account to increase users ’ satisfaction with recommender systems ( Adomavicius and Kwon 2011 ; Adomavicius and Kwon 2012 ; MceNee et al . 2006 ) . Some hold that recommender design should be less focused on technical aspects , but more on the underlying user behavior ( Fleder and Hosanagar 2009 ) . In this context , recommendation novelty is frequently stated as being considerably influential ( Adomavicius and Kwon 2011 ; Adomavicius and Tuzhilin 2005 ) . More recent approaches also target recommendation serendipity , which involves a positive feeling of surprise ( Zhang et al . 2012 ) . We follow this line of research and hold that in addition to accuracy , it is recommendation novelty as well as recommendation serendipity which mainly govern users ’ evaluation of recommendations . Novelty and Serendipity of Online Recommendations Research claims that novelty is highly desirable for online recommendations ( Vargas and Castells 2011 ) . Novelty measures whether recommended items are already known to distinct users or to a community as a whole . At the same time , novel recommendations should not consist of obvious items . Therefore , items which are very likely to be already familiar to users should not be reeommended , since these users could have already made a considerate decision to not purchase the item ( Herlocker et al . 2004 ) . There are various approaches to measuring novelty , and most of them try to take the overall recognition of a product on a market basis into account . Since users may have already seen an item in a different place , taking market sales figures into account could help to estimate , whether an item is already familiar to users . However , in the past many authors believed that there is a trade-off between accuracy and novelty , i.e . more recommendation novelty may lead to less accurate recommendations and thus could elicit unsatisfactory results for users ( Vargas and Castells 2011 ) . On the other hand , for online store providers , generating more recommendations of previously unrated items increases the likelihood of receiving more first time customer reviews for these products and can therefore , in turn , increase the accuracy of future recommendations ( Adomavicius and Kwon 2012 ) . As another potential measure that has recently gained more popularity , reeommendation serendipity builds upon the concept of novelty , but expands this by the factor of a positive , unexpected discovery ( Herlocker et al . 2004 ) . The positive , emotional surprise requires that in order to be attractive to users , a recommendation must be useful for users as well . McNee et al . ( 2006 ) stress that serendipity means experiencing fortuitous and unexpected recommendations . Ge et al . ( 2010 ) list unexpectedness and usefulness as two core characteristics of serendipity . According to them , besides novelty as one requirement for serendipity , the user should be unlikely to discover the recommended item unaided . Therefore , a recommendation of a new film by one ’ s favorite movie director may be novel as well as useful , but it is not necessarily serendipitous as it is very likely that users would have found this new film sooner or later themselves ( Herlocker et al . 2004 ) . Research in computer science continues to discuss the challenges in adjusting current recommender technologies to provide more novel and serendipitous recommendation ( Zhang et al . 2012 ) . However , there is a significant research gap in targeting users ’ perspective and analyzing what the ideal levels of novelty and serendipity from users ’ perspective actually are and how they relate to technological and market-based influence factors . Research Model and Hypotheses To empirically validate the impact of perceived recommendation novelty and perceived recommendation serendipity on perceived preference fit and perceived enjoyment , we developed the research model depicted in Figure 1 . With this , we do not only seek to clarify the relationships between perceived recommendation serendipity/perceived recommendation novelty and perceived preference fit/perceived enjoyment . In addition , we aim to provide a more comprehensive picture , by accounting for different antecedents in form of two technological and two market type influence factors . For the former , this 4 . Thirty Fifth International Conference on Information Systems , Auckland 2014 Escaping from the Filter Bubble ? includes the two most common basic recommendation approaches ( content-based and collaborative filtering ) . For the latter , we varied the ratios of known and unknown songs to assemble blockbuster and niche markets . We will discuss each of the resulting hypotheses in the following : Perceived i . Perceived Recommendation Preference Fit Novelty Recommender Technology Market Characteristics Perceived ; Perceived Recommendation j nd Enjoyment Serendipity Figure 1 . Conceptual Research Model Effects of Perceived Recommendation Novelty on Perceived Preference Fit/Perceived Enjoyment One main challenge is to measure the actual degree of novelty for a particular user/item-combination . Even if consumers have not previously seen a specific item in an online store , it does not necessarily mean that they do not know this item , as they could have seen the item elsewhere ( and they may also like it ) . Therefore , taking store-wide data for unseen items for each user into account does not guarantee that all of these items are new to users . Even when taking market purchase data into account , it is still not fully clear whether an item is already familiar to users . Therefore , instead of the system-inherent perspective , we consider the users ’ perceived level of recommendation novelty and what the effect on perceived preference fit and perceived enjoyment are . Research and practice have focused on increasing reeommenders ’ accuracy , mainly due to concerns that an increase in novelty can potentially decrease recommendation accuracy . In line with this , if recommendations are new to users they may still provide only little value if they do not fit the user ’ s taste . The higher risk of providing recommendations that do not match user preferences is due to the lower amount of underlying data that a provider has about a specific item/user relation . We follow this reasoning and conclude : Hypothesis 1a : Perceived novelty of online recommendations will have a negative effect on perceived preference fit . Independent of the aforementioned challenges in calculating recommendation novelty for specific user/item-combinations it is generally believed that users are interested in receiving novel online recommendations ( Herlocker et al . 2004 ) . However , the provision of recommendations of already known items can lead to unsatisfactory results for users . We believe that in contrast to this , receiving recommendations of novel items can have affective effects on users , leading to a higher enjoyment of the item selection task . In addition to experiencing something new , this is also because the recommender system has increased the number of salient products users can choose from . We thus hold : Hypothesis 1b : Perceived novelty of online recommendations will have a positive effect on perceived enjoyment . Effects of Perceived Recommendation Serendipity on Perceived Preference Fit/Perceived Enjoyment For novelty we assumed that recommendations are not of high value to users if they are merely novel , but do not match users ’ taste . In contrast to this , we argue that serendipity is a key element to providing Thirty Fifth International Conference on Information Systems , Auckland 2014 5 Human Behavior and IS better recommendations to users . In addition to the novelty component , being a valuable and surprising discovery to users is inherent to serendipity . We believe that this combination of factors is suitable to ensure a high preference fit for users . Therefore , in contrast to novelty , we argue : Hypothesis 2a : Perceived serendipity of online recommendations will have a positive effect on perceived preference fit . Serendipity and its effects on people has mostly been discussed in the context of Internet browsing and social media ( Hart et al . 2008 ) . Public media also discusses the potential effects of filtering algorithms on peoples ’ discovery of unexpected items — both from an outcome-oriented effectiveness angle as well as from an affective perspective ( CNN 2013 ) . In addition to providing recommendations that fit users ’ preferences better , we believe that unexpected , but rewarding discoveries of items can also have a positive effect on consumers ’ perceived enjoyment since users may realize that they have taken a better purchase decision than expected . We thus argue : Hypothesis 2b : Perceived serendipity of online recommendations will have a positive effect on perceived enjoyment . Effects of Recommender Technology on Perceived Recommendation Novelty/ Perceived Recommendation Serendipity The two main recommender technologies are content-based filtering ( CBF ) and collaborative filtering ( CLF ) ( Burke 2000 ; Xiao and Benbasat 2007 ) . However , today various sub-forms and also hybrid combinations of both methods are used to combine the advantages of both approaches ( Burke 2002 ) . CBF-systems create recommendations based on similarities between different items . Here , the main idea is that users are more likely to select or purchase items that are similar to the ones they have already purchased . Product similarities are calculated based on product characteristics , and for music , they include genre , artists or song length for instance . Product characteristics are more difficult to describe for experience goods ( such as music ) than for search goods ( such as cars ) . In contrast to this , CLF-systems create recommendations based on similarities between users ( Balabanovié and Shoham 1997 ) . The main assumption is that if two users have purchased similar goods in the past , they are also likely to enjoy similar items in the future . Thus , purchases that only one of the two similar users has made , are recommended to the other user . CLF-recommenders frequently use the Pearson correlation coefficient or the cosine function to calculate similarities ( Ahn 2006 ) . Previous research argues that CBF-recommenders are less likely to create novel and unexpected recommendations since if products are recommended that are close to users ’ tastes , there is a high likelihood that users are already familiar with this product ( Herlocker et al . 2004 ) . We acknowledge this point , but believe that this is difficult to generalize and probably differs between products and domains . As mentioned before , product characteristics are difficult to describe for experience goods . Thus , if similarities between two songs are calculated merely based on their content ( i.e . music-related similarities such as genre or tone ) , they could be seen as similar content-wise , but still appear fairly different to users . CBF-recommenders promote products based on their characteristics and not based on_ their popularity . Thus , even slow-selling products have equal chances of being recommended by CBF-systems . In contrast to this , for CLF-recommendations a self-enhancing circle can arise , for which products that are purchased by many customers ( popular products ) are more likely to be recommended by CLF- recommenders . If these already popular products are recommended more often , they are more likely to be purchased more often and so on ( Fleder and Hosanagar 2009 ) . Therefore , we hold that CBF- recommenders could lead consumers to discover more unfamiliar products and hold : Hypothesis 3a : Consumers will perceive higher novelty of online recommendations generated with CBF than with CLF . The assumptions for the effects of the reeommender technology in use on perceived recommendation serendipity are more difficult to estimate . Since we believe that CBF-recommendations will include a higher number of novel recommendations , one requirement for serendipity is fulfilled . Moreover , serendipitous recommendations must be both unexpected and useful to consumers . We argue that in addition to the higher level of novelty , CBF will also successfully generate more unexpected , but still useful recommendations . The recommendations are likely to be more unexpected , given that the 6 Thirty Fifth International Conference on Information Systems , Auckland 2014 Escaping from the Filter Bubble ? underlying popularity of the song is not taken into account and thus songs from rather unknown artists can be recommended . Recommendations are likely to be still useful , considering that CBF-systems seek to recommend products that match users ’ preferences closely . We therefore propose : Hypothesis 3b : Consumers will perceive higher serendipity of online recommendations generated with CBF than with CLF . Effects of Market Characteristics on Perceived Recommendation Novelty/ Perceived Recommendation Serendipity In many online markets a steady growth of long-tail market distributions has been observed ( Anderson 2006 ; Brynjolfsson et al . 2011 ) . Markets for media products are typically blockbuster markets , for which few bestseller products typically account for large shares of the overall market sales . In contrast to this , niche markets are characterized by a high share of slow-selling products which , viewed aggregately , can amount to a large share of revenue for vendors ( Fleder and Hosanagar 2009 ; Ho et al . 2011 ) . Providing more niche products can help vendors to increase profits and retention rates ( Park and Han 2013 ) . From a statistical point of view , it seems rather obvious that a higher share of niche songs increases the probability that recommendations will contain more niche songs . However , apart from population-based assumptions it is not fully clear whether a higher share of niche items in the population will lead to a higher share of novel recommendations . Instead , it could well be that rather popular items remain more successful in being promoted , leaving the ratio of recommended blockbuster and niche products unchanged . For CBF this does not seem realistic . Since sales-popularity is not taken into account when calculating similarities , we follow the statistical assumption that a higher share of unpopular songs in the population will lead to more recommendations of niche songs . For CLF things are slightly different . If a high proportion of users still decides to purchase generally well- known items , these are more likely to be reeommended . So it would be possible that a higher number of less well-known items does not change the ratio of blockbuster versus niche recommendations . However , since niche songs do not need to be of worse quality , we believe that a higher number of the previously unknown songs will be purchased and build the basis for further recommendations to other users . We thus hypothesize : Hypothesis 4a : Consumers will perceive higher novelty of online recommendations in niche markets than in blockbuster markets . Furthermore , for recommendation serendipity , again we follow the previously discussed statistical assumptions that a higher number of unknown songs in the population will lead to more recommendations of unknown songs . Assuming identical quality and an identical ratio of novel and serendipitous songs among the niche songs compared to the blockbuster-market , we suggest : Hypothesis 4b : Consumers will perceive higher serendipity of online recommendations in niche markets than in blockbuster markets . Implementation as a Web-Experiment Experimental Design , Incentives and Procedures In contrast to simulations and analytical models , a web-based field experiment allows us to analyze actual , instead of intended , user behavior . In addition , it provides us with a high level of control over the environment and thus enables us to clearly exclude undesired effects . To ensure a high ecological validity , we used state-of-the-art technologies and designed the experiment in the form of a very interactive web application ( Appendix 1 and 2 ) . The interactive features and the elaborate design helped to enable our online music store to look similar to real online stores for digital music . We have chosen digital music as the product in question because purchasing music over the Internet has become very popular among consumers . Furthermore , music is considered to be an experience good and its quality is therefore difficult to evaluate prior to consumption , based solely on product information . In contrast , even a short trial of the product enables consumers to better anticipate the fit of a music track to Thirty Fifth International Conference on Information Systems , Auckland 2014 7 Human Behavior and IS their taste . Therefore , in our experiment , participants had the opportunity to listen to free 30-second previews for all tracks . To increase participants ’ motivation to choose among all available songs carefully , participants were told that every 10 % participant would win the 5 songs they were asked to select during the experiment . We did not apply atime limit to leave participants as much time as needed to make well-founded choices . In a 2x2 between-subjects-design we implemented four different treatments to which participants were randomly assigned . The treatments included two different recommender system technologies , namely collaborative filtering ( CLF ) and content-based filtering ( CBF ) , as well as two different underlying market characteristics - “ blockbuster ” and “ niche ” markets , which differed in the share of well-known and less well-known songs ( Table 1 ) . To make participants believe that the recommendations were individually calculated for them , the recommendations were introduced as “ personal recommendations ” . However , participants did not learn which type of recommender technology was used to calculate their recommendations . Table 1 . Overview of Treatments Recommender Type Market Type oa ae Collaborative Filtering ( CLF ) Content-based Filtering ( CBF ) Blockbuster ( BB ) CLF x BB ( n=33 ) CBF x BB ( n=31 ) Niche ( NI ) CLF x NI ( n=32 ) CBF x NI ( n=34 ) To provide CBF- and CLF-recommendations , it is necessary to have information on participants ’ tastes . For this purpose a separate rating phase was conducted first , in which all participants were asked to evaluate 15 different songs ( “ rating tracks ” ) on a Likert scale from 1 ( do not like the song at all ) to 5 ( like the song very much ) . These tracks included the currently most popular ( # 1 ) , the fifth ( 45 ) and the 500th most popular song ( # 500 ) as indicated by the music intelligence platform Echo Nest in the genres pop , rock , hip-hop/r & b , electronic music , and oldies . The track selection was intended to cover a wide range of songs and genres to gain a differentiated picture of the participants ’ musical tastes and to provide an appropriate basis for the content-based and collaborative recommendations . In the subsequent purchasing phase , participants received recommendations which were created by the two different recommender technologies . Here , participants had to purchase 5 out of 500 digital music tracks ( “ choice tracks ” in the following ) . For the blockbuster treatments these songs consisted of 350 popular and 150 niche songs , while in the niche market the ratio of popular and niche songs was inverse . Popular tracks were randomly drawn from the 500 most popular tracks as indicated by Echo Nest . As in the rating phase , participants again had unlimited access to 30-second samples of each song to see whether they liked the song . In addition , participants received 5 recommendations of different music tracks . These tracks ( “ recommendation tracks ” ) were clearly marked as recommendations and located in a dedicated part of the website . Participants were not obliged to listen to or to select any of the recommended tracks . In a post-experimental survey , we asked participants to rate their music selection experience during the experiment and in relation to the reeommendations they received . We also gave participants the option to see and listen to the previously obtained recommendations again , in case they had not yet listened to all of the recommendations during the music selection task . Based on the different survey items , we measured participants ’ levels of perceived recommendation novelty , perceived recommendation serendipity , perceived preference fit , and perceived enjoyment . Implemented Recommender Technologies Collaborative Filtering To provide recommendations , collaborative filtering calculates similarities between different users . The underlying assumption is that if two users have had similar opinions on two common products in the past , 8 Thirty Fifth International Conference on Information Systems , Auckland 2014 Escaping from the Filter Bubble ? they are more likely to share the same opinion on future items . We used the cosine similarity function to calculate the collaborative filtering function . CLF-recommenders may suffer from a cold-start problem if they are based on little or no initial data . In this case , early recommendations can be heavily affected by new incoming data , since a small change in votes or purchases may have a strong impact on the recommendation order of the items . Since we are interested in the general effect of CLF and not its potential problems in special situations ( most online stores use proxy data to reduce these issues ) , we previously collected data about music tastes from two different groups of participants ( in the following they are referred to as “ basic profiles ” ) . These participants received the same experimental conditions as those in the experimental treatment ( e.g . interface design , selection of songs ) , but they did not have access to a recommender system . One of the two basic profile groups received the blockbuster and the other the niche market selection of songs . Based on this , for each current participant » , the most similar participant from the basic profiles was identified . Given p , as the current participant with b , as the 15-dimensional vector that contained the participant ’ s rating , then the cosine similarity 5 , , , to another participant from the set of basic profiles » ; © P with their respective vector 5 , , is calculated as : Seas ( Pa ? ) = by , * Bp ; cos Pa PI Tb , Mbp . The cosine function returns the highest similarity between two users , the closer 5 , , ; is to 1 . Therefore , it was the highest similarity with one of the participants from the basic profiles p , ; € P , where the difference to 1 was minimal 5 , , , ( p , . p ; ) . For each participant » , , the 5 tracks that were selected by the most similar participant ; from the basic profiles were reeommended . Content-based Filtering From all 500 songs in the purchasing phase , the implemented content-based filter t:37 reeommended those songs to participants that have the highest similarity coefficient with the aggregated rating of the 15 songs that were evaluated in the rating phase . For the content-similarity calculation between music tracks , we used a professional music comparison program that involved a number of different algorithms and parameters for the similarity calculation and that returned a matrix with content-based “ distances ” between all tracks . The similarity coefficient was calculated based on the degree of similarity between the two most similar songs ( as reported by the music comparison program ) multiplied with the participant ’ s rating of this song . In line with this , let # ; © T be a track from the choice set T and y the most similar track from the rating set . Furthermore , let R ( ¥ ) be the rating of the current participant » , for the track and S ( i ; , 7 ) the degree of similarity between t ; and y . Under consideration of the rating R , , of the current participant » , the similarity coefficient @ of track t ; was calculated and based on which participant B , received the 5 tracks with the highest similarity coefficient as recommendations : Olt Ay . ) = AO ) Say ) For content-based filters , no data from other users is needed . The data basis for both CBF and CLF were dynamically updated during the experiment once new data arrived . Survey Instruments and Measurement Model The survey instruments used validated scales with minor wording changes to achieve a better fit with the local scenario ( see Table 2 ) . All the questionnaire items were measured on Likert-type scales , anchored at 1 = “ strongly disagree , ” 4 = “ neutral ” , and 7 = “ strongly agree. ” As in Kamis et al . ( 2008 ) , two binary variables were constructed ( i.e. , reeommender type = 1 for CBF , recommender type = 0 for CLF ; market type = 1 for niche market , market type = o for blockbuster market ) to capture the four experimental group conditions . The model was tested via partial least squares ( PLS ) analysis using SmartPLS 2.0 with the bootstrapping resampling procedure ( Ringle et al . 2005 ) . The measurement models were validated using recommended validation procedures ( Chin 2010 ) . Scale items in one domain were pooled and factor analyzed to assess Thirty Fifth International Conference on Information Systems , Auckland 2014 . 9 Human Behavior and IS their convergent and discriminant validity ( Table 2 ) . While convergent validity was determined both at the individual item level and at the specified construct level , discriminant validity was assessed by analyzing the average variance extracted ( AVE ) . Further , all standardized factor loadings were significant ( p < 0.05 ) , thus providing evidence of convergent validity . Construct reliability was assessed by computing the composite reliability for each construct . All constructs had a composite reliability above the suggested threshold value of 0.70 ( Bagozzi and Yi 1988 ) . Further , all constructs met the suggested threshold value for the average variance extracted ( AVE > 0.50 ) . To prevent common method bias , we followed the reeommendations related to questionnaire design ( e.g. , assurance of respondent anonymity , concrete survey instructions to answer questions as honestly as possible , and to reduce ambiguity ) as suggested by Podsakoff et al . ( 2003 ) . To statistically test for common method bias , we used Harman ’ s one-factor test ( Harman 1967 ) . We conducted an exploratory factor analysis on all the variables , but the first single factor accounted for only 34.29 % of the covariance in the variables . Besides , correlation statistics indicate that correlations between all latent variables were significantly below 0.9 as recommended by Bagozzi et al . ( 1991 ) . The procedural and statistical remedies used in our study suggest that common method bias is unlikely to have significantly affected our results . Table 2 . Survey Instruments and Descriptive Statistics Constructs * | Indicators Loadings Source Perceived Please indicate how familiar you are with the reeommended songs : Becker- Recommen- a : a : Olsen dation not at all familiar / extremely familiar 0.946 ( 2002 ) ; Novelty - - - - Simonin a=0.925 definitely do not recognize / definitely do recognize 0.917 and Ruth - ‘ 1998 CR=0.953 definitely have not heard of it / definitely have heard of it before 0.02 ( 2998 ) AVE=0.870 “ 935 Perceived The recommendation system provided me with : Recommen- ws : : new : .. Surprising recommendations that helped me discover new dation : A 0.780 we music that I wouldn ’ t have found elsewhere . Serendipity a=0.881 .. recommendations that I had not considered in the first place 0 CR=0.924 but turned out to be a positive and surprising discovery . ‘ 947 AVE= 0.803 | ... recommendations that were a pleasant surprise to me because 0.0F1 I would not have discovered them somewhere else . ‘ 95 Perceived Conformity between recommended songs and user preferences . Franke et Preference Fit al . ( 2009 ) ; I like the selection of songs recommended to me on the website . | 0.931 a=0.918 Randall et CR=0.924 The selection of music titles reeommended to me on the website | 0.901 al . ( 2007 ) AVE=0.856 comes close to my idea of a perfect selection . The music titles recommended to me on the website coincide 0.943 with my personal preferences . Perceived While using the music website : Kamis et Enjoyment .. I found my visit interesting . 0.943 al . ( 2008 ) ; a=0.937 ———— Koufaris CR=0.958 .. 1 found my visit enjoyable . 0.961 ( 2002 ) AVE=0.884 .. 1 found my visit fun . 0.917 * Presentation of latent variable correlations is omitted for brevity . 10 Thirty Fifth International Conference on Information Systems , Auckland 2014 Escaping from the Filter Bubble ? Results Descriptive Statistics The experiment was conducted in March/April 2014 and included one pre-test to ensure the usability of the user interface and the readability of the task . Invitations to participate were distributed in several university-administered mailing lists and on social media sites . Thus , our sample consisted of a particularly high share of students among the participants . However , we deliberately decided to target students as participants not only for accessibility reasons , but also since students constitute a main purchasing group , both in e-commerce in general , but also with respect to purchasing music online . Eventually , a total of 130 participants completed the final experiment , of which 47 ( 36.15 % ) were male , 76 ( 58.46 % ) were female and 7 ( 5.35 % ) did not provide their gender . As expected , 98 ( 75.38 % ) and thus the majority of participants was in the age group of 20-29 years . During the experiment we recorded participants ’ song ratings , as well the number of songs they listened to and the number of recommendations that were played or purchased by them . The main characteristics for the different treatment groups are shown in Table 3 . The high average level of decision-making involvement ( based on Zhang et al . 2011 , also measured on a Likert-type scale from 1-7 ) indicated that our incentive scheme , offering the chance to win the songs that were selected during the experiment , seemed successful in increasing participants ’ motivation . Table 3 . Overview of Participation Treatment * CLF x BB CLF x NI CBF x BB CBF x NI Number of 33 32 31 34 Participants Number of Played | 43.00 63.50 51.00 60.50 Songs ( Median ) Number of 2.76 3.34 3.84 4.00 Recommendations Played ( Mean ) Number of 0.39 0.84 0.45 0.32 Recommendations Purchased ( Mean ) Decision Making 6.34 6.51 6.11 6.57 Involvement * CLF=collaborative filtering , CBF=content-based filtering , BB=blockbuster market , NI=niche market Test of Hypotheses We tested Hypotheses 1 and 2 by analyzing the total ( pooled ) sample of our model ( Figure 2 ) . Based on this , 32.9 % of the variance in perceived preference fit and 7.3 % of the variance in perceived enjoyment is explained by the research model . Regardless of recommender technology and market characteristics , a significant negative effect of perceived recommendation novelty on perceived preference fit was found , thus supporting Hia . The effect of perceived recommendation novelty on perceived enjoyment was negative , and not statistically significant — therefore Hib was rejected . As hypothesized , perceived recommendation serendipity had a significant positive effect on both perceived preference fit and on perceived enjoyment , thus supporting H2a and H2b . Thirty Fifth International Conference on Information Systems , Auckland 2014 11 Human Behavior and IS Perceived Preference Fit 32.9 % Perceived Recommendation Novelty -0.449 * * * 0.413 * * * Perceived Enjoyment 7-3 % Perceived Recommendation Serendipity * p < 0.05 , * * p < 0.01 , * * * p < 0.001 Figure 2 . Measurement Model Results To analyze Hypotheses 3 and 4 and to account for the influences of reeommender technology and market type characteristics , we split the data according to their treatment groups . Table 4 depicts the means and standard deviations for the construct variables for each treatment . Table 4 . Means and Standard Deviations for the Different Treatments Construct/ Treatment CLF x BB CLF x NI CBF x BB CBF x NI Perceived Recommendation Novelty ( PRN ) 2.32 ( 1.27 ) 3.66 ( 1.61 ) 3.23 ( 1.51 ) 4.29 ( 1.57 ) Perceived Recommendation Serendipity ( PRS ) | 2-24.39 ) | 3.72.72 ) | 2.908 ( 4.29 ) | 3.39 ( 2.50 ) Perceived Preference Fit ( PPF ) 3.22 ( 1.96 ) 3.47 01.63 ) 3.09 ( 1.48 ) 2.37 ( 1.29 ) Perceived Enjoyment ( PE ) 4.77 ( 1.53 ) 4.92 ( 1.73 ) 5.11 ( 1.18 ) 5.36 ( 1.40 ) Effect sizes were calculated using partial n2 , whereas 0.009 constitutes a small , 0.058 a medium and 0.138 a large effect ( Cohen 1988 ) . A two-way MANOVA revealed significant multivariate main effects for both recommender type ( Pillai ’ s Trace=0.111 , F=3.838 , p < o0.01 , partial 72=0.111 ) and market type ( Pillai ’ s Trace=0.216 , F=8.472 , p < 0.001 , partial n2=0.216 ) , while the interaction effect of recommender and market type was not significant ( Pillai ’ s Trace=0.053 , F=1.733 , p=0.147 , partial n2=0.053 ) . Given the significance of the tests of the two main influence factors , we continued with the analysis of the univariate effects . Significant univariate main effects were present for the influence of recommender type on perceived novelty ( F=8.644 , p < 0.01 , partial n2=0.064 ) as well as for the effects of market type on perceived novelty ( F=21.006 , p < o.001 , partial n2=0.143 ) and on perceived serendipity ( F=13.151 , p < 0.001 , partial n2=0.095 ) . The effect of recommender technology on perceived serendipity was not significant ( F=0.617 , p=0.434 , partial n2=0.005 ) . However , taking into account the fairly large mean differences for the different reeommender groups , pair-wise differences were calculated and tested for all relevant combinations of treatments ( Table 5 ) . Pairwise comparisons of means across groups revealed that CBFs lead to significantly higher levels of perceived recommendation novelty in blockbuster markets . Since the effects were not significant for niche markets , we see partial support for H3a . In respect of perceived recommendation serendipity , CBFs elicit higher levels only in blockbuster , but not in niche markets , where perceived serendipity is slightly ( but not significantly ) higher for CLFs - thus there is partial support for H3b . 12 Thirty Fifth International Conference on Information Systems , Auckland 2014 Escaping from the Filter Bubble ? Table 5 . Pair-wise Comparisons of Differential Effects of Recommender Technology and Market Characteristics Mean Differences for Different Perceived Recommen-_ | Perceived Recommen- Treatment Groups ( I-J ) dation Novelty dation Serendipity Recommender Technology CLF x BB ( D CBF x BB ( J ) -0.90 * -0.74 * CLF x NI ( 2 ) CBF x NI ( J ) -0.64 0.33 Market Characteristics CLF x BB ( D CLF x NI ( J ) -1.33 % * * -1.48 * * * CBF x BB ( 1 ) CBF x NI ( J ) -1.07 * * -0.41 * p < 0.05 , * * p < 0.01 , * * * p < 0.001 , based on LSD-test When comparing differences between blockbuster and niche markets , perceived recommendation novelty is higher for both recommender technologies and is therefore evidence for supporting H4a . When comparing levels of perceived recommendation serendipity , the differences are only significant for CLFs , but not for CBFs . This gives partial support for H4b . In Figure 3 , the estimated means of perceived recommendation serendipity were plotted for each of the two recommender technologies and market types . Estimated Marginal Means of Perceived Recommendation Serendipity 4,005 3,505 Estimated Marginal Means & i 2.504 2,005 T Collaborative Filtering T Content-based Filtering Recommender Type Market Type — Blockbuster —Nliche 4004 3504 3,004 Estimated Marginal Means 2,004 T Blockbuster T Niche Market Type Estimated Marginal Means of Perceived Recommendation Serendipity Recommender Type — Collaborative Fittering — Content-based Fittering Figure 3 . Means of Perceived Recommendation Serendipity Discussion and Further Implications The main objective of this paper was to unravel the effects of perceived recommendation novelty and perceived recommendation serendipity on the evaluation of online product recommendations and to account for contextual factors , involving different reeommender system technologies and different market characteristics . Our findings provide a finer-grained understanding of users ’ evaluation of online recommendations and help to answer the initial question of whether users want to escape from the so- called “ filter bubble ” . This was necessary as previous research has focused too much on optimizing recommender systems for accuracy , and the IS literature had not yet theorized about how different levels of perceived recommendation novelty and perceived recommendation serendipity impact users ’ perceived preference fit and their perceived enjoyment . Our results demonstrate that recommendation novelty alone is not a sufficient means to escape from the filter bubble , since more novelty comes at the costs of Thirty Fifth International Conference on Information Systems , Auckland 2014 13 Human Behavior and IS lower perceived preference fit . Higher levels of perceived serendipity on the other hand can positively influence users ’ perceived preference fit and their perceived enjoyment . Another important contribution of this study is related to its investigation of two antecedents of the perceived levels of recommendation novelty and serendipity : recommender technology and market type . The results show that CBF-systems are more likely to provide novel and serendipitous items in blockbuster markets , while this is not the case for niche markets . This is probably because CBF- recommenders do not take the items ’ popularity into account . Thus , in niche markets , the relative share of CBF-recommendations of niche products is likely to be larger than for CLF-recommenders . Particularly in niche markets , the higher values for perceived preference fit indicate that CLF-systems seem to profit from the quality assessment of users who have previously decided to purchase certain songs and thus these songs are more likely to be recommended again . From a practical perspective , the present results suggest that online retailers should place a stronger focus on providing serendipitous recommendations and integrate serendipity considerations into the design of recommendation algorithms . Most of the current recommender systems have been criticized to not sufficiently account for serendipity . Accordingly , providers of online stores need to analyze their current recommender systems and reassess their suitability of providing serendipitous recommendations . However , optimizing current recommender systems for more serendipitous recommendations is not a trivial task . The creation of serendipitous recommendations involves deviations from users ’ predefined preferences . This in turn entails higher risks that users may not like recommendations , since they do not fit their tastes and thus users could stop following recommendations in the future ( Ge et al . 2010 ) . Therefore , recommender systems need to be optimized for novel recommendations that are to some degree aligned to users ’ previous preferences . By monitoring user behavior over time , recommender systems could become more sophisticated in identifying such recommendations . But also since user preferences can change over time , it seems reasonable that serendipity metrics need to follow a user ’ s actions and interests over a longer period of time to identify patterns for deviations from users ’ regular behavior . A time-variant factor could also be used to identify items that are “ on the rise ” . If items receive many positive evaluations or are purchased often within a short period of time , they appear to be rather “ hip ” . This could serve as an indicator that such an item would also be liked by other users who have just not yet discovered it . However , since users may deviate in their personal attitude towards novel and serendipitous recommendations , online vendors may also think about explicitly asking users about their individual attitude and adopt recommendations based on this . Limitations and Opportunities for Further Research Despite extensive efforts to provide an experimental environment with high ecological validity , the current study at hand is subject to several limitations . First of all , our experiment only covered digital music . Digital music is an experience good and thus it is more difficult to describe and to be evaluated prior to consumption . Research has shown that effects of reeommender systems can differ between search and experience goods ( Benlian et al . 2012 ) . In addition , music is a product that is known to affect consumers emotionally rather than being evaluated by objective measures . Consequently , consumers ’ perceptions and desires for novelty and serendipity may well be affected by the product type we have chosen and should thus be validated with other types of products . Secondly , even for a distinct product type the perception of an ideal level of recommendation novelty and recommendation serendipity may differ dependent on the concrete usage situation and the evaluation costs of novel or serendipitous recommendations . For users of flat-rate-based streaming services for instance , trying out new products may be seen as a positive experience , since evaluation costs are little . However , with regard to product purchases , a very high share of unknown product recommendations could be seen as less constructive , since users may rather wish to stay closer to their current preferences ( Herlocker et al . 2004 ) . We therefore encourage the analysis of the effects of different levels of recommendation novelty and recommendation serendipity in other usage scenarios . Lastly , as previously mentioned , our sample consisted of a disproportionately high proportion of students . We believe that due to our incentive scheme which ensured participants ’ motivation and the fact that students are a consumer group who frequently purchases music online , they are appropriate for our study . 14 . Thirty Fifth International Conference on Information Systems , Auckland 2014 Escaping from the Filter Bubble ? However , our results should be validated with a representative sample of Internet users to ensure that our sample has not confounded the results . Conclusion Recommender systems have become omnipresent in e-commerce . Their wide usage spectrum has raised concerns that users could too often receive recommendations for products which they are already familiar with or that are too similar to their previous purchases . The proposed “ filter bubble ” phenomenon motivated our research to analyze how consumers perceive recommendations of items that are different from previously discovered items . By drawing on concepts of recommendation novelty and recommendation serendipity , the present study found that perceived recommendation serendipity has a strong positive effect , both on perceived preference fit as well as on the perceived enjoyment of the users . In contrast to this , a higher level of perceived recommendation novelty reduces perceived preference fit and does not lead to significant changes to users ’ perceived enjoyment . Theoretically , the study disentangles the differential effects of perceived recommendation novelty and perceived recommendation serendipity on both a directly reeommendation-related parameter ( preference fit ) as well as on an affective parameter ( perceived enjoyment ) . Practically , the study emphasizes that there should be a focus on recommendation serendipity , and not on recommendation novelty , in recommender system development . In respect of moving recommender algorithm design in this direction , environmental factors , such as the distribution of niche and blockbuster products , need to be considered . Therefore we advise the development of domain-specific recommender solutions . It is hoped that the present study ’ s results inspire future research which aims to improve and develop recommender systems that are capable of providing users with a suitable level of serendipitous recommendations . References Adamopoulos , P. , and Tuzhilin , A . 2011 . `` On Unexpectedness in Recommender Systems : Or How to Expect the Unexpected , ” in Proceedings of the Workshop on Novelty and Diversity in Recommender Systems at the Fifth ACM International Conference on Recommender Systems , Chicago , IL , USA . Adomavicius , G. , and Kwon , Y . 2011 . `` Maximizing Aggregate Recommendation Diversity : A Graph- Theoretic Approach , '' in Proceedings of the Workshop on Novelty and Diversity in Recommender Systems at the Fifth ACM International Conference on Recommender Systems , Chicago , IL , USA , pp . 3-10 . Adomavicius , G. , and Kwon , Y . 2012 . `` Improving Aggregate Recommendation Diversity Using Ranking- Based Techniques , '' IEEE Transactions on Knowledge and Data Engineering ( 24:5 ) , pp . 896-911 . Adomavicius , G. , and Tuzhilin , A . 2005 . `` Towards the Next Generation of Recommender Systems : A Survey of the State-of-the-Art and Possible Extensions , ” JEEE Transactions on Knowledge and Data Engineering ( 17:6 ) , pp . 734-749 . Ahn , H. J . 2006 . `` Utilizing Popularity Characteristics for Product Recommendation , '' International Journal of Electronic Commerce ( 11:2 ) , pp . 59-80 . Anderson , C. 2006 . The Long Tail : Why the Future of Business Is Selling Less of More . New York : Hyperion . Bagozzi , R. P. , and Yi , Y . 1988 . `` On the Evaluation of Structural Equation Models , '' Journal of the Academy of Marketing Science ( 16:1 ) , pp . 74-94 . Bagozzi , R. P. , Yi , Y. , and Phillips , L. W. 1991 . `` Assessing Construct Validity in Organizational Research , ” Administrative Science Quarterly ( 36:3 ) , pp . 421-458 . Balabanovié , M. , and Shoham , Y . 1997 . `` Content-Based , Collaborative Recommendation , '' Communications of the ACM ( 40:3 ) , pp . 66-72 . Bechwati , N. N. , and Xia , L. 2003 . `` Do Computers Sweat ? The Impact of Perceived Effort of Online Decision Aids on Consumers ’ Satisfaction with the Decision Process , '' Journal of Consumer Psychology ( 13:1/2 ) , pp . 139-148 . Becker-Olsen , K. L. 2003 . `` And Now , a Word from Our Sponsor : A Look at the Effects of Sponsored Content and Banner Advertising , ” Journal of Advertising ( 32:2 ) , pp . 17-32 . Bell , R. , Bennett , J. , Koren , Y. , and Volinsky , C. 2009 . `` The Million Dollar Programming Prize , '' IEEE Spectrum ( 46:5 ) , pp . 28-33 . Thirty Fifth International Conference on Information Systems , Auckland 2014 15 Human Behavior and IS Benlian , A. , Titah , R. , and Hess , T. 2012 . `` Differential Effects of Provider and User Recommendations in E-Commerce Transactions : An Experimental Study , '' Journal of Management Information Systems ( 29:1 ) , pp . 237-272 . Brynjolfsson , E. , Hu , Y. J. , and Simester , D. 2011 . `` Goodbye Pareto Principle , Hello Long Tail : The Effect of Search Costs on the Concentration of Product Sales , '' Management Science ( 57:8 ) , pp . 1373-1386 . Brynjolfsson , E. , Hu , Y. J. , and Smith , M. D. 2006 . `` From Niches to Riches : Anatomy of the Long Tail , ” MIT Sloan Management Review ( 47:4 ) , pp . 67-71 . Chin , W. W. 2010 . `` How to Write up and Report PLS Analyses , ” in Handbook of Partial Least Squares . Springer , pp . 655-690 . CNN . 2013 . “ Internet Gains Are Serendipity 's Loss . '' Retrieved 26.04.2014 , from http : //edition.cnn.com/2013/11/20/tech/web/internet-serendipit Cohen , J . 1988 . Statistical Power Analysis for the Behavioral Sciences . Hillsdale : Psychology Press . Fleder , D. , and Hosanagar , K. 2009 . `` Blockbuster Culture 's Next Rise or Fall : The Impact of Recommender Systems on Sales Diversity , '' Management Science ( 55:5 ) , pp . 697-712 . Franke , N. , Keinz , P. , and Steger , C. J . 2009 . `` Testing the Value of Customization : When Do Customers Really Prefer Products Tailored to Their Preferences ? , '' Journal of Marketing ( 73:5 ) , pp . 103-121 . Ge , M. , Delgado-Battenfeld , C. , and Jannach , D. 2010 . `` Beyond Accuracy : Evaluating Recommender Systems by Coverage and Serendipity , '' in Proceedings of the Fourth ACM Conference on Recommender Systems , Barcelona , Spain , pp . 257-260 . Harman , H. H. 1967 . Modern Factor Analysis . Chicago , IL , USA : Univ . of Chicago Press . Hart , J. , Ridley , C. , Taher , F. , Sas , C. , and Dix , A . 2008 . `` Exploring the Facebook Experience : A New Approach to Usability , '' in Proceedings of the 5th Nordic Conference on Human-Computer Interaction : Building Bridges , pp . 471-474 . Herlocker , J . A. , Konstan , J . A. , Terveen , L. G. , and Riedl , J. T. 2004 . `` Evaluating Collaborative Filtering Recommender Systems , ” ACM Transactions on Information Systems ( 22:1 ) , pp . 5-53 . Hess , T. , Legner , C. , Esswein , W. , MaaB , W. , Matt , C. , Osterle , H. , Schlieter , H. , Richter , P. , and Zarnekow , R. 2014 . `` Digital Life as a Topic of Business and Information Systems Engineering ? , ” Business & Information Systems Engineering ( 6:4 ) , pp . 1-7 . Hinz , O. , and Eckert , J . 2010 . `` The Impact of Search and Recommendation Systems on Sales in Electronic Commerce , ” Business & Information Systems Engineering ( 2:2 ) , pp . 67-77 . Ho , S. Y. , Bodoff , D. , and Tam , K. Y . 2011 . `` Timing of Adaptive Web Personalization and Its Effects on Online Consumer Behavior , '' Information Systems Research ( 22:3 ) , pp . 660-679 . Hosanagar , K. , Fleder , D. , Lee , D. , and Buja , A . 2014 . `` Will the Global Village Fracture into Tribes ? Recommender Systems and Their Effects on Consumer Fragmentation , '' Management Science ( 60:4 ) , pp . 805-823 . Hurley , N. J . 2011 . `` Towards Diverse Recommendation , ” in Proceedings of the Workshop on Novelty and Diversity in Recommender Systems at the Fifth ACM International Conference on Recommender Systems , Chicago , IL , USA . Kamis , A. , Koufaris , M. , and Stern , T. 2008 . `` Using an Attribute-Based Decision Support System for User- Customized Products Online : An Experimental Investigation , '' MIS Quarterly ( 32:1 ) , pp . 159-177 . Koufaris , M. 2002 . `` Applying the Technology Acceptance Model and Flow Theory to Online Consumer Behavior , '' Information Systems Research ( 13:2 ) , pp . 205-223 . Matt , C. , Hess , T. , and WeiB , C. 2013 . `` The Differences between Recommender Technologies in Their Impact on Sales Diversity , '' in 2013 International Conference on Information Systems ( ICTS 2013 ) , Milano , Italy . McNee , S. M. , Riedl , J. , and Konstan , J . A . 2006 . `` Being Accurate Is Not Enough : How Accuracy Metrics Have Hurt Recommender Systems , '' in Extended Abstracts on Human Factors in Computing Systems , Montréal , Québec , Canada , pp . 1097-1101 . Pariser , E. 2011 . The Filter Bubble : What the Internet Is Hiding from You . Penguin UK . Park , S.-H. , and Han , S. P. 2013 . `` From Accuracy to Diversity in Product Recommendations : Relationship between Diversity and Customer Retention , ” International Journal of Electronic Commerce ( 18:2 ) , pp . 51-72 . Pathak , B. , Garfinkel , R. , Gopal , R. D. , Venkatesan , R. , and Yin , F. 2010 . `` Empirical Analysis of the Impact of Recommender Systems on Sales , '' Journal of Management Information Systems ( 27:2 ) , pp . 159- 188 . 16 Thirty Fifth International Conference on Information Systems , Auckland 2014 Escaping from the Filter Bubble ? Podsakoff , P. M. , MacKenzie , S. B. , Lee , J.-Y. , and Podsakoff , N. P. 2003 . `` Common Method Biases in Behavioral Research : A Critical Review of the Literature and Recommended Remedies , ” Journal of Applied Psychology ( 88:5 ) , pp . 879-903 . Randall , T. , Terwiesch , C. , and Ulrich , K. T. 2007 . `` User Design of Customized Products , ” Marketing Science ( 26:2 ) , pp . 268-280 . Ringle , C. M. , Wende , S. , and Will , A . 2005 . `` SmartPLS 2.0 . '' Hamburg , Germany . Senecal , S. , and Nantel , J . 2004 . `` The Influence of Online Product Recommendations on Consumers ’ Online Choices , '' Journal of Retailing ( 80:2 ) , pp . 159-169 . Simonin , B. L. , and Ruth , J . A . 1998 . `` Is a Company Known by the Company It Keeps ? Assessing the Spillover Effects of Brand Alliances on Consumer Brand Attitudes , ” Journal of Marketing Research ( 35:1 ) , Pp . 30-42 . Vargas , S. , and Castells , P. 2011 . `` Rank and Relevance in Novelty and Diversity Metrics for Recommender Systems , ” in Proceedings of the Fifth ACM International Conference on Recommender Systems , Chicago , IL , USA , pp . 109-116 . Veit , D. J. , Clemons , E. K. , Benlian , A. , Buxmann , P. , Hess , T. , Kundisch , D. , Leimeister , J. M. , Loos , P. , and Spann , M. 2014 . `` Business Models - an Information Systems Research Agenda , ” Business & Information Systems Engineering ( 6:1 ) , pp . 45-53 . Xiao , B. , and Benbasat , I . 2007 . `` E-Commerce Product Recommendation Agents : Use , Characteristics , and Impact , ” MIS Quarterly ( 31:1 ) , pp . 137-209 . Zhang , T. C. , Agarwal , R. , and Lucas , H. C. 2011 . `` The Value of IT-Enabled Retailer Learning : Personalized Product Recommendations and Customer Store Loyalty in Electronic Markets , '' MIS Quarterly ( 35:4 ) , pp . 859-882 . Zhang , Y. C. , Séaghdha , D . ©. , Quereia , D. , and Jambor , T. 2012 . `` Auralist : Introducing Serendipity into Music Recommendation , ” in Proceedings of the Fifth ACM International Conference on Web Search and Data Mining , Seattle , WA , USA . Zhou , T. , Kusesik , Z. , Liu , J.-G. , Medo , M. , Wakeling , J. R. , and Zhang , Y.-C. 2010 . `` Solving the Apparent Diversity-Accuracy Dilemma of Recommender Systems , ” Proceedings of the National Academy of Sciences ( 107:10 ) , pp . 4511-4515 . Thirty Fifth International Conference on Information Systems , Auckland 2014 17 Human Behavior and IS Appendix > Diamonds 7 Weean ’ Stop Be Cinderella = ater sie Symphony . Sete Nata amy > piso Bose a Super Bass - ee From The Bottom ( Explicit Version ) ‘ Space City ( Feat . Tow Down & Lucky Luciano ) I Need Your Love Titanium ( feat . Sia ) HEHE & @ IWant Your Soul ( TV Rock Remix ) KKK KK Hee ve ok oe Wwe week kx Kk ik kr KKK KH Wek Heke wHeK KK Wee we ok ok wk KK woke kk ww K Appendix 1 . Screenshot of Rating Phase eT a ) Set Fire To The Rain is p Lights ( Single Version ) > > Dire Rolling In The Deep Cay entiomen | 5 A Tes Suatoer . = Kryptonite Cre Mi Mi . El amma Miia Dancing Queen uw x A g z > ABE 3 na In Black > i awe z Rollg In The Deep Ecc . Someone Like You ( Live From The Brit Awards 2011 ) = sf Fire To The Rain ¥ aA > Peed Ihr Einkaufskorb ( 3/5 ) Appendix 2 . Screenshot of Purchasing Phase 18 Thirty Fifth International Conference on Information Systems , Auckland 2014 Exploring the Filter Bubble : The Effect of Using Recommender Systems on Content Diversity Tien T. Nguyen Pik-Mai Hui F. Maxwell Harper Loren Terveen Joseph A. Konstan GroupLens Research Computer Science and Engineering University of Minnesota Minneapolis , MN 55455 { tien , hui , harper , terveen , konstan } @ cs.umn.edu ABSTRACT Eli Pariser coined the term ‘ filter bubble ’ to describe the po- tential for online personalization to effectively isolate people from a diversity of viewpoints or content . Online recom- mender systems - built on algorithms that attempt to pre- dict which items users will most enjoy consuming - are one family of technologies that potentially suffers from this ef- fect . Because recommender systems have become so preva- lent , it is important to investigate their impact on users in these terms . This paper examines the longitudinal im- pacts of a collaborative filtering-based recommender system on users . To the best of our knowledge , it is the first paper to measure the filter bubble effect in terms of content diver- sity at the individual level . We contribute a novel metric to measure content diversity based on information encoded in user-generated tags , and we present a new set of methods to examine the temporal effect of recommender systems on the user experience . We do find that recommender systems expose users to a slightly narrowing set of items over time . However , we also see evidence that users who actually con- sume the items recommended to them experience lessened narrowing effects and rate items more positively . Categories and Subject Descriptors H.1 [ Information Systems ] : Personalization , Recommender systems ; H.1 [ Human-centered computing ] : Collabora- tive filtering Keywords filter bubble ; recommender system ; content diversity ; user experience ; tag-genome ; longitudinal data INTRODUCTION In less than two decades , recommender systems have be- come ubiquitous on the Internet , providing users with per- 1 . Copyright is held by the International World Wide Web Conference Com- mittee ( IW3C2 ) . IW3C2 reserves the right to provide a hyperlink to the author ’ s site if the Material is used in electronic media . www ’ l4 , April 7-11 , 2014 , Seoul , Korea . ACM 978-1-4503-2744-2/14/04 . http : //dx.doi.org/10.1145/2566486.2568012 . 677 sonalized product and information offerings . They play a significant role in companies ’ profit margins . For exam- ple : Amazon once reported that 35 % of its sales came from its recommendation systems [ 7 ] . Netflix in 2012 reported that 75 % of what its users watched came from recommen- dations [ 1 ] . Recommender systems have greater influence on users ’ choices than peers and experts [ 14 ] . They lower users ’ decision effort , and improve users ’ decision quality [ 20 ] . But from the early days of recommender systems , re- searchers have wondered whether recommender systems might cause the ‘ global village ’ to fracture into tribes [ 12 ] , leading to ‘ balkanization ’ [ 17 ] . Pariser [ 11 ] characterizes this worry in terms of a ‘ filter bubble ’ — a self-reinforcing pattern of narrowing exposure that reduces user creativity , learning , and connection . Investigating the filter bubble effect requires access to a longitudinal dataset that represents users ’ interaction with a recommender system and consumption of information items . We also must be able to distinguish users who act on the system ’ s recommendations from those who do not . In this paper , we meet these challenges by analyzing long- term users of the MovieLens recommender system . We look at whether recommendations received become more narrow over time , but more important we also look at whether con- tent consumed by using recommendation systems becomes more narrow . And because the essence of the risk of filter bubbles - that is people enter them willingly because they provide appealing content - we also explore the question of whether recommenders indeed provide that positive expe- rience — leading their users to consume content they enjoy better . We frame two specific research questions : e RQ1 : Do recommender systems expose users to nar- rower content over time ? e RQ2 : How does the experience of users who take rec- ommendations differ from that of users who do not regularly take recommendations ? To answer these questions , we develop two new research methods to isolate and measure the effect of accepting rec- ommendations from recommender systems . First , we sepa- rate users into categories based on how often they actually consume recommended content . This separation lets us fo- cus on users where a filter bubble is possible , and to compare these users against a control group who use the same system but do not regularly follow recommendations . Second , we introduce a method and metric for exploring changes in the diversity of consumed items over time . This method looks at the items consumed ( in our case , rated ) in a time window , and then uses the tag genome — a content coding derived from the community of users — to measure the diversity of those consumed items of a user . Hence , these analyses let us address the question of the filter bubble where it is most relevant — at the individual level . In answering these research questions , we make several contributions . First , we introduce a novel set of methods to study the effect that recommender systems have on users . Second , we provide quantitative evidence suggesting that users who take recommendations receive a more positive experience than users who do not . Third , we find evidence that while top-recommended items become more similar , the reduction in diversity is relatively small . Finally , we find that recommendation-takers consume more content diverse movies than non-recommendation-takers , and that these users are actively seeking to watch more diverse movies . 2 . RELATED WORK While there is little debate about the efficacy of recom- mender systems in commerce , the debate about whether rec- ommender systems are harmful to users has plenty of schol- ars on each side . Pariser [ 11 ] argued that the root of human intelligence is the ability to adjust and adopt with new information , and that recommender systems trap a user into an unchanging environment . This unchanged environment , which he coined the filter bubble , reduces creativity and learning ability , and strengthens the belief of the user . Tetlock [ 16 ] , a political scientist , ran a study in which he asked different people with various background for opin- ions on political and economic issues . Surprisingly , he found that normal people gave more accurate predictions than the experts . A reason for the low prediction accuracy of the ex- perts is that their views of the world are strengthened after years of study , leading to bias in making predictions . Sunstein [ 15 ] went further and argued that by absorbing experiences that are personalized to them , users share fewer and fewer common experience with each other . He argued that ‘ Without shared experiences , a heterogeneous society will have a much more difficult time in addressing social problems . People may even find it hard to understand one another ’ ( p. 6 , [ 15 ] ) . On the other hand , Negroponte , co-founder of the MIT Media Lab , suggested that users can use recommender sys- tems in such a way that it helps them to learn and explore new things . One such way is explored in “ The Daily US ’ , in which users have personal intelligent agents that explore and summarize topics that are not the users ’ interests [ 9 ] . Negroponte called these intelligent agents ‘ the unequivocal future of computing ’ [ 8 ] . Linden , one of the authors of Amazon ’ s recommender sys- tem , suggested that narrowing user choices is not what per- sonalization via recommender systems does . He argued that users can ’ t search for items that they are not aware of , there- fore , personalization increases serendipity [ 5 ] . With the idea of helping users achieve a good balance of awareness of new things , Kamba et al . [ 4 ] implemented a personalized news- agent called Krakatoa Chronicle . With Krakatoa Chronicle , users can choose how to balance between news that was per- 678 sonalized for them and news selected by editors as important for the whole community . Fleder et al . [ 2 ] , in their simulation study about the ef fect of recommender systems on sales ’ diversity , argued that at the user-user level , users are directed towards a common experience . This is because recommender systems can not recommend items with less data ( i.e . ratings ) , even if these items are favorable to the users . Therefore , recommended items can be new to an individual user , but they are overall the same ( i.e . popular items ) . Hosanagar et al . [ 3 ] , with a two-group designed study with users using iTunes as a rec- ommender platform , also found that users tend to consume more common items . They argued that users consume the same items because recommender systems help users widen their interests , leading to higher chances of consuming same items . Although these studies present very interesting results re- garding the debate about the filter bubble , they have some limitations . In Fleder et al. ’ s study , although they model user purchasing behaviors and how a recommender system works , their simulation does not capture the complexity of the user behaviors and their decision making processes . Fur- thermore , with only two items in the simulation , their study can not model the complexity of the eco-system of a recom- mender system , in which new items are added , and users ’ preferences drift over time . In Hosanagar et al. ’ s study , they build networks based on the user purchasing behav- iors . They then compute the properties of these networks ( e.g . median degrees & distances ) as a measure if users tend to purchase the same songs . Prior work leaves open the question of whether taking rec- ommendations leads to narrowing of consumed content . To the best of our knowledge , our study is the first study look- ing at recommended content diversity , user behavior over the time , and the effect of taking recommendations on consumed content diversity . 3 . DATA & METRICS In this section we describe our datasets and discuss our methods for identifying recommendation takers and com- puting the content diversity of movies . 3.1 Dataset To answer our research questions , we use data from Movie- Lens ’ . MovieLens is a movie recommender system that has been in continuous use since 1997 . As of September 2013 , there are 217,267 unique users who have provided more than 20 million movie ratings for more than 20,000 movies . We use this data because it offers us three unique advantages : longitudinal data , a recommender system with a well-known recommender engine , and an expressive way to compute con- tent diversity . Longitudinal data : MovieLens provides us longitudinal data of user rating data . MovieLens logs capture timestamps and other information when users rate movies and when they view pages of recommended movies . MovieLens provides a feature called ‘ Top Picks For You ( shown in figure 1 ) that takes users to a page displaying movies the user has not seen , ordered from the highest pre- dicted ratings to the lowest predicted ratings . By default , a ‘ Top Picks For You ’ page displays 15 movies , though users ? ‘ http : //www.movielens.org/ Page 1 of 1434 Prediction Your or Rating + Rating WICK ION . ( Notscen ; ) Battlestar Galactica ( 2003 ) DVD Drama , Sci-Fi , War [ add tag ] Popular tags : post-apocalyptic Or ) | sci-fi eGR ? | sp KKK Notseen = ) [ add tag ] Popular tags : organi : kkk kK me G03 '' | based on a book ar ( 2003 ) DVD v Not seen [ add tag ] Popular tags : Artistic TOOK Notseen = Figure 1 : Top Picks For You can change this default number ” . Since May 2003 , Movie- Lens started to log all user access to ‘ Top Picks For You ’ pages and recommended movies with their respective posi- tions in the recommendation lists at the time users accessing the page . Knowing when and what movies users rated , and when and what was recommended to users helps us identify if users are taking our recommendations and how consistently they consume the recommendations . A recommender system with a well-known recom- mender engine : MovieLens uses an item-item collabora- tive filtering ( CF ) algorithm * , a well-known and broadly- used recommendation algorithm that is robust in perfor- mance and scalability with high dimension data [ 13 ] . Due to these advantages , Amazon - one of the early industrial recommender systems - used it in production [ 6 ] . We think that analyzing the longitudinal data generated from one of the well-known and broadly-used algorithms makes our case more generalizable . An expressive way to compute content diversity : MovieLens provides tag genome data , an expressive way to characterize movie content . ‘ Tag-genome ’ is an information space in which for any pair of a movie and a tag , a relevance score is computed to indicate how best the tag describes the movie . Since 2006 , MovieLens has provided a feature that allows users to apply tags ( words or short phrases ) to movies . Vig et al . [ 19 ] , based on this tagging feature and the tags that MovieLens users have applied , built tag genome to help users navigate and choose movies where all dimensions , but one , are the same as those of the compared movie . In section 3.3 , we will describe the tag genome data in details and illustrate why we use this data to measure content diversity . It is important to use data that is independent from the ‘ Top Picks For You ’ computations . The tag genome data is only used to help users navigate through MovieLens ’ movie collections , and not be part of the ‘ Top Picks For You ’ com- putations . At the time we took a snapshot of the tag genome data ( April 2013 ) , it consisted of 9,543 distinct movies de- scribed by 1,128 distinct tags ( 10,764,504 pairs ) . In our analyses , all of the movies are in this information space . 7Our analyses suggest that only 3.2 % of our users change this number . * MovieLens switched to item-item CF algorithm in 2003 . 679 In this study , we analyze data in the period from February 2008 to August 2010 ( 21 months ) . We choose to analyze this period because of missing log data from February 2007 to December 2007 and from October 2010 to May 2012 . Due to the potential missing data in January 2008 and September 2010 , these periods are served as our buffer zones . 3.2 . Identifying recommendation takers To study the effect of ‘ taking ’ recommendations , we need to classify the users in our dataset into those that do ‘ take ’ recommendations and those that do not . In this section , we describe how we define these two groups . Rating Block . The last rating The first 15 ratings removed yh 02/2008 The first rating block The last rating block The first 3 months removed Ignore due to insufficient number of ratings Figure 2 : Rating Block Tlustration Our objective in this study is to examine the temporal effect of recommender systems on users throughout their lifecycles . To do so , we have to divide the rating history of a user into discrete intervals . Before we define these smaller intervals , for each user we remove the first 15 ratings because these ratings are given based on the movies suggested by MovieLens in order to gain knowledge about the preference of the new user . Then , we remove all of the ratings from the first three months after the first 15 ratings . We do this for three reasons : e some users rated an abnormally high numbers of movies in the first three months . This is potentially due to the fact that these users had watched many movies before joining MovieLens — they rated these movies to help MovieLens understand their preference better . How- ever , in this study , we want to capture the consumed movies which were recommended ; e we want to give users sufficient time to learn how to use MovieLens ; e we want to give MovieLens enough time to understand users ’ preferences better , in order to improve the qual- ity of recommendations . After removing these initial movies , we formulate intervals for the remaining rating history of a user . There are several ways to define an interval . One is to define an interval as a login session . Another is to define an interval as a block of n consecutive months . However , both of these approaches possess some potential problems for our temporal analyses . First , the number of ratings per interval between users is different . These differences are due to the frequencies using recommender systems are different among users . Second , the numbers of ratings provided by users diminishes over the time . Hence , with an interval defined as n consecutive months ( or even as a logging-in session ) , some intervals will have a lot of ratings , at others will not . These problems potentially make our analyses unreliable because the effect of recommender systems are different in different intervals . LA 08/2010 To address both of the potential problems described above , we define an interval as a block consisting of 10 consecutive ratings * . With this definition , from now on we refer to an interval of 10 ratings as a rating block . With this con- stant number of ratings per block , we make sure that all users have the same levels of using recommender systems throughout a defined rating block . We choose 10 ratings per rating block because we want a rating block sufficiently long enough to capture the long-term effect , and because our analyses show that 10 is the median of the distribution of numbers of ratings per 3 months , a sufficiently long time interval . If there are not enough ratings to form the last rating block , we will drop these ratings because we want to make sure all rating blocks have the same number of ratings . Figure 2 summarizes our method of forming a rating block . We only select users whose first ratings were in the ana- lyzed period ( i.e . in the period of February 2008 - August 2010 as defined in the section 3.1 ) . We include only those users who have three or more ratings blocks in the analyzed period . To simplify our writing , in the remainder of this pa- per we refer to this selected group of experimental subjects simply as users . Overall , we have 1,405 users in our analyses . These users made at least 3 rating blocks and at most 203 rating blocks ( mean= 12 , o = 15 ) . In our analyzed period , February 2008 to August 2010 , the 1,405 users provided 173,010 ratings on 10,560 distinct movies . 100 % of these movies are in tag genome database described above . They accessed their ‘ Top Picks For You ’ 150,759 times . Identifying consumed recommendations in a rating block . To investigate the effect of recommender systems on users , we need to identify which movies in each rating block were explicitly recommended to the user in the interface . With these recommended movies identified , we can measure the level of recommendation intake of a user during his rating history . Furthermore , with recommended movies identified in a rating block , we can examine the user experience when taking and not taking recommendations at the same time ( ie . within a rating block ) . Based on individual levels of recommendation intake , we classify users into two groups - those who take recommendations and those who do not . We will discuss our classification method in more detail in the next section . We define if a movie was recommended to user u by check- ing if the movie was in the ‘ Top Picks For You ’ before . Specifically , for any user u , a movie in his i ‘ ” rating block is defined as recommended to him if and only if the movie was in ‘ Top Picks For You ’ between 3 hours and 3 months before user u rated this movie . Figure 3 visualizes our definition . We require at least three hours to avoid the case where user u rated a movie upon seeing it in his ‘ Top Picks For You ’ ( an indication that the user rated it because they had seen it previously , not because they took the recommenda- tion and watched it on the spot ) . We believe that three hours is sufficient time for a user to watch a movie , then rate it . We set a limit of three months to accomodate the fact that some users might need substantial time to rent and consume a movie ; we capped the time limit to accomodate “ We also analyzed with other block sizes ( e.g . a block con- sisting of 15 ( or 5 ) consecutive ratings ) , and we observed the similar results . 680 Top Picks For You the ith rating block \\ J | 3 hours 3 months Time @ Rated movie . Movie in ‘ Top Picks For You ’ % & Rated movie that was in ‘ Top Picks For You ’ Figure 3 : Identifying if a rated movie was recom- mended before . the reality that as time passes , the likelihood of a causal link between the recommendation and consumption diminishes . In the next section , we discuss how we classify our users into two groups - a group that took recommendations ( fol- lowing Group ) and a group that did not ( Ignoring Group ) . Ignoring Group v.s . Following Group . The purpose of our study is to investigate the long term effect of using recommender systems on content diversity . To this end , it is useful to draw comparisons between two groups of users - one that consumes recommendations consistently over the time , and one that does not . Suppose that we classify user u solely based on the ratio of his rated movies that were recommended over the num- ber of the rated movies in his rating history . Some users might always take recommendations towards the beginning of their rating histories , then do not take any recommenda- tions towards the end . With potentially high ratios , these users could be classified as recommendation takers . How- ever , the effects of the recommender systems on these users are only towards the beginning of their rating histories . In order to estimate the consistent recommendation intake of a user over his rating history , we first look at whether the user took at least one recommendation in one of his rating blocks using the proposed method in the previous section . We argue that as long as within a rating block , user u took a recommendation , there was an effect of the recommendation system on that user in that rating block . We then compute the percentage of that user ’ s rating blocks in which the user took at least one recommendation . With these per-user percentages computed , we rank our users from the highest percentage to the lowest percentage . That said , the users who took recommendations in all of their rating blocks ( i.e . percentage 100 % ) , are placed on top , those that did not take recommendations in any of their rating blocks ( ie . percentage = 0 % ) are placed bottom . Users who did not take any recommendations in any of their rating blocks are classified as non-recommender takers and placed in the Ignoring Group . Users who took recommendations in at least 50 % of their rating blocks are classified as recommender takers and placed in the Following Group . Overall , the Following Group consists of 286 users , and the Ignoring Group consists of 430 users . Of these 430 users in the Ignoring Group , 52 never access to ‘ Top Picks For You ’ and 378 accessed ‘ Top Picks For You ’ but never consumed any recommendations . Figure 4 visualizes our classification method . The top 286 users ( Following Group ) ( Ignoring Group ) % of rating blocks in which a user took recommendations All users are sorted from the highest to the lowest percentage Figure 4 : The visualization of our methodol- ogy to identify recommendation takers and non- recommendation takers . All users are sorted from the highest to the lowest percentages . The two cut- off points blue and red are at 50 % and 0 % respec- tively . 3.3 Measuring Content Diversity Our study examines the effect of recommender systems on the content diversity of recommended and consumed ( rated ) movies . In this section , we describe the tag genome data , our method to compute content diversity using tag genome and discuss why we use tag genome . The tag genome [ 19 ] is an information space containing a set M of movies , and a set T of tags . The set 7 consists of tags that are highly descriptive about movies . How well tag t describes movie m is expressed via the relevance score rel ( t , m ) . The relevance score rel ( t , m ) takes on values from 1 ( does not describe the movie m at all ) to 5 ( strongly de- scribes the movie m ) ® Each movie m ; is represented as a vector of size |7'| where entry i,7 is the relevance of tag j to movie i . Figure 5 visualizes the tag genome information space . To measure the similarity of two movies , we compute the Euclidean distance between two movie vectors . That is : ™m Lower numbers indicate greater similarity . We use Eu- clidean distance instead of cosine distance because the movie ® This figure is reproduced based on the original figure in Vig et al . Vig et al . originally proposed the range to be from 0 to 1 . However , after several revisions , as of 09/26/2013 MovieLens uses the range of 1 to 5 . The bottom 430 users 681 Movies m : m2 Moi Mn t 4.3 | 24 3.3 | 1.0 ta 3.5 | 1.2 2.5 | 2.1 2 : rel ( t , m ) tht 2.0 | 39 5.0 | 4.0 th 2.8 | 1.6 2.6 | 5.0 Figure 5 : The visualization of tag genome. ” x tag genome matrix is dense ( i.e . rel ( t , ,mi ) > 0 Vé , k ) . The minimum distance in MovieLens dataset is 5.1 , rep- resenting the distance between two movies in the ‘ Hal- loween Series ’ : ‘ Halloween 4 : The Return of Michael Myers ( 1988 ) ’ , and ‘ Halloween 5 : The Revenge of Michael Myers ( 1989 ) ’ . The maximum distance in MovieLens dataset is 44.24 , representing the distance between two movies ‘ Paris was a woman ’ and ‘ The Matrix ’ . The average distance is 23.44 representing the distance between two movies ‘ Chron- icle ( 2012 ) ’ and ‘ End of Watch ( 2012 ) ’ . The standard de- viation of movie distances is 4.45 . We use tag genome because it provides an expressive way to describe the content of a movie . This expressive way is better than the traditional method of computing movie content diversity via user rating vectors . If two movies have similar user rating vectors , that means they are similarly liked , not that their content is similar . It is also better than computing movie content diversity based on meta-data such as genres , actors , or directors , etc. , because two movies that share actors or directors ( or even are ‘ comedies ’ ) may not actually be similar . The strength of our tag genome-based method lies in how tag genome computes the relevances between the set of tags T and the set of movies Mf . These relevances are computed based on a community-supervised learning approach . In this approach , users provide the training dataset by evaluating how strongly a tag describe a movie . With the training dataset and other sources of tags such as IMDB , Movie- Lens predicts the relevances for other pairs based on differ- ent machine learning models . Furthermore , the relevance of any pair of tag t and movie ¢ is constantly refined via feed- back from users . Hence , these relevance scores are better at describing the content of movies than user rating vec- tors and properties such as genres and directors . Due to its unique advantages , researchers have shown that the tag genome can help users navigate through a collection of thou- sands of movies [ 18 ] , and can assist users in remembering what movies are about [ 10 ] . To illustrate the difference of using user rating vectors and the tag genome for computing content diversity , we look at the following example . Based on the tag genome , the movie that is the most content similar to movie ‘ Halloween 4 : The cree revenge nse to teen Table 1 : The 9 tags describe the three movies . Revenge of Michael Myers ’ is ‘ Halloween 5 : The Revenge of Michael Myers ’ . However , based on the user rating vectors of MovieLens data , the most similar movie to ‘ Halloween 4 ... ’ is ‘ The Front Page ’ ( with the cosine similarity is 0.991 ) . Clearly , taking the content similarity in consideration , it is obvious that the former is more accurate the later because ‘ Halloween 5 ... ’ is the fifth movie in the ‘ Halloween film series ’ whereas ‘ The Front Page ’ has a different story line . Table 1 shows the content of the three movies are described by 9 tags . We choose these 9 out of 1,128 tags because these tags tell what ‘ Halloween 4 ... ’ is and is not about . 3.4 Measuring The Effect of Recommender Systems In this study , we measure the effect of recommendation systems on content diversity as well as the user experience . In the next section , we describe the metrics to compute con- tent diversity and user experience . Then , we discuss how we measure the effect of recommender systems . 3.4.1 The Metrics : Content Diversity : We compute the content diversity distribution of a group of users by computing the movie distance distribution of the group . Specifically , the content diversity of a list of recommended movies to user u is the average pair-wise distances of the movies in the list . We also do the same to compute the content diversity of con- sumed movies . Measuring the diversity of a list of items by averaging pairwise diversity scores was developed by Ziegler et al . [ 21 ] . To make our study more robust , we also use the maximum value of the pair-wise distances as the con- tent diversity metric . In our results , we will report both the average as well as the maximum pair-wise distances of a list of movies . For recommended movies , we compute the content diver- sity of the top 15 recommended movies per user . We choose only the top 15 because for most of our users who consulted ‘ Top Picks For You ’ , MovieLens always captured at least the top 15 recommended movies for them . This is because 15 is the default number of recommended movies shown on the first page when a user clicked on ‘ Top Picks For You ’ , Furthermore , only 0.05 % of the MovieLens ’ users changed the default number to less than 15 . For the consumed movies , we measure the content diver- sity of rated movies . Since we divide a user history into smaller rating blocks , we compute the content diversity of all 10 rated movies in a rating block for all rating blocks . User Experience : For user experience , we measure how much users enjoy movies via their given ratings in Movie- Lens . Specifically , we compute per user rating average of movies in a given rating block . 682 3.4.2 Group Comparison Following Group Ignoring Group x rs E 8 L ao 2 < 3 = : afl | g B o “ a =a ic aah Uh e uu g = < = 5 A : a Es 2 j [ 8 = | 3 oO b | hid Ss m fT Between-Group Comparison Figure 6 : The visualization for our within and be- tween group comparison for the content diversity of the consumed movies , where x is movie distance and y is a number of users . ( For the recommended movies , we replace the first rating block and the last rating block as the beginning and the end of users ’ rating histories . ) Since all the content diversity and user experience distri- butions are approximately normal , we investigate the effect of recommender systems by measuring the shift in means of the two distributions of a group . Specifically , to examine the effect of recommender systems on content diversity of a group , we measure the shift in means of the content diversity distributions at the beginning and at the end of the rating histories of all users in the group . We do the same for measuring the effect on user experience . Comparing the effect of recommender systems at the beginning and the end of a rating period is used by other researchers ( for example Hosanagar et al . [ 3 ] ) . We call this within-group comparison . To examine how the effect on content diversity or user experience is different between two groups , we measure the shift in means of the distributions of the two groups at the beginning rating histories of all users in the group . We do the same for the two distributions of the group at end of user rating histories . We call this between-group comparison . Figure 6 visualizes our comparison method . Since all the content diversity ( i.e . movie distance ) dis- tributions are approximately normal , we use t-tests to com- pare the means of the two distributions . Specifically , for the within-group comparison , we use a paired t-test . For the between-group comparison , due to the different sizes of the populations , ( 286 users in the Following Group vs. 430 users in the Ignoring Group , we use Welch ’ s t-test . All the above t-tests can be performed using the R statistical package * . We do the same for the user experience distributions . `` http : //www.r-project.org 4 . RESULTS We present our results as they relate to our two research questions . RQ1 : Do recommender systems expose users to narrower content over time ? To answer this question , we compare the content diversity of recommended movies at the beginning and at the end of a user ’ s observed rating history . Table 2 shows the content diversity of all users ° . We ob- serve that for all users the average pair-wise distance of the top-15 recommended movies becomes smaller over the time with a drop from 25.02 to 24.67 . The p-value for the t-test is 2.43e-06 , showing that the difference in the means between the two distributions are statistically significant . Therefore , although the drop in content diversity of the recommenda- tions is small , it is statistically significant . Table 2 : The average content diversity of the top 15 recommended movies These drops in content diversity are also observed in Fol- lowing Group as well as the Ignoring Group with the within- group p-values are 0.014 and 0.08 respectively . That means for the movies recommended to the Following Group be- came more and more similar , and this trend is statistically significant at 95 % confidence interval . Although the drop of the Ignoring Group is not statistically significant at 95 % level but at 90 % level , this drop carries a significant mean- ing . The Ignoring Group did not take recommendations from ‘ Top Picks For You ’ , leading to minimal changes on in the recommendation lists . This change is due to the fact that MovieLens still learned about the preferences of these users via ratings . MovieLens then made adjustments in the recommendation lists , and recommended movies that were more similar to these users . Interestingly , we also observe that the recommended movies to the Following Group seems to be more content diverse that those recommended to the Ignoring Group ( the between- group p-value 0.0037 at the beginning and p-value 0.0406 at the end of user rating histories ) . However , the dif- ference in the content diversity of the two groups becomes smaller over the time ( 0.48 at the beginning v.s . 0.29 at the end ) . Eventually the content diversity of the Following Group may become less than that of the Ignoring Group . However , this is an issue for future work . Negroponte [ 9 ] , Linden [ 5 ] , Kamba et al . [ 4 ] , and other researchers have proposed that users can use recommender systems as tools to explore new things that they are not aware of . Hence , potentially the content of consumed movies might be diverse . Thus , it is of our interest to investigate how taking recommendations affects the users ’ consumed content diversity and user experience . In the next section , we set out to answer our second research question : 5Of 1405 , 4 changed the default number to less than 15 ; 52 users never accessed to the ‘ Top Picks For You ‘ . Thus the number of users analyzed for this analysis is 1349 . 683 RQ2 : How does the experience of users who take recommendations differ from that of users who do not regularly take recommendations ? To answer our second research question , we set out to answer the following questions : a ) Does taking recommendations lower the con- sumed content diversity ? Our results , as shown in table 3 , suggest that at the be- ginning , there is no difference in the content diversity of the consumed ( rated ) movies by the two groups ( 26.67 vs. 26.59 with p value of the t-test = 0.6162 ) . This suggests that , af- ter using recommender systems for the first three months ° , the effect of recommender systems on the consumed movies of both groups is not significantly different . [ Rating Block | The First | The Last [ Within-group p-value | All users 26.60 26.01 1.542e-12 Following Group 26.67 26.30 0.01007 Ignoring Group 26.59 25.86 8.236e-07 Between-group p-value 0.6162 0.006468 Table 3 : The average content diversity of the con- sumed movies of the two groups However , our results also suggest that after using Movie- Lens sufficiently long enough , we can see the effect on con- tent consumed by users . At the end of our observed peri- ods , the content diversity of both groups is reduced . With p-values of approximately zero showing that the reductions are significant . Interestingly , we also observe that compared to Following Group , the Ignoring Group had higher drop . We observe similar results when we define the content di- versity as the maximum distance of a pair movies in the movie list ( table 4 ) . Using this metric , we find no differ- ences between the two groups during the first three months ( p-value = 0.237 ) , and we find that users consume less di- verse movies over time ( p-value = 8.903e-07 ) . Again , the following group consumed more diverse content than the ig- noring group . | Rating Block | The First | The Last [ Within-group p-value | All users 34.56 34.00 8.903e-07 Following Group 34.73 34.36 0.127 Ignoring Group 34.45 33.73 0.000 Between-group p-value 0.237 0.008 Table 4 : The maximum content diversity of the con- sumed movies of the two groups Given the finding that the Following Group watched more diverse movies than the Ignoring Group , we ask : b ) Did the Following Group have better experi- ence ? By their nature , movies recommender systems help users find movies that they may enjoy . Enjoyment is expressed via ratings : the higher the rating , the more enjoyable the movie . However , we observe that for all users ( N = 1405 ) , the rat- ing averages at the first rating block and at the last rating block are 3.69 and 3.57 respectively , suggesting the drop of ®°We recall that the first three months of usage history are removed before forming the first rating block ( see section 3.2 ) . Rating Block | 0.5 - 1 stars | 1.5- 2 stars | 2.5 - 3 stars | 3.5 - 4 stars | 4.5 - 5 stars All Users The First 2.7 % 5.3 % 17.8 % 46.5 % 27.7 % The Last 2.8 % 6.3 % 22 % 46.4 % 22.5 % Following Group The First 2.2 % 6.0 % 17.8 % 46.2 % 27.8 % The Last 1.8 % 5.1 % 19.0 % 49.2 % 24.9 % Ignoring Group The First 2.4 % 4.6 % 18.0 % 45.3 % 29.7 % The Last 3.6 % 6.9 % 21.5 % 45.1 % 22.9 % Table 5 : The percentage of rated movies in the respective rating ranges . 0.12 . This drop surprised us since we expected that recom- mender systems should have helped users identify movies better suited to their tastes . To analyze the user experience further , we look at the per- centage of movies all users rated at the rating scale from 0.5 to 5 stars as shown in table 5 . The percentages of watched movies that were rated higher or equal to 3.5 stars drop ( from 74.2 % to 68.9 % ) , whereas for the other rating stars , the percentages increase . We observe that overall , our users watched less enjoyable movies . Interestingly , we observe that the Following Group con- sumed more enjoyable movies . The percentage of the movies rated from 3.5 - 4 stars for this group increases from 46.2 % to 49.2 % , and that of the movies rated from 0.5 - 1 star de- crease from 2.2 % to 1.8 % . Furthermore , the percentages of the movies rated from 4.5 - 5 stars of All Users and Ignoring Group receives higher drop than that of the Following Group ( 5.2 % , 6.8 % and 2.9 % respectively ) . To verify that the trend that the users in the Following Group watched more enjoyable movies than the users in the Ignoring Group is statistically significant , for each group , we compute the distributions of per user rating mean in the first rating block . We also do the same for ratings in the last rating block . Since these distributions are normal , and have the same number of users with approximately the same variance , we perform t-test on these distributions . Like the methodology visualized in figure 6 , we compare the between-group distri- butions , and within-group distributions . However , this time our distributions are the distributions of rating mean . Our | Rating Block | The First | The last | Within-group p-value | 3.69 3.57 All users 16 Following Group 3.69 68 0.7 Ignoring Group 3.74 3.55 3.128e-11 Between-group p-value 0.2129 0.001719 Table 7 : Rating Mean of the two groups results , as shown in table 7 , suggest that in the first rating block , the users in the Ignoring Group had better experience than those in the Following Group . However , the enjoyment difference between the two groups ( measured by the differ- ence in rating mean ) is not statistically significant at the 95 % level of confidence interval ( p-value = 0.2129 ) . However , in the last rating block , the Ignoring Group watched less en- joyable movies than the Following Group . The enjoyment difference between the two groups is statistically significant ( p-value = 0.001719 ) . Furthermore , although the Following Group watched less enjoyment movies over the time , this drop is not statistically significant ( p-value = 0.7 ) . For the Ignoring Group , the drop in enjoyment is statistically signif- icant ( p-value = 3.128e-11 ) . 684 We look further into the experience users receive when they consumed movies that were and were not recommended . Specifically , we look at the experience of the Following Group since this group consumed a significant amount of recommended movies . As shown in table 6 , we observe the users in the Following Group consumed more enjoyable movies . The group gave at least 3.5 stars for 85 % and 84.7 % of consumed recommended movies in the first and the last rating block respectively . On the other hand , the group only gave 72 % and 72.8 % of consumed non-recommended movies at least 3.5 stars in the first and the last rating block respectively . These numbers mean that the group received worse experience when watching movies that were not rec- ommended for them . These results suggest that the users who followed recom- mendations received a better experience than those who did not follow the recommendations . However , as we mentioned above , some users in the Following Group did not always take recommendations . To verify whether taking recom- mendations indeed improves the experience of a user , we seek to answer the following question : c ) What does the change of rating average mean ? To clearly understand what it means when the rating changes 0.12 , we define the positive experience index as the per- centile of per use rating average . That means the change in percentile of a user ( or a group ) indicates how the positive experience of that user ( or a group ) changes is comparing to the population . If the average rating of a user is at 90th percentile , that means he receives more positive experience than the rest of 90 % of the population . Rating mean change | Percentile change All users -0.12 -11.97 following Group -0.01 -1.20 Ignoring Group -0.19 -18.86 Table 8 : The change in percentile corresponding the change in rating mean . With this analogy , we build the percentile table based on the ratings of all of the users ( N = 1405 ) in the analyzed period ( i.e . from February 2008 to August 2010 ) . We ob- serve that overall at the first rating block with the average rating of 3.69 , the Following Group is at 58.93 * '' percentile . That means the group had a better experience than more than half of the population . Whereas , the Ignoring Group in the first rating block with the average rating of 3.74 ( at 63.63 '' percentile ) , had even better experience than the Fol- lowing Group . However , in the last rating block , the per- centile of the Ignoring Group drops to 44.77 '' percentile , a 18.86 drop whereas the drop of the Following Group is 1.21 . That implies as time went by , the Ignoring Group Group Rating Block | In Predictions | 0.5- 1 stars | 1.5 - 2 stars | 2.5 - 3 stars | 3.5 - 4 stars | 4.5 - 5 stars The First ‘ Yes 1.6 % 3.8 % 9.6 % 50.2 % 34.8 % Following Group No 2.5 % 6.1 % 19.4 % 45.4 % 26.6 % The Last Yes 1.6 % 2.9 % 10.8 % 52.0 % 32.7 % No 2.2 % 5.2 % 19.8 % 48.8 % 24.0 % Table 6 : The percentage of rated movies in the respective rating ranges . received worst experience , or watched significantly less en- joyable movies , than the Following Group did . Table 8 sum- marizes our results . 5 . DISCUSSION We set out to better understand the broadening or nar- rowing influence of an online recommender system on its users : did it tend toward a filter bubble ? We found evi- dence for two forms of narrowing when analyzing all users - the items recommended by the system and the items rated by users both became slightly narrower ( less diverse ) over time . However , the results for all users obscure the most interesting part of the story . The narrowing effect actually was mitigated for users who appeared to ” follow ” the recom- mender ( operationalized as having rated movies that appear in their top-n recommendation lists ) ; in other words , taking recommendations lessened the risk of a filter bubble . First , recommendation-following users received more di- verse top-n recommendation lists than non-following users . Because recommenders are personalized , user actions affect their output . In the case of the relatively standard item-item algorithm evaluated in this research , rating recommended movies ( rather than movies chosen via other means ) appears to encourage the algorithm to broaden its future recommen- dations . Second , recommendation-following users narrowed the content diversity of their rated movies more slowly — these users were still narrowing ( significantly , but slightly ) , but the effect was smaller than for those users who never rated the movies the recommender showed to them . This begs the question - is there a “ natural ” narrowing effect over time , at least in the domain of movies ? After all , we form habits based on what we ’ ve watched recently , and as we watch more , we solidify our preferences . In the movie domain , we face the additional possibility that the best movies are relatively diverse in content , but limited in number ; once we get through those , we turn to newer movies closer to our comfort zone . If this is true — if there is a natural tendency to narrow our consumption of movies ( or other media ) over time — then collaborative filtering-based recommenders appear to help mitigate the tendency , and thus may play a broadening role . What can the designers of recommender systems do to dis- courage the narrowing tendency ? First , they can use collab- orative filtering algorithms like those in MovieLens , which slows the narrowing effect over time . It is an open ques- tion if content-based recommenders have the same effect as collaborative recommenders , ; we suspect the content-based alorithms will more strongly push users towards narrow con- sumption . Second , recommender systems can inform users about the diversity of their consumption . Be it movies or news , a site can display diversity metrics or summary statis- tics that help users better understand if they have in fact gone too far into a particular interest of theirs . Finally , if recommenders aren ’ t enough to reduce the narrowing effect , we should explore further steps to intentionally increase di- 685 versification of recommendation lists . This is consistent with Ziegler ’ s finding [ 21 ] that diversification can improve user satisfaction . Our work has several limitations . We can not be sure if people are really following MovieLens recommendations , since we are using log data analysis methods . Addition- ally , users may be influenced by recommendations from other information sources or from their friends . To verify recommendation-following behavior would require contact- ing users to develop baseline measures for recommendation Furthermore , due to the design of the Movie- Lens logging infrastructure , we are restricted to analyzing the `` top picks for you ” interface . A superior set of log data would facilitate analysis across all recommendation in- terfaces in the system . Perhaps most importantly , we are attempting to find generalizable learning from a particular system ( MovieLens + item-item CF ) with a particular kind of item ( movies ) . There is plenty of room for studying the differential rates of narrowing ( or broadening ) across media , and across algorithms . We hope our methods and results can be applied to inform the study of those domains . awareness . 6 . ACKNOWLEDGEMENT This work is supported by the NSF grants IIS IIS 08- 08692 and IIS 10-17697 . We also thank the late Professor John T. Riedl for his advice and support in the first half of this project . We thank Shou Chang , Daniel Kluver , and Aaron Halfaker for feedback . 7 . REFERENCES [ 1 ] X. Amatriain and J. Basilico . The netflix tech blog : Netflix recommendations : Beyond the 5 stars ( part 1 ) . http : / /techblog.netflix.com/2012/04/netflix- recommendations-beyond-5-stars.html , visited on 2013-09-06 . D. Fleder and K. Hosanagar . Blockbuster culture ’ s next rise or fall : The impact of recommender systems on sales diversity . Management Science , 55 ( 5 ) :697-712 , May 2009 . K. Hosanagar , D. M. Fleder , D. Lee , and A. Buja . Will the global village fracture into tribes : Recommender systems and their effects on consumers . SSRN Scholarly Paper ID 1321962 , Social Science Research Network , Rochester , NY , Oct. 2012 . T. Kamba , K. A. Bharat , and M. C. Albers . The krakatoa chronicle-an interactive , personalized newspaper on the web . 1995 . G. Linden . Eli pariser is wrong . http : //glinden . blogspot . .com/2011/05/eli-pariser-is- wrong.html , visited on 2013-09-13 . G. Linden , B. Smith , and J. York . Amazon.com recommendations : itern-to-item collaborative filtering . IEEE Internet Computing , 7 ( 1 ) :76-80 , 2003 . [ 7 ] M. Marshall . Aggregate knowledge raises $ 5m from [ 11 [ 12 [ 13 kleiner , on a roll | VentureBeat . http : //venturebeat .com/2006/12/10/aggregate- knowledge-raises-5m-from-kleiner-on-a-roll/ , visited on 2013-09-06 . N. Negroponte . 000 000 111 - double agents . http : //www.wired.com/wired/archive/3.03/negroponte_pr -html , visited on 2013-09-13 . N. Negroponte . Being Digital . Random House LLC , Jan. 1996 . T. T. Nguyen , D. Kluver , T.-Y . Wang , P.-M. Hui , M. D. Ekstrand , M. C. Willemsen , and J. Ried ] . Rating support interfaces to improve user experience and recommender accuracy . To appear in the seventh ACM Recommender System Conference , RecSys 2013 , Oct. 2013 . E. Pariser . The Filter Bubble : What the Internet is Hiding from You . Penguin , Mar . 2012 . P. Resnick , N. Iacovou , M. Suchak , P. Bergstrom , and J. Riedl . GroupLens : an open architecture for collaborative filtering of netnews . In Proceedings of the 1994 ACM conference on Computer supported cooperative work , CSCW ’ 94 , pages 175-186 , New York , NY , USA , 1994 . ACM . B. Sarwar , G. Karypis , J. Konstan , and J. Riedl . Item-based collaborative filtering recommendation algorithms . In Proceedings of the 10th international conference on World Wide Web , WWW ’ 01 , pages 285-295 , New York , NY , USA , 2001 . ACM . 686 [ 14 ] 8 . Senecal and J. Nantel . The influence of online product recommendations on consumers ” online choices . Journal of Retailing , 80 ( 2 ) :159-169 , 2004 . C. R. Sunstein . Republic.com : XA-GB . ... Princeton University Press , 2002 . P. E. Tetlock . Expert political judgment : How good is it ? How can we know ? Princeton University Press , 2005 . M. Van Alstyne and E. Brynjolfsson . Global village or cyber-balkans ? modeling and measuring the integration of electronic communities . Management Science , 51 ( 6 ) :851-868 , 2005 . J. Vig , S. Sen , and J. Ried ] . Navigating the tag genome . In Proceedings of the 16th international conference on Intelligent user interfaces , pages 93-102 . ACM , 2011 . J. Vig , S. Sen , and J. Riedl . The tag genome : Encoding community knowledge to support novel interaction . ACM Trans . Interact . Intell . Syst. , 2 ( 3 ) :13:1-13:44 , Sept. 2012 . B. Xiao and I. Benbasat . E-commerce product recommendation agents : use , characteristics , and impact . MIS @ . , 31 ( 1 ) :1377209 , Mar . 2007 . C.-N. Ziegler , S. M. McNee , J . A. Konstan , and G. Lausen . Improving recommendation lists through topic diversification . In Proceedings of the 14th international conference on World Wide Web , pages 22-32 . ACM , 2005 . [ 15 ] [ 16 ] [ 17 ] [ 18 ] [ 19 ] [ 20 ] ( 21 ) 1308.6149v1 [ cs.SI ] 28 Aug 2013 arXiv The Extreme Right Filter Bubble Derek O ’ Callaghan University College Dublin Dublin 4 , Ireland . derek.ocallaghan @ ucd.ie Joe Carthy University College Dublin _ Dublin 4 , Ireland | joe.carthy @ ucd.ie ABSTRACT Due to its status as the most popular video sharing platform , YouTube plays an important role in the online strategy of extreme right groups , where it is often used to host associ- ated content such as music and other propaganda . In this paper , we develop a categorization suitable for the analysis of extreme right channels found on YouTube . By combining this with an NMF-based topic modelling method , we catego- rize channels originating from links propagated by extreme right Twitter accounts . This method is also used to cate- gorize related channels , which are determined using results returned by YouTube ’ s related video service . We identify the existence of a “ filter bubble ” , whereby users who access an extreme right YouTube video are highly likely to be rec- ommended further extreme right content . Keywords extreme right ; YouTube ; filter bubble ; matrix factorization . Categories and Subject Descriptors H.3.3 [ Information Search and Retrieval ] : Clustering ; H.3.5 [ Online Information Services ] : Web-based services 1 . INTRODUCTION Social media platforms have become a key component in the online strategy of extremist political groups , as they provide direct access to audiences , particularly youth , for radicaliza- tion and recruitment purposes [ 1 , 12 ] . YouTube ’ s status as the most popular video sharing platform means that it is es- pecially useful to these groups . Extreme right content such as music and other associated propaganda , some of which is deemed illegal in certain countries , is made freely avail- able there , often for long periods of time [ 4 ] . In addition to hosting user-generated video content , YouTube also provides Derek Greene University College Dublin Dublin 4 , Ireland derek.greene @ ucd.ie Maura Conway Dublin City University Dublin 9 , Ireland maura.conway @ dcu.ie Padraig Cunningham University College Dublin Dublin 4 , Ireland ; pacraig.cunningham @ ucd.ie recommendation services , where sets of related and recom- mended videos are presented to users , based on factors such as co-visitation count and prior viewing history [ 13 ] . In 2011 , Pariser proposed the filter bubble concept , which stated that recommendation services may limit the types of content to which a user is exposed [ 27 ] . Recommendation in social media can therefore have the undesirable consequence of a user being excluded from information that is not aligned with their existing perspective , potentially leading to im- mersion within an ideological bubble . In this paper we show that this can happen when a user accesses an extreme right ( ER ) video or channel on YouTube . In studies on English and German ER . content , we show that users are likely to be recommended further ER content within the same category , or related ER content from a different category . They are unlikely to be presented with non-ER content ( Figure 7 ) . Our previous work found that Twitter is used by extreme right groups to propagate links to content hosted on third- party sites , including YouTube [ 26 ] . These links enabled us to retrieve video and uploader channel information from YouTube , where subsequent analysis is focused upon chan- nels ( synonymous with uploaders or accounts [ 29 ] ) , rather than individual videos . We use a topic modelling strategy to characterize these channels ( see Section 4 ) , where content linked to these channels is then characterized in the same fashion . Our proposed scheme includes categories identified in the academic literature on the extreme right , which are suited to the videos and channels found on YouTube . We find evidence that an extreme right filter bubble does indeed exist , as shown by the results discussed in Section 5 . In Section 2 , we provide a description of prior work on You- Tube categorization and recommendation , along with re- search that involved the categorization of online extreme right content . The retrieval of YouTube data based on links originating from extreme right Twitter accounts is then dis- cussed in Section 3 . Next , in Section 4 , we describe the methodology used for related channel ranking , topic iden- tification , and channel categorization . Our investigation into the extreme right filter bubble can be found in Sec- tion 5 , where we focus on two data sets consisting primarily of English and German language channels respectively . An overview of the entire process can be found in Figure 1 . 2 . RELATED WORK 2.1 Video Recommendation Video recommendation on YouTube has been the focus of a number of studies . For example , Baluja et al . suggested that standard approaches used in text domains were not easily applicable due to the difficulty of reliable video labelling [ 2 ] . They proposed a graph-based approach that utilised the viewing patterns of YouTube users , which did not rely on the analysis of the underlying videos . The recommen- dation system in use at YouTube at the time was discussed by Davidson et al. , where sets of personalized videos were generated with a combination of prior user activity ( videos watched , favorited , liked ) and the traversal of a co-visitation graph [ 13 ] . In this process , recommendation diversity was obtained by means of a limited transitive closure over the generated related video graph . Zhou et al . performed a mea- surement study on YouTube videos to determine the sources responsible for video views , and found that related video recommendation was the main source outside of the search function for the majority of videos [ 33 ] . They also found that the click through rate to related videos was high , where the position of a video in a related video list played a critical role . A similar finding was made by Figueiredo et al . , where they demonstrated the importance of key mechanisms such as related videos in the attraction of users to videos [ 14 ] . Turning to the task of YouTube video categorization , Filip- pova et al . presented a text-based method that relied upon metadata such as video title , description , tags and com- ments , in conjunction with a pre-defined set of 75 categories [ 15 ] . Using a bag-of-words model , they found that all of the text sources contributed to successful category prediction . More recently , a framework for the categorization of video channels was proposed by Simonet , involving the use of se- mantic entities identified within the corresponding video and channel profile text metadata , [ 29 ] . Following the judgement that existing taxonomies were not well-suited to this partic- ular problem , a new category taxonomy was developed for YouTube content . Roy et al . investigated both video recom- mendation and categorization in tandem , where videos were categorized according to topics built from Twitter activity , leading to the enrichment of related video recommendation [ 28 ] . Video text metadata was used for this process , and the topics were based on the categories proposed by Filippova et al . , in addition to the standard YouTube categories at the time . Separately , they also analyzed diversity among related videos , where they found that there was a 25 % probability on average of a related video being from a different category . 2.2 Extreme Right Categorization In the various studies that have analyzed online extreme right activity , certain differences can be observed among re- searchers in relation to their categorization of this activity and associated organizations [ 5 ] . Burris et al . proposed a set of eight primarily US-centric categories in their analy- sis of a white supremacist website network ; Holocaust Re- visionists , Christian Identity Theology , Neo-Nazis , White Supremacists , Foreign ( non-US ) Nationalists , Racist Skin- heads , Music , Books/Merchandise [ 9 ] . A similar schema was used by Gerstenfeld et al. , which also included Ku Klux Klan and Militia categories [ 16 ] . They also discussed the dif- ficulty involved in the categorization of certain sub-groups , where a general category ( Other ) was applied in such cases . These categories were adapted in separate studies of Italian and German extreme right groups , where new additions in- cluded Political Parties and Conspiracy Theorists , while oth- ers such as Music and Skinheads were merged into a Young category ( Tateo [ 32 ] , Caiani et al . [ 10 ] ) . Rather than focus- ing on ideological factors , Goodwin proposed four organiza- tional types found within the European extreme right milieu ; political parties , grassroots social movements , independent smaller groups , and individual ‘ lone wolves ’ . Other notable categories include the Autonomous Nationalists identified within Germany in recent years . These groups focus specif ically on attracting a younger audience , where social media is often a critical component in this process [ 1 ] . The popularity of YouTube has led to its usage by extreme right groups for the purpose of content dissemination . Its related video recommendation service provides a motivation for the current work to analyze the extent to which a viewer may be exposed to such content . Separately , disagreements over the categorization of online extreme right activity sug- gests that a specific set of categories may be required for the analysis of this domain . 3 . DATA In our previous work , we investigated the potential for Twit- ter to act as one possible gateway to communities within the wider online network of the extreme right [ 26 ] . Two data sets associated with extreme right English language and German language Twitter accounts were generated , by retrieving profile data over an extended period of time . We gathered all tweeted links to external websites , and used these to construct an extended network representation . In the current work , we are solely interested in tweeted You- Tube URIs . Data for the Twitter accounts were retrieved between June 2012 and May 2013 , as limited by the Twit- ter API restrictions effective at the time . YouTube URIs found in tweets were analyzed to determine a set of chan- nel ( account ) identifiers that were directly ( channel profile page URD or indirectly ( URI of video uploaded by channel ) tweeted . All identified channels were included , regardless of the number of tweets in which they featured . Throughout this work , we refer to these as seed channels ; 26,460 and 3,046 were identified for the English and German data sets respectively . In order to explore the filter bubble hypothesis we must first categorize YouTube channels . To do this , we use text metadata associated with the videos uploaded by a particu- lar channel , namely their titles , descriptions and associated keywords . Although user comments have been employed in other work [ 15 ] , they were excluded here . This decision followed an initial manual analysis of a sample of tweeted videos , which found that comments were often not present , or had been explicitly disabled by the uploader . We also excluded the YouTube “ category ” field as it was considered too broad to be useful in the extreme right domain . Using the YouTube API , we initially retrieved the available text metadata for up to 1,000 of the videos uploaded by each seed channel , where the API returns videos in reverse chronologi- cal order according to their upload time . In cases where seed channels and their videos were no longer available ( e.g . the channel had been suspended or deleted since appearing in a tweet ) , these channels were simply ignored . ( a ) Data Related Channel ( b ) Methodology ( c ) Experiments Ranking YouTube Data Retrieval > > Filter Bubble Investigation Topic Identification Channel Categorization pty I | | Figure 1 : Overview of the process used to investigate the extreme right filter bubble on YouTube . In order to address the variance in the number of uploaded videos per channel , and to reduce the volume of subsequent data retrieval , we randomly sampled up to 50 videos for each seed . For each video in this sample , metadata values were retrieved for the top ten related videos returned by the API . Using the default parameter settings , these videos appear to be returned in order of “ relevance ” , as defined internally by YouTube , similar to the default behaviour of video search re- sults feeds described in the API documentation ( June 2013 ) . We refer to the corresponding uploaders as related channels ; 1,451,189 and 195,146 were identified for the English and German data sets respectively . As before , we then retrieved the available text metadata for up to 1,000 videos uploaded by each unseen related channel , from which a random sam- ple of up to 50 videos was generated . For both seed and related channels , the corresponding up- loaded video sample is used for categorization ; this is de- scribed in Section 4.2 . Separately , we also note that the videos in question may have been uploaded at any time prior to retrieval , where these times are not necessarily restricted to the period of either Twitter or YouTube data retrieval . 4 . METHODOLOGY Having retrieved the channel and video data from YouTube , the next steps involved ranking the related channels for each seed channel , identifying latent topics associated with the uploaded videos , and using these to categorize both seed and related channels . This section corresponds to part ( b ) of the process overview diagram found in Figure 1 . 4.1 Related Channel Ranking For our analysis , it was first necessary to generate a set of related channel rankings for each seed channel , according to the related rankings returned by the YouTube API for the sample of videos uploaded by the seed . We applied the SVD rank aggregation method proposed by Greene et al . to combine the rankings for each uploaded video into a single ranked set across all videos for the seed in question , from which we select the top ranked related channels [ 19 ] . We restrict our focus to the top 10 , given the impact of related video position on click through rate [ 33 ] . The aggregation process for each seed channel s ; and its n ; uploaded videos is as follows : 1 . For each uploaded video vw ; ( 7 € [ 1 , ni ] ) , generate a rank vector rvi ; between the seed s ; and its re- lated channels using the retrieved YouTube API re- lated video ranking . For channels related to seed videos other than w % ; , a rank of ( m ; + 1 ) is applied , where m ; is the total number of channels related to s ; . 2 . Stack all rv ; rank vectors as columns , to form the m ; x m rank matrix R ; , and normalise the columns of this matrix to unit length . 3 . Compute the SVD of Ri , and extract the first left sin- gular vector . Arrange the entries in this vector in de- scending order to produce a ranking of all channels related to this seed . From the ranking generated above , we then select the top 10 ranked related channels for each seed . These channels are used for our filter bubble investigation in Section 5 . 4.2 Topic Identification For the purpose of channel categorization , we initially iden- tified latent topics associated with the channels in both data sets , based on their uploaded videos . Following the ap- proach of Hannon et al . [ 20 ] , we generated a “ profile doc- ument ” for each seed and related channel , consisting of an aggregation of the text metadata from their corresponding uploaded video sample , from which a tokenized representa- tion was produced . All available terms in the channel doc- uments were used , where the tokenization process involved the exclusion of URIs and normalization of diacritics . We excluded a custom set of stopwords , such as official YouTube category terms , additional YouTube-specific terms such as “ video ” and “ view ” , and terms from multiple language stop- word lists . Due to the frequent presence of names in the data , we also excluded all identified first names . As sug- gested by Fillipova et al . [ 15 ] , terms were not stemmed due to the expectation of both noisy terms and those of multiple languages . Low-frequency terms appearing in < 20 channel documents were excluded at this point . These channel documents were transformed to log-based TF-IDF vectors , and subsequently normalized to unit length . However , in an attempt to reduce the term dimensionality found in the combination of seed and related channel docu- ments , we generated the TF-IDF vectors in two stages . The first stage constructed vectors for the seed documents , from which a reduced seed term vocabulary was derived . In the second stage , vectors for the related documents were then Table 1 : Categories of extreme right YouTube content , based on common categorizations found in academic literature on extreme right ideology . Category Description Source Anti-Islam Can include political parties ( e.g . Dutch PVV ) or groups such as the English | [ 1 , 17 ] Defence League ( EDL ) , which often describe themselves as “ counter-Jihad ” . Anti-Semitic All types of anti-Semitism , regardless of association ( existing literature tends | [ 9 , 32 ] to discuss this in relation to other categories ) . Conspiracy Theory | ‘ Themes include New World Order ( NWQ ) , Hluminati etc . Not exclusively | [ 1 , 30 , 32 ] ER , but often related to Patriot in this context . Music Includes any ER . music such as Oi ! , Rock Against Communism ( RAC ) etc . 1 , 9 , 32 Neo-Nazi Nazi references , such as to Hitler , WWIL , SS etc . 1 , 9 , 16 Patriot US-centric , including groups such as “ Birthers ” , militia , anti-government , | [ 30 ] anti-immigration , opposition to financial system . Some of these themes are not exclusive to ER . Political Party Primarily European parties such as the BNP , FPO , Jobbik , NPD , PVV , | [ 1 , 10 , 18 ] Swedish Democrats , UKIP etc . Many of these parties are also categorized as Populist . Populist Broader category that includes various themes such as anti-EU , anti- | [ 3 , 24 ] establishment , anti-state/government , anti-immigration ( as with Patriot , some of these are not exclusive to ER ) . Although some disagreement about this category exists [ 23 ] , we have used it as it has proved convenient for categorizing certain groups that span multiple themes . Revisionist References to Holocaust/W WII denial . Closely associated with Neo-Nazi . 9 , 16 , 32 ] Street Movement Groups such as the EDL , Autonome Nationalisten , Spreelichter , Anti-Antifa | [ 1 , 18 ] etc . White Nationalist | References to white nationalism and supremacism , also used to characterize | [ 9 , 16 , 32 ] political parties such as the BNP or Jobbik . constructed using the seed vocabulary . In both stages , short documents containing < 10 terms were excluded . We use m , and m , to refer to the number of seed and related channel document vectors in a particular data set . Topic modelling is concerned with the discovery of latent semantic structure or topics within a text corpus , which can be derived from co-occurrences of words and documents [ 31 ] . Popular methods include probabilistic models such as latent Dirichlet allocation ( LDA ) [ 6 ] , or matrix factoriza- tion techniques such as Non-negative matrix factorization ( NMF ) [ 21 ] . We initially evaluated both LDA and NMF- based methods with the seed channel document representa- tions described above ( the former was applied to TF vec- tors ) . However , as in our previous work , NMF was found to produce the most readily-interpretable results , which ap- peared to be due to the tendency of LDA to discover topics that over-generalized [ 11 , 25 ] . We were aware of the pres- ence of smaller groups of channels associated with multiple languages in both data sets , and opted for specificity rather than generality by applying NMF to the TF-IDF channel vectors . As we found previously , the IDF component en- sured a lower ranking for less discriminating terms , thus leading to the discovery of more specific topics . To allow the seed channel vectors to determine the topic ba- sis vectors , we undertook the process in two stages . Firstly , we generate topics for the seeds : 1 . Construct an n x m , term-document matrix V , , where each column contains a seed channel TF-IDF vector . 2 . NMF is applied to V , to produce two factors ; W ; , an n x T matrix containing topic basis vectors and H , , aT x ms matrix containing the topic assignments or weights for each seed channel document . For both data sets , this results in a set of basis vectors con- sisting of both ER and non-ER topics . The second stage involves producing topic assignments for the related chan- nel vectors : 1 . Construct an n x m , term-document matrix V , con- taining the related channel TF-IDF vectors . 2 . Generate a corresponding T ' x m , topic weights matrix H , by transforming V , according to the W ; model . The latter step was achieved with a single outer iteration of the H non-negative least squares sub-problem from the approach by Lin et al . [ 22 ] . As the basis vectors matrix Ws was fixed , only one outer iteration was necessary in order to generate an approximation of a converged H , . , thus permit- ting large related channel matrices to be factorized given the initial NMF operation on a far smaller seed matrix . In both cases , to address the instability introduced by random ini- tialization in standard NMF , we employed the deterministic NNDSVD initialization method [ 7 ] . 4.3 Topic and Channel Categorization As discussed earlier in Section 2.1 , some prior work has pro- posed generic categories for use with YouTube videos and channels . However , as these studies have focused on the categorization of mainstream videos , they are not sufficient for the present analysis where categories specifically associ- ated with the extreme right are required . In Section 2.2 , we discuss prior work that characterized online extreme right activity using a number of proposed categories , but as indi- cated earlier , no definitive set of categories is agreed upon in this domain [ 5 ] . Therefore , we propose a categorization based on various schema found in a selection of academic lit- erature on the extreme right , where this category selection is particularly suited to the ER videos and channels we have found on YouTube . Some categories are clearly delineated while others are less distinct , reflecting the complicated ide- ological make-up and thus fragmented nature of groups and sub-groups within the extreme right [ 16 ] . In such cases , we have proposed categories that are as specific as possible while also accommodating a number of disparate themes and groups . Details of the categories employed can be found in Table 1 . As both data sets contained various non-ER channels , we also created a corresponding set of non-ER . categories con- sisting of a selection of the general YouTube categories as of June 2013 , in addition to other categories that we deemed appropriate following an inspection of these channels and associated topics . These non-ER categories were : e Entertainment e Politics ¢ Gaming e Religion ° Military e Science & Education e Music e Sport e News & Current Af fairs e Television Having produced a set of T topics for a data set , we then proceeded to categorize them . For each topic , we manually inspected the high-ranking topic terms from the correspond- ing vector in W , , in addition to profiles and uploaded videos for a selection of seed channels most closely assigned to the topic , according to their weights in H ; . Multiple categories were assigned to topics where necessary , as using a single category per topic would have been too restrictive while also not reflecting the often multi-faceted nature of most topics that were identified . In many cases , categories for topics were clearly identifiable , with a separation between ER and non-ER . categories . For example , an English Defence League ( EDL ) topic was categorized as Anti-Islam and Street . Move- ment , while a topic having high-ranking terms such as “ gui- tar ” and “ band ” was categorized as Music . For certain topics , this separation was more ambiguous , where the channels as- signed to a particular topic consisted of a mixture of both ER and non-ER channels . A combination of both ER and non-ER , categories were assigned in such cases . The set of categorized topics was then used to label both seed and related channels , using the channel topic assign- ment weights found in the H matrices . This supports the potential assignment of multiple categories to a single chan- nel . To achieve this , it was first necessary to determine a weight threshold w for selecting discriminating topics to be used in the categorization of a particular channel . Using a Topics Categories Neo-Nazi hitler , adolf , reich Revisionist cover , guitar , acoustic ( a ) Categories assigned to topics . Channels Channel 1 Channel 2 ( b } Channel H weights for topics . Topics hitler , adolf , reich cover , guitar , acoustic Channels Channel 1 Channel 2 ( c ) Channels categorized using topics where H > w ( in this example , w = 0.05 ) . Categories Neo-Nazi Figure 2 : Topic and Channel categorization process . range of values for w , we calculated yp , the mean number of topics per channel with H weight > w , and selected the value for w where p =~ 1 ; the minimum number of topics required for categorization . As we performed NMF in two stages to produce H , and H , . for seed and related channels respectively , two corresponding ws ; and w , thresholds were generated due to the dependency of the H weights ’ upper bound on the input matrices V. Using these thresholds , each channel was categorized as follows : 1 . Select all topics where the channel ’ s corresponding row weights in H are > w. 2 . Add each selected topic weight to the totals maintained for the topic ’ s corresponding categories . 3 . Rank these categories in descending order based on their totals across all selected topics , and assign the highest ranked category to the channel . Multiple cat- egories are assigned in the event of a tie . A simple example illustrating the complete process of map- ping of channels to categories is shown in Figure 2 . We found that a certain number of channels , both seed and re- lated , had a flat profile with relatively low weights ( < w ) for all topics ; these could be considered as grey sheep . Further analysis found this to be due to factors such as the original documents being short or containing few unique terms . As we were unable to reliably categorize such channels , they were excluded from all subsequent analysis . Separately , al- though the NMF process often identified topics with high- ranking discriminating terms in languages other than that of the data set , a small number of topics with less discrimi- nating general language terms were also found . As it would have been difficult to distinguish between ER and non-ER . channels closely associated with these topics , these were also excluded . Further details on the w thresholds and numbers of excluded channels are provided in Section 5 . 5 . THE ER FILTER BUBBLE In this section , we discuss the filter bubble analysis of the English and German language YouTube data sets . The ex- perimental methodology is as follows : 1 . Generate an aggregated ranking of related channels for each seed channel . 2 . Generate TF-IDF channel document vectors , and iden- tify topics using NMF . 3 . Categorize the identified topics according to the set defined in Table 1 . 4 . Categorize the channels based on their topic weights in H. 5 . Investigate whether an extreme right filter bubble is present . For Step 5 above , we define an extreme right filter bubble in terms of the extent to which the related channels for a par- ticular extreme right seed channel also feature extreme right content . It has been shown that the position of a video in a related video list plays a critical role in the click through rate [ 33 ] . Therefore , we investigate the presence of a filter bub- ble using the top & ranked related channels , with increasing values of k € [ 1,3,5,7 , 10 ] , as follows . For each ER . seed channel : 1 . Select the top & ranked related channels , filtering any excluded channels as defined in Section 4.3 . Seed chan- nels with no remaining related channels following fil- tering are not considered for rank k. 2 . Calculate the total proportion of each category as- signed to the < & related channels . Then , for each ER . category : 1 . Select all seed channels to which the category has been assigned . 2 . Calculate the mean proportion of each related category associated with these seed channels . We consider a filter bubble to exist for a particular ER . cat- egory when its highest ranking related categories , in terms of their mean proportions , are also ER categories . 5.1 English language categories From the total number of channels in the English language data set , we generated 24,611 seed and 1,376,924 related channel documents , using a corresponding seed-based vo- cabulary of 39,492 terms . The TF-IDF matrices V ; and V , were then generated for seed and related documents re- spectively , and topics were identified by applying NMF to V ; . To determine the number of topics T ' , we experimented with values of T in [ 10,100 ] to produce topics that were as specific as possible , given prior knowledge of the pres- ence of smaller groups of channels associated with multiple languages within both data sets . This led to the selection of T ' = 80 , as larger values resulted in topic splits rather than the emergence of unseen topics . Of these , 27 ER . top- ics ( 33.75 % ) , 39 non-ER topics ( 48.75 % ) , 8 topics that were a combination of ER . and non-ER categories ( 10 % ) , and 6 topics based on general terms of a separate language ( 7.5 % ) were found . —— Seed —— Related Mean topics Topics =~ 1 0.01 0.02 0.03 0.04 0.05 0.06 007 0.08 0.09 w Figure 3 : English mean topics per channel at ws , w , in ( 0.01 , 0.09 ] . ws ; and w , were set to 0.03 and 0.08 respectively . These 80 topics were then categorized according to the set defined in Table 1 , which permitted the subsequent catego- rization of the seed and related channels using their corre- sponding H , and H , topic weights . As described in Section 4.3 , we first generated the weights thresholds ws ; and wr . Figure 3 contains the mean number of topics per channel p with H weight > w , for values of w in [ 0.01 , 0.09 ] . Us- ing 4 : =~ 1 as the selection criterion resulted in values of 0.03 and 0.08 for ws and w , respectively . Using these , we excluded 8,225 ( 33.42 % ) seed and 482,226 ( 35.66 % ) related grey sheep channels that could not be categorized . Related channels ranked at & > 10 were also excluded , and all non- ER . seed channels were removed from the candidate seed set . The remaining 6,573 ER seed and their 22,980 related ER-Anti-Islam im ER-Conspiracy Theory 0.65 __ER-Street Movement 5 NER-Entertainment eS NER-Religion 8 oO 04 > 2 Qa c oO oD = 0.27 | he A Wt ad ( a ) Anti-Islam ER-Music | ER-White Nationalist 0.65 NER-Entertainment Ss PY NER-Music 2 8 o 0.45 2 Q Cc o ® = 0.27 | ol al il u t t 1 1 i 1 3 5 7 10 k ( b ) Music || ER-Conspiracy Theory ( I ER-Patriot 0.65 HB ER—Political Party Ss | ER-Populist 2 | ER-White Nationalist g NER-Entertainment oO 0.44 | NER-News & Current Affairs Q Cc o ® 7 | i | oo . | I | hoa t t 1 1 i 1 3 5 7 10 k ( c ) Populist Figure 4 : English mean category proportions of top & ranked related channels ( & € [ 1,3,5,7,10 ] ) , for selected seed ER categories . channels were used to calculate the mean related category proportions for each ER . category . Figure 4 contains plots for three ER categories that we have selected for more detailed analysis , where ER and non-ER . categories have been prefixed with ER- and NER- respec- tively . To assist visual interpretation , we have omitted any weakly related categories whose mean proportion < 0.06 for a particular & ranking . From inspecting these plots , two initial observations can be made ; ( 1 ) the seed category is the dominant related category for all values of k , and ( 2 ) al- though related category diversity increases at lower & rank- ings with the introduction of certain non-ER . categories , ER . categories consistently have the strongest presence . In the case of Anti-Islam seed channels , it appears that the top ranked related channels ( k = 1 ) are mostly affiliated with various groups from the UK and USA . Street Movement re- lated channels at this rank are associated with the English Defence League ( EDL ) , a movement opposed to the alleged spread of radical Islamism within the UK [ 18 ] . Channels from various international individuals and groups that often describe themselves as “ counter-Jihad ” can also be observed [ 17 ] . The Conspiracy Theory and non-ER Religion cate- gories appear to be associated with channels based in the USA , where the dominance of these categories at lower rank- ings ( excluding the seed category ) suggests that the channels become progressively more US-centric . The ER Music seed channels usually upload video and audio recordings of high-profile groups associated with the extreme right . For example , content from bands such as Skrewdriver ( UK ) or Landser ( Germany ) can be found , along with other groups from genres such as Oi ! , RAC ( Rock Against Com- munism ) and NSBM ( National Socialist Black Metal ) [ 1 , 8 ] . Given this , the consistent presence of the White Nationalist related category would appear logical . At the same time , we also observe that non-ER . Music becomes more evident as k increases , perhaps reflecting the overlap between music gen- res . For example , someone who is a fan of NSBM is often a fan of other metal music that would not be categorized as ER . For Populist seed categories , the related categories generally appear more diverse . Channels affiliated with po- litical parties can be observed , including the Eurosceptic United Kingdom Independence Party ( UKIP ) or the British National Party ( BNP ) , where the latter is also considered as White Nationalist [ 3 , 24 ] . Opposition to establishment organizations such as the EU may be a link to similar op- position within the Patriot and Conspiracy Theory related categories that are also present [ 30 ] , while also explaining the presence of the non-ER News & Current Affairs category . It should also be mentioned that our definition of Populist is broad and spans multiple themes ( Table 1 ) , where a certain amount of disagreement about this category exists [ 23 ] . 5.2 German language categories A total of 2,766 seed and 177,868 related channel documents were generated from the German language data set . Topics were then identified by applying NMF to the corresponding TF-IDF matrices . As before , we experimented with values of T in [ 10,100 ] , and selected T = 60 given a similar ob- servation of redundant topic splits for larger values of T. Of these , 33 ER topics ( 55 % ) , 20 non-ER topics ( 33.33 % ) , 2 topics that were a combination of ER . and non-ER categories ( 3.33 % ) , and 5 topics based on general terms of a separate language ( 8.33 % ) were found . Having categorized these top- ics , we calculated the mean number of topics per channel jz with H weight > w , for values of w in [ 0.01 , 0.09 ] , as seen in Figure 5 . Values of 0.06 and 0.087 were found for w ; and w , respectively at jz =~ 1 . We excluded 785 ( 28.38 % ) seed and 56,565 ( 31.8 % ) related grey sheep channels that could not be categorized , in addition to related channels ranked at k > 10 and non-ER seed channels . The remaining 1,123 ER seed and 4,973 related ( ER and non-ER , k < 10 ) channels were used to calculate the mean related category proportions for each ER . category . Figure 6 contains plots for three ER categories that we have selected for in-depth analysis . As seen in Figure 4 , the seed category is the dominant related category for all values of k , and the ER related category presence is consistently stronger than that of the non-ER categories , notwithstanding the in- crease in diversity . The Populist and Political Party related categories are prominent for Anti-Islam , given the inclu- sion of channels affiliated with parties such as the National Democratic Party of Germany ( NPD ) , the Pro-Bewegung collective , and the Freedom Party of Austria ( FPO ) ; all strong opponents of immigration , particularly by Muslims ( 1 , 3 , 17 ) . 64 —— Seed —— Related B44 a 9 £ < oS oO = 24 Topics =~ 1 Figure 5 : German mean topics per channel at ws , wr in ( 0.01 , 0.09 ] . ws and wy were set to 0.06 and 0.087 respec- tively . This data set also features many ER Music seed channels that upload recordings of high-profile groups , with the main difference being the prominence of the Neo-Nazi related cat- egory for all rankings . These recordings and videos , along with other non-music videos uploaded by these channels , often feature recognizable Nazi imagery . Separately , chan- nels that upload videos associated with groups that have alleged ER ties , for example , Béhse Onkelz or Frei . Wild [ 1 ] , may explain in part the presence of the non-ER Music cat- egory , given the mainstream success of these groups . This may also be explained by material associated with hip-hop groups such as “ n ’ Socialist Soundsystem ” , which provide an alternative to traditional ER . music based on rock and folk . The close relationship with Music is also present for the Neo-Nazi seed category , although further related diversity can be observed . Seed channels featuring footage of German participation in WWII , including speeches by high-ranking members of the Nazi party , are likely to be the source of the White Nationalist and Revisionist related categories . We can safely assume that the prominence of Music is responsi- ble for the appearance of its non-ER , counterpart here . 5.3 . Discussion We conclude our filter bubble analysis by measuring the mean proportions for the seed ER categories as a whole , where the possible aggregated related categories were ( 1 ) the same ER category as that of the seed , ( 2 ) a different ER category , or ( 3 ) a non-ER category . The results for both data sets can be found in Figure 7 . As with the individual seed categories , an ER filter bubble is also clearly identi- fiable at the aggregate level . Although the increase in di- versity for lower & rankings introduces a certain proportion ER-Anti-Islam HB ER-Political Party 0.65 | ER-Populist 5 NER-Entertainment eS __NER-News & Current Affairs °° S 0.44 2 a Cc wo a = 0.24 0.0 i 1 1 1 1 1 1 3 5 7 10 k ( a ) Anti-Islam ER-Music | ER-Neo-Nazi 0.65 |__ ER-White Nationalist Ss | NER-Music g 8 © 0.4- 2 Qa Cc wo a = 0.24 0.04 qt i i l 1 3 5 7 10 k ( b } Music ER-Music | ER-Neo-Nazi 0.65 | _ ER-Populist 5 __ER-Revisionist 2 | ER-White Nationalist g | NER-Music © 0.4- 2 Qa Cc wo a = 0.24 | | | 0.0 | 1 3 5 7 10 k ( c } Neo-Nazi Figure 6 : German mean category proportions of top k ranked related channels ( k € [ 1,3,5 , 7 , 10 ] ) , for selected seed ER . categories . of non-ER . categories , this is always outweighed by ER cate- gories , where the seed ER category remains dominant for all values of k. These findings would appear to contrast those of certain prior work where greater related video diversity was observed [ 28 , 33 ] . Although we have analyzed related channels rather than individual videos , we might have ex- pected to also find this behaviour at both levels . However , it would appear this is not always true , at the very least in the case of ER channels . 1.00 = 0.504 | | | 0.00 = | l i 3 5 k Millsame ER Category Other ER Category ___Non-ER Category 7 10 Mean proportion Q Ny or °O iy a 1 ( a ) English 1.00 = Ml same ER Category Other ER Category © 0.754 |_Non-ER Category 2 3 Q 2 0.504 Q c ow ® = 0.255 0.00 5 = ll i | 1 3 5 ; i k ( b ) German Figure 7 : Aggregated mean category proportions of top & ranked related channels ( & € [ 1,3,5,7 , 10 ] ) , for seed ER categories . The data retrieval process described in Section 3 involved following related video links for only one step removed from the corresponding seed video ; no further related retrieval was performed for related videos themselves . Of the ER seed channels used in the filter bubble analysis in Sections 5.1 and 5.2 , we identified those that appeared in top k re- lated rankings of other ER seed channels , for k < 10 ; 6,186 ( 94 % ) and 1,056 ( 94 % ) such channels respectively for the English and German language data sets . These high per- centages allude to the presence of cycles within the related channel graph , where retrieving additional data by following related videos for multiple steps may have been somewhat redundant . They also further emphasize the existence of the filter bubble . Separately , it might be argued that our findings merely con- firm that YouTube ’ s related video recommendation process is working correctly . However , this is precisely what we were trying to quantify , in terms of the categories of extreme right content to which a user may be exposed following a short series of clicks . As a consequence , users viewing this content may rarely be presented with an alternative perspective . 6 . CONCLUSIONS AND FUTURE WORK YouTube ’ s position as the most popular video sharing plat- form has resulted in it playing an important role in the online strategy of the extreme right , where it is used to host as- sociated content such as music and other propaganda . We have proposed a set of categories that may be applied to this YouTube content , based on a review of those found in existing academic studies of the extreme right ’ s ideological make-up . Using an NMF-based topic modelling approach , we have categorized channels according to this proposed set , permitting the assignment of multiple categories per chan- nel where necessary . This categorization has helped us to identify the existence of an extreme right filter bubble , in terms of the extent to which related channels , determined by the videos recommended by YouTube , also belong to ex- treme right categories . Despite the increased diversity ob- served for lower related rankings , this filter bubble maintains a constant presence . The influence of related rankings on click through rate [ 33 ] , coupled with the fact that the You- Tube channels in this analysis originated from links posted by extreme right Twitter accounts , would suggest that it is possible for a user to be immersed in this content following a short series of clicks . In future work , we would like to experiment with alternative channel representations that address the existence of noise found with certain channels and associated topics at lower related rankings . We would also like to perform a longer temporal analysis in an attempt to investigate any correla- tion between changes in this filter bubble and extreme right activity across multiple social media platforms . Separately , although we have used the methodology presented in this paper to study extreme right channels , it may be interest- ing to investigate its application to other types of extremist political content found on YouTube . 7 . ACKNOWLEDGMENTS This research was supported by 2CENTRE , the EU funded Cybercrime Centres of Excellence Network and Science Foun- dation Ireland ( SFI ) under Grant Number SFI/12/RC/2289 . 8 . REFERENCES [ 1 ] Baldauf , J. , Grof , A. , Rafael , S. , and Wolf , J. Zwischen Propaganda und Mimikry . Neonazi-Strategien in Sozialen Netzwerken . Amadeu Antonio Stiftung ( 2011 ) . Baluja , $ . , Seth , R. , Sivakumar , D. , Jing , Y. , Yagnik , J. , Kumar , S. , Ravichandran , D. , and Aly , M. Video suggestion and discovery for youtube : taking random walks through the view graph . In Proc . 17th international conference on World Wide Web , WWW 08 , ACM ( 2008 ) , 895-904 . [ 3 ] Bartlett , J. , Birdwell , J. , and Littler , M. The New Face of Digital Populism . Demos ( 2011 ) . [ 4 ] Bell , M. Frei verfiigbarer Nazi-Rock : YouTube und die braunen Musikanten . Der Spiegel ( 03 2013 ) . [ 5 ] Blee , K. M. , and Creasap , K. A . Conservative and Right-Wing Movements . Annual Review of Sociology 86 ( 2010 ) , 269-286 . Blei , D. M. , Ng , A. Y. , and Jordan , M. I . Latent dirichlet allocation . J. Mach . Learn . Res . 3 ( Mar . 2003 ) , 993-1022 . N & [ 7 ] Boutsidis , C. , and Gallopoulos , E. SVD based [ 12 [ 13 [ 14 [ 15 [ 16 [ 17 [ 18 [ 19 initialization : A head start for nonnegative matrix factorization . Pattern Recogn . 41 , 4 ( Apr . 2008 ) , 1350-1362 . Brown , T. 8 . Subcultures , Pop Music and Politics : Skinheads and ” Nazi Rock ” in England and Germany . Journal of Social History 38 , 1 ( 2004 ) , 157-178 . Burris , V. , Smith , E. , and Strahm , A . White Supremacist Networks on the Internet . Sociological Focus 33 , 2 ( 2000 ) , 215-235 . Caiani , M. , and Wagemann , C. Online Networks of the Italian and German Extreme Right . Information , Communication & Society 12 , 1 ( 2009 ) , 66-109 . Chemudugunta , C. , Smyth , P. , and Steyvers , M. Modeling General and Specific Aspects of Documents with a Probabilistic Topic Model . In Advances in Neural Information Processing Systems ( 2006 ) , 241-248 . Conway , M. , and McInerney , L. Jihadi Video and Auto-radicalisation : Evidence from an Exploratory YouTube Study . In Proc . 1st European Conference on Intelligence and Security Informatics , EurolISI ’ 08 , Springer-Verlag ( 2008 ) , 108-118 . Davidson , J. , Liebald , B. , Liu , J. , Nandy , P. , Van Vleet , T. , Gargi , U. , Gupta , S. , He , Y. , Lambert , M. , Livingston , B. , and Sampath , D. The YouTube video recommendation system . In Proc . 4th ACM conference on Recommender Systems , RecSys ’ 10 ( 2010 ) , 293-296 . Figueiredo , F. , Benevenuto , F. , and Almeida , J. M. The Tube over Time : Characterizing Popularity Growth of YouTube Videos . In Proc . 4th ACM international conference on Web search and data mining , WSDM ’ 11 ( 2011 ) , 745-754 . Filippova , K. , and Hall , K. B . Improved video categorization from text metadata and user comments . In Proc . 34th Int . ACM SIGIR Conference on Research and development in Information Retrieval , SIGIR ’ 11 ( 2011 ) , 835-842 . Gerstenfeld , P. B. , Grant , D. R. , and Chiang , C.-P . Hate Online : A Content Analysis of Extremist Internet Sites . Analyses of Social Issues and Public Policy 3 , 1 ( 2003 ) , 29-44 . Goodwin , M. The Roots of Extremism : The English Defence League and the Counter-Jihad Challenge . Chatham House ( 2013 ) . Goodwin , M. , and Ramalingam , V. The New Radical Right : Violent and Non-Violent Movements in Europe . Institute for Strategic Dialogue ( 2012 ) . Greene , D. , and Cunningham , P. Producing a Unified Graph Representation from Multiple Social Network Views . In Proc . 5th Annual ACM Web Science 10 [ 20 [ 22 [ 23 [ 24 ] [ 25 [ 26 [ 27 [ 28 ] [ 33 ] Conference , WebSci ’ 13 , ACM ( 2013 ) , 118-121 . Hannon , J. , Bennett , M. , and Smyth , B . Recommending Twitter users to follow using content and collaborative filtering approaches . In Proc . 4th ACM Conference on Recommender Systems ( RecSys ’ 10 ) ( 2010 ) , 199-206 . Lee , D. D. , and Seung , H. 8 . Learning the parts of objects by non-negative matrix factorization . Nature 401 ( 1999 ) , 788-791 . Lin , C.-J . Projected Gradient Methods for Nonnegative Matrix Factorization . Neural Comput . 19 , 10 ( Oct. 2007 ) , 2756-2779 . Marliére , P. Populism and the enchanted world of * moderate politics ’ . openDemocracy ( 2013 ) . Mudde , C. Populist Radical Right Parties in Europe . Cambridge University Press , 2007 . O ’ Callaghan , D. , Greene , D. , Conway , M. , Carthy , J. , and Cunningham , P. An Analysis of Interactions Within and Between Extreme Right Communities in Social Media . In To Appear : MSM 2012 and MUSE 2012 Postproceedings ( 2013 ) . O ’ Callaghan , D. , Greene , D. , Conway , M. , Carthy , J. , and Cunningham , P. Uncovering the Wider Structure of Extreme Right Communities Spanning Popular Online Networks . In Proc . 5th Annual ACM Web Science Conference , WebSci 713 ( 2013 ) , 276-285 . Pariser , E. The Filter Bubble : What the Internet Is Hiding from You . Penguin Group USA , 2011 . Roy , 8S . D. , Mei , T. , Zeng , W. , and Li , S. SocialTransfer : cross-domain transfer learning from social streams for media applications . In Proc . 20th ACM international conference on Multimedia , MM 12 , ACM ( 2012 ) , 649-658 . Simonet , V. Classifying YouTube Channels : a Practical System . In Proc . 2nd International Workshop on Web of Linked Entities ( WoLE 2013 ) , ACM ( 2013 ) , 1295-1304 . SPLC . Ideology . Southern Poverty Law Center ( 2013 ) . Steyvers , M. , and Griffiths , T. Probabilistic Topic Models . In Latent Semantic Analysis : A Road to Meaning. , T. Landauer , D. Mcnamara , 5 . Dennis , and W. Kintsch , Eds . Laurence Erlbaum , 2006 . Tateo , L. The Italian Extreme Right On-line Network : An Exploratory Study Using an Integrated Social Network Analysis and Content Analysis Approach . Journal of Computer-Mediated Communication 10 , 2 ( 2005 ) . Zhou , R. , Khemmarat , S. , and Gao , L. The impact of YouTube recommendation system on video views . In Proc . 10th ACM SIGCOMM conference on Internet measurement ( 2010 ) , 404-410 . [ PDF ] The Filter Bubble : What The Internet Is Hiding From You Eli Pariser - pdf download free book The Filter Bubble pled __ ad Books Details : ES ( ternct Title : The Filter Bubble : What the I ll Author : Eli Pariser | : Released : 2011-05-12 es Language EE icing Pages : 304 ( hill ISBN : 159d20 5008 El oon ISENL3 : 9F8-L59d203008 Po ASIN : 1594205008 es vo . Eli Pariser CLICK HERE FOR DOWNLOAD pdf , mobi , epub , azw , kindle Description : Author Q & A with Eli Pariser Q : What is a “ Filter Bubble ” ? A : We 're used to thinking of the Internet like an enormous library , with services like Google providing a universal map . But that ’ s no longer really the case . Sites from Google and Facebook to Yahoo News and the New York Times are now increasingly personalized - based on your web history , they filter information to show you the stuff they think you want to see . That can be very different from what everyone else sees - or from what we need to see . Your filter bubble is this unique , personal universe of information created just for you by this array of personalizing filters . It ’ s invisible and it ’ s becoming more and more difficult to escape . Q : | like the idea that websites might show me information relevant to my interests—it can be overwhelming how much information is available | already only watch TV shows and listen to radio programs that are known to have my same political leaning . What ’ s so bad about this ? A : It ’ s true : We 've always selected information sources that accord with our own views . But one of the creepy things about the filter bubble is that we ’ re not really doing the selecting . When you turn on Fox News or MSNBC , you have a sense of what their editorial sensibility is : Fox isn ’ t going to show many stories that portray Obama in a good light , and MSNBC isn ’ t going to the ones that portray him badly . Personalized filters are a different story : You don ’ t know who they think you are or on what basis they ’ re showing you what they ’ re showing . And as a result , you don ’ t really have any sense of what ’ s getting edited out - or , in fact , that things are being edited out at all . Q : How does money fit into this picture ? A : The rush to build the filter bubble is absolutely driven by commercial interests . It ’ s becoming clearer and clearer that if you want to have lots of people use your website , you need to provide them with personally relevant information , and if you want to make the most money on ads , you need to provide them with relevant ads . This has triggered a personal information gold rush , in which the major companies - Google , Facebook , Microsoft , Yahoo , and the like - are competing to create the most comprehensive portrait of each of us to drive personalized products . There ’ s also a whole “ behavior market ” opening up in which every action you take online - every mouse click , every form entry - can be sold as a commodity . Q : What is the Internet hiding from me ? A : As Google engineer Jonathan McPhie explained to me , it ’ s different for every person - and in fact , even Google doesn ’ t totally know how it plays out on an individual level . At an aggregate level , they can see that people are clicking more . But they can ’ t predict how each individual ’ s information environment is altered . In general , the things that are most likely to get edited out are the things you 're least likely to click on . Sometimes , this can be a real service - if you never read articles about sports , why should a newspaper put a football story on your front page ? But apply the same logic to , say , stories about foreign policy , and a problem starts to emerge . Some things , like homelessness or genocide , aren ’ t highly clickable but are highly important . Q : Which companies or Websites are personalizing like this ? A : In one form or another , nearly every major website on the Internet is flirting with personalization . But the one that surprises people most is Google . If you and | Google the same thing at the same time , we may get very different results . Google tracks hundreds of “ signals ” about each of us - what kind of computer we ’ re on , what we've searched for in the past , even how long it takes us to decide what to click on - and uses it to customize our results . When the result is that our favorite pizza parlor shows up first when we Google pizza , it ’ s useful . But when the result is that we only see the information that is aligned with our religious or social or political beliefs , it ’ s difficult to maintain perspective . Q : Are any sites being transparent about their personalization ? A : Some sites do better than others . Amazon , for example , is often quite transparent about the personalization it does : “ We ’ re showing you Brave New World because you bought 1984. ” But it ’ s one thing to personalize products and another to personalize whole information flows , like Google and Facebook are doing . And very few users of those services are even marginally aware that this kind of filtering is at work . Q : Does this issue of personalization impact my privacy or jeopardize my identity at all ? A : Research psychologists have known for a while that the media you consume shapes your identity . So when the media you consume is also shaped by your identity , you can slip into a weird feedback loop . A lot of people see a simple version of this on Facebook : You idly click on an old classmate , Facebook reads that as a friendship , and pretty soon you 're seeing every one of John or Sue ’ s posts . Gone awry , personalization can create compulsive media - media targeted to appeal to your personal psychological weak spots . You can find yourself eating the equivalent of information junk food instead of having a more balanced information diet . Q : You make it clear that while most Websites ’ user agreements say they won ’ t share our personal information , they also maintain the right to change the rules at any time . Do you foresee sites changing those rules to profit from our online personas ? A : They already have . Facebook , for example , is notorious for its bait-and-switch tactics when it comes to privacy . For a long time , what you “ Liked ” on Facebook was private , and the site promised to keep it that way . Then , overnight , they made that information public to the world , in order to make it easier for their advertisers to target specific subgroups . There ’ s an irony in the fact that while Rolex needs to get Tom Cruise ’ s permission to put his face on a billboard , it doesn ’ t need to get my permission to advertise my endorsement to my friends on Facebook . We need laws that give people more rights in their personal data . Q : Is there any way to avoid this personalization ? What if I 'm not logged into a site ? A : Even if you ’ re not logged into Google , for example , an engineer told me there are 57 signals that the site uses to figure out who you are : whether you 're on a Mac or PC or iPad , where you ’ re located when you 're Googling , etc . And in the near future , it ’ ll be possible to “ fingerprint ” unique devices , so that sites can tell which individual computer you 're using . That ’ s why erasing your browser cookies is at best a partial solution—it only partially limits the information available to personalizers . What we really need is for the companies that power the filter bubble to take responsibility for the immense power they now have - the power to determine what we see and don ’ t see , what we know and don ’ t know . We need them to make sure we continue to have access to public discourse and a view of the common good . A world based solely on things we “ Like ” is a very incomplete world . I ’ m optimistic that they can . It ’ s worth remembering that newspapers were n't always informed by a sense of journalistic ethics . They existed for centuries without it . It was only when critics like Walter Lippman began to point out how important they were that the newspapers began to change . And while journalistic ethics are n't perfect , because of them we have been better informed over the last century . We need algorithmic ethics to guide us through the next . Q : What are the business leaders at Google and Facebook and Yahoo saying about their responsibilities ? A : To be honest , they ’ re frustratingly coy . They tend to frame the trend in the passive tense : Google ’ s Eric Schmidt recently said “ It will be very hard for people to watch or consume something that has not in some sense been tailored for them , ” rather than “ Google is making it very hard ... ” Mark Zuckerberg perfectly summed up the tension in personalization when he said “ A squirrel dying in your front yard may be more relevant to your interests right now than people dying in Africa. ” But he refuses to engage with what that means at a societal level - especially for the people in Africa . Q : Your background is as a political organizer for the liberal Website MoveOn.org . How does that experience inform your book ? A : I 've always believed the Internet could connect us all together and help create a better , more democratic world . That ’ s what excited me about MoveOn - here we were , connecting people directly with each other and with political leaders to create change . But that more democratic society has yet to emerge , and | think it ’ s partly because while the Internet is very good at helping groups of people with like interests band together ( like MoveOn ) , it ’ s not so hot at introducing people to different people and ideas . Democracy requires discourse and personalization is making that more and more elusive . And that worries me , because we really need the Internet to live up to that connective promise . We need it to help us solve global problems like climate change , terrorism , or natural resource management which by their nature require massive coordination , and great wisdom and ingenuity . These problems can ’ t be solved by a person or two - they require whole societies to participate . And that just won ’ t happen if we ’ re all isolated in a web of one . Review `` A powerful indictment of the current system . '' -- -The Wall Street Journal -- This text refers to the edition . Title : The Filter Bubble : What the Internet Is Hiding from You Author : Eli Pariser Released : 2011-05-12 Language : Pages : 304 ISBN : 1594203008 ISBN13 : 978-1594203008 ASIN : 1594203008 ® Check for updates 129 The British British Journal of Social Psychology ( 2019 ) , 58 , 129-149 Psychological Society © 2018 The Authors . British Journal of Social Psychology published by fohn Wiley & Sons Ltd on behalf of British Psychological Society | www.wileyonlinelibrary.com Special section paper The triple-filter bubble : Using agent-based modelling to test a meta-theoretical framework for the emergence of filter bubbles and echo chambers Daniel Geschke ! * , Jan Lorenz ” ? @ ® and Peter Holtz * @ Institut fir Demokratie und Zivilgesellschaft ( Institute for Democracy and Civil Society , IDZ ) , Jena , Germany 2BIGSSS Bremen International Graduate School of Social Sciences , Jacobs University , Bremen , Germany 3Department of Computational Social Science , GESIS Leibniz Institute for the Social Sciences , Cologne , Germany ‘ Leibniz-Institut fiir Wissensmedien IWM ( Knowledge Media Research Center ) , Tubingen , Germany Filter bubbles and echo chambers have both been linked recently by commentators to rapid societal changes such as Brexit and the polarization of the US American society in the course of Donald Trump ’ s election campaign . We hypothesize that information filtering processes take place on the individual , the social , and the technological levels ( triple-filter-bubble framework ) . We constructed an agent-based modelling ( ABM ) and analysed twelve different information filtering scenarios to answer the question under which circumstances social media and recommender algorithms contribute to fragmen- tation of modern society into distinct echo chambers . Simulations show that , even without any social or technological filters , echo chambers emerge as a consequence of cognitive mechanisms , such as confirmation bias , under conditions of central information propagation through channels reaching a large part of the population . When social and technological filtering mechanisms are added to the model , polarization of society into even more distinct and less interconnected echo chambers is observed . Merits and limits of the theoretical framework , and more generally of studying complex social phenomena using ABM , are discussed . Directions for future research such as ways of comparing our simulations with actual empirical data and possible measures against societal fragmen- tation on the three different levels are suggested . The ubiquitous availability of information in the age of social media and the personal- ization of information flows have had substantial effects on our daily lives and on our socio- political culture ( Castells , 2010 ; Happer & Philo , 2013 ; Hermida , Fletcher , Korell , & Logan , 2012 ) . In consequence , we are currently observing a polarization and This is an open access article under the terms of the Creative Commons Attribution-NonCommercial License , which permits use , distribution and reproduction in any medium , provided the original work is properly cited and is not used for commercial purposes . * Correspondence should be addressed to Dr. Daniel Geschke , IDZ Institut fir Demokratie und Zivilgesellschaft , Talstr . 84 , 07743 Jena , Germany ( email : daniel . geschke @ idz-jena.de ) . DOI:10.11 | I/bjso . 12286 BSUBDLT ] SUOMI BALEAID s [ geoydde By ) Aq pouISAOB aie saague YC ! 8sn Jo sana Joy KreAQE ] UYU Ka [ L , y\\ Uo ( SUOYEpUOD- puE-sUUBY/LUDD Kay KresgEsUAlUO//-SdNY ) SUONIPUOD PUR SLD , BP 99g [ ZZOTA LEO ] UO Kresge SULlUG Aa [ Ey “ faxas ] SuEIYDOS Aq 9EZTL-OSg/ LLL -OI/OPAUOD Karyn Kueagyauyuo-qnysksdsdayysdy Woy papEofUMoc ] ‘ | “ GLOT ‘ 6OESPPOT . 130 Daniel Geschke et al . fragmentation of the political sphere in many countries ( e.g. , Sunstein , 2018 ) . Notable examples include the rise in populist politics and mass protests against immigration in Europe , the polarizing election campaign of Donald Trump , or the British people ’ s vote for Brexit . These events developed relatively fast and were surprising for many observers , who wondered about the reasons for these rapid social changes . The possible influence of modern communication technologies on these events is discussed not only in academia , but also in newspapers and political debates ( e.g. , Ott , 2017 ) . Still , there is disagreement about if and under which circumstances these technolog- ical changes have positive or negative consequences for individual users and society as a whole . Whereas some optimists are confident that the Internet and social media eventually will expand everyone ’ s chances to find unbiased information ( e.g. , Michal Kosinski in Noor , 2017 ) , critics have warned of the emergence of filter bubbles , minimizing exposure to information that challenges individual attitudes ( Pariser , 2011 ) . Filter bubbles are defined here as an individual outcome of different processes of information search , perception , selection , and remembering the sum of which causes individual users to receive from the universe of available information only a tailored selection that fits their pre-existing attitudes . On the societal level , individuals tend to share a common social media bubble with like-minded friends ( Boutyline & Willer , 2017 ; McPherson , Smith-Lovin , & Cook , 2001 ) ; over time , such communities in which Internet content that confirms certain ideologies is echoed from all sides are particularly prone to processes of group radicalization and polarization ( Vinokur & Burnstein , 1978 ) ; this phenomenon has come to be known as the echo chamber effect ( Garrett , 2009 ; Sunstein , 2001 , 2009 ) . Thus , echo chambers are a social phenomenon where the filter bubbles of interacting individuals strongly overlap . The dangers of a society falling apart into distinct echo chambers can be described as a lack of society-wide consensus and a lack of at least some shared beliefs among otherwise disagreeing people that are needed for processes of democratic decision-making ( Sunstein , 2001 , 2009 ) . Furthermore , increasingly radical- ized ideological online groups may at some point resort to real-life violence and terrorism to achieve their goals ( e.g. , Holtz , Wagner , & Sartawi , 2015 ; Weiman , 2006 ) . In our study , we analyse the interplay between processes on the levels of individual minds , social groups , and technology , using agent-based modelling ( ABM ; Smith & Conrey , 2007 ) . We employ an interdisciplinary approach in so far as our model takes into account theories from cognitive psychology , social psychology , and micro-sociology . The goal of our study is first to summarize relevant existing theories on filter bubbles and echo chamber effects in a formal ABM and then to explore the dynamics of this model . The resulting ‘ triple-filter-bubble model ’ is a step towards understanding how technological changes and their interplay with cognitive and social factors can contribute to rapid societal change . Agent-based modelling Rapid social change follows non-linear dynamics on interacting micro- , meso- , and macro- levels . It is therefore often hard to predict , when using traditional social scientific research methods that ( mostly ) rely on linear connections of a limited number of variables , rather than simulating multi-level and non-linear interactions . In ABM , interactions between individual agents are simulated as a consequence of rules that were set by the researcher . Effects of interest are usually systemic and appear on the macro-level ( Flache ef al , 2017 ) . That means , the dependent variables of interest are often properties of the society and not of individuals . ABM is particularly suited for studying interactions between individuals BSUBDL ] SUOMI SALEAID s [ geoydde By ) Aq pouUISAOB aie sajague YC ‘ 8sn Jo seina Joy KreAQy ] UYU Ka [ L , y\\ Uo ( SUOYEpUOD- puE-sUIBY/LUDD Kay A resgEsUAlUO// : SANY ) SUONIPUOD UR SLID , BP 99g [ ZZOTA LEO ] UO Kresge SULlUG Aa [ ty “ faxas ] SuEIYDOD Aq 9EZTL-OSg/ LL L-OI/OPAUOD Karyn Kueagyauyuo-qnysksdsdgyysday Woy , papEo~UMoc ] ‘ | “ GLOT “ GOESPPOT The triple-filter bubble 131 instead of interactions between variables ( Smith & Conrey , 2007 ) and how such interpersonal influence processes play out ( Mason , Conrey , & Smith , 2007 ) . This approach enables us to distinguish individual effects from effects which emerge in their interaction with macroscopic phenomena and , in turn , to tentatively gauge possible effects of changing technological environments on individual users and society . Thus , ABM can be used to test the dynamics of complex , non-linear , theoretical assumptions and as a tool for theory building . The method has been applied in previous studies to simulate such different social phenomena as the occurrence of traffic jams ( Bazzan & Kligl , 2014 ) or segregation in housing ( Huang , Parker , Filatova , & Sun , 2014 ; Schelling , 1971 ) . In the next paragraph , we will briefly summarize the available empirical research on filter bubble and echo chamber effects and afterwards present our triple-filter-bubble framework . Empirical findings on filter bubbles and echo chambers Already in 2009 , Garrett had found evidence that within the political domain , Internet users preferred to consume information that confirmed their ideologies . These findings build upon earlier research on the effects of ‘ traditional ’ mass media such as television ( e.g. , Vallone , Ross , & Lepper , 1985 ) . Del Vicario et al . ( 2016 ) were recently able to show in a study using Facebook data how information is passed along ideological fault lines in scientific as well as conspiracy-theory communities . Bakshy , Messing , and Adamic ( 2015 ) analysed the data of 10.1 million US American Facebook users who identified themselves as being either politically liberal , moderate , or conservative . They found that most information filtering is the result of bomopbily , in the sense that Facebook users have significantly more friends with a political orientation similar to their own . The Facebook newsfeed then relies on information that was shared by at least one person in the friend network , and this already leads to information selection with a severe bias in favour of information confirming a certain ideology . However , an earlier study of the same research group ( Bakshy , Rosenn , Marlow , & Adamic , 2012 ) found that the majority of the information that was displayed in the Facebook newsfeed was not shared by close friends with whom the Facebook users exchanged chats and comments and updates on a regular basis ( strong ties ) , but by acquaintances with whom users only communicated ona casual basis ( weak tes ; cf . Granovetter , 1973 ) . As long as there is at least some heterogeneity within a user ’ s friend network , the user will at least have some exposure to differing points of view . Such information would be totally out of the user ’ s reach if information were only accessible via offline communication with close friends who normally share a person ’ s ideologies and beliefs . A somewhat related result was found using Twitter data ( Vaccari et al , 2016 ) : On the one hand , Twitter users more frequently interact ( comment or retweet ) with authors with a similar political ideology ; still , Twitter is used frequently as well to interact with representatives of networks that display an oppositional ideology . The authors draw the conclusion that apparently there are not only echo chambers on Twitter , but also contrarian clubs . However , another group of researchers found a definite longitudinal political polarization of primarily US American Twitter users : Over time ( between 2009 and 2016 ) , the number of politicians and media with similar ideologies that the users followed increased continuously . However , this finding could also be a result of Donald Trump ’ s polarizing election campaign ( Garimella & Weber , 2017 ) . Recently , the specific role of recommender systems in the emergence of filter bubbles and echo chambers has been investigated in a number of empirical studies . Technically speaking , recommender systems provide recommendations in three basic ways : They BSUBDL ] SUOMI SALEAID s [ geoydde By ) Aq pouUISAOB aie sajague YC ‘ 8sn Jo seina Joy KreAQy ] UYU Ka [ L , y\\ Uo ( SUOYEpUOD- puE-sUIBY/LUDD Kay A resgEsUAlUO// : SANY ) SUONIPUOD UR SLID , BP 99g [ ZZOTA LEO ] UO Kresge SULlUG Aa [ ty “ faxas ] SuEIYDOD Aq 9EZTL-OSg/ LL L-OI/OPAUOD Karyn Kueagyauyuo-qnysksdsdgyysday Woy , papEo~UMoc ] ‘ | “ GLOT “ GOESPPOT 132 Daniel Geschke et al . recommend content that was previously selected by a user or other ( to some extent similar ) users ( collaborative filtering ) . They recommend content based on similarities of properties and characteristics between previously chosen and available content ( comtent- based filtering ) . Or they combine both approaches ( hybrid recommender systems , Burke , 2002 ) . Nguyen , Hui , Harper , Terveen , and Konstan ( 2014 ) found mixed results when they analysed the effects of a movie rating page ’ s collaborative filtering-based recommender system on its users ’ range of interests . The users ’ average movie diversity decreased over time , but the effect was stronger for those users that did not usually follow the recommendations than for those who did frequently click the recommended links . In a study on the effects of a music platform ’ s recommender system , Hosanagar and colleagues found little empirical evidence for fragmentation over time ( Hosanagar , Fleder , Lee , & Buja , 2013 ) . The development of recommendation strategies that counter possible filter bubble or echo chamber effects has become a topic of interest for software engineers in the last several years ( e.g. , Resnick , Garrett , Kriplean , Munson , & Stroud , 2013 ) . Overall , there seems to be no common interpretation of the available evidence in the research community as to whether technological features such as recommender systems or many- to-many communication patterns in social media facilitate or attenuate the emergence of filter bubbles and echo chambers . Therefore , the present study aims to shed light on their emergence by empirically testing the joint effects of three levels of filters in an ABM . ' The triple-filter-bubble model We refer to filters in a very general way as processes that lead to a limitation of information that is available to individuals . In our models , we will take into account filtering processes on three different levels : The individual , the social , and the technological level ( Geschke , 2017 ) . Individual filters The first group of filters — cognitive motivational processes — has been studied extensively in cognitive and social psychology . As a means of confirming pre-existing attitudes ( Nickerson , 1998 ) , verifying their selfviews ( Swann , Pelham , & Krull , 1989 ) , avoiding cognitive dissonance ( Festinger , 1957 ) , and boosting social identity ( Brewer , 1991 ) , individuals are to different extents cognitively motivated to search for and add fitting bits of information and to ignore or deny conflicting ones . Similar effects have also been studied under the term confirmation bias ( Jonas , Schulz-Hardt , Frey , & Thelen , 2001 ; Knobloch-Westerwick , Mothes , & Polavin , 2017 ) . In all these cases , filtering refers to selective exposure due to an individual ’ s information search , processing , and memory . Curiosity may , however , motivate individuals to have a preference for consuming information that is at least to some degree novel and surprising ( Loewenstein , 1994 ) . Social filters Human beings display a tendency to form friendships and other social network structures preferably with people with whom they share ‘ sociodemographic , behavioral , and intrapersonal characteristics ’ ( McPherson ef al , 2001 , p. 415 ) . In social media ' The authors would like to kindly thank Alex Haslam for proposing to empirically test the triple-filter-bubble model by using the method of ABM . BSUBDL ] SUOMI SALEAID s [ geoydde By ) Aq pouUISAOB aie sajague YC ‘ 8sn Jo seina Joy KreAQy ] UYU Ka [ L , y\\ Uo ( SUOYEpUOD- puE-sUIBY/LUDD Kay A resgEsUAlUO// : SANY ) SUONIPUOD UR SLID , BP 99g [ ZZOTA LEO ] UO Kresge SULlUG Aa [ ty “ faxas ] SuEIYDOD Aq 9EZTL-OSg/ LL L-OI/OPAUOD Karyn Kueagyauyuo-qnysksdsdgyysday Woy , papEo~UMoc ] ‘ | “ GLOT “ GOESPPOT The triple-filter bubble — 133 communities as well , processes of self-categorization ( Turner , Hogg , Oakes , Reicher , & Wetherell , 1987 ) contribute to the formation of communities with a shared social identity ( Ridings & Gefen , 2004 ) . Furthermore , social media users frequently unfriend acquain- tances holding different views on conflictual topics John & Dvir-Gvirsman , 2015 ) . In the age of social media , information is often passed along such online networks ( Bakshy et al. , 2012 ) . Hence , homogeneous network structures can potentially limit the width of information to which a social media user is exposed . The tendency for homophily is even stronger among social media users holding conservative or more extreme views ( Boutyline & Willer , 2017 ) . Hence , in particular in certain milieus social homophily can be a strong contributing factor to the emergence of filter bubbles and echo chambers and consequently group polarization effects ( Sunstein , 2018 ; Vinokur & Burnstein , 1978 ) . Technological filters The third group of filters — algorithms — operates on the technological level : Online media providers , such as Google or Facebook , compete for user attention . Therefore , they filter the provided information according to individual users ’ assumed wants and needs , leading to individually selected media offers ( Pariser , 2011 ) . The goal of this filtering is to maximize the time users spend on their respective sites , in order to maximize profits generated through advertising . To accomplish this , companies use proprietary , non- transparent automatic algorithms . In effect , this leads to different information offers tailored to the individual . For instance , none of us gets the same output on any given Google search ; instead , each user gets an individualized selection of information . We assume that stronger automatic filtering leads to a decreased variety of information that is offered to individuals . This eventually leads to a decreased spectrum of attitudes that are cognitively available and salient in individuals and , thus , to smaller filter bubbles . However , these recommender systems also constantly confront the user with novel not yet consumed information to maximize click-through rates , thereby potentially increasing the exposure to different points of view ( Herlocker , Konstan , Terveen , & Riedl , 2004 ) . Therefore , an alternative assumption is that , in spite of the filtering processes mentioned above , online media increase the spectrum of attitudes that are cognitively available and salient in individuals . In sum , the filters on these three levels are expected to influence how much of the abundant information is cognitively available to individuals . More importantly , this influence is not random , but systematic : Information is more likely sought , delivered , or perceived when it fits the individual ’ s needs as determined by individual characteristics , and this is partly gauged through automatic recommender systems . Additionally , the outcome depends as well on attitudinal characteristics of the peer groups that individuals interact with . For the present study , we created a parsimonious ABM to simulate these different processes . Research questions We ran several simulations using the aforementioned parsimonious ABM to gauge the effects of different ways of information propagation ( see the paragraph ‘ Simulation scenarios ’ below ) on the formation of echo chambers and filter bubbles . We also implemented rudimentary social structures in the form of friendship networks analogue to online social media platforms such as Facebook . We wanted to find out which combinations of these social and technological ‘ filters ’ facilitate and attenuate the BSUBDL ] SUOMI SALEAID s [ geoydde By ) Aq pouUISAOB aie sajague YC ‘ 8sn Jo seina Joy KreAQy ] UYU Ka [ L , y\\ Uo ( SUOYEpUOD- puE-sUIBY/LUDD Kay A resgEsUAlUO// : SANY ) SUONIPUOD UR SLID , BP 99g [ ZZOTA LEO ] UO Kresge SULlUG Aa [ ty “ faxas ] SuEIYDOD Aq 9EZTL-OSg/ LL L-OI/OPAUOD Karyn Kueagyauyuo-qnysksdsdgyysday Woy , papEo~UMoc ] ‘ | “ GLOT “ GOESPPOT 134 Daniel Geschke et al . emergence of echo chambers and filter bubbles . Details of our model , the different scenarios , and the outcome variables ( see the paragraph ‘ Possible outcomes ’ below ) are explained in the section below . Methods Model synopsis We designed a dynamic ABM where several individuals ( together representing a society ) position themselves in a two-dimensional attitude space based on attitudinal bits of information they hold in memory . In the model , individuals repeatedly receive new information with differing attitudinal messages from different sources . The sources of new information represent the technological filters and can be ( 1 ) individual discovery , ( 2 ) central announcement , for example through mass media , or personalized recom- mendations , for example through online media providers , that either G ) fit or ( ) challenge the attitudes of the individual . Further on , individuals may also receive posted information from their friends through their social network , when a social media channel is provided . The friendship network thus provides a social filter for the individual . Individuals integrate the information they receive through cognitive filters : They integrate a particular bit of information more likely when the distance of its attitudinal message to their own attitude is below a latitude of acceptance . This means that it is unlikely that they integrate information that does not fit their pre-existing average attitudes . The concept of the latitude of acceptance goes back to Sherif and Hovland ( 1961 ) . In the social simulation literature , the concept is known as bounded confidence ( Hegselmann & Krause , 2002 ) . Individuals have a limited memory and can only integrate a certain amount of information . When their memory is full , they have to forget bits of information to integrate new ones . These processes lead to repositioning of individuals in the attitudinal space according to the average information they consequently hold in their memory . We have implemented the model in NetLogo ( Wilensky , 1999 ) . In the following , we lay out the model following the procedure proposed by Jackson , Rand , Lewis , Norton , and Gray ( 2017 ) adapted to our model . In the info Tab of the model ( Lorenz , Holtz , & Geschke , 2018 ) , we provide a description which follows the implementation code closely . The model can be downloaded here : https : //doi.org/10.5281/zenodo . 1407733 . Individuals and news items in attitude space The model has two types of agents : individuals and bits of information . Both live in a two- dimensional world that represents an attitude space . Thus , the position of an information bit represents its attitudinal content on two dimensions , and the position of an individual represents the individual ’ s attitudes on the same dimensions . Attitudes range from —1 to +1 on both dimensions . A dimension can , for example , represent political attitudes on the economic left-right and the societal progressive-traditional axes , or valence attitudes on two issues . Individuals are connected among each other through bidirectional friendship links . These links represent a friendship graph as it exists in social media platforms . Individuals also connect to bits of information . Such info-links represent that the individual integrated this bit of information in memory . Consequently , individuals can also be connected as sharers of information when they hold at least one common bit of information in their memories . The attitude space and all types of agents and links are outlined in Figure 1 . BSUBDL ] SUOMI SALEAID s [ geoydde By ) Aq pouUISAOB aie sajague YC ‘ 8sn Jo seina Joy KreAQy ] UYU Ka [ L , y\\ Uo ( SUOYEpUOD- puE-sUIBY/LUDD Kay A resgEsUAlUO// : SANY ) SUONIPUOD UR SLID , BP 99g [ ZZOTA LEO ] UO Kresge SULlUG Aa [ ty “ faxas ] SuEIYDOD Aq 9EZTL-OSg/ LL L-OI/OPAUOD Karyn Kueagyauyuo-qnysksdsdgyysday Woy , papEo~UMoc ] ‘ | “ GLOT “ GOESPPOT The triple-filter bubble 135 Agents ’ activities In every time step , new bits of information appear in attitude space at random positions . They come to the attention of individuals , who try to integrate them . Further on , individuals might also post a randomly selected bit of information they hold in memory to the attention of their friends . For example , in Figure 1 , the red individual might additionally receive one bit of the information from its friend inked in yellow ) . Whenever a new bit of information comes to the attention of an individual , it tries to integrate it by creating an infolink . We model the integration of information as a probabilistic event . The integration probability is a function of the attitude distance between the individual and the information . We use the following functional formula : Dp PUASD . 9 ) = 555 ( 1 ) where dis the attitude distance , D the latitude of acceptance , and 6 a sharpness parameter that specifies how steep the integration probability drops from one to zero around the latitude of acceptance . The probability of integration decreases with d ( cf . Abelson , 1964 ; Fishbein & Ajzen , 1975 ; Fisher & Lubin , 1958 ) . This means that information fitting the individual ’ s average pre-existing attitudes is more likely to be integrated . While the concept of the latitude of acceptance goes back to Sherif and Hovland ( 1961 ) , the functional form is taken from the formalization of the Social Judgment Theory by Hunter , Danes , and Cohen ( 1984 ) . However , they only dealt with the case of 6 = 2 and did not take into consideration a sharper decline around the latitude of acceptance . The limit in the case of very large 6 coincides with the bounded confidence model ( effuant , Neau , Amblard , & Weisbuch , 2000 ; Krause , 2000 ) . The integration probability is 0.5 when the distance is equal to the latitude of acceptance ( d = D ) . At the limit of very large sharpness parameters 6 , integration becomes deterministic . In this case , info-bits are integrated with certainty if the distance is less than D , and are rejected otherwise . The functional form is shown in Figure 2 . Attitude space +1 Agents @ individual Bit of information Links \\ —— Friendship o+ ne _ * ® Info-link = ec ~ — — Sharer of information Attitude dimension 2 1 Outcome variables Mean distance info-bits Mean distance info-sharers Mean distance friends “ 4 t -1 0 +1 Attitude dimension 1 Figure I . Conceptual figure showing the attitude space and all types of agents and links of the model , as well as the three central outcome measures . [ Colour figure can be viewed at wileyonlinelibrary.com ] BSUBDL ] SUOMI SALEAID s [ geoydde By ) Aq pouUISAOB aie sajague YC ‘ 8sn Jo seina Joy KreAQy ] UYU Ka [ L , y\\ Uo ( SUOYEpUOD- puE-sUIBY/LUDD Kay A resgEsUAlUO// : SANY ) SUONIPUOD UR SLID , BP 99g [ ZZOTA LEO ] UO Kresge SULlUG Aa [ ty “ faxas ] SuEIYDOD Aq 9EZTL-OSg/ LL L-OI/OPAUOD Karyn Kueagyauyuo-qnysksdsdgyysday Woy , papEo~UMoc ] ‘ | “ GLOT “ GOESPPOT 136 Daniel Geschke et al . Individuals can only maintain a limited number of info-links due to their limited memory . Therefore , they drop a random info-link when necessary to integrate a new bit of information . Whenever an individual integrates a new bit of information , it adjusts its own attitudes . On both attitude dimensions , the individual sets the attitude to the average attitude of all the bits of information it holds in memory , following Anderson ’ s ( 1971 ) integration theory . Thus , the integration of a new bit of information pulls the individual a bit towards attitudinal values communicated in it . Conceptual Figure 1 shows the individuals at the attitudinal barycentre of the information they hold in memory . Individual may also change their friends , typically at a much lower rate . Ifa friendship is up to be potentially dropped , the probability to keep the friendship depends on the attitude distance to the friend analogue to the integration probability as defined in Equation ( 1 ) . When a friendship is dropped , the individual selects a new friend at random from the friends of its friends . Initial conditions and simulation time In all simulations discussed in the following , we initialized 500 individuals with random positions in attitude space ( uniformly distributed in both dimensions ) and no bits of information initially . As initial friendship networks , we created networks where each individual has on average twenty friends . For the network generation , we assigned each individual to one of four pre-defined equally sized groups and made a random network such that for each individual on average 80 % of its friends come from the same group and 20 % from the other three groups . We used this group structure network to check whether friendship groups have an impact on evolving echo chambers . As robustness check , we also checked random networks without group structure and small world networks of the Watts— 1.00 - 0.75 = 0.50 - 0.25 = Integration probability 0.00 - 1 1 I 1 0.0 0.2 0.4 0.6 Distance info-bit ( d ) Baseline in thick black : D = 0.3 , 6 = 20 Scales of green : D = 0.1 , 0.2 , 0.3 , 0.4 , 0.5 Scales of red : 6 = 5 , 10 , 20 , 50 , 100 Figure 2 . The functional form of the integration probability P ( d ) = D°/ ( d° + D® ) from Equation ( 1 ) . The thick black line marks the baseline case ( D = 0.3 , 6 = 20 ) used for the simulation results in most of the following figures . Green lines mark other latitudes of acceptance D , and red lines other sharpness parameters 0 . [ Colour figure can be viewed at wileyonlinelibrary.com ] BSUBDL ] SUOMI SALEAID s [ geoydde By ) Aq pouUISAOB aie sajague YC ‘ 8sn Jo seina Joy KreAQy ] UYU Ka [ L , y\\ Uo ( SUOYEpUOD- puE-sUIBY/LUDD Kay A resgEsUAlUO// : SANY ) SUONIPUOD UR SLID , BP 99g [ ZZOTA LEO ] UO Kresge SULlUG Aa [ ty “ faxas ] SuEIYDOD Aq 9EZTL-OSg/ LL L-OI/OPAUOD Karyn Kueagyauyuo-qnysksdsdgyysday Woy , papEo~UMoc ] ‘ | “ GLOT “ GOESPPOT The triple-filter bubble 137 Strogatz type , with a 20 % fraction of long-distance links ( Watts & Strogatz , 1998 ) . The effects presented in the following appear essentially identical for all these types of networks . Each simulation lasted for 10,000 time steps ; this ensures that a metastable configuration is reached in all configurations we simulated . In each time step , each agent is independently of others exposed to one new bit of information . Additionally , it might be exposed to more bits of information — one posted from each ofits friends . The 10,000 time steps would represent 3 years where each individual is exposed to about nine new bits of information per day and — with twenty posting friends — about 180 posted bits of information per day . Note that these are the bits of information the individual is exposed to , not necessarily the number of bits it integrates each day . Possible outcomes of our simulations For every individual , we computed the mean attitude distance to all bits of information in memory , the mean attitude distance to all sharers of information , and the mean attitude distance to all friends . All these distances are shown in Figure 1 for the red individual . The average of these three outcome variables over all individuals after 10,000 time steps characterizes how the society they form evolved . Let us consider three prototypical cases . 1 . The distance to bits of information is smaller than the distance to sharers of information which is smaller than the distance to friends . In this society , individuals share information with others , some of whom hold very different attitudes , while some of their friends hold even more different attitudes . The posted information they received from these friends is , of course , usually not integrated , since it is beyond their latitude of acceptance . 2 . The distance to sharers of information is smaller than the distance to bits of information which is smaller than the distance to friends . In this society , individuals do share information only with others who hold very similar attitudes . Thus , communities of information sharers usually have their bits of information exclusively within this society . Individuals have friends in other communities of info-sharers , but usually do not integrate their posted bits of information . 3 . The distance to friends is smaller than the distance to sharers of information which is smaller than the distance to bits of information . In this society , all the friends as wellas all information sharers of individuals have very close attitudes . As the bits of information they hold in individual memories are more diverse than in their social surroundings , they may even have the perception of living in a attitude-diverse information environment , while at the same time there may exist another community of the same type with drastically different attitudes , representing strongly discon- nected echo chambers . Simulation scenarios In the simulation analysis , we were interested to see which of the three societies ( 1 ) —- ( 3 ) evolves under different modes for the generation of new information , and different characteristics of cognitive , social , and technological filters . To that end , we set up twelve scenarios , whose configurations and outcomes are summarized in Table 1 . The three output measures in the table are direct computations after one simulation run . We extensively tested that these reproduce with minor variation in other simulation runs , which can be tested ( Lorenz ef ai , 2018 ) . In that sense , the numbers are generalizable BSUBDL ] SUOMI SALEAID s [ geoydde By ) Aq pouUISAOB aie sajague YC ‘ 8sn Jo seina Joy KreAQy ] UYU Ka [ L , y\\ Uo ( SUOYEpUOD- puE-sUIBY/LUDD Kay A resgEsUAlUO// : SANY ) SUONIPUOD UR SLID , BP 99g [ ZZOTA LEO ] UO Kresge SULlUG Aa [ ty “ faxas ] SuEIYDOD Aq 9EZTL-OSg/ LL L-OI/OPAUOD Karyn Kueagyauyuo-qnysksdsdgyysday Woy , papEo~UMoc ] ‘ | “ GLOT “ GOESPPOT 20448309 , 2019 , 1 , Downloaded from hteps-/epspsychub.oniinelibrary.wiley.com/doi/10.111 1/bjs0.12286 by Cochrane Israel , Wiley Online Library on [ 09/11/2022 ] . See the Terms and Conditions ( https.//onlinelibrary.wiley.com/terms-and-conditions ) on Wiley Online Library for rules of use ; QA articles are governed by the applicable Creative Commons License ‘ auNseaW IndjNO JVseYs-OJU ] PUL SIIG-OJu ] BU ) JO ANjeA J9BIE ] SYD RLU S4aquuNU Plog ‘ AeIDos Jo sodA ayy Aq payeds you si samuNWWod jo Joquunu ay ] “ AUNWIWOD apni duo AjuUO sI seY | | IVYA SI | PUR g SOLIZUADS 02 OdUBJOYIP [ BIUBWEPUNY ‘ ISIXS JOU OP UONRWUOJU ! JO Sig PaseYs ‘ O|eUADS SIU ) Uj , ‘ SUG-OJUI > JOIPYS-OJUI > Spualy ( ¢ ) ‘ SPpUaLYy > SUq-OJUI > JasJeYS-OJUl ( Z ) ‘ SPUdLY > JB4RYS-OJUI > SUg-OJul ( | ) : AIIDOs Jo add | ‘ sdays aun .Q| Jaye saunseaw nding “ se10N ( 1 ) 6£5°0 95¢°0 L0E ' 0 ) 50 HO jesques Zl S q ( € ) 020°0 & 40°0 L870 ty ) s0 ud fenPIAIpU| i s ( g ) 620 ' 0 1€0 ' 0 es1 ' 0 | £0 ud fenPIAIpU| ol v ( g ) 8£0°0 170 ' 0 951° 10°0 £0 ud fenPIAIpU| 6 v ( 2 ) 7690 700 gr 1 ' 0 ty ) £0 ud 8 £ ( 2 ) 40L0 700 pri ‘ ty ) £0 ud BSO ] > 12414 Z £ ( ) 678 ' 0 S670 870 ty ) £0 HO qweIsip 193 ) ! 9 £ ( 2 ) £65°0 & 40°0 7910 ty ) £0 HO g £ ( 2 ) 0£ZL0 +r0 ' 0 os ! '' ty ) £0 ud yeaquas v z ( 2 ) 0750 S0 ' 0 os ! '' ty ) £0 ud fenPIAIpU| £ zt ( ) 068°0 S870 7810 ty ) £0 HO yeaquas z z ( 2 ) Oreo 0 7810 0 £0 HO fenPIAIpU| | z Aainos jo addy spual4 Jd.4RYS-OJu| suq-oju| “ qoud puajoy ‘ Doe Jo apne ] 8unsod |eID05 UOIBUOJU ! MBU BPP ] # 3 “ `` '' Q27 SDUeIsSIP UPRSLU 'SOUNSPSLU anding uonesn3yuod OLIRUSI $ UN4J UONRINUIS DUO JO s } jNse4 By UO paseq peindwos QUOM SdANseaW INdINC `` Z| O } | SOLMBUADS JO Sd1 } sINaIDBIeYD A @ lD0s aaneyjenb pur ‘ soinseaw jnd3no aanewWuenb ‘ suopeinsyuod Oleuads ayy Jo AsRWLUNS “ | ajqeL 138 Daniel Geschke et al . The triple-filter bubble 139 output measures for the corresponding input parameters , and the characteristics of the evolving society ( 1 ) 3 ) can be inferred from the order of them . We distinguished four modes for the generation of new bits of information . ( 1 ) In the individual mode , each individual receives one new individual bit of information and tries to integrate it . ( 2 ) In the central mode , all individuals try to integrate one central new bit of information . This represents mass media input from one central , unbiased channel ( mainstreaming ; Griffin , 2012 ) . In the two remaining modes , ( 3 ) select close info-bits and ( 4 ) select distant info-bits , a new random info-bit is created and presented to each individual analogously to the individual mode until the total number of info-bits is equal to the number of individuals . When the number of info-bits is equal to the number of individuals , each individual is presented a random existing info-bit that is either inside Gin the mode select close info-bits ) or outside Gin the mode select distant info-bits ) of its latitude of acceptance . This represents a recommendation algorithm that aims to present info-bits that the receiver will integrate with a probability higher than 0.5 ( select close info- bits ) or , respectively , an info-bit that confronts the individual with very different information that is unlikely to be integrated . The latter two modes represent influences of different technological filters . The concept of social filters is implemented through the possibility that agents post one of their bits of information ( randomly selected ) to all of their friends . This represents a social media mechanism . In Scenarios 1 to 8 , we study the four modes of information generation once with social posting and once without social posting . Further on , Scenarios 9 and 10 show what happens when individuals sometimes drop friendships and add a new friend from their friends of friends . In Scenario 9 , each friendship is up for dropping with a probability of 0.01 , and in Scenario 10 , each friendship is up for dropping with certainty . Whether a friendship up for dropping is kept or dropped is a probabilistic event analogue to the integration of information . Friends with very different average attitudes are dropped more likely . The evolution of the friendship networks in Scenarios 9 and 10 thus follows the same mechanism but at much faster pace in Scenario 10 . The concept of cognitive filters is always present through the mechanism that information is more likely integrated if it fits closely to pre-existing attitudes . This mechanism is active in all scenarios of the model , since such biases can not be easily switched off . In most simulations , we used a latitude of acceptance of D = 0.3 . In Scenarios 11 and 12 , we tested which changes a larger latitude of acceptance D = 0.5 elicits . We always used a sharpness parameter 6 = 20 . This strong sharpness implies that integration is very likely when the info-bit is at a distance smaller than five in attitude space and very unlikely otherwise . We used this comparatively high sharpness value because it leads to relatively stable outcome states and less fluctuation of different simulation runs under the same configuration . We made exploratory simulations and observed that the effects also emerge when the latitude of acceptance is less sharp . A detailed parameter study for the effects of D and 6 is beyond the scope of this paper . Results Results for Scenarios | to 4 Figure 3 shows the positions of individuals in the attitude space and their info-links after stabilization . The info-bits are not shown in the figure because they would often cover the individuals . Their location can be assessed by the other empty end of the info-links . Friend links and info-sharer links are not shown for similar reasons . Nevertheless , they are part of the simulation . The quantitative characteristics are summarized in Table 1 . BSUBDL ] SUOMI SALEAID s [ geoydde By ) Aq pouUISAOB aie sajague YC ‘ 8sn Jo seina Joy KreAQy ] UYU Ka [ L , y\\ Uo ( SUOYEpUOD- puE-sUIBY/LUDD Kay A resgEsUAlUO// : SANY ) SUONIPUOD UR SLID , BP 99g [ ZZOTA LEO ] UO Kresge SULlUG Aa [ ty “ faxas ] SuEIYDOD Aq 9EZTL-OSg/ LL L-OI/OPAUOD Karyn Kueagyauyuo-qnysksdsdgyysday Woy , papEo~UMoc ] ‘ | “ GLOT “ GOESPPOT 140 Daniel Geschke et al . Individual new information Central new information No social posting Social posting Figure 3 . Individuals and their info-links after stabilization for Scenarios | , 2 , 3 , and 4 . The colour of individuals determines their group . On average , 80 % of an individual ’ s friends were of the same colour . [ Colour figure can be viewed at wileyonlinelibrary.com ] In Scenarios 3 and 4 with social posting , the bubble of people with whom information was shared ( as indicated by mean distance info-sharer ) was smaller than the information bubble itself ( as indicated by mean distance info-bits ) . This means that these individuals might have perceived strong attitude homogeneity with the people they shared information with and at the same time had the perception that they held diverse info- bits . This was different without social posting in Scenarios 1 and 2 . Under the condition of pure individual info-bits ( as in Scenario 1 ) , there was no clustering and no info-sharing . Under the condition of central information propagation ( Scenarios 2 and 4 ) , there was some clustering , but the info-bridges between different clusters remained ( individuals also shared information with individuals from other clusters ) . In our baseline case , the availability of social posting enforced strong clustering into sharers of information , who operated in slightly wider information bubbles with no informational contact to the other communities . These clusters evolved even though there was continual inflow and exposure to info-bits from the whole attitude space , because through social posting each individual became exposed to on average twenty bits of information from the social BSUBDL ] SUOMI SALEAID s [ geoydde By ) Aq pouUISAOB aie sajague YC ‘ 8sn Jo seina Joy KreAQy ] UYU Ka [ L , y\\ Uo ( SUOYEpUOD- puE-sUIBY/LUDD Kay A resgEsUAlUO// : SANY ) SUONIPUOD UR SLID , BP 99g [ ZZOTA LEO ] UO Kresge SULlUG Aa [ ty “ faxas ] SuEIYDOD Aq 9EZTL-OSg/ LL L-OI/OPAUOD Karyn Kueagyauyuo-qnysksdsdgyysday Woy , papEo~UMoc ] ‘ | “ GLOT “ GOESPPOT The triple-filter bubble 141 network , in addition to the one new bit of information with a random position . The attitudinal position of the information from the social networks was not randomly distributed , but was , in each time step , based upon the current distribution of info-bits . This implies that a region in attitude space where the concentration of individuals is slightly higher by chance can self-reinforce through the propagation of the information these individuals post . In that way , they attract other individuals to move towards these regions . This is the mechanism how social posting together with the cognitive filter creates the pronounced and disconnected clusters . The square geometry of the attitude space and the level of the latitude of acceptance then determined how many such concentrated regions ultimately emerge and remain . A second result was that the friend network had no effect on attitude clustering . The bubble of friends maintained its large attitude radius and clusters in no way self-sorted with respect to friendship communities . Figure 3 shows the communities of individuals by their colour . It is clearly visible that the info-sharer bubbles were composed of members of all four friendship communities . Actually , the formation of info-sharer bubbles would evolve as it would do with only one friendship community . Thus , attitude clustering was possible even though all individuals continuously received strongly differing info-bits from many of their friends , who held different average attitudes . They just did not integrate this information . The impact of technological filters : Scenarios 5 to 8 We repeated the design above and analysed effects of the technological filter mechanisms for the exposure of individuals with new bits of information . The select close info-bits mode appears in Scenarios 5 and 7 , and the select distant info-bits mode in Scenarios 6 and 8 . Scenarios 5 and 6 are without social posting , and 7 and 8 with . Results are depicted in Figure 4 , and their quantitative characteristics are summarized in Table 1 . The technological filter selecting close info-bits had an effect similar to social posting , even when posting was disabled . Individuals formed tight info-sharer bubbles with almost no shared info-bits between the bubbles . A filter selecting distant info-bits was able to sustain a fully connected info-sharer network . When social posting was switched on , the final outcome was very similar to the former scenarios ( 3 and 4 ) with social posting : Eight info-sharer bubbles evolved . The only difference is that it took much longer to reach stability when only distant info-bits were selected by the technological filter . The impact of refriending : Scenarios 9 and 10 People not only map real-life friendship and family networks onto online social networks ; they also defriend and refriend online contacts . The refriend mechanism in our model makes defriending more likely when the attitudinal distance is greater , while new friends are random friends of friends . In previous simulations , we had found that existing community structures in the friendship networks of information sharing with social posting led to info-sharer bubbles with people from all friendship communities ( Scenarios 3 and 4 ) . Scenarios 9 and 10 in Figure 5 show the situation after stabilization when new bits of information appear individually and with social posting enabled as in Scenario 3 , but additionally with refriend probabilities of 0.01 and one . This result implies that echo chambers evolve when refriending happens in addition to social posting , but refriending is not the driving force for the formation of disconnected clusters of individuals with similar attitudes . BSUBDL ] SUOMI SALEAID s [ geoydde By ) Aq pouUISAOB aie sajague YC ‘ 8sn Jo seina Joy KreAQy ] UYU Ka [ L , y\\ Uo ( SUOYEpUOD- puE-sUIBY/LUDD Kay A resgEsUAlUO// : SANY ) SUONIPUOD UR SLID , BP 99g [ ZZOTA LEO ] UO Kresge SULlUG Aa [ ty “ faxas ] SuEIYDOD Aq 9EZTL-OSg/ LL L-OI/OPAUOD Karyn Kueagyauyuo-qnysksdsdgyysday Woy , papEo~UMoc ] ‘ | “ GLOT “ GOESPPOT 142 Daniel Geschke et al . Recommend close information Recommend distant information No social posting i % * Figure 4 . Individuals and their info-links after stabilization for Scenarios 5 , 6 , 7 , and 8 . [ Colour figure Social posting can be viewed at wileyonlinelibrary.com ] Refriend prob . 0.01 Refriend prob . 1 Individual information and social posting Figure 5 . Scenarios 9 and 10 , individual new-info-mode with social posting and a refriend probability of 0.01 ( Scenario 9 ) or | ( Scenario 10 ) . Colours represent connected components of the evolving friendship network . [ Colour figure can be viewed at wileyonlinelibrary.com ] BSUBDL ] SUOMI SALEAID s [ geoydde By ) Aq pouUISAOB aie sajague YC ‘ 8sn Jo seina Joy KreAQy ] UYU Ka [ L , y\\ Uo ( SUOYEpUOD- puE-sUIBY/LUDD Kay A resgEsUAlUO// : SANY ) SUONIPUOD UR SLID , BP 99g [ ZZOTA LEO ] UO Kresge SULlUG Aa [ ty “ faxas ] SuEIYDOD Aq 9EZTL-OSg/ LL L-OI/OPAUOD Karyn Kueagyauyuo-qnysksdsdgyysday Woy , papEo~UMoc ] ‘ | “ GLOT “ GOESPPOT The triple-filter bubble 143 Larger latitudes of acceptance : Scenarios [ 1 and 12 We also tested the impact of larger latitudes of acceptance . In particular , we studied Scenario 2 ( central new information without social posting ) and Scenario 3 ( new information individually with social posting ) with a latitude of acceptance of 0.5 instead of 0.3 . Figure 6 shows the results . Interestingly , the larger latitude of acceptance led to a large consensual cluster with social posting , while much more diversity including some clustering remained with central information without social posting . This suggests that social media could also have the potential to bring about a societal consensus that would not happen without . On the other hand , as we saw before , social media could also cause strong cohesive clusters maintained without any shared information between clusters . Scenario 11 also shows interesting transient dynamics until the large consensual cluster forms . This can be observed running the simulation ( Lorenz ef al , 2018 ) . In transient , two or three clusters evolve with only very little shared info-bits . Over time , the number of shared bits of information increases slowly and at some point a certain tipping point is reached and clusters converge rapidly to one cluster . The parameter constellation is thus prone to rapid social change . We conjecture that there are parameter configurations , which always lead to the same characteristic outcomes , while others are more prone to path dependence . A further exploration of this is beyond the scope of this paper , but proposed for future research . Discussion Main findings Without central information propagation , social posting , or recommender systems , no echo chambers emerged ( Scenario 1 ) . Individuals spread out evenly in the attitude space ( except for the extreme fringes ) . With central information propagation but without social posting or recommender systems , distinct echo chambers emerged , but individuals still shared some information with people outside their respective echo chambers ( Scenario 2 ) . Without central information propagation , but with social posting and without recommender systems , distinct echo chambers without links between them emerged Individual info . & social posting Central info . & no social posting Latitude of acceptance D=05 Figure 6 . Scenarios with latitude of acceptance D = 0.5 , which is higher than the baseline case of D = 0.3 used in all other scenarios . Left : individual new-info-mode with social posting ( analogue to Scenario 3 ) ; right : central new-info-mode without social posting ( analogue to Scenario 2 ) . [ Colour figure can be viewed at wileyonlinelibrary.com ] BSUBDL ] SUOMI SALEAID s [ geoydde By ) Aq pouUISAOB aie sajague YC ‘ 8sn Jo seina Joy KreAQy ] UYU Ka [ L , y\\ Uo ( SUOYEpUOD- puE-sUIBY/LUDD Kay A resgEsUAlUO// : SANY ) SUONIPUOD UR SLID , BP 99g [ ZZOTA LEO ] UO Kresge SULlUG Aa [ ty “ faxas ] SuEIYDOD Aq 9EZTL-OSg/ LL L-OI/OPAUOD Karyn Kueagyauyuo-qnysksdsdgyysday Woy , papEo~UMoc ] ‘ | “ GLOT “ GOESPPOT 144 Daniel Geschke et al . ( Scenario 3 ) . This indicates strong attitude group polarization . With central information propagation and social posting , but without recommender systems , distinct echo chambers emerged as well ( Scenario 4 ) . Taken together , this shows that in our ABM filter bubbles and echo chambers evolved from individual cognitive processes ( modelled in all scenarios ) in combination with central news sources that reach almost everyone alone , even without any social ( posting or refriending ) or technological ( recommender systems ) processes involved ( Scenario 2 ) . If , however , additional social posting processes occurred ( simulating many-to-many communication ; Scenarios 3 and 4 ) , these echo chambers became more distinct and less interconnected ; this would lead to even more fragmentation and polarization of society . Thus , these scenarios resemble the supposed impact of social media on strongly polarizing , political events such as the election of Donald Trump as US President or the British people ’ s decision on Brexit . In Scenarios 5 to 8 , recommender systems were used to present new information to individuals . We found that recommendation of close info-bits had the same effect as social posting even without social posting , while recommendation of distant info-bits could maintain a connected info-sharer network at least for some time . Social posting had the same effects as before . The triple-filter-bubble framework The triple-filter-bubble framework takes into account information filtering processes on the individual , the social , and the technological level . While the filtering mechanisms on the different levels had already been identified and described in previous research , their complex combination in a joint framework is novel . Results of our simulations show that the different filters interact and have effects on individual and social conceptual phenomena in ways that are not trivial : Disconnected echo chambers of individuals with almost identical attitudes based on information that nobody outside shares evolve through social posting and the cognitive filter given a relatively small latitude of acceptance . Interestingly , existing communities of friends that were initially not based upon shared attitudes did not have any substantial effect on attitude clustering . No selfsorting with respect to attitudes into existing friendship communities happened , and individuals typically ended up in different echo chambers from many or even most of their friends within the social network . With refriending , the clustering into echo chambers is just accelerated . Without social posting , bridges of information between such clusters of individuals could survive . Our simulations yielded results that bear resemblance to phenomena that can be observed in real-life contexts as well , such as the emergence of homophilous social networks and , under some circumstances , the emergence of detached echo chamber formations . The complexity of the framework might seem like a disadvantage ; however , colleagues who are interested in running simulations as means of testing more specific predictions , can build upon the face validity of our ABM and adjust it to their purposes . [ The model can be downloaded at https : //doi.org/10.5281/zenodo.1407733 . To run the model , download the latest ( free ) version of NetLogo and open the downloaded file . ] Of course , they are invited as well to validate or invalidate our initial findings . Limitations and directions for future research With regard to our ABM , the results presented here are not a complete analysis of the behaviour of the model . Next steps of interest departing from our baseline case would be , BSUBDL ] SUOMI SALEAID s [ geoydde By ) Aq pouUISAOB aie sajague YC ‘ 8sn Jo seina Joy KreAQy ] UYU Ka [ L , y\\ Uo ( SUOYEpUOD- puE-sUIBY/LUDD Kay A resgEsUAlUO// : SANY ) SUONIPUOD UR SLID , BP 99g [ ZZOTA LEO ] UO Kresge SULlUG Aa [ ty “ faxas ] SuEIYDOD Aq 9EZTL-OSg/ LL L-OI/OPAUOD Karyn Kueagyauyuo-qnysksdsdgyysday Woy , papEo~UMoc ] ‘ | “ GLOT “ GOESPPOT The triple-filter bubble 145 for example , to study the effect of memory size or different settings of the latitude of acceptance . Potential sensitivity analyses should address the questions of whether the effects are similar in attitude spaces with one or multiple dimensions . We expect that increasing the number of dimensions would have a strong effect on the number of evolving info-sharer bubbles . Furthermore , other distributions for the random appearance of the bits of information could be tested . Additionally , a birth-death mechanism for individuals could be used to model the possibility of adding additional dynamics to the network by having individuals leave it or join it and to explore how robust our findings would be with such a turnover ( Kurahashi-Nakamura , Mas , & Lorenz , 2016 ) . Another direction for future research will be to compare our results with those of studies using actual behavioural data . Our Scenario study admittedly uses a relatively stylized configuration of isolated dynamical mechanisms of micro—macro interaction . Nevertheless , the set-up of the model matches well to digital behavioural data from social media platforms . In line with previous studies that have analysed opinion dynamics using ‘ big data ’ techniques ( e.g. , Bakshy ef al , 2015 ; Del Vicario et al , 2016 ) , the importance of the technical infrastructure and of the properties of the respective social networks on the emergence of filter bubbles and echo chambers can in principle also be studied using authentic data from social media users . For example , our simulations indicate that enabling serendipity in recommender systems ( Herlocker et a/. , 2004 ) may attenuate the emergence of filter bubbles and echo chambers ( Scenarios 6 and 8 ) . However , we would assume that in view of the sheer number of information that is shared by friends and acquaintances in social media , the effectiveness of such technological countermeasures could be only marginal ( cf . Scenario 8 ) . The first challenge for such studies would be to assess the relevant societal attitudinal space and to develop methods of measuring it . One typical concern about ABM is that researchers might relatively easily create any desired model outcome by trying out different rules and settings until their model fits their theory . Jackson et ai . ( 2017 ) and ourselves do not agree with this concern in its generality . To counter it , we provide all details including the simulation code and intuitively understandable buttons to reproduce our findings . A critical reader can thus check , refute , or validate the findings and their robustness and sensitivity with respect to additional or other theoretical assumptions about the behaviour of individuals . Conclusion Modern technology can not be stopped ; people like to share their experiences digitally , and tech giants will further professionalize recommender systems to maximize the time users spend on their sites . On an individual level , these processes may lead to reassurance and enhancement of individually existing attitudes , behaviours , and identities . They increase individual attitudinal stability , and , thus , individual certainty and security . On a societal level , however , these processes are prone to increase attitudinal differences between opinion groups and individuals and to cut communication ties between them , leading to attitude clusters , societal fragmentation , and polarization . This poses a problem for modern democracies that rely on conflict resolution and reaching consensus through processes of democratic discourse . For the democratic process , it is necessary to be able to hear people express different opinions , to be willing to listen to them , and to engage in mutual discussion . So the digital world presents a genuine dilemma , where positive individual effects go along with negative societal effects . What can be done ? Generally , remedies to these issues on the individual , social , technological , and societal level have been proposed : On the individual level , knowledge about the BSUBDL ] SUOMI SALEAID s [ geoydde By ) Aq pouUISAOB aie sajague YC ‘ 8sn Jo seina Joy KreAQy ] UYU Ka [ L , y\\ Uo ( SUOYEpUOD- puE-sUIBY/LUDD Kay A resgEsUAlUO// : SANY ) SUONIPUOD UR SLID , BP 99g [ ZZOTA LEO ] UO Kresge SULlUG Aa [ ty “ faxas ] SuEIYDOD Aq 9EZTL-OSg/ LL L-OI/OPAUOD Karyn Kueagyauyuo-qnysksdsdgyysday Woy , papEo~UMoc ] ‘ | “ GLOT “ GOESPPOT 146 Daniel Geschke et al . processes leading to filter bubbles , or more generally , media competence , might mitigate these effects . On a social level , alternative mechanisms for debate , discussion , and creation of consensus are proposed ( possibly using social media ) . On the technological level , means of increasing the serendipity of recommender systems are currently being discussed ( Zhang , Séaghdha , Quercia , & Jambor , 2012 ) and will hopefully be imple- mented in the future . On the societal level , the deletion of fake news or unwanted content from the Internet , that is censorship ( as recently enforced in Germany for private companies like Facebook and the other tech giants ) , or the institutionalization of the latter is proposed as solutions . However , since these measures limit the human right of free speech and damage free discourse , they may finally turn out to be more harmful than useful to a democratic society . We believe that it is necessary to not only study the effects of interventions on these different phenomena separately . Such studies should be complemented by attempts to employ a methodology that allows for gauging possible non-linear effects of different combinations of these factors and that allows for the development of theories that integrate findings from as different fields as sociology , politology , computer engineering , and psychology into a common framework like our triple-filter-bubble model . Acknowledgements Jan Lorenz ’ s work benefited from grant LO2024/2-1 ‘ Opinion Dynamics and Collective Decision ’ from the German Research Foundation ( DFG ) . Peter Holtz ’ s work benefited from grant No . 687916 ‘ AFEL — Analytics for Everyday Learning ’ ( EU Research & Innovation Programme ‘ Horizon 2020 ’ ) . References Abelson , R. P. ( 1964 ) . Mathematical models of the distribution of attitudes under controversy . In L. R. Tucker ( Ed . ) , Contributions to mathematical psychology ( pp . 142-160 ) . New York , NY : Holt , Rinehart & Winston . Anderson , N. H. ( 1971 ) . Integration theory and attitude change . Psychological Review , 78 , 171— 206. https : //doi.org/10.1037/h0030834 Bakshy , E. , Messing , S. , & Adamic , L. A . ( 2015 ) . Exposure to ideologically diverse news and opinion on Facebook . Science , 348 ( 6239 ) , 1130-1132. https : //doi.org/10.1126/science.aaal 160 Bakshy , E. , Rosenn , I. , Marlow , C. , & Adamic , L. ( 2012 ) . The role of social networks in information diffusion . In Proceedings of the 21st international conference on World Wide Web ( pp . 519- 528 ) . ACM . https : //doi.org/10.1145/2187836.2187907 Bazzan , A. L. , & Kliigl , F. ( 2014 ) . A review on agent-based technology for traffic and transportation . The Knowledge Engineering Review , 2903 ) , 375-403. https : //doi.org/10.1017/ $ 0269888913000118 Boutyline , A. , & Willer , R. ( 2017 ) . The social structure of political echo chambers : Variation in ideological homophily in online networks . Political Psychology , 38 ) , 551-569. https : //doi . org/10.1111/pops.12337 Brewer , M. B . ( 1991 ) . The social self : On being the same and different at the same time . Personality and Social Psychology Bulletin , 17 ( 5 ) , 475-482. https : //doi.org/10.1177/0146167291 175001 Burke , R. ( 2002 ) . Hybrid recommender systems : Survey and experiments . User Modeling and User- Adapted Interaction , 12 ( 4 ) , 331-370. https : //doi.org/10.1023/A:102 1240730564 Castells , M. ( 2010 ) . End of millennium : The information age : Economy , society , and culture . Oxford , UK : Wiley-Blackwell . BSUBDL ] SUOMI SALEAID s [ geoydde By ) Aq pouUISAOB aie sajague YC ‘ 8sn Jo seina Joy KreAQy ] UYU Ka [ L , y\\ Uo ( SUOYEpUOD- puE-sUIBY/LUDD Kay A resgEsUAlUO// : SANY ) SUONIPUOD UR SLID , BP 99g [ ZZOTA LEO ] UO Kresge SULlUG Aa [ ty “ faxas ] SuEIYDOD Aq 9EZTL-OSg/ LL L-OI/OPAUOD Karyn Kueagyauyuo-qnysksdsdgyysday Woy , papEo~UMoc ] ‘ | “ GLOT “ GOESPPOT The triple-filter bubble 147 Deffuant , G. , Neau , D. , Amblard , F. , & Weisbuch , G. ( 2000 ) . Mixing beliefs among interacting agents . Advances in Complex Systems , 3 , 87-98. https : //doi.org/10.1142/S0219525900000078 Del Vicario , M. , Bessi , A. , Zollo , F. , Petroni , F. , Scala , A. , Caldarelli , G. , ... Quattrociocchi , W. ( 2016 ) . The spreading of misinformation online . Proceedings of the National Academy of Sciences , 113 ( QB ) , 554-559. https : //doi.org/10.1073/pnas.1517441113 Festinger , L. ( 1957 ) . A theory of cognitive dissonance . Evanston , IL : Row , Peterson . Fishbein , M. , & Ajzen , I . ( 1975 ) . Belief , attitude , intention and bebavior : An introduction to theory and research . Reading , MA : Addison-Wesley . Fisher , S. , & Lubin , A . ( 1958 ) . Distance as a determinant of influence in a two-person serial interaction situation . The Journal of Abnormal and Social Psychology , American Psychological Association , 56 , 230-238. https : //doi.org/10.1037/h0044609 Flache , A. , Mas , M. , Feliciani , T. , Chattoe-Brown , E. , Deffuant , G. , Huet , S. , & Lorenz , J . ( 2017 ) . Models of social influence : Towards the next frontiers . Journal of Artificial Societies & Social Simulation , 20 ( 4 ) , 1-31. https : //doi.org/10.18564/jasss.3521 Garimella , V. , & Weber , I . ( 2017 ) . A long-term analysis of polarization on Twitter . https : //arxiv . org/pdf/1703.02769.pdf Garrett , R. K. ( 2009 ) . Echo chambers online ? : Politically motivated selective exposure among Internet news users . Journal of Computer-Mediated Communication , 14 ( 2 ) , 265-285. https : //doi.org/10.1111/j.1083-6101.2009.01440 Geschke , D. ( 2017 ) . The RECO-KIT : A REality COnstruction KIT — technological , group dynamic , cognitive and motivational aspects . Poster presented at the /8tb General Meeting of the European Association of Social Psychology , Granada , Spain , July 5—8th , 2017 . Granovetter , M. S. ( 1973 ) . The strength of weak ties . American Journal of Sociology , 78 ( 6 ) , 1360— 1380. https : //doi.org/10.1086/225469 Griffin , E. ( 2012 ) . Communication communication communication ( pp . 366-377 ) . New York , NY : McGraw-Hill . Happer , C. , & Philo , G. ( 2013 ) . The role of the media in the construction of public belief and social change . Journal of Social and Political Psychology , 1 , 321-336. https : //doi.org/10.5964/jspp . vl1il.96 Hegselmann , R. , & Krause , U . ( 2002 ) . Opinion dynamics and bounded confidence , models , analysis and simulation . Journal of Artificial Societies and Social Simulation , 5 , 2 . Herlocker , J. L. , Konstan , J . A. , Terveen , L. G. , & Riedl , J. T. ( 2004 ) . Evaluating collaborative filtering recommender systems . ACM Transactions on Information Systems CTOIS ) , 22 ( 1 ) , 5-53. https : //doi.org/10.1145/963770.963772 Hermida , A. , Fletcher , F. , Korell , D. , & Logan , D. ( 2012 ) . Share , like , recommend : Decoding the social media news consumer . Journalism Studies , 13 , 815-824. https : //doi.org/10.1080/ 1461670X.2012.664430 Holtz , P. , Wagner , W. , & Sartawi , M. ( 2015 ) . Discrimination and immigrant identity : Fundamentalist and secular Muslims facing the Swiss Minaret Ban . Journal of the Social Sciences , 43 ( 1 ) , 9-29 . Hosanagar , K. , Fleder , D. , Lee , D. , & Buja , A . ( 2013 ) . Will the global village fracture into tribes ? Recommender systems and their effects on consumer fragmentation . Management Science , 60 ( 4 ) , 805-823. https : //doi.org/10.1287/mnsc.2013.1808 Huang , Q. , Parker , D. C. , Filatova , T. , & Sun , 8 . ( 2014 ) . A review of urban residential choice models using agent-based modeling . Environment and Planning B : Planning and Design , 41 ( 4 ) , 661— 689. https : //doi.org/10.1068/b120043p Hunter , J. E. , Danes , J. E. , & Cohen , S. H. ( 1984 ) . Mathematical models of attitude change . Cambridge , MA : Academic Press . Jackson , J.C. , Rand , D. , Lewis , K. , Norton , M.I. , & Gray , K. ( 2017 ) . Agent-based modeling : A guide for social psychologists . Social Psychological and Personality Science , 8 , 387-395. https : //doi.org/ 10.1177/1948550617691 100 John , N. A. , & Dvir-Gvirsman , S. ( 2015 ) . “ I Don ’ t Like You Any More ” : Facebook unfriending by Israelis during the Israel-Gaza Conflict of 2014 . Journal of Communication , 65 ( 6 ) , 953-974. https : //doi.org/10.1111/jcom.12188 BSUBDL ] SUOMI SALEAID s [ geoydde By ) Aq pouUISAOB aie sajague YC ‘ 8sn Jo seina Joy KreAQy ] UYU Ka [ L , y\\ Uo ( SUOYEpUOD- puE-sUIBY/LUDD Kay A resgEsUAlUO// : SANY ) SUONIPUOD UR SLID , BP 99g [ ZZOTA LEO ] UO Kresge SULlUG Aa [ ty “ faxas ] SuEIYDOD Aq 9EZTL-OSg/ LL L-OI/OPAUOD Karyn Kueagyauyuo-qnysksdsdgyysday Woy , papEo~UMoc ] ‘ | “ GLOT “ GOESPPOT 148 Daniel Geschke et al . Jonas , E. , Schulz-Hardt , S. , Frey , D. , & Thelen , N. ( 2001 ) . Confirmation bias in sequential information search after preliminary decisions : An expansion of dissonance theoretical research on selective exposure to information . Journal of Personality and Social Psychology , 80 ( 4 ) , 557. https : //doi . org/10.1037/0022-35 14.80.4.557 Knobloch-Westerwick , S. , Mothes , C. , & Polavin , N. ( 2017 ) . Confirmation bias , ingroup bias , and negativity bias in selective exposure to political information . Communication Research , 00936502 17719596 ( online first ) . https : //doi.org/10.1177/00936502 17719596 Krause , U . ( 2000 ) . A discrete nonlinear and non-autonomous model of consensus formation . In S. Elaydi , G. Ladas , J. Popenda & J. Rakowski ( Eds . ) , Communications in Difference Equations ( pp . 227-236 ) . Amsterdam , The Netherlands : Gordon and Breach . https : //doi.org/10.1201/ b16999 Kurahashi-Nakamura , T. , Mas , M. , & Lorenz , J . ( 2016 ) . Robust clustering in generalized bounded confidence models . Journal of Artificial Societies and Social Simulation , 19 ( 4 ) , 7 . Loewenstein , G. ( 1994 ) . The psychology of curiosity : A review and reinterpretation . Psychological Bulletin , 116 ( 1 ) , 75-98. https : //doi.org/10.1037/0033-2909.116.1.75 Lorenz , J. , Holtz , P. , & Geschke , D. ( 2018 ) . janlorenz/TripleFilterBubble : TripleFilterBubble NetLogo Model ( Version v1.0 ) . Zenodo . https : //doi.org/10.5281/zenodo . 1407733 Mason , W. , Conrey , F. , & Smith , E. ( 2007 ) . Situating social influence processes : Dynamic , multidirectional flows of influence within social networks . Personality and Social Psychology Review , 11 , 279-300. https : //doi.org/10.1177/1088868307301032 McPherson , M. , Smith-Lovin , L. , & Cook , J. M. ( 2001 ) . Birds of a feather : Homophily in social networks . Annual Review of Sociology , 27 ( 1 ) , 415-444. https : //doi.org/10.3410/f.725356294 . 793504070 Nguyen , T. T. , Hui , P. M. , Harper , F. M. , Terveen , L. , & Konstan , J . A . ( 2014 ) . Exploring the filter bubble : The effect of using recommender systems on content diversity . In Proceedings of the 23rd international conference on World wide web . ACM , pp . 677-686. https : //doi.org/10 . 1145/2566486.2568012 Nickerson , R. S. ( 1998 ) . Confirmation bias : A ubiquitous phenomenon in many guises . Review of General Psychology , 2 ( 2 ) , 175-220. https : //doi.org/10.1037/1089-2680.2.2.175 Noor , P. ( 2017 ) . ‘ The fact that we have access to so many different opinions is driving us to believe that we ’ re in information bubbles ’ : Poppy Noor meets Michal Kosinski , psychologist , data scientist and Professor at Stanford University . The Psychologist , 30 , 44-47 . Ott , B. L. ( 2017 ) . The age of Twitter : Donald J. Trump and the politics of debasement . Critical Studies in Media Communication , 34 ( 1 ) , 59-68. https : //doi.org/10.1080/15295036.2016 . 1266686 Pariser , E. ( 2011 ) . The filter bubble : What the Internet is hiding from you . London , UK : Penguin UK . Resnick , P. , Garrett , R. K. , Kriplean , T. , Munson , 8 . A. , & Stroud , N. J . ( 2013 ) . Bursting your ( filter ) bubble : Strategies for promoting diverse exposure . In Proceedings of the 2013 conference on Computer supported cooperative work companion . ACM , pp . 95-100. https : //doi.org/10 . 1145/2441955.2441981 Ridings , C. M. , & Gefen , D. ( 2004 ) . Virtual community attraction : Why people hang out online . Journal of Computer-Mediated Communication , 1001 ) , JCMC10110 . https : //doi.org/10.1111/ j.1083-6101.2004.tb00229.x Schelling , T. C. ( 1971 ) . Dynamic models of segregation . Journal of Mathematical Sociology , 1 ( 2 ) , 143-186. https : //doi.org/10.1080/0022250X.1971.9989794 Sherif , M. , & Hovland , C. ( 1961 ) . Social judgment : Assimilation and contrast effects in communication and attitude change . New Haven , CT : Yale University Press . Smith , E. R. , & Conrey , F. R. ( 2007 ) . Agent-based modeling : A new approach for theory building in social psychology . Personality and Social Psychology Review , 11 , 87-104. https : //doi.org/10 . 1177/1088868306294789 Sunstein , C. R. ( 2001 ) . Echo chambers : Bush v. Gore , impeachment , and beyond . Princeton , NJ : Princeton University Press . Sunstein , C. R. ( 2009 ) . Republic.com 2.0 . Princeton , NJ : Princeton University Press . BSUBDL ] SUOMI SALEAID s [ geoydde By ) Aq pouUISAOB aie sajague YC ‘ 8sn Jo seina Joy KreAQy ] UYU Ka [ L , y\\ Uo ( SUOYEpUOD- puE-sUIBY/LUDD Kay A resgEsUAlUO// : SANY ) SUONIPUOD UR SLID , BP 99g [ ZZOTA LEO ] UO Kresge SULlUG Aa [ ty “ faxas ] SuEIYDOD Aq 9EZTL-OSg/ LL L-OI/OPAUOD Karyn Kueagyauyuo-qnysksdsdgyysday Woy , papEo~UMoc ] ‘ | “ GLOT “ GOESPPOT The triple-filter bubble 149 Sunstein , C. R. ( 2018 ) . # Republic : Divided democracy in the age of social media . Princeton , NJ : Princeton University Press . Swann , Jr. , W. B. , Pelham , B. W. , & Krull , D. S. ( 1989 ) . Agreeable fancy or disagreeable truth ? Reconciling self-enhancement and self-verification . Journal of Personality and Social Psychology , 57 ( 5 ) , 782. https : //doi.org/10.1037//0022-3514.57.5.782 Turner , J. C. , Hogg , M. A. , Oakes , P. J. , Reicher , S $ . D. , & Wetherell , M. S. ( 1987 ) . Rediscovering the social group : A self-categorization theory . Oxford , UK : Basil Blackwell . Vaccari , C. , Valeriani , A. , Barbera , P. , Jost , J. T. , Nagler , J. , & Tucker , J . A . ( 2016 ) . Of echo chambers and contrarian clubs : Exposure to political disagreement among German and Italian users of twitter . Social Mediat+ Society , 203 ) , 2056305116664221. https : //doi.org/10.1177/ 2056305 116664221 Vallone , R. P. , Ross , L. , & Lepper , M. R. ( 1985 ) . The hostile media phenomenon : Biased perception and perceptions of media bias in coverage of the Beirut massacre . Journal of Personality and Social Psychology , 49 ( 3 ) , 577. https : //doi.org/10.1037/0022-3514.49.3.577 Vinokur , A. , & Burnstein , E. ( 1978 ) . Novel argumentation and attitude change : The case of polarization following group discussion . European Journal of Social Psychology , 8 ( 3 ) , 335— 348. https : //doi.org/10.1002/CISSN ) 1099-0992 Watts , D. J. , & Strogatz , $ . H. ( 1998 ) . Collective dynamics of ‘ small-world ’ networks . Nature , 393 ( 6684 ) , 440-442. https : //doi.org/10.1038/30918 Weiman , G. ( 2006 ) . Terror on the internet . The New Arena , the New Challenges , 147-171 . Wilensky , U . ( 1999 ) . NetLogo . http : //ccl.northwestern.edu/netlogo/ . Center for Connected Learning and Computer-Based Modeling , Northwestern University , Evanston , IL . Zhang , Y. C. , Séaghdha , D. o. , Quercia , D. , & Jambor , T. ( 2012 ) . Auralist : Introducing serendipity into music recommendation . In Proceedings of the fifth ACM international conference on Web search and data mining . ACM , 13-22. https : //doi.org/10.1145/2124295.2124300 Received 29 December 2017 ; revised version received [ 3 September 2018 BSUBDL ] SUOMI SALEAID s [ geoydde By ) Aq pouUISAOB aie sajague YC ‘ 8sn Jo seina Joy KreAQy ] UYU Ka [ L , y\\ Uo ( SUOYEpUOD- puE-sUIBY/LUDD Kay A resgEsUAlUO// : SANY ) SUONIPUOD UR SLID , BP 99g [ ZZOTA LEO ] UO Kresge SULlUG Aa [ ty “ faxas ] SuEIYDOD Aq 9EZTL-OSg/ LL L-OI/OPAUOD Karyn Kueagyauyuo-qnysksdsdgyysday Woy , papEo~UMoc ] ‘ | “ GLOT “ GOESPPOT DE GRUYTER Open Information Science 2020 ; 4 : 85-90 3 Research Article Lauren Valentino Bryant * The YouTube Algorithm and the Alt-Right Filter Bubble https : //doi.org/10.1515 /opis-2020-0007 Received October 31 , 2019 ; accepted April 9 , 2020 Abstract : The YouTube algorithm is a combination of programmed directives from engineers along with learned behaviors that have evolved through the opaque process of machine learning which makes the algorithm ’ s directives and programming hard to understand . Independent tests to replicate the algorithm have shown that the algorithm has a strong bias towards right-leaning politics videos , including those racist views expressed by the alt-right community . While the algorithm seems to be pushing users towards the alt-right video content merely in an attempt to keep users in a cycle of video watching , the end result makes YouTube a powerful recruiting tool for Neo-Nazis and the alt-right . The filter bubble effect that this creates pushes users into a loop that reinforces radicalism instead of level-headed factual resources . Keywords : YouTube , filter bubble , alt-right , Neo-Nazi , algorithm , racism , search engine YouTube is a source of not only entertainment , but information and instruction with content that will teach users to do anything from style their hair to replace a car ’ s battery . When asked about her company , YouTube , CEO Susan Wojcicki was eager to say , “ we ’ re really more like a library in many ways , because of the sheer amount of video that we have , and the ability for people to learn and to look up any kind of information , learn about it ” ( Thompson , 2018 ) . While YouTube may be a convenient source of information , YouTube is not like a library in many ways . The taxonomy and organization of YouTube ’ s topics and categorizations are broad and ill defined . Libraries , both physical and digital , are often curated by librarians to include balanced voices that give patrons an accurate view of political , philosophical , literary , and other arguments , while YouTube ’ s content is not curated as much as it is lightly moderated . YouTube does employ content moderators to remove disturbing content such as “ terrorism ” and “ child abuse ” from its servers , but this content does so much harm to their employees that “ Google is conducting experiments on some moderators to see whether technological interventions , such as allowing workers to watch videos in grayscale , reduce emotional harms ” ( Newton , 2019 ) . The publishing process that books , journals , magazines , and other publications go through before making their way to a library ’ s shelves or electronic holdings create varying degrees of checks and balances , while YouTube ’ s content is contributed by anyone with an internet connection . Arguably one of the last impartial spaces , libraries are unique because the information they offer does not come with a hidden consumer or political agenda . YouTube has done little to equip themselves with mission statements , values , and frameworks that would have established best practices for an information commons , a system that does not just offer information in various formats , but builds ways to confirm the validity of that information and preserve it . The business was built upon the goal of making money and not informing or educating . Without regulation , pockets of users with a racist or political agenda found that they could manipulate the algorithm and take control of the way content was presented through both Search Engine Optimization ( SEO ) and alignment with political structures . Safiya Noble , the author of Algorithms of Oppression , reminds her audience that , “ Google Search is in fact an advertising platform , * Corresponding author , Lauren Valentino Bryant , Ray W. Howard Library , Shoreline Community College , Shoreline 98133 WA USA , E-mail : lbryant @ shoreline.edu ; Laurenvbryant @ gmail.com 8 Open Access . © 2020 Lauren Valentino Bryant , published by De Gruyter . This work is licensed under the Creative Commons Attribution 4.0 Public License . 86 — _L . Valentino Bryant DE GRUYTER not intended to solely serve as a public information resource in the way that , say , a library might ” ( Noble 2019 ) . Noble and her ground-breaking research has paved the way for a larger conversation from many angles which have brought inequities to light in burgening technologies . As a for-profit company , YouTube is not in a position to be an impartial third party , and indeed are acting in exactly the opposite of that role , pushing and prodding its viewers indiscriminately towards its advertisements . This manipulative system is not the root of the problem , but rather the directive that the algorithm had been told to aim for , resulting in an unintended consequence on its own . Youtube ’ s video recommendation system may be promoting racist viewpoints which is distorting the overall perception of content on YouTube as a whole , a dangerous misunderstanding since the platform has taken on the responsibility of providing not only amusement and entertainment for the masses , but informing and educating them as well . The measure of success for the YouTube algorithm is convincing the user to watch an additional video after the end of the first video has finished . The default behavior of the YouTube player is to immediately play the suggested video , an issue in itself with consent . The algorithm improves through machine learning which means every time it has a successful interaction , and a user allows one of the suggested videos to be played , the algorithm learns that there is a relationship between the video watched and the video suggested . Exactly how the algorithm works is a bit of a black box , some of its internal logic is opaque even to its engineers . The algorithm ’ s learned behavior , a process that takes place without human intervention , is internal . Google did publish a white paper in 2016 that reveals the engineering intent behind the design . The formula incorporates every moment that a video is watched as a positive number while videos that were not clicked end up as negative numbers , failures adding to the negative watch time ( Covington , Adams , & Sargin , 2016 ) . A user ’ s demographics which we see in Figure 1 as “ example age ” and “ gender ” is mentioned as a factor along with “ items in a user ’ s history ” which is supposed to accurately determine what kind of videos the person might want to watch next ( Covington , Adams , & Sargin , 2016 ) . The other factor mentioned is “ search query tokens ” which would imply that the keywords a user types into a search box would follow them around and inspire future recommendations ( Covington , Adams , & Sargin , 2016 ) . Pg approx.topN ss ! EP . ; class probabilities —_ ' ee videorvectors U ; , ‘ nearest neighbor } # ——+ = softmax ' index ' = training serving | ReLU [ watch vector | search vector | Joes example age average average = li cee ol ; af embedded video watches embedded search tokens gender geographic LY embedding Figure 1 . The YouTube algorithm is designed to use “ example age ” and other demographic information to anticipate what the user may want to watch next . Covington , P. , Adams , J. , & Sargin , E. ( 2016 ) . Deep neural networks for YouTube recom- mendations . RecSys ‘ 16 Proceedings of the 10th ACM Conference on Recommender Systems , pp . 191-198. https : //doi . org/10.1145/2959100.2959190 DE GRUYTER The YouTube Algorithm and the Alt-Right Filter Bubble ——=_ 87 The intent of the engineers was to maximize exposure of advertisements on YouTube which is problematic , but not as malicious as the actual outcome we see the algorithm performing . The Google engineers measure their success by “ watch-time ” or “ click-through rate ” which tells us that their goal is to make sure the user watches more videos which creates more opportunities for users to click on videos or advertisements ( Covington , Adams , & Sargin , 2016 ) . Since YouTube ’ s main source of revenue is through their advertisers , the most obvious goal is to encourage users to click on the advertisements . There are two sides to the YouTube algorithm : one facet represents the design and intent of the algorithm by its engineers . The other facet is represented as an unknown factor because the algorithm is a learning neural network and has created some connections on its own through machine learning . Machine learning is distinct from a programmed response in that it is a behavior that the computer has improved upon on its own , often using pattern recognition to determine a better or faster way to attain the original directive which has been set by a human engineer . There are educated guesses supported by data that conclude that this second facet of the YouTube algorithm may be operating in some ways that were unintended by its creators . An independent test was done , “ each query in a fresh search session with no personal account or watch history data informing the algorithm , except for geographical location and time of day , effectively demonstrating how YouTube ’ s recommendation operates in the absence of personalization ” ( O ’ Donovan , Warzel , McDonald , Clifton , & Woolf , 2019 ) . After more than 140 such tests , the observers decided , “ YouTube ’ s recommendation engine algorithm isn ’ t a partisan monster — it ’ s an engagement monster . [ ... ] Its only governing ideology is to wrangle content — no matter how tenuously linked to your watch history — that it thinks might keep you glued to your screen for another few seconds ” ( O ’ Donovan et . al. , 2019 ) . Indeed , this is a popular theory that YouTube ’ s algorithm is not trying to teach or convince the user of a certain truth , but simply wants to convince them to continue to watch the videos on the site . Zynep Tufekci , a Turkish techno-sociologist , has studied YouTube ever since she had an unexpected experience with it as she was researching the 2016 presidential election campaign . While doing research for an article , she watched several “ Donald Trump rallies on YouTube ” which led the recommendation engine to autoplay “ white supremacist rants , Holocaust denials and other disturbing content ” ( Tufekci , 2018 ) . Even though racist content was the trigger that caused Tufecki to dig deeper , she concluded that the algorithm ’ s overall intent was not racist in nature . “ For all its lofty rhetoric , Google is an advertising broker , selling our attention to companies that will pay for it . The longer people stay on YouTube , the more money Google makes ” ( Tufekci , 2018 ) . YouTube is a for-profit company driven by online advertisements and we know that the goal of the algorithm is to drive users to use the service as much as possible , optimizing the chance that the user will click on an ad , therefore generating revenue for the website . YouTube ’ s recommendation system makes complex , goal-based decisions , using a set of independently operating computer programs that mimic the human brain , often called a neural network . YouTube uses a neural network learning algorithm that perpetuates content to users . This algorithm may have found an unexpected relationship between racism and the right amount of curiosity that prompts a person to continue to watch YouTube videos . Two academic researchers made a visualized data map of 13,529 YouTube channels , starting with the top most popular channels from opposite political perspectives , recreating the YouTube algorithm in an attempt to figure out what was happening when it was recommending increasingly extreme political content ( Kaiser & Rauchfleisch , 2018 ) . They found tightly bound relationships between the right-leaning content on YouTube , specifically “ Fox News , ” “ Alex Jones , ” and “ white nationalists , ” along with some conspiracy theories , anti-feminist , anti-political correctness channels , and a channel called the Manosphere ( Kaiser & Rauchfleisch , 2018 ) . The connection between these channels was more tightly knit and closer together on the right-leaning side than it was on the left-leaning one . The authors found this , “ highly problematic ” because a user who pursues even mildly conservative content is “ only one or two clicks away from extreme far-right channels , conspiracy theories , and radicalizing content ” ( Kaiser & Rauchfleisch , 2018 ) . There was a multitude of other data included in the visualization data , including non-political channels such as video games , guns , music , and tech , which are individually popular on their own but not interconnected in the way the right-wing communities within YouTube are connected ( Kaiser & Rauchfleisch , 2018 ) . Since the algorithm has made this unlikely connection , it has a bias of recommending racist or white supremacist videos more often to users . The surprising outcome of this machine learning is 88 — LL . Valentino Bryant DE GRUYTER that the algorithm is showing an unexplained bias to suggest alt-right content to users , even promoting it to an inflated presence on the website without prior prompting of this preference . Some employees within YouTube ’ s company “ raised concerns about the mass of false , incendiary and toxic content that the world ’ s largest video site surfaced and spread ” ( Bergen , 2019 ) . A user-run video database without moderation is dangerous on its own , but that is not exactly what was happening here ; the algorithm was interfering with peoples ’ preferences and seemed to be pushing racist and alt-right propaganda to the surface . An employee at YouTube proposed a new “ vertical ” in 2018 , “ a category that the company uses to group its mountain of video footage , ” suggesting that this section of videos should be dedicated to the alt-right ( Bergen , 2019 ) . “ Based on engagement , the hypothetical alt-right category sat with music , sports and gaming as the most popular channels at YouTube , an attempt to show how critical these videos were to YouTube ’ s business ” ( Bergen , 2019 ) . While this one employees ’ efforts may not reflect the values of YouTube ’ s company as a whole , they were not the first one to notice a trend in the massive amount of white supremacist videos on the video sharing site . The Southern Poverty Law Center had articles as early as 2007 that mentioned how compared to dropping pamphlets on lawns , “ posting video footage [ on video sharing sites ] is vastly less difficult , expensive , risky and time-consuming—and it can be done anonymously with virtually no effort ” ( Mock , 2007 ) . YouTube has always had hate speech policies , but recently updated these policies of June 2019 to specifically target white nationalists by condemning behavior that might , “ [ c ] all for the subjugation or domination over individuals or groups ” or “ [ d ] eny that a well-documented , violent event took place ” such as the Holocaust which is a conspiracy theory that is popular with many members of the alt-right ( “ Hate speech policy ” , 2019 ) . There was evidence that YouTube knew about the problematic content in 2017 because Susan Wojiciki mentioned in a 2018 Wired interview that “ we started working on making sure we were removing violent extremist content . And what we started doing for the first time last year was using machines to find this content . So we built a classifier to identify the content and lo and behold , the machines found a lot more content than we had found ” ( Thompson , 2018 ) . That Wojicki both admits that the extremist content is problematic and claims that there was a lot more of it than the human searchers were able to find means that YouTube does not seem to have some secret alt-right agenda , but is just preoccupied and does not consider it a top concern . During that same Wired interview , Wojicki was asked about morality and responsibility , but she said the company is not sure where they stand with moral concerns , adding an answer in the form of an analogy : “ we don ’ t want it to be necessarily us saying , we don ’ t think people should be eating donuts , right . It ’ s not our place to be doing that ” ( Thompson , 2018 ) . Online hate groups have unified on the internet and even though they span across many spaces such as Reddit , 8chan , 4chan , Twitter , Discord channels , a large majority of them claim that the content on YouTube with its constant stream of recommendations contributed to their recruitment . An internet investigative journalist on Bellingcat , an organization of independent online investigators , tracked down and interviewed 75 white supremacist facists to find out about each person ’ s “ red-pilling , ” a term to explain “ converting someone to fascist , racist and anti-Semitic beliefs ” ( Evans , 2018 ) . When spaces are created on the internet for hate groups , the concern has been raised that the groups will echo hateful messages back to each other , preventing the influence from the outside world to create a more realistic perspective for these individuals . The term “ filter bubble ” was coined by the internet activist Eli Pariser to describe a phenomenon in which search algorithms can contribute to surrounding a user with their own viewpoints , sending their own search terms back at them in the form of results , ensuring that they rarely come into contact with an opposing source . In Pariser ’ s book , The Filter Bubble : How the New Personalized Web is Changing What We Read and How We Think , he points out one of the main problems with the filter bubble : “ But the filter bubble isn ’ t tuned for a diversity of ideas or of people . It ’ s not designed to introduce us to new cultures . As a result , living inside it , we may miss some of the mental flexibility and openness that contact with difference creates ” ( Pariser , 2011 ) . Unfortunately one of the problems with internet subcultures is that they create an artificial space that guarantees the absence of diversity and conflict , even if the belief system is illogical or harmful . A dramatic contrast to the filter bubble may be the ideal library space , where each individual can encounter intelligent , well-worded perspectives that are opposed to one ’ s own . The Bellingcat journalist published findings that are similar to Pariser ’ s “ filter bubble ” theory , and mentioned that “ Infowars reached the height of its influence as a result of sites like Facebook and YouTube . DE GRUYTER The YouTube Algorithm and the Alt-Right Filter Bubble —=_ 89 By the time they were kicked off YouTube , Infowars had more than 2.4 million followers and 1.6 billion page views across 36,000 videos ” ( Evans , 2018 ) . Like YouTube , Facebook uses a unique algorithm that serves up content to the user in their news feed that is predictably similar to their own searches and browsing clicks . The two online environments provide spaces where they could continue to explore and browse for hours and not encounter an opposing perspective . Similar to the findings of the researchers who visualized the data points of YouTube ’ s political channels , the Bellingcat investigator gives an example of one person who identified as “ ‘ moderate republication ’ before ‘ Steven Crowder , Paul Joseph Watson , Milo Yiannopolos , Black Pidgeon Speaks , ’ and other far-right YouTubers slowly red-pilled him . Over time he ‘ moved further and further right until he could no longer stand them . That ’ s why he likes those groups even still , because if we just had the Fascists , we ’ d never convert anyone ’ ” ( Evans , 2018 ) . American politics plays into this situation a great deal as we have seen with both the Harvard researcher ’ s data and Bellingcat . The racist viewpoints are connected inextricably to the topics of video games , feminism , LGBTQ , and a multitude of other political talking points . With President Donald Trump supporting groups like the alt-right , many hate groups have grown emboldened and more active during Trump ’ s presidency . Groups online that may have been niche , hidden , and remote have found footholds in lax hate speech policies such as Twitter ’ s and until recently , YouTube ’ s . These groups have created echo chambers where it is difficult to hear anything outside their own voices , espousing their hate speech in the anonymous , risk-free , public forum that the internet has provided . Ina grouping of pure data taken from YouTube , a pair of researchers claimed , “ we were able to identify a YouTube- created right-wing filter bubble . [ ... /YouTube ’ s algorithm connects them visibly via recommendations . It is , in this sense , an algorithmic version of the Thomas theorem , which famously suggested that , ‘ If men define situations as real , they are real in their consequences ” ( Kaiser & Rauchfleisch , 2018 ) . If a community such as the alt-right does have influence and control over a large chunk of YouTube ’ s content , does this reflect the views and beliefs of the people in the United States ? After all , YouTube is as ubiquitous as the internet itself , the YouTube app coming standard on nearly every cell phone , tablet , and web enabled device , the videos available in the results screen of any Google search . The Bellingcat investigator shares some pop culture references that are used by the alt-right groups online and then reminds readers that , “ it is important to remember that these groups have a body count and represent a real threat . Their absurdity does not negate their danger ” ( Evans , 2018 ) . Many of the mass shooting attacks worldwide have been traced back to a small , thriving online community , the 8chan website , where users reinforce each others ’ racist beliefs and claim violence as the only remedy . “ The El Paso shooting follows a pattern carried out in Christchurch , New Zealand in March and in Poway , California in April . In both attacks , the suspects published manifestos to 8chan . Both manifestos were saturated with white nationalist talking points , portraying whites as the victims of a plan for elimination ” ( Hayden , 2019 ) . 8chan , the anonymous message board site that is proud to be moderation free and allow their users completely free speech , even if those things are illegal . Because of this lenient policy , 8chan has attracted violent extremists from many groups that use the platform to organize and encourage each other ’ s malicious crimes . After the El-Paso shooting of a Walmart where 26 were injured and 22 people died , authorities reported that they were , “ working to confirm the authenticity of , and any links between , the suspect and a manifesto published to the fringe internet platform 8chan in advance of the attack . The apparent manifesto refers to the ‘ Hispanic invasion of Texas ’ ” ( Hayden , 2019 ) . When the news of the El Paso shooting was released , one 8chan user wrote simply , “ ACCELERATE , ACCELERATE , ” while another joked , “ Clean up in aisle 4 ! ” ( Hayden , 2019 ) . The comment about cleaning up , can only be interpreted as the user ’ s attempt to dehumanize the victim and compare them to a broken or spilled item . The coaxing comments seen on 8chan could be exactly what a hesitant individual needs to enact real-life violence . In 2017 an independent survey found that only 9 % of Americans found it acceptable to hold alt-right or Neo-Nazi views , while 50 % of Americans found these views unacceptable ( Langer , 2017 ) . The surprising truth is that there appears to be small , vocal right-leaning groups online that produce a great deal of online content and much of that content is for YouTube . However , the majority of Americans are not supportive of alt-right , racist ideologies . There is danger in allowing our media to define a political spectrum that is not representative of the actual country . It allows the views of a vocal minority to be represented as a majority 90 — _ L.Valentino Bryant DE GRUYTER which is a danger when so many people find the appearance of consensus so persuasive . political situations for the rest of the country that are not supported by the majority of the citizens because perceptions , even illusions , can be deceiving . If our main information source is viewed on a skewed angle from an alt-right perspective , it can lend malicious influence to the general population . If the alt-right continues to be allowed to dominate our major media platform that 9 % can only grow and the country may come to resemble the content on Youtube if Youtube isn ’ t changed to better reflect its viewers . The relationship of racist content equating to increased ad clicks to the algorithm is one that may do harm , not only to those users that are exposed to YouTube , but to future applications of the algorithm . The YouTube algorithm itself was not programmed with the intent to cause racial bias in the video it recommends . It is likely that the algorithm ’ s design will be used to produce future technologies , which is why I hope the company of YouTube , Google , and the parent company Alphabet consider making the current algorithm more transparent to those that might study it , so that it can be improved upon . YouTube is beginning to consider aspects of itself that libraries have long figured out : collection development policies , standards of ethics , freedom of information and its boundaries , along with cataloging and categorization . Instead of making generalizations and vague comparisons of YouTube to a library , the leaders at YouTube need to take responsibility for the fact that their media has become an influential factor not just on the way the world entertains itself , but the way we educate and inform ourselves as well . References Bergen , M. ( 2019 , April 2 ) . YouTube executives ignored warnings , letting toxic videos run rampant . Bloomberg . Retrieved from https : //www . bloomberg.com/news/features/2019-04-02/youtube-executives-ignored-warnings-letting-toxic-videos-run- rampant Covington , P. , Adams , J. , & Sargin , E. ( 2016 ) . Deep neural networks for YouTube recommendations . RecSys ‘ 16 Proceedings of the 10th ACM Conference on Recommender Systems , pp . 191-198. https : //doi.org/10.1145/2959100.2959190 Evans , R. ( 2018 , October 11 ) . From memes to Infowars : How 75 fascist activists were “ red-pilled ” [ Blog post ] . Retrieved from Bellingcat website : https : //www.bellingcat.com/news/americas/2018 /10/11/memes-infowars-75-fascist-activists-red- pilled/ Hate speech policy . ( 2019 , June 5 ) . Retrieved October 28 , 2019 , from YouTube Help website : https : //support.google.com/ youtube/answer/2801939 ? hl=en Hayden , M. E. ( 2019 , August 04 ) . White nationalists praise El Paso attack and mock the dead . Southern Poverty Law Center . Retrieved from : https : //www.splcenter.org/hatewatch/2019/08/04/white-nationalists-praise-el-paso-attack-and-mock- dead Kaiser , ] . , & Rauchfleisch , A . ( 2018 , April 11 ) . Unite the right ? How YouTube ’ s recommendation algorithm connects the U.S. far-right . Retrieved October 28 , 2019 , from Medium website : https : //medium.com/ @ MediaManipulation /unite-the-right- how-youtubes-recommendation-algorithm-connects-the-u-s-far-right-9f1387ccfabd Langer , G. ( 2017 , August 21 ) . Trump approval is low but steady ; On Charlottesville lower still . ABC News/Washington Post . Retrieved from https : //www.langerresearch.com/wp-content/uploads/1190a1TrumpandCharlottesville.pdf Mock , B . ( 2007 , April 20 ) . Neo-Nazi groups share hate via YouTube . Southern Poverty Law Center . Retrieved from https : //www . splcenter.org/fighting-hate/intelligence-report/2007 /neo-nazi-groups-share-hate-youtube Newton , Casey . ( 2019 , December 16 ) . The terror queue : These moderators help keep Google and YouTube free of violent extremism—and now some of them have PTSD . The Verge . Retrieved from https : //www.theverge . com/2019/12/16/21021005/ google-youtube-moderators-ptsd-accenture-violent-disturbing-content-interviews-video O ’ Donovan , C. , Warzel , C. , McDonald , L. , Clifton , B. , & Woolf , M. ( 2019 , January 24 ) . We followed YouTube ’ s recommendation algorithm down the rabbit hole . Retrieved October 28 , 2019 , from BuzzFeed News website : https : //www.buzzfeednews . com/article/carolineodonovan/down-youtubes-recommendation-rabbithole Pariser , E. ( 2011 ) . The filter bubble : How the new personalized web is changing what we read and how we think . Retrieved from https : //books . google.com/books ? id=wcalrOl1YbQC & lpg=PP1 & pg=PP1 # v=on epage & q & f=false Thompson , N. ( 2018 , March 15 ) . Susan Wojcicki on YouTube ’ s fight against misinformation . Wired . Retrieved from https : // www.wired.com/story/susan-wojcicki-on-youtubes-fight-against-misinformation/ Tufekci , Z . ( 2018 , March 10 ) . YouTube , the great radicalizer . The New York Times , Opinion . Retrieved from https : //www . nytimes.com/2018/03/10/opinion/sunday/youtube-politics-radical.html ACADEMIA Accelerating the world 's research . Understanding and controlling the filter bubble through interactive visualization Sayooran Nagulendra Proceedings of the 25th ACM conference on Hypertext and social media - HT '14 Cite this paper Downloaded from Academia.edu4 Get the citation in MLA , APA , or Chicago styles Related papers Download a PDF Pack of the best related papers 7 Understanding and Controlling the Filter Bubble through Interactive Visualization : A User Study Sayooran Nagulendra and Julita Vassileva Department of Computer Science University of Saskatchewan , Saskatoon , Canada { sayooran.nagulendra , julita.vassileva } @ usask.ca ABSTRACT “ The filter bubble ” is a term popularized by Eli Pariser which refers to people getting encapsulated in streams of data such as news or social network updates that are personalized to their interests . While people need protection from information overload and maybe prefer to see content they feel familiar with and viewpoint that they agree with , there is the danger that important issues that should be of concern for everyone will get filtered away and people will live in “ echo-chambers ” , blissfully unaware of reality , and exposure to different views . We have proposed a design of an interactive visualization , which provides the user of a social networking site with awareness of the personalization mechanism ( the semantics and the source of the content that is filtered away ) , and with means to control the filtering mechanism . The visualization has been implemented in a peer-to-peer social network and we present here the results of a qualitative and a quantitative evaluation . The quantitative study with 163 participants demonstrates that the visualization leads to increased users ’ awareness of the filter bubble , understandability of the filtering mechanism and to a feeling of control over the data stream they are seeing . Categories and Subject Descriptors D.2.8 [ Information Storage and Retrieval ] : Information Search and Retrieval — information filtering General Terms Design , Experimentation , Human Factors Keywords Visualization , Filter Bubble , Recommender Systems , Online Social Networks 1 . INTRODUCTION Today , social networks provide a global platform for people to share and collaborate with their friends and families . Facebook , Twitter and Google+ are currently the most widely used social networks . With the growth of mobile and web technologies , these social networks are growing rapidly and millions of users are sharing data with their friends and families . As of September 2013 , Facebook has 1.15 billion users and 699 million daily active users [ 28 ] . Nearly a quarter ( 24 % ) of the content that is shared on the internet is shared on Facebook [ 27 ] and more than Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . To copy otherwise , or republish , to post on servers or to redistribute to lists , requires prior specific permission and/or a fee . Conference ’ 10 , Month 1—2 , 2010 , City , State , Country . Copyright 2010 ACM 1-58113-000-0/00/0010 ... $ 15.00 . 3.5 billion pieces of content shared each week [ 26 ] , creating a stream of data that can overload any user . The social data overload problem is commonly solved by filtering out the irrelevant data . Personalized stream filtering mechanisms aim at reducing information overload by presenting the user with only the content deemed to be the most relevant . Social media sites , such as Facebook , Digg and YouTube , have already implemented personalized stream filtering . Paradoxically , the main problem with information filtering is that they could be “ too good ” . The high level of optimization to the interest of the user that typical algorithms lead to items that remain in the data fit the user ’ s scope of interest that has been inferred by the system from the user ’ s previous behavior , users tend to becoming encapsulated in a “ bubble ” of their comfort , seeing only content related to their interests , and being spared of anything else . This is referred as “ the filter bubble ” problem . We proposed an approach to make the user aware of the filtering mechanism and take control over it . It is based on an interactive visualization that shows the filter bubble and some features of the hidden filtered data ( its semantics and origin ) . The intention is to make the user aware of the user model that the recommender system has developed , so that they can consciously decide to explore items that are filtered away by changing interactively her . But showing what is hidden and filtered away from the stream can increase the social data overload problem again . Therefore , the main challenge is to find an effective visualization technique that can be seamlessly integrated into the activity stream without contributing additionally to the social data overload . In addition to that the visualization design has to take into account of the right amount of detail to expose in the hidden filtered social data display the hidden social data stream in an understandable way to the user . In this paper we present a qualitative and a quantitative evaluation of an interactive visualization which metaphorically visualizes the filter bubble and provides awareness , understanding and control of personalized filtering to alleviate the filter bubble problem . 2 . RELATED WORK Recommender Systems ( RSs ) are software tools and techniques which adapt to the needs of an individual user and provide personalized suggestions of most relevant information [ 1 ] . The personalized suggestions help users to make decisions on various types of items , such as what news items are interesting , what book to read , what movie to watch and so on . Information filtering systems can be considered as a type of recommender systems , which select from a stream of data ( e.g . news , certain events , social updates , etc . ) those that fit the scope of interest of the user . The difference between filtering and recommendation is that in filtering the irrelevant data is simply not displayed , i.e . remains hidden from the users , while in recommendation the relevant data is highlighted in some way ( e.g . shown first in a list of search results , highlighted in a stream of data , etc . ) , but the irrelevant data is still available for the user to see . Recommendation techniques have been applied to personalize the streams in online social networks such as Facebook , Google+ and Twitter [ 2 , 3 ] . Facebook ’ s edge rank algorithm is one such filtering technique which presents a personalized stream of news and friends ’ status updates to the user by ranking every interaction on the site [ 4 ] . While all these social networks are centralized , Tandukar & Vassileva [ 5 ] have developed an interest-based filtering model for a decentralized online social network ( OSN ) , which enables each peer to learn the user ’ s interests and to filter away messages received from the user ’ s friends , . Many researchers have worked on developing new RSs and improving the accuracy of their filtering algorithms . However the ultimate measure of success in this area is the user acceptance and trust of the recommendations [ 6 ] . The way recommendations are presented is critical for the user acceptance of recommender systems . Visualization techniques can be deployed to provide an intuitive “ at a glance ” explanation for recommendations and can also motivate the user to accept the recommendation . Presenting the recommendations in a ranked list according to their recommendation score is the most simple and commonly used visualization technique . Features like colour and font-size can be used to emphasize recommended items in a stream or list or items [ 7 ] . iBlogViz is a system to visualize blog archives . It uses many visual cues to represent the blog content and social interaction history with the blog entry which help to navigate the blog archive quickly and easily . Particularly , visual cues about the social response ( comments ) to the news can be used to help users navigate stream data quickly to find interesting news [ 8 ] . Webster & Vassileva [ 9 ] proposed an interactive visualization of a collaborative filtering that allows the user viewer to see the other users in her “ neighborhood ” , who are similar to her , and also to change manually to degree of influence that any of the other users can have on the recommendations of the viewer . Rings is a visualization of social data stream developed by Shi [ 10 ] . It is organized around the people who post in the user ’ s Facebook stream and empathizes users who have posted many and influential posts recently , without filtering any posts . It helps the users of OSN to browse social data efficiently and find out the active users and the time pattern of their social updates . As the activity stream in Online Social Network is personalized according to the user ’ s interests , the user will ultimately only see activities related to her interests and will thus have no opportunity of discovering items not related to her current interests , or developing new interests . “ The filter bubble ” is a term introduced by Eli Pariser [ 11 ] to denote a limited scope of information defined by the user ’ s interests and isolated from anything that doesn ’ t belong to this scope . Isolating the user in a filter bubble has its advantages and disadvantages . The main advantage is that it can help users get relevant information a lot faster while not causing social data overload . On the other hand , there are number of problems outlined by Eli Pariser [ 11 ] . The first one is the problem of distortion of the content posted on the site or by the user ’ s friends and the user does not know in what way the way is biased . Users become less likely to be recommended information that is important , but not “ likeable ” . The second problem is the information equivalent of obesity . Because of the users ’ tendency to give positive feedback , they will give feedback only to information items they are most compulsively attracted to . Using an analogy from food , users will be eating candy all the time , and the filter bubble leave users locked in a world consisting of information junk food . As a result the users are increasingly surrounded by the ideas with which they are already familiar and agree , while being protected from surprising information , or information that challenges their views , the filter bubble threats people ’ s open-mindedness and prevents learning . Psychologist Lowenstein mentions that the “ curiosity is aroused when we are presented with an ‘ information gap ’ ” and Pariser suggests that the existence of curiosity , is based on the awareness that something exists that is hidden or unknown [ 11 ] . The third problem is the matter of control i.e . the growth of user knowledge will be greatly influenced by the algorithms and systems giving excessive power to the computer scientists who develop the personalization techniques . The importance of these three problems increases rapidly , as an increasing proportion of users are using OSN to get all their information and news ; and nearly all OSN deploy information filtering to personalize their streams to users . Yet , most of the personalization systems do not create awareness about what is being hidden from the user . Resnick et al . [ 12 ] outline some strategies for promoting diverse exposure . They discuss two approaches : the first one is to build diversity aware recommender systems and filtering mechanisms . As an example of this approach , Tandukar and Vassileva [ 13 ] developed an interest-based stream filtering technique , which allows for diversity exposure by allowing popular items to pass through the filter to ensure some serendipity . The second approach is to provide tools and techniques that encourage users to consider themselves searching for diverse exposure . Munson has implemented a browser extension which displays the bias in a user ’ s online news reading over time , which encourages users to seek the diverse exposure of news [ 14 ] . Though algorithmic personalization approaches can certainly find the most relevant content related to what users are already interested in a more efficient manner human curators and especially the user herself is probably the most appropriate agent to take the responsibility for ensuring a diverse exposure , to address the third problem outlined by Pariser . This means enabling the users to select what they want to see as well as what they do not want to see over the personalization presented by the algorithms . To enable them to do this , it is necessary first to make them aware of their filter bubble , as well as understanding of how they got inside it , and how they can control it to let different kind of information in and out , enlarge it or make it smaller ... To our best knowledge there is currently no existing work that aims to create this kind of awareness and control in users . This is the aim of our work . 3 . VISUALIZATION DESIGN The visualization of filter bubble has been designed and implemented based on the personalized stream filtering used in MADMICA [ 15 ] - an implementation of a privacy-aware decentralized ( peer-to-peer ) OSN using the Friendica open source framework [ 16 ] . MADMICA implements an approach to filtering social data , according to a model of the strength of the user ’ s interests in different semantic categories overlaid over a model of their social relationships , which was originally developed and evaluated in a simulation [ 13 ] . The intuition behind the filtering approach is that two people can be friends , but not share the same level of interest in different topics or categories and not trust each other ’ s judgment with regard to these categories . In essence , the filtering approach is based on a model of the user ’ s interest in a finite set of categories of social data that is overlaid with a model of the strength of user interpersonal relationships ( over each category ) . The visualization design is based on a bubble metaphor to make the effect of the personalized stream filtering in OSNs more understandable for the users ( see Figure 1 ) . The main goal of the visualization is to creating awareness , understanding , and control of personalized stream filtering in an OSN to alleviate the filter bubble problem and increase the users ’ trust in the system . It divides the space of the screen in two parts - outside and inside the bubble . The items that are inside the bubble are visible for the user , those outside the bubble are those that have been filtered away and are invisible in the stream ( but they are shown in the visualization ) . The visualization is personalized to the user viewing it ( let ’ s say Anna ) , and provides two alternative points of view : one focusing on the user ’ s ( Anna ’ s ) friends ( see Figure 2 ) and one focusing on the semantic categories of the social data originating from them in the OSN ( see Figure 1 ) . We assume that there is a finite , enumerable set of sematic categories in which the content can be classified . For practical reasons , these are categories of higher level of generality , e.g . “ news ” , “ technology ” , “ health ” , “ sport ” , similar to the categorization used by news websites , Google , Yahoo , etc . The category view shown in Figure | represents all the categories of posts shared by Charlie during last week that were shown in Anna ’ s newsfeed or filtered out by the system . All the category circles inside the bubble represent the categories of posts that are shown in Anna ’ s newsfeed ; they represent the common categories of interest between Anna and her friend Charlie . But Charlie has more interests , which are outside Anna ’ s filter bubble and are therefore being filtered out by the filtering mechanism based on the past history of actions that Anna performed on the posts shared by Charlie in the category “ health ” . The “ friends view ” of Anna ’ s bubble visualization is shown in Figure 2 . It represents all the friends who shared some posts in the “ health ” category during the last week that were shown in Anna ’ s newsfeed or filtered out by the system . The position of each friend circle relative to the big bubble is intended to create awareness about the filtering i.e . whose posts the user ( Anna ) can see in her newsfeed . Moreover , the filter bubble shape itself metaphorically creates the awareness that the user is encapsulated in a bubble and that there are friends outside of the bubble who have posted on the topic but the user has not seen these posts . As mentioned earlier , providing some understanding about the personalized stream filtering is one of the main goals of this visualization . Organizing posts by categories and friends gives some understanding about the personalized filtering : that there is a relationship between the categories of posts and the post origin ( the friends who shared them ) , and the underlying filtering mechanism . In addition to that , it visualizes the common interests between user and her friends i.e . what is shown inside the big From Friend ( s ) On Category ( s ) [ All [ = ] Time Period : Tech Finance Neve Games Movies Autos Music Politics Health Fashion Food Sports Shopping Travel Figure 1 . Anna ’ s “ category view ” of her filter bubble related to Charlie ’ s posts Jessie 0 C4 Gena A = Cs a i Charlie Alice A | a | So c- | —_ oe Bob Tim Victor a Dave a a 8 en - an Frank Ann o ae om Glen aa Mike Figure 2 . Anna ’ s “ friends view ” of her filter bubble related to a certain category ( “ health ’ ’ ) of posts bubble are common interests between the user and her friends . Providing control of the personalized stream filtering to the users ie . users can manually override the filtering system is another main goal of this visualization . This is achieved by allowing users to drag and drop the circles in and out of the big bubble . For example , if Anna drags and drops the circle representing the “ games ” category ( see in Figure 1 ) from inside the big bubble to its outside the user effectively tells the system that she does not like to see that category of posts in her newsfeed in the future . Similarly , the user could also drag and drop a friend from within her “ friends-view ” bubble to the outside and it signals the system to filter out the posts shared by that friend in the future . In the reverse situation , when the user realizes that she is interested in posts in category “ health ” shared by a friend ( say , Glen ) , who is outside her “ friends-view ” bubble in Figure 2 and wants to see his posts in her newsfeed homepage in the future , she will drag and drop that particular friend inside the big bubble . Apparently , this action is equivalent of the Anna coming out of her filter bubble and explore new interests . If Anna wants to see all posts by Glen in any category , she will select the “ Friends ” view and the generic category “ All ” from the “ Categories ” menu and drag him in her bubble . Nagulendra and Vassileva presented justification of the visualization design decisions and a pilot user study to evaluate the usability and user acceptance of the visualization and whether it achieves its goals of providing awareness , control and trust in the filtering mechanism in MADMICA in [ 17 ] . Eleven ( 11 ) graduate students from the MADMUC research lab used the MADMICA system with the filter bubble visualization instead of Facebook and shared interesting and research-related links over a period of three weeks in March 2013 . The results of the study showed that the filter bubble visualization makes the users aware of the filtering mechanism , engages them in actions to correct and change it , and as a result , increases the users ’ trust in the system [ 17 ] . Next we present the results of two more studies : a qualitative study with 5 participants and a larger scale quantitative study with 163 Mechanical Turk participants . 4 . EVALUATION 4.1 Qualitative User Study A qualitative study was carried out to understand in-depth the user perception of the filter bubble visualization ic . what do users think about the visualization . Five ( 5 ) participants from different departments in the university took part in this study . 4.1.1 Experimental Setup The study was carried out in a lab environment where users were given computers to use the MADMICA system and_ the visualization . The subjects were 5 university students from different fields of study such as public education , public health and statistics . They were recruited through a mailing list of potential subjects for HCI studies . First , the users were given some introduction to MADMICA and then about the filter bubble problem . After the introduction , users were given instructions to get familiar with the MADMICA newsfeed homepage and the filter bubble visualization for 10 minutes . Once they have explored the system , an interview was conducted . The interview consists of a set of tasks related to with 15 different views that are generated using the filter bubble visualization . They were asked to interact with the systems and think aloud , the users ’ actions were observed and recorded and the users ’ voice responses were recorded . The views in the questionnaire were generated to collect the perceptions about the visualization ’ s main goals : providing awareness , understanding and control . Moreover , the views included both the category view and friends view . 4.1.2 Methods The recorded users ’ voice responses were imported into NVivo software [ 18 ] which is a platform for qualitative research analysis . Then the voice responses were transcribed into text . With the help of the NVivo software , thematic analysis was carried out to identify the desirable and undesirable perceptions of the visualization . Thematic analysis categorizes qualitative data into themes . It encodes the qualitative information into codes that act as labels for sections of data [ 19 ] . The users ’ responses were coded and the codes were grouped into three : position of circle , size of circle and drag action . While coding , the number of references for each code was also recorded ie . the frequency of that code in the transcript of users ’ responses . Then based on the three criteria , the number of desirable references and undesirable references as calculated . The three criteria were : 1 . Circles inside the big bubble represent content or friends that was shown in the user ’ s newsfeed . 2 . Circles outside the big bubble represent content of friends that were filtered out by the system 3 . The visualization only shows the newsfeed shared by friends organized into categories and friends . 4.1.3 Results The thematic analysis results are summarized in Table 1 . The desirability percentage for a perception category is calculated as the number of references that are desirable in that perception category divided by the total number of references for the position of circle visual representation multiplied by 100 . Regarding the position of circle visual representation , 108 total references were made i.e . users mentioned 108 times in all of their responses together that the position of circles relative to the wall of the big bubble represents the user ’ s interest . This is the most referred perception category ( 16.67 % ) about the position of circle that is desirable . Some excerpts from the transcript for the user ’ s interest perception category follow : “ categories outside the bubble represent the posts that the user doesn ’ t want to see ” , “ categories inside the bubble represent my interests ” , “ categories inside the bubble represent users main interests for the selected duration ” , “ All the categories outside the bubble represent that none of user ’ s friends posts are related ” , “ categories outside the bubble represent the areas outside of my interest for that period ” , and “ categories inside the bubble represent that the user wants to focus on them ” . The least referred ( 1.85 % ) desirable perception category regarding the position of circle is relationship . Some excerpts from the transcript for the least referred desirable perception follows : “ friend circle outside the bubble for a category doesn ’ t mean that the user unfriended with that friend ” , “ having some categories inside the bubble for last month for a friend might mean an acquaintance relationship ” , and “ friend relationship is maintained regardless of user ’ s friends are outside the bubble ” . Some excerpts from the transcript for the least referred desirable perception follows : “ friend circle outside the bubble for a category doesn ’ t mean that the user unfriended with that friend ” , “ having some categories inside the bubble for last month for a friend might mean an acquaintance relationship ” , and “ friend relationship is maintained regardless of user ’ s friends are outside the bubble ” . Some excerpts from the transcript for the least referred desirable perception follows : “ friend circle outside the bubble for a category doesn ’ t mean that the user unfriended with that friend ” , “ having some categories inside the bubble for last month for a friend might mean an acquaintance relationship ” , and “ friend relationship is maintained regardless of user ’ s friends are outside the bubble ” . Table 1 . Thematic analysis results Feature/Visual Perception Sources References Desirability Undesirability Representation Category ( number ( desirable : percentage ( % ) percentage ( % ) of users ) undesirable ) Position of circle Common interest 4 13 ( 10:3 ) 9.26 ( 10/108 ) 2.78 ( friend/category ) Friends ’ interest 4 40 ( 16:24 ) 14.81 22.22 Friends ’ sharing 5 25 ( 18:7 ) 16.67 6.48 Interaction with 1 3 ( 3:0 ) 2.8 0 newsfeed User ’ s interest 5 23 ( 19:4 ) 17.59 3.7 Relationship 3 A ( 2:2 ) 1.85 1.85 Size of circle Number of posts 5 7 ( 6:1 ) 37.5 ( 6/16 ) 6.25 Frequency of sharing 2 2 ( 2:0 ) 12.5 0 Friends ’ interest 2 5 ( 4:1 ) 3.7 6.25 Common interest 1 2 ( 0:2 ) 0 12.5 Drag action Common interest 4 5 ( 4:1 ) 57.14 ( 4/7 ) 14.29 Relationship 1 2 ( 0:2 ) 0 28.57 The most referred ( 22.22 % ) undesirable perception category is the friend ’ s interest . But here only 4 users have referred this whereas in the most desirable perception all the 5 users referred it at some point in the transcript . Following are some excerpts from the transcript regarding the most undesirable perception : “ categories inside the bubble represent friend ’ s interest and outside represents not interested ” and “ friend circle more in the middle more interest in the category selected ” . Like the least referred desirable perception , the least referred undesirable perception is relationship and the excerpt follows : “ friend circle outside the bubble represents unfriending ” ’ . The number of posts related perception category is the most referred ( 37.5 % ) desirable perception for the size of the circle . Users perceive it as follows : “ bigger circle for friend/category represents more number of posts and small for less number of posts ” . As for the least referred ( 3.7 % ) desirable perception for the size of the circle , users perceive it as friend ’ s interest ie . “ larger circle for category means the selected friend has more interest on that category ’ . In case of undesirable perception category , the most referred ( 12.5 % ) one is common interest ( “ small friend circle means more common interest between the user and friends ” and “ larger circle represents user has less interest on that friend ” ) and the least referred ( 6.25 % ) one is number of posts and friends ’ interest ( “ small circle means actually posted and big circle means less posted ” and “ bigger circle outside the bubble represents less interest of friend on that category ’ ’ ) . There are two perception categories that emerged by the thematic analysis for drag action : common interest and relationship . Common interest is the most referred desirable perception category ( 57.14 % ) and there are no references for relationship on desirable perception . The excerpt from the transcript for common interest perceptions follows : “ dragging a category inside means to share more on that category with the friend ” , “ dragging in may represent my future interest ” , “ drag out because I don ’ t want to have common interest ” , “ drag out means lost interest in that category from that friend ” , and “ drag all the friends outside the bubble means I want to ignore all the news from them ” . The most and least referred undesirable perception category for the drag action are , relationship ( 28.57 % ) and common interest ( 14.29 % ) respectively . Excerpt related to relationship is “ dragging outside a friend/category means unfriend ” and for the common interest is “ drag inside represents forcing the friend to take interest on that category ” 4.1.4 Discussion The results of the qualitative data suggests that the subjects had both perceptions which are desirable and undesirable . Desirable perceptions ( 62.96 % ) regarding the position of circle had more references than undesirable perceptions ( 37.04 % ) . This shows that most of the time the visualization users were aware of and had a good understanding about the filtering . In particular , the emergent codes such as common interests , friends ’ interest , friends ’ sharing , interaction with newsfeed , user ’ s interest and relationship from the thematic analysis clearly show that the users have some understanding about the filtering . On the other hand the users also had undesirable perceptions . This could be due to poor graphical language of the visualization and interface as a whole . For example , the reason that friends ’ interest was perceived as the most undesirable perception category , could be the poor label texts of the dropdown menus which are used to view the filter bubble in different dimensions . During the experiment , the labels for the first two dropdown menu were as follows , Friend ( s ) and Category ( s ) . This creates a false perception when “ Charlie ” was selected and the category was selected as “ All ” ie . Charlie ’ s interests were shown inside the bubble and what lies outside the bubble were not the interests of Charlie . As a result the labels were later changed into “ From Friend ( s ) ” and “ On Category ( s ) ” ( shown in Figure 1 depicting the updated version ) before the quantitative study . The size of the circle is another indicator for creating awareness about the filtering , i.e . having bigger size of the circle outside the filter bubble would let the users know that there are more of posts that have been filtered out by the system on that category from that friend . Having 75 % of desirable perceptions for size of the circle shows that it is intuitive enough to create an awareness about the filtering . The 25 % of undesirable perceptions regarding the size of the circle shows that the graphical language needs improvement . For example , it would be clearer if there is a number shown with the varying size . Moreover , the false perceptions of common interest for the size of the circle showed that users may have wrong perceptions about the meaning of the size of circles . For example , size of the circles represent the interests of the friends i.e . smaller circle means that the friend has less interest on that category . The drag action has 57.14 % of desirable perception and 42.86 % of undesirable percentages . Despite the small difference , considering the number of users who referred the perception gives some clear indication that the majority of the participants ( 60 % ) were able to understand the control functionality of the filter bubble visualization . Though the perceptions were classified as desirable and undesirable , both of them helped to get more insight about the users perceptions about the visualization , improve the visualization and helped to prepare the questions and answers for the questionnaire of the quantitative study , presented in the next section . 4.2 Quantitative User Study A quantitative study was carried out to evaluate the understandability of the visualization and whether the users understand that the visualization provides awareness , understanding and control of filtering and the filter bubble . The study was conducted as an online survey and 163 participants from different parts of the world participated in the study . 4.2.1 Hypotheses The goal of this user study was to find out if the visualization is understandable , if it creates awareness and understanding of the personalized stream filtering mechanism and ability to control it to alleviate the filter bubble . So the evaluation aims at testing the following hypotheses . 1 . Users understand that the visualization provides awareness of the filtering and the filter bubble . 2 . Users understand that visualization _ provides understanding of the filtering and the filter bubble . 3 . Users understand that visualization provides control of the filtering and the filter bubble . 4 . Users understand the visualization and its functions . 4.2.2 . Experimental Setup The study was carried out as an online survey . Unlike the conventional online surveys , this survey had the interactive visualization embedded into the survey so that users could explore it and get some hands-on experience with it before answering the survey . First , the participants were given some introduction about the MADMICA social network and the filter bubble problem in general . Then a sample newsfeed homepage was displayed in the survey so that users could actually browse through the newsfeed without leaving the survey page . The sample newsfeed contained around 15 newsfeed items on 5 different categories such as Health , News , Movies , Music and Sports from five different friends named Alice , Bob , Charlie , Dave and Frank . The participants were given instructions to assume that the aforementioned people are their friends in MADMICA social network and to browse through the newsfeed homepage as they would do in Facebook . In addition to this , the newsfeed did not show around 7 posts out of those five categories from different friends i.e . the system filtered out some of the posts . Then the users were presented with the interactive visualization exactly as in the MADMICA system and were instructed to explore the visualization . Then they were directed to the questionnaire to answer the questions . The link to the online survey is given in the appendix section of this paper . 4.2.3 Method The online survey was conducted using Amazon Mechanical Turk ( MTurk ) which is a popular crowd-sourced participant pool . We ensured the data quality by placing attention check questions ( ACQs ) and restricting participation to MTurk workers with certain qualifications [ 20 ] . The suggested qualification among researchers to ensure data quality was to allow participants who have the HIT Approval Rate ( % ) for all Requesters ' HITs greater than or equal to 95 [ 20 ] . But we set even higher qualification to ensure the high data quality as follows : HIT Approval Rate ( % ) for all Requesters ' HITs greater than or equal to 98 % AND Number of HITs Approved greater than or equal to 5000 . The data collection continued for 1 week and reached our target sample of 230 . Then we analyzed the data and checked the ACQ for validity and as a result , 163 valid responses were collected . For each participant with a valid response , we paid a compensation of 1 $ , which is a good rate for an approximately 30-45 min . long study on MTurk . The questionnaire contained 25 questions . The questions were grouped according to the metrics which they intend to measure . The metrics for understandability of the visualization are adapted based on the International Standards for Software Quality Evaluation [ 21 ] . Table 2 summarizes the metrics chosen for measuring the understandability of the visualization [ 21 ] . There are 3 independent variables : awareness , understanding and control to assess the understandability of the visualization . Each of the independent variables was evaluated using the metrics given in Table 2 i.e . understandability of each independent variable was calculated . In addition to that , the overall understandability ( referred as understandability hereafter ) was also calculated using the understandability metrics . Six ( 6 ) questions ( 2 Yes/No and 4 Multiple Choice Questions ) were used to evaluate each of the independent variables . Altogether , there were 18 questions that were used to evaluate the overall understandability with 6 questions for each metrics . Our original hypotheses mentioned in section 4.2.1 were converted into the statistical form with the corresponding null hypothesis ( see Table 3 ) . Table 2 . Understandability Metrics Interpretation Metric Name Purpose Formula of measured value What proportions of functions x a of functions identified b 0 < =X < = 1 Evident Functions users were able to identify by the user y The closer to exploring the visualization B =Total number of actual functions 1.0 is the better . Function understand-ability What proportions of functions X=A/B 0 < =X < = 1 users were able to understand correctly by exploring the visualization The closer to 1.0 is the better . A= Number of functions whose purpose is correctly described by the user B= Number of functions available Can users understand what is Understandable input and required as input data and what is X=A/B A= Number of input and output data items which user successfully O < =X < = 1 The closer to output provided as output by the understands / 1.0 is the better visualization ? B= Number of input and output data items available from the visualization Table 3 . Statistical Hypotheses Normal - @ Plot of Understandability Test HO ( null ) H1 ( alternative ) 7 1 Lt Awareness = 0.5 LL Awareness > 0.5 7 2 Mt Understanding < 0.5 ML Understanding > 0.5 3 Lt Control = 0.5 Lt Control > 0.5 E 4 | Understandability < 0.5 ML Understandability > 0.5 i `` | i As shown in Table 3 , we considered the mean value of understandability for our hypothesis testing . The mean value is 0.5 according to the scale of metrics used to measure the understandability . We set the null hypothesis as the mean value of understandability is less than or equal to 0.5 i.e . users do not have a clear understanding about the visualization . Our research hypothesis is the mean value is greater than 0.5 i.e . users do have clear understanding about the visualization . As mentioned in the metrics Table 2 , the closer this mean value to 1.0 is , the better the understanding . 4.2.4 Results 4.2.4.1 Reliability Test The internal consistency ( reliability ) of question items was measured using the Cronbach ’ s alpha . Higher value of a reliability coefficient ( Cronbach ’ s alpha ) is associated with lower random error and greater measurement of the true score of the understandability . The acceptable value of Cronbach ’ s Alpha should be the range of 0.70 to 0.95 [ 22 ] . The rules of thumb when considering Cronbach ’ s Alpha value explanation are as follows : greater than 0.9 means excellent , greater than 0.8 means good , greater than 0.7 means acceptable , greater than 0.6 means questionable , greater than 0.5 means poor , and less than 0.5 is unacceptable [ 23 ] . The measured value for the Cronbach ’ s alpha is 0.7 for our questionnaire . This value is in the acceptable range . 4.2.4.2 . Normality Test The assessment of the normality of the data is a prerequisite and essential to t-tests . The Normal Q-Q plot for understandability was generated using SPSS ( see Figure 3 ) . If the data are normally distributed , the data points will be close to the diagonal line . If the data points move away from the line in a non-linear way then the data are not normally distributed [ 24 ] . As we can see from the Normality Q-Q Plot shown in Figure 3 , the data is normally distributed because the data points stay close to the diagonal line . Observed Value Figure 3 . Normality Q-Q Plot of Understandability 4.2.4.3 Hypothesis Test One-sample t-test was used to determine whether the mean of a particular data set is different from the particular value . Before doing the t-tests , the following 4 assumptions were met : understandability is measured at the ratio level , the collected data are independent which means that there is no relationship between the observations , there are no significant outliers in the data , and the understandability is approximately normally distributed [ 25 ] . Then the t-tests were conducted for the 4 hypothesis tests and the results are summarized in the Table 4 . The first t-test was conducted for the hypothesis 1 defined in section 4.2.1 . The Mean understandability of awareness ( M = 0.7117 , SD = 0.2379 ) was higher than the tested understandability value of 0.5 , a statistically significant mean difference of 0.21 , 95 % CI [ 0.18 to 0.25 ] , t ( 162 ) = 11.358 , p < .001 . Similarly , the t- tests for hypothesis 2 , 3 , 4 were conducted and the results follow respectively , the Mean understandability of understanding the filtering ( M = 0.6176 , SD = 0.2159 ) was higher than the tested understandability value of 0.5 , a statistically significant mean difference of 0.12 , 95 % CI [ 0.08 to 0.15 ] , t ( 162 ) = 6.953 , p < .001 , the Mean understandability of control ( M = 0.7607 , SD = 0.2246 ) was higher than the tested understandability value of 0.5 , a Statistically significant mean difference of 0.26 , 95 % CI [ 0.23 to 0.30 ] , t ( 162 ) = 14.824 , p < .001 and the Mean understandability of visualization ( M = 0.6967 , SD = 0.1808 ) was higher than the tested understandability value of 0.5 , a statistically significant mean difference of 0.20 , 95 % CI [ 0.17 to 0.23 ] , t ( 162 ) = 13.884 , p < .001 . In all four tests , there were a statistically significant difference between means ( p < .001 ) and , therefore , we can reject the null hypotheses defined in Table 3 , and accept the alternative hypotheses . Table 4 . Hypothesis Analysis Test | Variable Mean 2- Degree of 1-tailed 1-tailed Means Alternative tailed t | freedom Critical t t < are in Hypothesis ( df ) 2-tailed correct Accepted t order 1 Awareness -7117 11.358 162 1.6543 YES YES YES 2 | Understanding 6176 6.953 162 1.6543 YES YES YES 3 Control -7607 14.824 162 1.6543 YES YES YES 4 | Understandability 6967 13.884 162 1.6543 YES YES YES 4.2.4.4 Additional Test on Graphical Language The key graphical language constructs of this visualization are , 1 . The relative position of user 's circles to the bubble ( inside / outside ) 2 . The size of the users ’ circles ( larger - more posts ) 3 . Dragging user circles in and out ( showing / filtering away ) In addition to the above 3 constructs , we identified another potential construct from the qualitative study as follows : the position of circles inside the bubble ( closer to the center or to the periphery ) . All the 3 other constructs were as part of each function of the visualization ( providing awareness , providing understanding , and providing control ) and were tested for Statistical significance . In order to test whether users interpret this fourth construct or not , we included the answers based on this construct for two of the questions in the survey . During the analysis , we created a score for users based on how many out of the 2 questions they did not select this construct as an answer . Then the hypotheses were formed as follows : HO : score < 0.5 , H1 : bt score > 0.5 . One sample t-test was conducted and the results are as follows : the Mean score for not selecting the graphical construct ( M = 0.9571 , SD = 0.1405 ) was much higher than the test score value of 0.5 , a statistically significant mean difference of 0.46 , 95 % CI [ 0.44 to 0.49 ] , t ( 162 ) = 41.523 , p < .001.There were a Statistically significant difference between means ( p < .001 ) and , therefore , we can reject the null hypothesis , and accept the alternative hypothesis . 4.2.5 Discussion The results of the quantitative study suggest that overall the new users had better understanding about the visualization . By comparing the means of variables Awareness , Understanding , and Control , we can see that users have a better understanding ( 0.7607 ) about the control of filtering and the filter bubble provided by the visualization . This can be linked with the drag and drop feature of the visualization , which is very popular and commonly used action in many user interfaces and it is a very user friendly user interface construct . On the other side , the users ’ understanding about the visualization providing understanding to the filtering and the filter bubble has the lower value ( 0.6176 ) . Though it is higher than 0.5 , it clearly shows that the visualization has to be improved on this aspect . A possible improvement could be to provide some context sensitive help to the visual cues in the visualization . The overall understandability value of the visualization ( 0.6967 ) shows that the users had a_ better understanding about the visualization after exploring it for the first time and it could be considered as an intuitive visualization . But it can be envisioned that the users will better understand if there is a context sensitive help provided with the visualization . Analyzing the t-test values gives us more insight into the understandability measures . As mentioned earlier , the understandability of visualization is calculated using the three variables awareness , understanding and control . These three variables are understandability variables and are measured using the metrics presented in Table 2 . The variables awareness , understanding and control obtained a high 2-tailed value respectively 11.358 , 6.953 , and 14.824 . These values are comparatively very high when compared with their relevant one- tailed t-test value , which is 1.65 . This indicates that these three variables are a very good measure for the understandability of this visualization . The additional test on graphical language results suggest that the users very rarely interpreted the position of circles inside the bubble ( closer to the center or to the periphery ) ie . very few users selected it . A possible reason for this might be the nature of the question ; the users might have only focused on the first 3 graphical constructs which are intuitive and obvious . But it seems a useful construct and could be added as an improvement to the visualization in future . 5 . CONCLUSION AND FUTURE WORKS This paper presented the results of a qualitative and a quantitative evaluation of an interactive visualization which metaphorically visualizes the filter bubble in a P2P Social Network . The qualitative study reveals several user perceptions which provide desirable explanation for the awareness , understanding and control of the filter bubble provided by the interactive visualization . The quantitative study with 163 participants demonstrates that the visualization leads to increased users ’ awareness of the filter bubble , understandability of the filtering mechanism and to a feeling of control over the data stream they are seeing . Future work directions include conducting a study of evaluating the intuitiveness of the visualization by comparing it to the same interactive visualization provided with guided help . 6 . REFERENCES [ 1 ] Resnick , P. , Varian , H-R. : Recommender systems . Communications of the ACM . 40 , 3 , 56-58 ( 1997 ) [ 2 ] Kywe , S.M . et al . : A Survey of Recommender Systems in Twitter . Proc . 4th International Conference , SocInfo 2012 , Lausanne , Switzerland , December 5-7 , 2012. pp . 420-433 ( 2012 ) [ 3 ] Manish , A. et al . : An Online News Recommender System for Social Networks . SIGIR-SSM . ( 2009 ) [ 4 ] Kincaid , J. : EdgeRank : The Secret Sauce That Makes Facebook ’ s News Feed Tick | TechCrunch , Available online at : http : //techcrunch.com/2010/04/22/facebook-edgerank/ . ( accessed 6 July 2013 ) [ 5 ] Tandukar , U. , Vassileva , J. : Selective Propagation of Social Data in Decentralized Online Social Network . Proc . UMAP 2011 Workshops , LNCS 7138. pp . 213-224 Springer-Verlag Berlin Heidelberg ( 2012 ) [ 6 ] Konstan , J.A. , Riedl , J. : Recommender systems : from algorithms to user experience . User Modeling and User- Adapted Interaction . 22 , 1-2 , 101-123 ( 2012 ) [ 7 ] Webster , A. , Vassileva , J. : Visualizing personal relations in online communities . Proceedings of the adaptive hypermedia and adaptive web-based systems ( AH ’ 2006 ) , June 21-23 , pp . 223-233 , Springer LNCS 4018 , Dublin ( 2006 ) [ 8 ] Indratmo , Vassileva , J. , Gutwin , C. : Exploring blog archives with interactive visualization . In : International conference on Advanced Visual Interfaces ( 2008 ) [ 9 ] Webster , A. , Vassileva , J. : The KeepUP Recommender System . Proc . 2007 ACM Conference on Recommender Systems RecSys ’ 07 . pp . 173-176 ACM , Minneapolis , Minnesota , USA . ( 2007 ) [ 10 ] Shi , S. : Keeping Up with the Information Glut by Visualizing Patterns of Posting by Friends on Facebook , http : //hdl_handle.net/10388/ETD-201 1-09-139 , ( accessed 11 Feb 2013 ) [ 11 ] Pariser , E. : The Filter Bubble : What the Internet Is Hiding from You . Penguin Press HC ( 2011 ) [ 12 ] Resnick , P. , A. Munson , S. , Garrett , R.K. , Stroud , N.J. , Kriplean , T. : Bursting Your ( Filter ) Bubble : Strategies for Promoting Diverse Exposure . Proc . Conference on Computer supported Cooperative Work CSCW 2013 Companion proc . pp . 95-100 ACM ( 2013 ) [ 13 ] Tandukar U. , Vassileva J. : Ensuring Relevant and Serendipitous Information Flow in Decentralized Online Social Network . Proc . AIMSA ’ 2012 , 15th biennial conference on AI Methods Systems , Applications , Springer Verlag , LNAI 7557 , pp . 79-88 . ( 2012 ) [ 14 ] Munson , S.A. , Resnick , P. : Presenting diverse political opinions . Proc . 28th international conference on Human factors in computing systems - CHI 10. p. 1457 ACM Press , New York , New York , USA ( 2010 ) [ 15 ] Nagulendra , S. , Vassileva , J. : Minimizing Social Data Overload through Interest- Based Stream Filtering in a P2P Social Network , Proc . IEEE International Conference on Social Computing , SocialCom ’ 2013 ( 2013 ) [ 16 ] Macgirvin , M. : DFRN — the Distributed Friends & Relations Network , Available online at : https : //macgirvin.com/spec/dfim2.pdf . ( accessed 2 Aug 2012 ) [ 17 ] Nagulendra , S. , Vassileva , J. : Providing Awareness , Understanding and Control of Personalized Stream Filtering in a P2P Social Network . 19th International Conference , CRIWG 2013. pp . 61-76 Springer Berlin Heidelberg ( 2013 ) . [ 18 ] NVivo 10 for Windows , Available online at : http : //www.qsrinternational.com/products_nvivo.aspx . ( accessed 25 Feb 2014 ) [ 19 ] Boyatzis , R.E . : Transforming qualitative information : Thematic analysis and code development . Thousand Oaks , London , & New Delhi : SAGE Publications ( 1998 ) [ 20 ] Paolacci , G. , Chandler , J. : Running experiments on Amazon Mechanical Turk . 5 , 5 , 1-14 ( 2014 ) . [ 21 ] ISOAEC TR 9126-2:2003 — Product Quality —- External Metrics , Available online at : http : //www.iso.org/iso/iso_catalogue/catalogue_tc/catalogue _ detail htm ? csnumber=22750 . ( accessed 2 Feb 2014 ) [ 22 ] Bland , J. M. , Altman , D. G. : `` Statistics notes : Cronbach's alpha , '' pp . 570-572 ( 1997 ) [ 23 ] George , D. , Mallery , P. , SPSS for Windows step by step : A simple guide and reference . 11.0 update ( 4th ed . ) , Boston : Allyn & Bacon ( 2003 ) [ 24 ] Testing for Normality using SPSS , Available online at : https : //statistics.laerd.com/spss-tutorials/testing-for- normality-using-spss-statistics_php . ( accessed 2 Mar 2014 ) [ 25 ] One-Sample T-Test using SPSS , Available online at : https : //statistics.laerd.com/spss-tutorials/one-sample-t-test- using-spss-statistics.php . ( accessed 2 Mar 2014 ) [ 26 ] An Infographic : The Biggest Shift since the Industrial Revolution | TechnoBuffalo , Available online at : http : //www.technobuffalo.com/2010/06/01/an-infographic- the-biggest-shift-since-the-industrial-revolution/ . ( accessed 5 Sept 2013 ) [ 27 ] Chart of the day : How People Share Content on the Web , Available online at : http : //www.businessinsider.com/chart- of-the-day-social-networking-sites-dominate-sharing-2009-7 . ( accessed 4 Aug 2013 ) [ 28 ] Facebook Investors , Available online at : http : //investor.fb.com/releasedetail.cfm ? ReleaseID=780093 . ( accessed 4 Aug 2013 ) APPENDIX The online survey link used for the quantitative user study : http : /sayooran.usask.ca/limesurvey/index.php/985992/lang-en ACADEMIA Accelerating the world 's research . Values in the filter bubble Ethics of Personalization Algorithms in Cloud Computing Job Timmermans Ist International Workshop on Values in Design @ @ @ Building Bridges between RE , HCI and Ethics Cite this paper Downloaded from Academia.edu4 Get the citation in MLA , APA , or Chicago styles Related papers Download a PDF Pack of the best related papers 7 Designing and Evaluating for Trust : A Perspective from the New Practitioners Christian A Detweiler Requirements for Reconfigurable Technology : a challenge to Design for Values Jeroen van den Hoven Application Autopsy and Artifact-Altering Technologies Matthew Hockenberry 1 “ International Workshop on Values in Design — Building Bridges between RE , HCI and Ethics 6 '' of September , 2011 , Lisbon , Portugal Christian Detweiler , Delft University of Technology , The Netherlands Alina Pommeranz , Delft University of Technology , The Netherlands Jeroen van den Hoven , Delft University of Technology , The Netherlands Helen Nissenbaum , New York University , USA Table of Contents PREFACE wee ces cescesceeceeceecee aes eeeeee ene cesaeaes cae seeseeaeseeeeaesae cea aeaes caeseeaesanseeeeaeeaeaae 3 ORGANIZATION ooo cesses cesceeeeeceecee ces aeecaeeae cee aesaes cee eaeceaeea aes caeeaeseeaesaeseeeeaeeeaesase 4 VALUES IN THE FILTER BUBBLE ETHICS OF PERSONALIZATION ALGORITHMS IN CLOUD COMPUTING eeee eee eee cesses eee saeeneeee eee es APPLICATION AUTOPSY AND ARTIFACT-ALTERING T ECHNOLOGIES REQUIREMENTS FOR RECONFIGURABLE TECHNOLOGY : A CHALLENGE TO DESIGN FOR VALUES ... ceeceeceeceeceeceeaeeeeeeee ce ceseeeee eae ceeeee aes eeesneseeaesaeeeaeeaeenae APPROXIMATING USER VALUES TO PRESERVE PRIVACY — A PROPOSAL ....... EXPLORING NORM-CRITICAL DESIGN IN ONLINE YOUTH COUNSELING DESIGNING AND EVALUATING FOR TRUST : A PERSPECTIVE FROM THE NEW EXPERIENCING MOBILITY DATA uu . seseeseseeeeeeeee cesses caeeaeceeaesaeseeeeeceaeeaaeeeaeeae 56 LOCKBOX : APPLYING THE VALUE OF PRIVACY TO CLOUD STORAGE ............ 63 ELICITATION OF VALUES , MOTIVATIONS AND EMOTIONS : THE VBRE METHOD ou . eeecesceeceeeee cee ceeces cee cae ceeee aes eeeee eae eeeaesaes cae seeeee aes eeesnese sea eens eaeeee 71 Preface Designing for values has become increasingly important for technology development . In many technological systems ( medical applications , social networks etc . ) values ( privacy , autonomy , trust etc . ) play a role and are sometimes violated . In working with stakeholder requirements or user needs , various design methods in requirements engineering ( RE ) and human computer interaction ( HCI ) , in specific user-centered ( UCD ) , deal with “ soft issues ” , “ social issues ” , “ people issues ” or values . At the same time , applied ethics has begun to pay attention to design . We believe that many of the approaches could complement each other in useful ways . The aim of this workshop is to bring together people from different disciplines to share knowledge and insights about how to account for values in technology design , and to work towards integrating approaches , thereby putting value conscious design approaches ( e.g . values-in-design or value sensitive design ) to practice . Nine submissions were selected for inclusion in the workshop . Topics included approaches to various aspects of design ( Thew and Sutcliffe ; Normark et al . ; Sanches and Bylund ) , applications ( Stark and Tierney ; Caplan and Hockenberry ; Koch et al . ) , reflection on existing technology ( Dechesne et al. , Bozdag and Timmermans ) , and enquiry into industrial practice ( O'Kane et al. ) . Christian Detweiler , Delft University of Technology , The Netherlands Alina Pommeranz , Delft University of Technology , The Netherlands September , 2011 Organization Workshop Chairs Christian Detweiler , Delft University of Technology , The Netherlands Alina Pommeranz , Delft University of Technology , The Netherlands Jeroen van den Hoven , Delft University of Technology , The Netherlands Helen Nissenbaum , New York University , USA Program Committee Joost Broekens , Delft University of Technology , The Netherlands Catholijn Jonker , Delft University of Technology , The Netherlands David Keyson , Delft University of Technology , The Netherlands Cees Midden , Eindhoven University of Technology , The Netherlands Mark Neerincx , TNO , The Netherlands Barbara Paech , Heidelberg University , Germany Jens Riegelsberger , User Experience Design , Google , UK Alistair Sutcliffe , University of Manchester , UK Yao-Hua Tan , ICT , Delft University of Technology , The Netherlands Michael Zimmer , University of Wisconsin-Milwaukee , USA Keynote Talk : Serving a Community of Homeless Young People through Value Sensitive Design David G. Hendry Value Sensitive Design Research Lab The Information School The University of Washington Seattle , Washington , USA Abstract . For the past four years , we have conducted an unfolding series of service , design , and research projects in a community of homeless young people . Working within the value sensitive design methodology , the overarching aim of this work is twofold : First , to understand how homeless youth adopt digital media and personal digital technologies and generally bring information systems in their lives ; and second , to develop design knowledge for improving the welfare of homeless youth through information systems . Our design stance , while explicitly precautionary , is oriented towards intervening through policy , social organization , and information systems . In this talk I will introduce value sensitive design , the project , some key values and value tensions , the direct and indirect stakeholders , and some of the empirical methods that we have been using . I will conclude with some lessons leamed and open questions for the application of value sensitive design in this community . Invited talk : Designing for Trust Andreas Woelk , Manager , User Experience Design , eBay Marketplaces As Manager of User Experience and Content Strategy at eBay Inc. , Andreas Woelk is leading an effort to create a design and communications framework that seeks to better understand and influence the perceptions of trust within a dynamic , global marketplace . Since its formation , eBay has provided a platform built on trust that allows buyers and sellers to connect and conduct business on a global scale . In recent years , the company has strongly invested in actively shaping the experience between buyers and sellers and their overall relationship with eBay . The key focus of this new framework is to put structure around these relationships in order to develop bilateral trust not only between buyers and sellers , but also between buyers and eBay as well as sellers and eBay . To achieve this goal , Mr. Woelk and his team conducted extensive global research , identifying the top priorities and nuances between these relationships and the opportunities to develop them further in unique ways . The introduction of strategic programs such as purchase protection and seller certification as well as enhancements to the feedback system were important steps taken to support buyers in making informed purchase decisions based on trust in the marketplace . Further , to keep these critical relationships in balance , the team actively engaged the seller community to understand the overall impact to their perception of trust and to ensure that these buyer programs did not come at the expense of sellers ’ trust overall . Mr. Woelk is excited to be part of this year 's panel on “ Values in Design - Building Bridges between RE , HCI & Ethics ” . He will be discussing the challenges and opportunities uncovered during this unique initiative as well as the innovative methodology that was employed throughout the process . Values in the filter bubble Ethics of Personalization Algorithms in Cloud Computing Engin Bozdag and Job Timmermans Delft University of Technology Faculty of Technology , Policy and Management Section Philosophy P.O . Box 5015 , 2600 GA Delft , the Netherlands { V.E.Bozdag , J.F.C.Timmermans } TUDelft.nl Abstract . Cloud services such as Facebook and Google search started to use personalization algorithms in order to deal with growing amount of data online . This is often done in order to reduce the “ information overload ” . User ’ s interaction with the system is recorded in a single identity , and the information is personalized for the user using this identity . However , as we argue , such filters often ignore the context of information and they are never value neutral . These algorithms operate without the control and knowledge of the user , leading to a “ filter bubble ” . In this paper , by building on existing philosophical work , we discuss three human values implicated in personalized filtering : autonomy , identity , and transparency . Keywords : value sensitive design , personalization , filtering , computer ethics , cloud computing , software as a service 1 Introduction Emerging web technologies such as Cloud Computing allow users to outsource their computing and storage needs to data centers managed by a third party [ 12 ] . This transforms the computing world rapidly towards developing software for millions to consume as a service , rather than to run on their individual computers [ 4 ] . One of the most important ethical implications of this technological development is the shift of control from users to software providers [ 18 ] . Not only do users lose control of their personal data , but computation as well . Cloud service providers can change features and the algorithms of an application “ on-the-fly ” , without the control of the user . Cloud services , such as Facebook and Google Search inherit these ethical problems and often deal with large amounts of user generated data . The availability of immense computing power and storage offered by the cloud leads to a fast increase in the generated and stored data. ! The amount of data makes it very difficult for the user to select and process relevant information . In order to overcome this “ information overload ” , cloud services started developing personalization algorithms . ! According to Cisco ’ s latest research , in 2015 , consumer generated data on the Internet will be 4 times more than what it is in 2010 [ 5 ] . Web personalization is the process of changing the content and structure of a web application to adapt it to the specific needs , goals , interests and preferences of each user [ 7 ] . By building a user model , the beliefs and knowledge that the system has about the user is captured [ 7 ] . This way the system can predict what will be relevant for the user , filtering out the irrelevant ones , increasing its personal relevance to an individual [ 2 ] . For instance , according to Pariser [ 14 ] , Google uses various “ signals ” ( previous search keywords , location , status updates of contacts in social networking sites , etc . ) in order to customize search results per user . Facebook on the other hand checks a user ’ s interactions with other users , and filters certain users ’ posts . This means user activities ( click history ) are translated into a single identity , and on the basis of this identity certain information is filtered out . Further , photos and videos receive a higher ranking than regular status posts . Facebook therefore determines the importance of the information on behalf of the user . The problem with this sort of algorithmic filtering is that information is filtered before reaching the user , and this occurs silently . The criteria on which filtering occurs are unknown ; the personalization algorithms are not transparent . The user ’ s previous interaction with the system is the basis of future personalization . However , as we later will argue , we have different identities , depending on the context , which is ignored by the current personalization algorithms . Personalized filtering is gaining importance and it is used by many cloud services . Considering the increase of popularity of cloud services , we can expect to see personalization more often in the future . This , therefore , requires a good analysis of the implicated values in the design of such algorithms . In this paper we use Value Sensitive Design methodology [ 6 ] to identify the values and value assumptions implicated in personalization algorithms . In Section 2 , we start a conceptual investigation by clarifying the ( moral ) value of information and the necessity of filterig in the information age . In Section 3 , the concept of ‘ personalized filtering ’ is investigated by relating it to a theory of filtering . Next , in Section 4 , building on existing philosophical work , we discuss three human values implicated in personalized filtering : autonomy , identity , and transparency . Finally , in Section 5 , we conclude with a list of guidelines to consider when designing personalization algorithms . 2 Value of Information and the Need for Filtering In his book A Theory of Justice [ 16 ] , John Rawls introduces the concept ‘ primary goods ’ : goods that are supposedly useful ( or at least not harmful ) to anyone , irrespective of their conception of the good . By applying Thomas Pogge ’ s widely accepted interpretation and extension of the Rawlsian idea of justice [ 15 ] , Van den Hoven and Rooksby [ 10 ] argue that information should be accepted as a primary good within Rawls ’ s theory . Information online is vital for people to plan their lives rationally and to participate adequately in the common life of their societies [ 10 ] . Thus , having access to information affects the worth of liberty felt by an individual . We therefore argue that personalizing algorithms affect the moral value of information as they facilitate an individual ’ s access to information . Contrary to earlier stages of the Internet-era , when the problem information access boiled down to having access to hardware , nowadays the problem of access to information concerns the ability of intentionally finding the right information , or unintentionally stumbling on upon relevant information . We rely more and more on technology to find relevant information . In the cloud , relevance is determined to a large extent by algorithms . The lowering of cost of communication and production of informational goods enabled by the Internet , has led to an enormous increase in information available to the public both in quantity and diversity [ 1 , 17 ] . The declining influence of traditional news media as filters to the flood of information that is unleashed every day , the threat of information overload arises . ‘ Having too much information with no real way of separating the wheat from the chaff is what Benkler [ 1 ] calls Babel objection : ‘ individuals must have access to some mechanism that sifts through the universe of information , knowledge , and cultural moves in order to whittle them down into manageable and usable scope. ’ The question then arises whether the service providers currently active on the Internet are able to fulfill the “ human need for filtration ’ . Although the fulfillment does not hinge on proprietary services alone as there are cooperative peer-production alternatives that operate as filters as well , the filtering market is dominated by commercial cloud services like Google and Facebook ’ . 3 Filtering In this section we first give a theory of filtering based on Goldman [ 8 ] . We later describe the characteristics of personalized filtering done by algorithms . 3.1 A theory of filtering According to Goldman [ 8 ] , filtering involves a designated channel of communication and a system of people with three kinds of roles ( Figure 1 ) : senders , receivers and the filterer ( or gatekeeper ) , an individual or group with the power to select which of the proffered messages are sent via the designated channel . When a gatekeeper disallows a message , this is filtering . According to Goldman , not every form of filtering is censorship . Filtering occurs for instance in peer-review process in scientific journals where the reviewers are the gatekeepers , or in the system of trial procedure , where the judges are the gatekeepers . Certain filtering practices are commonly rationalized in terms of helping the relevant audience to determine the truth . Goldman identifies 3 doxastic stages , processes that ultimately produce belief ( See Figure 2 ) . In order for people to believe truths and avoid believing falsehoods , some selections must be made at one or more stages . If filtering happens at the reporting stage , the gatekeeper filters some of the sources or certain types of information to be sent to the receiver . If filtering happens at the reception stage , all the information is sent to the receiver , and the receiver himself can choose which messages he wishes to receive , that is , read , and digest . The receiver does this by first 2 Tm 2010 in the UK for instance , Google and Facebook dominate as gateways to the wider Internet [ 9 ] . selecting which channels to tune in to and then selecting which messages aired or displayed on those channels to ‘ consume ’ ( read or listen to ) . Finally , in the acceptance stage , the receiver , having read a certain number of messages on a particular topic , must decide which of these messages to believe . According to Goldman , if the gatekeepers , for instance newspaper editors , are not competent enough , filtering done at the reporting level might not be reliable . one | Reporting v Gatekeeper Reception v tin Acceptance Figure 1 . Roles of filtering Figure 2 . Doxastic stages 3.2 Personalized filtering In Cloud Computing , algorithms practice the role of the gatekeeper , reducing the volume of information reaching their users ( receivers ) during the reporting stage ( Figure 2 ) . Depending on certain criteria , the information is personalized per individual user . Because of this , the information is filtered before reaching the user , and it occurs silently . If important and diverse information is already filtered out by the system , the user might come into a different belief . User also can not customize the filtering . If he is aware of it , opting out is possible . However , as we have argued in Section 2 , the filtering is needed ; an option to turn it on or off is not enough . Since the outcome of personalized algorithms depend on many factors ( number of users who are using it , differences in languages , variability of the user input , etc . ) the outcome and reliability of the algorithms are very difficult to predict , even for the engineers who developed them . According to Pariser [ 14 ] , complex systems such as Google search engine have reached a level of complexity at which even their programmers can not fully explain any given output . 4 Values in Personalized Filtering In their article on the politics of search engines , Introna and Nissenbaum [ 11 ] claim that the design of search engines is ‘ not only a technical matter but also a political one. ’ ( p.31 ) Building on the Rawlsian notion of information as a primary good , they argue that the design of technical mechanisms behind search engines should transcend commercial needs as dictated by the marketplace and involve political choices concerning social justice such as equality and inclusiveness . This boils down to design challenges such as the incorporation of ‘ human values ’ , e.g . “ relevancy ” , into 10 the search algorithm . Introna and Nissenbaum thus argue that these algorithms must be considered as value-laden or non-neutral . The main mechanism behind search engines is filtering ; these systems filter at the “ reporting ” stage ( Figure 2 . ) Personalization algorithms , just like search algorithms also contain embedded values . In this section we discuss three human values implicated in personalized filtering : autonomy , identity , and transparency ’ . 4.1 Autonomy In section 2 we discussed the Babel objection to stress the necessity of filtering . This objection , Benkler [ 1 ] argues , can only be answered when it is accepted that filtering is vital to an autonomous individual ( p.174 ) . The ability of filtering of informational goods thus is closely related to autonomy . According to Brey [ 3 ] , to be autonomous is to be a self-governing agent . Autonomy can thus be defined as ‘ self-governance , that is , the ability to construct one 's own goals and values , and to have the freedom to make choices and plans and act in ways that are believed by one to help achieve these goals and promote these values. ’ [ 3 ] . Autonomy is therefore essential for a life to be meaningful and fulfilling . In order to be self-governing and make choices one needs to be properly informed . The unprecedented availability of information offered by the Internet can be regarded as an increase in the degree of autonomy of individuals . The quantity of information available makes filtering inevitable , however . The reliance of individuals on web services supporting their quest for relevant information , without providing insight on the filtering process , can decrease user autonomy . Although it is impossible to sift through all sources of information ourselves , in order for us to employ our capacity for choice , it seems that we at least need to be able to assess and influence the mechanisms that are doing the filtering for us . The value of autonomy thus implies more influence and control of users over the filtering process in order to align it to their personal preferences . The promise held by the Internet of an increase in the degree of autonomy due to a wider availability of information can therefore only be fulfilled when there is proper filtering in place . The filter bubble is a phenomenon that is closely related to what Sunstein have called “ echo chambers ” [ 17 ] . Sunstein worried that citizens would use technological tools to over-customize their information sources , leading to what he calls “ echo chambers ” or “ information cocoons ” [ 17 ] . However , there is a major difference ; filter bubble occurs without the autonomy of the user . It should further be noted that the value of autonomy is potentially in conflict with a defining feature of Cloud Computing : the shifting of control from users to third party service providers . Because of this control shift , the service providers can add features to the existing software , such as personalization , without notifying their users . Thus , while autonomy entails controlling the filtering service , the technological properties of the underlying architecture and software make it more difficult to realize this value . 4.2 Transparency 3 Due to limited space and time available we focus on only three values . Further analysis is needed to identify other values and value assumptions , such as trust , anonymity , etc . 11 Transparency is closely related to autonomy . A user can not assert control in an opaque system , since he will not be well informed how the system works . If the user has prior knowledge to the information requested when he uses the cloud service , he can assess the quality of the delivered information . However if the user does not know what he wants , then he can not assess if he is receiving relevant information . For instance , a query for “ Ajax ” , intending the mythological Greek hero , is returned by Google with a first page filled with results about Amsterdam ’ s football team ( which is also called Ajax ) , because I live in the Netherlands . Since I know which result is relevant to me , I can check other pages or revise my keyword to find the information I am looking for . However , if I am searching for “ best digital camera ” , and Google assumes that the price is the most important criterion for me ( because of my previous search keywords ) , then I will not be able to assess the quality of this information . According to Introna and Nissenbaum [ 11 ] , users have the right to demand full and truthful disclosure of the underlying rules or algorithms governing indexing , searching , and prioritizing , stated in a way that is meaningful to the majority of Web users . Even though this helps spammers , authors argue that this will lead to a clearer grasp of what is at stake in selecting among the various services . Pariser [ 14 ] argues that for the users to control the services they are using , users must know what information is used for personalization and how their data are used . We are not so sure whether full disclosure of the underlying algorithm will lead to full transparency and better user experience . Not only because of possible misuses such as spam and conflicts with trade secrets , but it will be very difficult for an average user to comprehend the algorithm . Instead , the implications of such algorithms must be shown to the user . When a personalized filtering takes place , the user should be notified of this filtering activity and also on what basis the system is filtering . This way he will know that he might be missing some information .. 4.3 Identity In personalization , by tracking the online activity associated with the user a profile is created that represents traits of the user ’ s identity . Personalized filtering is thus based on an interpretation of a user ’ s identity . Identity refers to people ’ s understanding of who they are over time , embracing both continuity and discontinuity [ 13 ] . To a certain extent there is also a discontinuity of identity when a person moves from one context to the other . In her account of privacy as contextual integrity , Nissenbaum [ 13 ] argues that the kind of privacy needed depends on the particular context personal information is flowing to . In each context individuals have different expectations of what kinds of information are appropriate and inappropriate and how that information should be distributed . When these information norms are violated , an individual ’ s privacy is infringed . According to Nissenbaum , privacy thus involves a person ’ s ability to control the flux of his/her personal data being distributed for each particular context . The idea that a person has different expectations per context about what information she wants to share can be useful in explaining filtering needs . Just like sharing , as a person has expectations about what information she holds as appropriate or suiting to receive in a particular context . In a social context , such as being amongst friends , sustaining relationships might be more important than realizing professional ambitions ( although these goals sometimes do coincide ) . 12 When contextual expectations are taken into account , autonomy is not just dependent on filtering as such , but more specifically on filtering according to particular contextual requirements . These requirements are related to traits of one ’ s identity materialized in a profile used by algorithms to personalize filtering . Currently personalized filters used by most cloud services often do not take the context of a person into account . As a result all information is filtered to a generic identity or profile of the user . For instance , in Facebook , if I do not show interests in the pictures of a contact , the system will assume that I have no interest in this contact at all . However , I might be interested in his status updates about work related links . The one-filter for all interactions principle can be omitted when discontinuity of identity in different contexts is taken into account . When different personalized filters can be deployed in different settings , conflicting context specific requirements are no longer in each other ’ s way . 5 Conclusion and Recommendations To recapitulate , building on the work of Van den Hoven [ 10 ] , we showed that access to information should be viewed as a primary good in terms of Rawls theory of justice . Then we argued that due to enormous increase in information supply this good can only be obtained by individuals if they rely on filtering technology . Next , we showed by extrapolating on the work of Introna and Nissenbaum [ 11 ] on search engines that filtering is not a value neutral process . We then dicussed three values in design of personalization systems : autonomy , identity and transparency . We argue that implicated values should be taken into account during the design of personalized algorithms . In order to do that , it would be useful to come up with a list of guidelines to consider when designing such algorithms . Accordingly , we have a tentative suggestion of what such a list could look like . This list is intended to be a first proposal , not as the final and only possible list . Our analysis of the cloud services is based on personal interactions with these systems and the work of Pariser [ 14 ] . More empirical study is needed in order to understand full implications of these algorithms . Further , even if the service providers design personalization filters that respect the identified values , the user can still trap himself in his own “ echo chamber ’ [ 17 ] . This brings the question whether information intermediaries such as Google and Facebook have a social responsibility to expose the user to public values , in order to increase diversity of information . This will allow the user to encounter information he did not know and that was not available through his friend network . However , questions such as which public values should be included remain open . More debate is needed to answer these questions . Table 1 . Guidelines for Designing Personalization Filter Algorithms 1 . Make sure different identities are allowed per user , which might differ per context . 2 . Design for autonomy , so that the user can customize the filter , and change the identity that is formed on basis of his previous interactions . 3 . Design for transparency , so that the user is aware that a filter is taking place . The user must be able to see which criteria is used for filtering , and which identity the system has of the user . 13 Funding This research is supported by the Netherlands Organization for Scientific Research ( NWO ) Moazaiek grant , file number 017.007.111 References 1 . Benkler , Y . ( 2006 ) . The Wealth of Networks : How Social Production Transforms Markets and Freedom ( Yale Press ) . 2 . Blom , J . ( 2000 ) . Personalization - A Taxonomy . CHI 2000 . A pril ( 2000 ) . 3 . Brey , P. ( 2000 ) . Disclosive computer ethics . SIGCAS Comput . Soc . 30 , 4 . 4 . Buyya , R. , Yeo , C. S. , Venugopal , S. , Broberg , J. , & Brandic , I ( 2009 ) . Cloud computing and emerging IT platforms : Vision , hype , and reality for delivering computing as the Sth utility . Future Generation Computer Systems 25 ( 6 ) , 599-616 5 . Cisco Systems ( 2011 ) . Cisco Visual Networking Index : Forecast and Methodology , 2010-2015 , whitepaper . 6 . Friedman , B. , Kahn , P. H. , & Borning , A . ( 2006 ) . Value Sensitive Design and Information Systems . Technology , 3 ( 6 ) , 1-27 . ME Sharpe . 7 . Garrigés , I , , Gomez , J. , and Houben. , G. ( 2010 ) . Specification of personalization in web application design . Information and Software Technology , 991- 1010 . 8 . Goldman , A . ( 2008 ) . The Social Epistemology of Blogging . Information Technology and Moral Philosophy . Cambridge University Press . 9 . Hitwise ( 2010 ) Social networks now more popular than search engines in the UK . Available at http : //www.hitwise.com/index.php/uk/press-centre/press- releases/2010/social-media-alert-june-2010/ ( Accessed:27 July 2011 ) 10 . Hoven , MJ van den & Rooksby , E ( 2008 ) . Distributive justice and the value of information : a ( broadly ) Rawlsian approach . Information technology and moral philosophy ( pp . 376-396 ) . Cambridge , New York 11 . Introna , L.D . and Nissenbaum , H. ( 2000 ) . Shaping the Web : Why the Politics of Search Engines Matters . The Information Society , 16 , 169-185 12 . Jaeger , P. T. , Lin , J. , & Grimes , J. M. ( 2008 ) . Cloud Computing and Information Policy . Journal of Information Technology and Politics 5 ( 3 ) . 13 . Nissenbaum , H. ( 2004 ) . Privacy as Contextual Integrity . Washington Law Review Vol 79 , No . 1 , February 2004 : 119-158 14 . Pariser , E. ( 2011 ) , The Filter Bubble : What the Internet Is Hiding from You . Penguin Group USA 15 . Pogge , T. ( 1989 ) . Realizing Rawls . Ithaca : Cornell University Press 16 . Rawls , J. , A Theory of Justice , Cambridge Mass. , Belknap Press of Harvard University Press , 1971 17 . Sunstein , C. ( 2007 ) Republic.com 2.0 , Princeton University Press 14 18 . Timmermans , J. , Stahl , B.C. , Ikonen V. , and Bozdag , E. ( 2010 ) . The Ethics of Cloud Computing : A Conceptual Review . Cloud Computing , HCI , & Design : Sustainability and Social Impacts , 2nd IEEE International Conference on Cloud Computing Technology and Science , Indianapolis , USA . 15 Application Autopsy and Artifact-Altering Technologies Robyn Caplan , Matthew Hockenberry ’ 1 Department of Media , Culture , and Communication , New York University 239 Greene Street , 7th Floor New York , NY { rdc3 10 , hock } @ nyu.edu Abstract . Product Autopsies “ dissect ” material goods to understand what goes into them , where these components come from , and what that means for producers , consumers and owners . We extend this idea to digital “ goods ” — looking at the autopsies of web sites and web applications in order to better understand them . Every web application is the product of a careful process of construction . Libraries , platforms , links , and embeds are pulled together to construct a commodity with a seemingly concrete appearance . App Autopsies expose these connective threads in order to understand the implications for the site , and its visitors , across a variety of value dimensions . Keywords : Internet ethics , open source , commons-based peer production , reflective design 1 Introduction Product autopsies take apart a finished artifact to examine the parts constituting the whole . They take objects that have been packaged , boxed up , and commodified , and open them up to inspection and scrutiny . The dismantling of a product results in its contextualization and creates a design methodology that investigates the ramifications of design decisions . This `` dissection '' opens up the internal workings of products and technologies and , in doing so , asks designers to observe the effects of particular design decisions , their externalities , consequences , and future implications . They may notice that items which are presented as functional ( screws or other fastenings ) serve only an aesthetic role , while other components selected for particular technological capabilities have design consequences that shape the form and function of the object [ 1 ] . App autopsies extend this practice to digital artifacts , opening them up to understand the consequences and concerns of particular technological choices made in their construction . Our work ( http : //appautopsy.com ) implements this analysis with digital dissections inspired by those conducted on products ( and bodies of all kinds ) . While the name implies the inspection of a dead object , the autopsy of the digital more precisely performs dissections on living artifacts ; websites and other applications ; artifacts 16 which are in active use and are therefore still capable of being transformed . This reveals elements of digital design that can not be directly seen , or are intentionally obscured , through the interface . At the centre of this project is a belief in reflective design . Sengers et al . define this approach as one of “ critical reflection. ” A process of “ bringing unconscious aspects of experience to conscious awareness , thereby making them available for conscious choice ” [ 2 ] . Without this critical reflection , they argue , individuals will embrace and maintain attitudes , practices , values and identities without a conscious acceptance or understanding . Our implementation of “ The App Autopsy ” was built to further the ends of this reflective practice . Through a visualisation of the constituent elements of digital applications , it supports a new awareness of the political and cultural choices being made as a result of the use of digital applications . It stands in opposition to an instrumental theory of technology , which would view digital applications as value “ neutral , ” indifferent to the political and economic systems ( such as socialism or capitalism ) which exist in the modern world . Instead , the App Autopsy is used to bolster a critical theory of technology , as developed by Andrew Feenberg [ 3 ] . This theory resembles a substantive theory in rejecting the neutrality of technology , but , rather than place the moral emphasis on technological design , as substantive theory suggests , a critical theory would take a descriptive approach to the technology and determine where and how these technologies - or our relationship to these technologies - can be changed . The App Autopsy is therefore a tool which can be used to transform a critical theory of technology into praxis . It is through this theory that one can begin to delineate a place for values alongside the other technical standards and functional goals of design . App autopsies aid in the descriptive theory of a technology , in an effort to promote critical reflection . To demonstrate the existence of values within technical systems and devices , there was a pragmatic and conscious attempt to integrate values into the design . The App Autopsy was built using the methodology , Values at Play , provided by Mary Flanagan and Helen Nissenbaum , in “ Embodying Values in Technology : Theory and Practice , ” [ 4 ] . This methodology holds that to achieve a technical design which soundly incorporates values , designers must not only be competent with the technology and science , but they must also have a reflective understanding of relevant values and the way in which these values function in the lives of peoples affected by the technical systems in question . Values at Play postulates that conscientious designers must “ juggle ” the relevant dimensions of three interrelated modes of inquiry : the engagement of scientific and technical results , relevant philosophical reflections on values , and empirical investigations of values in relation to individuals and their societies . 2 The App Autopsy The App Autopsy is a tool which can be used to critically reflect on any digital application . When entering the site , the user encounters a screen providing a url prompt . Entering a url into this text box results in an autopsy of a site , visualized as a three dimensional cube comprised of multiple layers . Each layer represents an application or technology that has been used in the construction of the site . The user can analyse these results by choosing from a list of values . The visualizations are then 17 ordered by the coded value . For example , a user concerned about web standards would see those components which conform to WC3 standards in white , and those which do not conform , in magenta . In this way , the App Autopsy makes clear the values latent in the technological construction of the artifact . Those applications normally hidden from view , become visible , allowing the user of our product to assess the state of the applications they use frequently . This inward look at digital applications is critical reflection , “ bringing unconscious aspects of experience to conscious awareness , ” thereby making them available for conscious choice [ 5 ] . The App Autopsy is an attempt to draw attention to the blind spots . The site acts as a perceptual field , but one that is dependent upon the observer , and requires participatory design to expand the value categories used to classify various applications . 2.1 Technological Mode The App Autopsy is structured to be extensible and generic . At a broad level , given a specific url , it extracts the markup rendered and processes it to discover specific technologies . It does this by operating a series rule files that describe regular expressions , heuristic rules , and other techniques for determining the existence of a particular technology . For example , it may determine that the jQuery javascript library exists based on the presence of a specific javascript include , the use of specific jQuery functions throughout other javascript files , or a reference from a mainstream content delivery network . As the rules process , it builds a key-value listing of the technologies and versions of those technologies that are revealed by the process . Once a key-value listing has been built , the system loops through sets of value files that map values to particular technologies . Value file contain additional meta information ( citations , descriptions , etc . ) as well as particular value-ranking pairs . Additional value ranking pairs can be constructed , but the core free and open value set demonstrates the mapping of values to particular technologies . In addition to the value rankings , notes and citations accompany the value mappings in order to allow users to evaluate them . We agree with the suggestion that a design team should consider recent developments in their field of interest on design specifications that might help them in realizing values within the design process [ 6 ] . In the technical mode , a designer reflects upon existing technologies which might realize the technical standards and values the designer is attempting to leverage . The site was built by extending the opensource project WhatWeb , a system that parses web applications to examine individual technological components , and integrates services like geocoding and visualization [ 7 ] . In addition , we merged this information with a system of annotations that would serve to classify each application being parsed . These annotations classify an application based on the presence or absence of certain features . They are themselves extensible , developed in a similar manner to other open source collaborative projects following the format of citation , argument , and value assignment . This process began with values developed from the free and opensource software community , an exemplar value set that can be taken and extended [ 8 ] . Four programs were found which exemplified the functionality required by the App Autopsy : Builtwith , WhoApi , Quarkbase , and WhatWeb [ 9 ] . Each of these sites 18 use algorithms designed to gain back-end information on a digital application through various data sources . Their purpose and often their analysis differs from that required by the App Autopsy , although they are certainly app autopsies of a sort . Builtwith , WhoApi and Quarkbase are programs intended for commercial purposes , and give their users information on the functionality of a site , and its popularity online . WhatWeb provides an opensource scaffolding that is directly extensible to us . We can not only integrate additional services with WhatWeb , we also modify the character of its output , producing a three-dimensional visualization in an architectural metaphor . Each layer signifies a technology that comprises the application located at the url queried . This analogy of a building highlights the aggregate nature of applications , which are composed of many elements built upon one another , and resting atop tangled networks constructed by users and designers . The code used to build an application serves as a blueprint for what they eventually become , each element regulating a range of possible behaviours and experiences online . The construction of a site and the use of one component over others is the realization of one value in the place of another . 2.2 Philosophical Mode The philosophical mode implores designers to address questions about the origin and scope of values relevant to their technical creation . While this mode necessitates a discussion on the contentious debate of the origin of values , this will not be addressed in this work . This section will , however , outline those values which were instructive in the development of the App Autopsy . The values of the site itself were informed by existing work done in the philosophy and history of technology , and in the field of human-computer interaction . Fundamentally , the site presupposes that technologies can have politics and are therefore not value neutral , expanding Langdon Winner to treat this idea as a practice of inspection [ 10 ] . Arguing that one must “ pay attention to the characteristics of technical objects and the meaning of those characteristics , ” Winner has arguably set the stage for product autopsies . By studying the constituent elements of applications , it is possible to determine where meaning and values are produced in seemingly apolitical digital products . Winner also suggests that technological objects should not be removed from their context and should be examined in favour of explanations that seek to expose an “ interplay of social forces. ” The applications studied using the App Autopsy can not therefore be separated from communities which already adhere to a particular set of values . Following from this idea , in performing autopsies using our site , users can parse applications according to an exemplar value set . We selected as an exemplar value set , those that are found in the free and opensource software community . In particular we draw these values from the Debian Constitution and Social Contract which emphasizes freedom , openness , and transparency [ 11 ] . Development of additional value sets can be accomplished by following traditional opensource development . While developers are not able to contribute directly to the value definitions and rankings in app autopsy as hosted , they are able to create their own forks . By observing these forks , we can pull additional value definitions ( or possibly alternative rankings for existing values and technologies ) and merge them into our 19 value definition . These values are extensible . Users are able to develop annotations with different value categories and evaluations of particular technologies ( the justness of a javascript library , for example ) . This approach follows from a principle of technological change [ 12 ] . Technologies built using an open source framework introduce an expectation of participatory and incremental innovation and growth . Postman argues that one must acknowledge that technological change is ecological , not additive , and “ therefore too important to be left entirely in the hands of Bill Gates. ” The participatory requirement of the App Autopsy is founded in this necessity for placing both these determinations of value , and the information informing these decisions , in the hands of the largest amount of individuals possible . This type of organization follows from Yochai Benkler ’ s commons-based peer production ; a model which describes the leveraging of large numbers of individuals who coordinate work on projects , often attempting to evade a hierarchical structural organization [ 13 ] . This socio-economic system of production , both Nissenbaum and Benkler argue , has emerged “ in the digitally networked environment ” and is facilitated by the material and technical infrastructure of the Internet [ 14 ] . In this system , no one owns a free software , project ... [ and there is ] no formal manager who tells different people what they must do so that the project can succeed. ” While this type of system of production is available to all , it does , however , require a degree of computer and web literacy that is not attainable by every individual online . In terms of the App Autopsy , every individual can , in theory , reap the benefits of this system of production , but only those with even a basic knowledge of open-source software development will be able to contribute to the design of the tool . Regardless of the level of technical skill of potential contributors and modifiers , the App Autopsy can be used by any individual to reveal the back-end of applications in a comprehensible format . This practice is intended to address another principle of technological change espoused by Postman : “ [ Tlechnology tends to become mythic ; that is , perceived as part of the natural order of things , and therefore tends to control more of our lives than is good for us. ” Postman ’ s continuation of Barthes ’ idea describes a process wherein objects become naturalized ; technological creations , once developed and laboured over by human hands and minds , become accepted as fixed objects without histories or futures . The technology is then seen as beyond modification or control , and is transformed into a black box which hides the character of its internal workings , making it immune to inspection . Digital applications have gained this mythic status for many users . A lack of literacy in code , or an understanding of the function of various web applications , can have consequences for individuals using these products . For instance , without this understanding individuals use applications that compromise their privacy , unknowingly releasing their data . While this practice is legal , digital applications go to great lengths to minimize the visibility of this practice . Without knowledge of these 20 operations taking place , an individual can neither consent nor object to the practice . The App Autopsy reveals this practice under the assumption that if such operations are made visible , users will be aware their data is being monitored , stored , and even shared , online . The openness provided by the App Autopsy might have the unintended consequences of creating security vulnerabilities for certain websites and web applications , however , with an increased awareness of such vulnerabilities , developers have the opportunity to address the problem . 2.2.1 Value Nomenclature The App Autopsy uses a classification system for digital applications that is influenced by the values the authors themselves hold . The system addresses the challenges for classification systems outlined by Geoffrey C. Bowker and Susan Leigh Star , in “ Sorting Things Out : Classification and its Consequences ” [ 15 ] . The classifications use a consistent citation structure , which uses similar language for each category to identify whether an application ( through its operationalization or implementation ) fulfills the requirements for inclusion or exclusion . The classification is done through an assessment of presence or absence of certain features that gave us the nomenclature positive , neutral and negative . This limited classification system was done to constrain any ambiguity ; either the application has features indicative of a category inclusion , or they do not . They are visible in that the classification is available in the code , and open to inquiry should a user want to use the code to produce their own site with alternative classifications . Evidence must be provided , and the source used for the classification is available to view . As an example , consider Opengraph , Facebook ’ s technology for manipulating and storing the social graph created by their social network . The rankings for Opengraph have been generated by surveying news stories and articles that highlight opinions about Opengraph with regard to our exemplar value set - we look for consensus among multiple sources when possible . For example , we rank it as non-private , it is widely reported to hoard invasive user metadata . We evaluate it as non-webstandard , developed and owned by a commercial entity , and leveraged for profit making . At the same time we rank it as transparent and accessible , because it is well documented , publicly presented , and presents useful capabilities and technology hooks for developers . Each of these rankings is accompanied by a link or a note justifying the process The App Autopsy relies on information acquired through production . The common goal of the project , a record of present state and changes made to digital applications , benefits greatly from repeated inquiries into the changes made to web applications over time . As it stands , the only way to accomplish this would be through multiple instantiations of App Autopsy tools , which address different values drawn from different sets of value annotations . 2.3 Empirical Mode Using the methodology provided by Flanagan , Howe and Nissenbaum , empirical investigations would be required to examine whether our attempt at embodying the 21 values embodied in the App Autopsy has been successful . We did discover , however , that the site can not parse for subdomain information . This will be addressed as we continue the investigation . Empirical investigations with users have not been fully developed . To test whether the site provided additional information not known to users before the use of the site , a survey administered both prior and post-use of the site could be helpful in determining whether the site was successful . While the relevant interest groups have not yet been fully exhausted , we have identified several groups who have a vested interest in performing Application Autopsies . These are : governmental organizations assessing the conformance to web standards , programmers and web application designers , owners of web applications , and lastly , curious individuals online ( ideally all individual impacted by web technology would share this interest ) . The first three categories have a direct participation in digital application design but their roles in this process are frequently quite different . The last category encompasses those affected by design and who influence a digital application through use . This category has been further stratified in terms of technological and non-technological individuals and is more inclusively considered . 3 Conclusion The classification system is one way in which we can innovate in the future . Ideally individuals would be able to create their own systems of classification , and add information to the site without needing the technical skill necessary to fork and develop the value sets through a technological practice . This , however , would require servers that could provide a degree of data protection and privacy that would correspond with the values embedded in the goals of the site itself . Additionally , we hope to be able to store various changes in the design and development of web applications . This feature would be able to track changes made to the code of sites like Facebook , which would highlight the transformations in technology that would have repercussions for categories such as privacy and property . Ideally this would involve caching a site to provide a snapshot of a digital application during a specific period of their development . Lastly would be a modification of the site that would demonstrate any overlapping between the use of specific technologies , between sites . This would be in an effort to examine how different communities of sites ( perhaps with their own social , commercial and political agendas ) form around various technologies . Product Autopsies are performed to introduce a critical theory of technology into practice . The App Autopsy acts as a tool to aid individuals in understanding more about the applications they are using online .. Since the artifact scrutinizes other digital applications , it became necessary throughout the design process to subject the App Autopsy to the same criticisms . Every design decision was evaluated to ensure that we did not violate one of the values that we used to classify other digital applications . While our values did become embodied within the site , we will remain open to scrutiny by those who hold different values from our own . This can be done through modifications of the code provided online . 22 The App Autopsy was developed in an effort to both integrate values in design and showcase the values embedded in other design systems . The site attempts to prevent the closing down of digital technologies , to demonstrate the flexible nature of digital design . Acknowledgments . We would like to thank Helen Nissenbaum for her generous support and feedback on this work . References 4 . Bonanni , L. , Parkes , A. , and Ishii , H. Future Craft : How Digital Media is Transforming Product Design . In CHI '08 extended abstracts on Human factors in computing systems . ( 2008 ) 5 . Sengers , P. , Boehner , K. , David , S. and Kaye , J . “ Reflective Design. ” Culturally Embedded Computing Group . Ithaca , NY : Cornell Information Science , 49-58 . ( 2005 ) 6 . Feenberg , A . Transforming Technology : A Critical Theory Revisted . New York , NY : Oxford University Press . ( 2002 ) 7 . Flanagan , M. , Howe , D. , and Nissenbaum , H. `` Embodying Values in Technology : Theory and Practice . '' Information Technology and Moral Philosophy . Eds . J. van den Hoven and J. Weckert . Cambridge : Cambridge University Press , 322-353 . ( 2008 ) 8 . [ Sengers et . al . ] 9 . [ Flanagan et . al ] 10 . WhatWeb , http : //WhatWeb.com 11 . Constitution for the Debian Project ( v1.4 ) , http : //www.debian.org/devel/constitution ; Debian Manifesto , http : //www . debian . org/doc/manuals/project-history/ap- manifesto.en . html 12 . BuiltWith , http : //builtwith.com ; WhodApi , http : //whoapi.com ; Quarkbase , http : //quarkbase.com ; WhatWeb , http : WhatWeb.com . 13 . Winner , L. `` Do Artifacts have Politics ? '' The Whale and the Reactor . Chicago : The University of Chicago Press , 19-39 . ( 1986 ) 14 . [ The Debian Project ] 15 . Postman , N. `` Five Things We Need to Know About Technological Change . '' Denver , CO ( 1998 ) 16 . Y. Benkler and Nissenbaum , H. `` Commons-Based Peer Production and Virtue. ” Journal of Practical Philosophy . 14 ( 4 ) , 394-419 . ( 2006 ) . 17 . Geoffrey C. Bowker and Susan Leigh Star , in “ Sorting Things Out : Classification and its Consequences , ” ( 1999 ) . 18 . Friedman , B . & Nissenbaum , H. Bias in Computer Systems . ACM Transactions on Information Systems . 14 ( 3 ) , 330-347 . ( 1996 ) 23 Requirements for Reconfigurable Technology : a challenge to Design for Values F. Dechesne , M.J. van den Hoven , M.E . Warnier Department of Technology , Policy and Management , Delft University of Technology , The Netherlands Jaffalaan 5 , 26282 BX Delft The Netherlands Tel . +31-15-2785143 Fax . +31-15-2786439 F.Dechesne @ tudelft.nl , M.J.vandenHoven @ tudelft.nl , M.E.Warnierétudelft.nl Abstract . With the increasing use of information technology for different societal goals , the demand for flexible and multiple-functionality appliances has risen . Making technology reconfigurable could be a way of achieving this . This working paper is written against the background of a large scale research project developing reconfigurable sensors in order to achieve a continuous and affordable infrastructure for both safety and security ( STARS ) . Our role in the project is to explore the ethical challenges reconfigurability raises for sociotechnical systems like sensor networks . We foresee that reconfigurable technology adds an extra challenge to the identification and specification of functional and non- functional requirements for the technology . Keywords : reconfigurability , design for values , sensor networks 1 Introduction : the STARS project This paper is written against the background of a large scale research project in The Netherlands called STARS : Sensor Technology Applied in Reconfigurable Systems . The STARS project is still in its initial phase , and involves both academic and private research partners . The project is motivated by the fact that our current society shows an increasing complexity and associated risks , under the influence of developments like globalization and the growing use and dependence on technology . In response to this , more technology is developed and deployed in order to manage both complexity and risks . Sensors ( like , e.g. , cameras or motion detectors ) are viewed as important 24 sources of information that can be used to protect our society against threats on the one hand , and to help resolve crisis situations on the other . Such sensors are connected in networks , allowing for gathering and analyzing the combined information , and making it accessible to human decision makers . Especially the application area of security has pushed the development of all kinds of sensor technology . The goal of the STARS-project is the development of `` necessary knowledge and technology to be able to build reconfigurable sensors and sensor networks ” [ 14 ] . By making sensors reconfigurable , the project aims to deliver a continuous and affordable infrastructure for societal security , but it also anticipates possible use in other application areas . Reconfigurable parts of sensor networks that will be looked at are antennas , receivers , transmitters , on-chip and off-chip communication . As an example , one may want to be able to transform a sensor network installed in a harbor for security purposes , e.g . to prevent theft or sabotage , into an information system for rescue workers during a fire in the same harbor . The security domain is characterized by the great diversity of threats and the absence of warning time . The creativity of the opponent ensures that the circumstances change continuously and unpredictably so . It is therefore essential to be able to anticipate and respond adequately to new situations . The societal problem is that it takes too long , and it is too expensive , to invest over and over again in new systems to be developed to protect against ever changing threats . Truly successful security technologies should therefore satisfy a number of characteristics : reliable and affordable , sustainable and effective , multi-domain and multi-service . Reconfigurable sensors are developed to have these characteristics . They allow for flexible application , because the functionality enclosed in the system can be altered relatively simply and quickly . In the scenarios that are expected , reconfigurability is used to instantaneously optimize for foreseen situations and the corresponding tasks . In the new , unexpected scenarios , the reconfigurability is used to respond to circumstances that were unforeseeable at the time of the system development , by adapting the functionality of the system to the new situation . With this as motivation , the feature of reconfigurability will be leading in the design and development of the architecture and technologies in the STARS-project . Although the first use cases primarily speak of the police , security- and information services fire brigade as intended users , it is expected that the technology , if successful , will cover a broader application area by a broader range of users . During the project , system concepts and application potential are to be defined and explored . The reconfigurable sensor networks are developed to serve the societal goals of safety and security , but it is not just the technical features of the network that will determine the effect of the technology . The effect will be determined by the way in which the system with its features is embedded in social and societal structures : What data will be gathered and by whom ? Who will handle the data ? How will the data be used ? Who determines the priority of functionalities , if the system is intended to serve different goals ? The aspect of reconfigurability makes these questions even more complex , but also more pressing . The role of the authors of the current paper is to evaluate societal and moral implications of the technology that is developed within the STARS-project . 25 We illustrate these issues in the next section , where we describe a use case from the STARS project . As the project in itself is still in its initial phase , this paper presents an initial exploration of questions we think will be the relevant ones , rather than giving theories and answers . In the rest of the paper , we aim to show that reconfigurable technology adds an extra challenge to the identification and specification of functional and non-functional requirements for the technology . Already , the wide applicability of the technology in society ( logical malleability in Jim Moor ’ s terminology [ 8 ] ) requires that societal and moral values are considered in the application phase , and ideally also already in the design phase . With the flexibility of reconfigurable technology , this requires new tools . A specification language that is both general and specific enough to cover all possible uses is needed . 2 Use Case : Sensor Usage in a Large Mainport The intended application of the reconfigurable sensors and sensor networks is the safety and security domain . A use case for the sensor networks is for example the situation at a mainport : a large port area ( for example , the port of Rotterdam or Shanghai ) . Radar systems are used in large ports to ‘ follow ! the movement of ships . Ship sizes can also be determined by these systems . Such radar systems consist of a number of radar devices , which send their data to a central control center . Here the data is processed to provide a full overview of the whole area . Other sensor data , for example from camera surveillance systems ( CCTV : closed circuit television ) or motion detectors ( around security gates ) is also sent here , providing even more information in case of an incident . Numerous issues around safety and security can arise in a port environment , including fire hazards , drug trafficking , terrorism , people trafficking or transport of hazardous chemicals . During an incident all sensor data can be combined to coordinate emergency services . Reconfigurable sensors can be very useful in such environments , since they can be used for different tasks as the need arises , whereas previously multiple sensor systems were required . Consider , for example , the case where a small plane crashes into the port area . The police might be worried that this is part of an organized terrorist attack , in which case ( part of ) the radar system can be reconfigured to look for other ( low flying ) planes . Information provided by the reconfigured radar system can be very useful in this case , but it also leads to a number of problems . First of all , by reconfiguring the radar system , the 'normal ' radar view of the ships in the harbor is compromised : the spatial resolution will go down , making it harder to distinguish different ship sizes . Part of the harbor may not be visible at all . This might be acceptable in a crisis situation , but it does lead to another issue : Who decides if the radar system may be reconfigured , and under which circumstances ? Is the fire brigade in charge or the police ? Or perhaps the port authorities or the government ? Clear policies need to be defined for this , policies that can become more complex as the sensor systems ’ reconfigurable functionality increases . Although the aim is to be almost instantaneously reconfigurable , initial versions of the technology will be likely 26 to need some processing time for each reconfiguration . This can be crucial in crisis situations : during reconfiguration sensors can not be used , leaving the control center in essence blind to the current situation . This may be acceptable if reconfiguration time is in the range of fractions of seconds , but longer delays may compromise the functionality of the technology . All these issues stem from the same core problem : reconfigurable systems have more functionality than normal systems , but they can not use the added functionality concurrently . One can either search for ships or for low flying planes , not both ( at the same time ) . If different functionalities support different values , who gets to decide which value should be given priority ? 3 What is reconfigurable technology ? Before we head on to discuss ethical and societal issues that we expect to come up in the development of reconfigurable sensor technology , we briefly reflect on the notion of “ reconfigurable technology ” . It turns out this notion requires a deeper analysis . The computer ( the ‘ universal machine ’ ) possibly seems the most obvious example of reconfigurable technology . In his seminal paper “ What is Computer Ethics ? ” [ 8 ] , James Moor refers to the logical malleability of computers as the essence of the revolutionary character of computer technology , from which the need for a separate attention for computer ethics follows : “ The essence of the Computer Revolution is found in the nature of a computer itself . What is revolutionary about computers is logical malleability . Computers are logically malleable in that they can be shaped and molded to do any activity that can be characterized in terms of inputs , outputs , and connecting logical operations . [ ... ] This is all I need to support my argument for the practical importance of computer ethics . In brief , the argument is as follows : The revolutionary feature of computers is their logical malleability . Logical malleability assures the enormous application of computer technology . This will bring about the Computer Revolution . During the Computer Revolution many of our human activities and social institutions will be transformed . These transformations will leave us with policy and conceptual vacuums about how to use computer technology . Such policy and conceptual vacuums are the marks of basic problems within computer ethics . Therefore , computer ethics is a field of substantial practical importance. ” [ 8 ] Here the logical malleability of computers is taken as the central cause of several effects computers will have on society , and from these effects , the need for computer ethics follows . What we would like to explore , is what ethical issues follow from the aspect of reconfigurability in itself ( hence , not from the effects ) in reconfigurable technology . Does reconfigurable technology ask for different types of functional and non-functional requirements ? Do we need to specify meta-requirements to capture requirements on the level of the reconfiguration process ? We think it is important to distinguish flexible functionality from flexible configuration : the relationship between them deserves some more detailed study ( also beyond this paper ) . 27 Literally “ reconfiguration ” means : to modify the configuration , i.e . the arrangement of the parts ( of a system ) . The use of computers has extended functionality of sensor systems already , for example the enhancement of CCTV systems with software that processes faces and compares these to a database with known subjects in order to identify them . In a sense this extension could be described as a reconfiguration of the CCTV system , since the original functionality of the system is altered for a specific purpose . But not every alteration or extension of functionality is necessarily a reconfiguration . In the case of adding computers for information processing in a sensor network , this is not just a rearrangement of existing parts of the system , but adding elements to the system . Furthermore , reconfigurability is not essential for a piece of technology to have multiple functionality : the same piece of technology may have very different functionalities depending on how and with which intention it is used . An example of this is a plane : usually a means of transportation , but can be used as a highly destructive explosive in the hand of terrorists without any adaptations to the configuration . Returning to the concrete background of this paper : what kind of reconfigurability can we expect within the STARS-project ? The ultimate goal of the project is to develop sensors and sensor networks with as much ( potential ) functionality as possible . The project proposes to achieve this by making the hardware reconfigurable , which will involve mainly analogous front-ends ( infrared , radar , etc . ) and digital signal processing . We think the resulting range of range of possible reconfigurations will be rather limited , but as such , this will provide an interesting starting point . The system concepts and architecture have yet to be developed . Even so , methodological questions are raised by making parts of the architecture reconfigurable , such as those concerning testing procedures , software-hardware partitioning and composability ( as pointed out for software architecture in [ 4 ] ) . In our involvement in the STARS-project , we aim to identify specific ethical challenges related to the reconfigurability of technology , although we will also touch upon more general issues of multiple-functionality , with the goal of creating awareness and anticipating these challenges in the research and development phase of the technology . In this process , we will address the question whether design for values for reconfigurability related values asks for a different approach , and how design for values for reconfigurable technology relates to proposed approaches to the ethics of emerging technologies ( like Ethical Technology Assessment [ 11 ] or Anticipatory Technology Ethics [ 2 ) ) . 4 Reconfigurability as a challenge for design for values An important aspect of reconfigurability is that it challenges the type of stable , knowable , unambiguous function ascriptions to artifacts and systems . In that sense , it may ask for an extension of existing theories of technical functions . [ 5 ] This bears on the principle of informed consent . A prerequisite of that principle is a knowable impression of what the system will do under which circumstances . One can argue that this prerequisite is hard to fulfill for many of today ’ s ( socio- technological ) systems , as they are developed for a certain goal , but once in place , 28 easily used for or combined with other functionalities . This is called function creep , a well known example is the use of cameras introduced to implement a road pricing system ( also ) for the detection of stolen cars , or tax evaders . But the issue is even more prominent if the system is intended to be reconfigurable to changing circumstances , and maybe even fit for yet unthought of functionalities . At what level of abstraction can the system 's behaviour be specified for people subject to it , and is that enough of a basis for them to be able to consent or as a basis to justifiedly assume their consent ? The specification of the behaviour of the system requires a sophisticated and complex balancing of the different goals the different functionalities of the technology serves . Combining technology for multiple-functionality into one sensor , adds the restriction that only one functionality at a time can be actually used : as mentioned above , the functionality may not be usable concurrently . This means that more crucially than usual , priorities of the different functionalities must be assigned . This adds an extra dimension to the design process : the specification of priorities . The observations above show that the reconfigurability leads to an increased range of choices that need to be made . These choices address not only practical aspects , but more essentially higher order choices : who will be in control of such ( practical ) choices ? Who will bear responsibility for the different functionalities , or for the system as a whole ? This indicates that the development of policies around reconfigurable systems will bring in new complexities . Such complexity may compromise the expected efficiency of reconfigurability . A fundamental question that should be asked whether the ( physical ) reconfiguration of the technology is in fact essential for the issues we relate to reconfigurability . Without actually reconfiguring the technology , we can already conceive of certain technology to be used for something else . Think of a car or a plane that can be used for terrorist attacks rather than for transportation , or the use of nuclear technology for the development of weapons rather than for the generation of electricity ( dual use ) . Sometimes it just takes another perspective towards the technology in order to enable different functionality . Can we distinguish between ethical issues related to the ( intended ) reconfiguration of technology and ( unintended ) ( re ) perception of the functionality of certain technology ( without being reconfigured ) ? Although the initial use case for the reconfigurable sensor networks is not primarily related to the observation of persons and their behaviour , we deem it useful to look at the ethical issue related to sensor networks like camera surveillance and RFID access control systems . There is extensive literature discussing how sensor networks for observation of individuals and their environment bring up issues concerning privacy and the protection of personal data , e.g . [ 3,12,6,13 ] . Despite the fact that the described use case for the reconfigurable sensor networks does not center around privacy , we expect that the technology may in the future be applied in privacy sensitive ways . But besides that , we argue that central notions from the discussion of privacy may be helpful in the analysis of reconfigurability . Reconfigurability puts the context of use and control of information , captured in notions like ‘ spheres of justice ’ / ‘ spheres of access ’ [ 7,9 ] and ‘ contextual integrity ’ 29 [ 1,10 ] , even more crucially at the heart of the challenge put forward by privacy . For example , Nissenbaum understands privacy in terms of context-relative information norms , and distinguishes norms of appropriateness , and norms of distribution . She defines contexts as “ structured social settings , characterized by canonical activities , roles , relationships , power structures , norms ( or rules ) , and internal values ( goals , ends , purposes ) . ” Most relevant to the framework of Contextual Integrity are the roles , activities , norms and values . [ 10 , p.132-134 ] . For reconfigurable systems there may be different roles , activities , norms and values that need to be combined in the design of one system . How to deal with the composition of these different contexts for one system is a particular challenge . Reconfigurability involves applicability of one system with multiple functionality in possibly distinct contexts . In the case of reconfigurable sensor networks , the challenge will be to formulate requirements that are both general and specific enough to cover each possible use . For example , how to balance privacy issues if the sensor system monitors individuals only in very few of its configurations ? And how to go about changes in this configuration ? Nissenbaum 's framework for Contextual Integrity provides explanation , evaluation and prescription , and thereby contributes to the design process . However , it does not “ support substantive descriptions for general families of technologies ” , and “ the most fruitful assessments take place within particular contexts ” . ( 10 , p.190 ] In the case of reconfigurable systems , the particular context may be underspecified , or only one of a vast number of possible contexts . Therefore , a specific challenge for design for values of reconfigurable technology , like the sensor networks , requires an analysis of the composition and interaction of different contexts . 5 Conclusion Reconfigurability of sensors in networks seems to be an attractive answer to the increasing and unvariably changing demands in the security and crisis management domain , both in terms of economy and of effectivity . In this paper , we have presented an initial exploration of challenges reconfigurability may add in the ethical analysis of technology . In the coming years , we will develop a more thorough analysis of the concept . It will be interesting to see how reconfigurability can be analyzed from the perspective of the literature on function ascriptions and requirements engineering . Is ( physical ) reconfiguration essentially different from reconception of the possible use of a piece of technology ( like in dual use ) ? We believe that a proper analysis and definition of context and spheres will be crucial in the ‘ design for values ’ of such technology , and essential for understanding its effect . References 1 . Ackerman , M. , Darrell , T. , & Weitzner , D. ( 2001 ) . Privacy in context . Human-Computer Interaction , 16 , 167-176 . 30 10 . 11 . 12 . 13 . 14 . Brey , P. ( 2011 ) , Anticipatory Ethics for New and Emerging Technologies , Presidential address at the Society for Philosophy and Technology conference , Denton TX , USA , May 27 , 2011 ( https : //spt201 L.unt.edu/ ) . Chan , H. , & Perrig , A . ( 2003 ) . Security and privacy in sensor networks . EEE Computer , 36 ( 10 ) , 103-105 . Guo , Y . ( 2006 ) . Mapping applications to a coarse-grained reconfigurable architecture . PhD-thesis , University of Twente . Houkes , W. , and P.E . Vermaas ( 2010 ) Technical Functions : On the Use and Design of Artefacts , vol . 1 of Philosophy of Engineering and Technology ( Dordrecht : Springer ) . Hoven , J. v. ( 2008 ) . Information Technology , Privacy , and the Protection of Personal Data . In J. v. Hoven , & J. Weckert ( Eds . ) , Information Technology and Moral Philosophy ( pp . 301-321 ) . Cambridge University Press . Hoven , M. J . ( 1999 ) . Privacy or informational injustice ? In L. Pourcia ( Ed . ) , Ethics and information in the twenty-first century ( pp . 140-150 ) . Purdue University Press . Moore , J . ( 1985 ) . What is computer ethics ? Metaphilosophy , 16 ( 4 ) : 266-275 . Retrieved from _ http : //www.cs.ucdavis.edu/~rogaway/classes/188/spring06/papers/moor.html ( June 16 , 2011 ) Nagenborg , M. ( 2009 ) . Designing spheres of informational justice . Ethics and Information Technology , 11 ( 3 ) , 175-179 . Nissenbaum , H. ( 2010 ) . Privacy in Context . Stanford University Press . Palm , E. & Hansson , S.O . ( 2006 ) , The case for ethical technology assessment ( eT A ) , Technological Forecasting and Social Change , 73 ( 5 ) , 543-558 . Shi , E , & Permg , A . ( 2004 ) . Designing Secure Sensor Networks . Wireless Communications , I1 ( 6 ) , 38-43 . Solove , D. J . ( 2008 ) . Understanding Privacy . Harvard University Press . STARS . ( 2010 , July ) . Project Information . Retrieved from STARS-Project website : http : //starsproject.nl/ 31 32 Approximating user values to preserve privacy — a proposal Sven H . Koch ! , Rumyana Proynova ’ , Barbara Paech * , Thomas Wetter ! 3 Institute of Medical Biometry and Informatics ; { Sven.Koch , Thomas.Wetter } @ med.uni-heidelberg.de , ? Institute of Computer Science , Heidelberg University , Heidelberg , Germany { Proynova , Paech } @ informatik.uni-heidelberg.de 3 Dept . of Biomedical and Health Informatics , U of Washington , Seattle , USA Abstract . Users have different sets of personal values , such as benevolence , self-direction , and tradition . Among other factors , these personal values influence users ’ emotions , preferences , motivations , and ways of performing tasks - and hence , information needs . We sketch a method where , during software development , multiple value-dependent interface variants with different functions are created . When used the first time , personal values of the individual user are identified , and the software presents itself in the variant that best matches these values . In this paper we focus on identifying values when using software the first time . Currently used methods to identify values are work intensive and/or solicit personal user information . A method intended for routine use when a user starts using the interface , should require little effort and not intrude privacy . Instead of probing for user values directly , we propose to approximate users ’ personal values based on the users ’ preferences for work tasks and to neglect other factors influencing preferences . Questionnaires allow efficient data collection , and users have few issues sharing opinions about work . Inasmuch as this indirect querying of user values approximates underlying values , appropriate interfaces can be identified when using the software , Keywords : personal values , elicitation , approximation , privacy , software tailoring , individualized interface 1 Introduction Interfaces which are developed with values in mind are better suited for the user ’ s needs , e.g . [ 1-4 ] . In general , values describe properties of the context and properties of the user . Among contextual values are ethical values , business values , quality properties of the system to be built , values of the system developers , as well as values of teams of users . Amid a user ’ s values are his or her goals , motivation , emotions , preferences , and personal values or beliefs . Personal values or beliefs are the concepts which guide individuals during their life and stay constant over time [ 5S ] e.g . the concepts of benevolence , self-direction , and power [ 6 ] . They are explained in further detail in Section 2 . Users ’ information needs are impacted by their specific personal values , so tailored interfaces might better support individual ways of working . Personal values influence users ’ goals , decisions , motivation , and preferences . Specific values therefore influence the tasks individual users see as essential to reach goals , and which information the individual user considers essential to perform these task . Tailored interfaces could show only relevant data and avoid cluttered displays which try to satisfy all information needs . Consider the following examples of functions dependent on personal values : Imagine a physician whose personal values are predominantly benevolent compared to another physician who is rather guided by power . Both physicians would need to perform a similar set of basic tasks — however , the information they need , the way it is provided and the functions they can perform would differ according to their specific personal value . The benevolent physician may aim to detect a patient ’ s problem before it becomes a threat and may want to plan the least harmful therapy personally . Possibly preferred functions for benevolence include information about the burden of treatment options on the patient and his/her quality of life , and leaving comments to coworkers to ensure continuity of treatment and prevent possible harm . The physician for whom power is essential might in the same situation instead want to delegate the task of treatment to co-workers and/or order procedures the patient needs to follow . Possibly preferred functions for power include adding tasks to others to-do lists and seeing their workloads . However , it is not easy to measure personal values . Approved questionnaires are work intensive and use items that users feel concerned to answer in a work context because they are related to their private lives ( Section 2 ) . Software tailoring based on approximated personal values comes with the benefits of individualized information without the privacy concerns of directly measured values . Therefore , we propose a method to approximate personal values without users ’ privacy concerns . Requirements for a method to approximate values are that it should have a low workload and a low impact on users ’ privacy . After determining user interface ( UI ) variants during development , every user would perform the method once when starting to use the software . Therefore , it should be efficient with many users by requiring low workload on UI practitioners who tailor interfaces to individual users ’ needs . Furthermore , a method should take into account the user ’ s privacy related concerns . If methods don ’ t respect privacy needs , users might plainly refuse to participate . The approximation of personal values should rely on information people are willing to talk about instead of very personal ( “ secret ” ) information . 33 We propose to approximate values through attitudes towards work for situations where it is not feasible to directly measure personal values . Furthermore , we suggest that multiple value dependent interface variants are developed and each user , when using the software , sees the variant appropriate for his or her specific personal values . Our research focuses on constructing a method to approximate the individual personal values of many users . In the following , we first describe what we mean by the user ’ s personal values , and review currently used approaches to elicit user values . In the Section 3 we explain our proposal of a method to approximate user ’ s personal values - exemplified with a case study . In the last section , we discuss possible implications and limitations of the method . 2 Background Personal values describe an individual ’ s basic concepts and beliefs which guide the individual through life . We center our research on the validated personal values theory of Shalom Schwartz [ 6 ] . Schwartz ’ value theory provides us with verified questionnaires for value measurement and specific descriptions of each value concept [ 5 ] . We expect that using this theory will make our research reproducible . Schwartz is one of the leading researchers in psychological analysis of personal values and found that the values of individuals stay constant over time and are present in individuals of different races , nationalities , and social or cultural background . Schwartz ’ personal values theory was verified through broad empirical research in many countries and individuals with a wide range of different demographics . His value system is commonly used and differentiates between ten personal values . Table 1 lists the ten personal values which were determined by Schwartz and short descriptions for each . The Schwartz value system is based on two dimensions : 1 ) focus on the self or not ( self-enhancement vs. self-transcendence ) and 2 ) seeking stability or change ( openness to change vs. conservation ) . The category self- enhancement ( focus on self ) includes the values achievement , power and hedonism , contrasted by the category self-transcendence ( not-self ) with the values universalism and benevolence . The category conservation ( stability ) has the values security , tradition , and conformity , contrasted by the category ( openness to change ) with stimulation , self-direction , and hedonism ( which belongs to two categories ) . Table 2 shows an overview of methods which are currently used or proposed to elicit user values and properties . We included requirements elicitation methods that identify properties of users outside of the very strict definitions of the Schwartz value method because we are interested in properties related to IT . Table 1 . Personal values determined by Schwartz [ 5 , 6 ] and short descriptions for each . Value Description Achievement Personal success through demonstrating competence according to social standards Benevolence Preservation and enhancement of the welfare of people with whom one is in frequent personal contact . Conformity Restriction of actions , inclinations and impulses likely to accept or harm 34 others and violate social norms or standards . Hedonism Pleasure and sensuous gratification to oneself . Power Social status and prestige , control and dominance over people and resources . Security Safety , harmony and stability of society , of relationship , and of self . Self-direction Independent thought and action-choosing , creating , exploring . Stimulation Excitement , novelty and challenge in life . Tradition Respect , commitment and acceptance of the customs and ideas that traditional culture or religion provide the self . Universalism Understanding , appreciation , tolerance and protection for the welfare of all people and for nature . Table 2 . Examples of currently used methods to approximate user values and needs , their estimated impact on privacy , and estimated workload on UJI practitioners who tailor the interface to individual user , in case values for many users have to be determined . Method Impact on users ’ UI Proposed or privacy practitioners used e.g . by workload with many users Ethnographic observation Medium High [ 1 , 4 , 7 , 8 ] User review of scenarios and Low High [ 1 ] storyboards User evaluation of prototypes Low High [ 1 ] Discussing users ’ needs in the Low High [ 4 ] design team Personal informatics Medium High [ 2 ] Interviews Medium High [ 1 , 9 ] Questionnaires High Low [ 5 , 10 ] Dealing with privacy concerns is important to make eliciting of personal values feasible . Our rating about the impact of methods on privacy in Table 2 is based on how much personal information the user needs to reveal and how . During ethnographic observation , participants are followed by an observer who notes e.g . actions and goals . Some participants might feel they are assessed , which could result in a feeling of uneasiness concerning privacy . During user review of scenarios and storyboards , as well as when reviewing prototypes , participants ’ comments and feedback can be used to reveal to what extent the system reflects their values or motivation . If used correctly , these review methods should have a low impact on participants ’ privacy : users only share opinions . If the design team needs to discuss many users ’ needs this results in a high workload . When using personal informatics systems [ 2 ] , participants collect personally relevant information , for the purpose of self-reflection and gaining self-knowledge about their personal values without directly talking to the developers . Interviews are time intensive and dependent on the questions require users to directly reveal private information . Users found filling 35 questionnaire about personal values was difficult [ 10 ] — but researchers workload is low due to automated evaluation . Our assumptions about workload on the UI practitioner in Table 2 distinguish between direct and indirect methods . Methods where direct , time intensive one-to-one contact between UI developer and user is required were assumed to have a high workload when used with many users . Questionnaires , which can be completed without UI practitioner-user contact and which can be evaluated automatically , were assumed to have a low workload . In conclusion , a method which requires a low workload and has a low impact on user ’ s privacy when approximating personal values of many users is currently missing . In the following , we describe our approach to approximate personal values through a low impact — low effort questionnaire presentation . 3 Method proposal Our method to approximate users ’ personal values targets concepts which are influenced by the user ’ s personal values and can be easily obtained from the user . In the following , we describe the method to approximate values based on preferences for work tasks and exemplify it with a case study . 3.1 . Description of our proposed method Values influence behavior indirectly through attitudes . While individuals are seldom aware of their values , they are aware of their attitudes and use them as rationales for decisions [ 11 , 12 ] . As such , attitudes are one of the values-related concepts which can influence users ’ preferences and expectations about software . An attitude can be expressed as a single statement of the type “ I like X ” ( a positive attitude ) or “ I don ’ t like Y ” ( a negative attitude ) . Attitudes are formed , among other factors , based on values . For example , if the value tradition is very strong in a particular individual , there is a high probability that this individual has a positive attitude towards things considered traditional . Users are rather more willing to share their attitude towards work tasks than their personal values . Although the preference for sharing personal information varies from user to user , the willingness or reluctance to reveal personal information depends on the type of information to be shared . During preliminary interviews we found users to be very reluctant to reveal personal information such as personal values . However , they were openly talking about what they liked and what they didn ’ t like about their work and their attitude towards individual tasks . Approximating personal values through attitudes towards work tasks might be feasible without strong privacy concerns but not as accurate as directly measuring values . Figure 1 exemplifies this relationship in a simplified conceptual model . It shows how we plan to approximate personal values based on preferences towards work tasks . Although attitudes towards work tasks are influenced by other factors , 36 such as the nature of tasks or devices a task is performed with , we believe that attitudes allow value approximation . Attitude Work task Personal values a towards category divi .S ! personal-value- work task ° of individual “ n ( attitude user 5 , dependent user towards ) Mn , interface a Figure 1 If during development several personal value specific interface variants were developed , then we could display the appropriate variant to each user — dependent on his/her personal values . Our method proposes to approximate users ’ personal values based on individual attitudes towards ( work ) tasks for situations where privacy concerns prevent direct value measurement . Questionnaires suggest themselves as a method for data collection . They can be employed without personal contact between the users or software engineers and can be automatically evaluated , and are less intrusive or intimidating to users compared to revealing personal information in a one-to-one conversation . We propose to use lists of work tasks , to ask users about their attitudes towards these tasks and to infer their personal values based on value-dependent properties of these tasks . Such task lists can be based on canonical work descriptions . For further streamlining , these tasks can be grouped in work task categories , and questionnaires can be shortened by only asking for tasks that each represent a task category . The correlation between personal values and task preferences would be determined prior to the study based on a reference model with task categories and associated values ( e.g . Table 3 ) which we are currently developing . In the following we explain how we used our method in a case study . 3.2 Pilot study : Approximating personal values of nurses and physicians A pilot study was conducted with a total of seven participants working at two university hospitals in Germany - three physicians and four nurses . The pilot study covered multiple aspects of our research in several parts . In this paper we report the two parts related to value approximation . Our research question was : does our proposed method allow to select tasks or task categories appropriate for routine use ? By routine use we mean that they approximate user values with enough precision to inform provision of user individualized interfaces ? The first part for personal value approximation was a list of users ’ work tasks which were typical for their respective professions . Our task selection included different kinds of tasks such as delegation tasks , decision support tasks , and patient centered tasks ( see Table 3 for examples ) , and was based on medical literature and preliminary observations . Physicians received a questionnaire of 43 physician tasks , 37 and nurses got 45 nursing tasks . For each task , participants indicated their attitude on a Likert scale ranging from 1 ( strongly dislike task ) to 9 ( favorite task ) . Table 3 . Attitudes towards work task categories and associated values as examples . The table shows task categories which correlated with individual users ’ personal values . For each task category example tasks are given , followed by the correlated values with positive or negative correlation . For example , we found that communication tasks were liked by 2 users with the value self-direction , and 1 user with the value stimulation and | with hedonism . Task category Example tasks Personal value ( attitude towards task category ) Communication with Ask for second opinion , self-direction ( likes , 2 ) , co-workers ask for advice stimulation ( likes ) , hedonism ( likes ) Documentation Document patient data , self-direction ( dislikes , 2 } , write a discharge letter benevolence ( dislikes , 2 ) Manual tasks Patient examination , hedonism ( likes ) , benevolence drug administration ( likes ) The second part of the questionnaire consisted of the Schwartz Value Survey [ 6 ] , a standardized instrument for identifying personal values . The survey asked participants to assess the importance of 56 items in their life and values . Items include human properties such as successful , polite , daring , and healthy . Participants rated each item on Likert scales ranging from “ This item is opposed to my personal values ” ... “ very important to my personal values ” . Response rates were 100 % ( physicians ) and from the initially invited six nurses , only four replied ( 67 % ) . We identified task categories in which individual users liked or disliked most tasks . Table 3 shows examples of the findings in our pilot study . Our participants predominantly exhibited the values self-direction , benevolence , hedonism , and stimulation . We found that a positive attitude towards communication tasks correlated with self-direction , stimulation , and hedonism . Documentation tasks showed a negative correlation towards self-direction and benevolence , and liking manual tasks correlated with hedonism and benevolence . 4 Discussion and Conclusion We propose to use the attitudes towards work tasks to approximate personal values . We have applied and evaluated our method in a small scale case study , and found a correlation between attitudes towards some task categories and personal values . Our proposed method is a compromise between workload , accuracy , and the protection of privacy : during pilot interviews , users only took 10 minutes to complete questions about attitudes towards tasks , did not have to reveal very private information , but accuracy might be limited . Therefore , our method might be more feasible in everyday situations than directly measuring values . Limitations of the case study include the sample size being too small in order to identify significant correlations between values and tasks categories . It also was too 38 small to allow conclusions whether the four values found in our subjects are prevailing in healthcare professionals or just a selection artifact . The validity of the questionnaires was not verified ; therefore , our preliminary results might lack reliability . Our ongoing work focuses on the correlation between values , attitudes towards tasks and software requirements [ 13 ] . We aim to create a reference model for the development of personalized value specific software requirements which shows value-task group relationships and value specific software requirements . Developers should be able to use the reference model to identify which type of information would be particularly useful for users with specific personal values . Finally , we plan to investigate the relationship between personal values and specific interface features . Future work will aim to evaluate our proposed method and its accuracy to approximate personal values based on attitudes on a large sample of users . Furthermore , studies could explore the relationship between personal values and other soft issues . If successful , our method will make the detection of personal values easier and contribute a step towards value specific personalized interfaces . References 1 . Thew , S. , Sutcliffe , A. : Value-based requirements engineering . REFSQ 2008 , Barcelona ( 2008 ) 2 . Detweiler , C. , Pommeranz , A. , Jonker , C. : Personal Informatics for Reflection on Personal Values . CHI'l1 workshop on `` Personal Informatics & HCI : Design , Theory , & Social Implications , Toronto ( May 2011 ) 3 . Nissenbaum , H. : Values in technical design . Encyclopedia of Science , Technology and Society , ed . by C. Mitcham , MacMillan , New York ( 2005 ) 4 . Flanagan , M. , Howe , D. , Nissenbaum , H. : Embodying values in technology : Theory and practice . In : Hoven , J.v.d . ( ed . ) Information technology and moral philosophy , pp . 322-353 . Cambridge University Press , Cambridge ( 2008 ) 5 . Schwartz , S. , Melech , G. , Lehmann , A. : Extending the Cross-Cultural Validity of the Theory of Basic Human Values with a Different Method of Measurement . Journal of Cross-Cultural Psychology 32 , 519-542 ( 2001 ) 6 . Schwartz , S . ( ed . ) : Universals in the content and structure of values : Theoretical advances and empirical tests in 20 countries . Academic Press , San Diego ( 1992 ) 7 . Ramos , L , Berry , D.M . : Is emotion relevant to requirements engineering ? Requirements Engineering 10 , 238-242 ( 2005 ) 8 . Ramos , I. , Berry , D.M. , Carvalho , J. : Requirements engineering for organizational transformation . Information and Software Technology 47 , 479-495 ( 2005 ) 9 . Friedman , B. : Social judgments and technological innovation : Adolescents ’ understanding of property , privacy , and electronic information . Computers in Human Behavior 13 , 327-351 ( 1997 ) 10.Pommeranz , A. , Detweiler , C. , Wiggers , P. , Jonker , C.M . : Self-Reflection on Personal Values to support Value-Sensitive Design . In : Conference Self- Reflection on Personal Values to support Value-Sensitive Design . ( Year ) 39 11.Tesser , A. , Schwarz , N . ( eds . ) : Intraindividual process , Vol . 1 . Blackwell publishers , Malden ( 2003 ) 12 . Fishbein , M. : The influence of attitudes on behavior . The Handbook of Attitudes 173 ( 2005 ) 13 . Proynova , R. , Paech , B. , Koch , $ .H. , Wicht , A. , Wetter , T. : Investigating the influence of personal values on requirements for health care information systems . SEHC '11 Proceeding of the 3rd workshop on Software engineering in health care pp . 48-55 . ACM ( 2011 ) 40 Exploring Norm-Critical Design in Online Youth Counseling Sofia Lundmark ! ? , Maria Normark ! ? , Minna Rasinen ! ! Sédertém University , 141 89 Huddinge , Sweden ? Uppsala University Box 256 , 751 05 Uppsala , Sweden 3 Mobile Life Centre , DSV , Forum 100,164 40 Kista , Sweden sofia . lundmark , maria.normark , minna.rasanen @ sh.se Abstract . Although digital artefacts constitute a fundamental part of the contemporary lifestyle it is seldom discussed how the use of such objects affect the way we understand the world . We propose a new concept , norm-critical design , in which the unit of analysis is the interaction design consisting of technology , interaction , images , sounds , text and how they together construct meaning . We argue that there is a need to unpack how digital design embeds norms and to examine how the relationship between norms and design can be critically examined . We base our discussion on studies of online youth counseling . Keywords : norm-critical design , values for youth counseling , values-in-design , critical perspectives in design 1 Introduction A little more than a decade ago the influential book ‘ Sorting Things Out : Classification and Its Consequence ’ came out [ 7 ] . It discussed the way that classification schemes are organized and embedded into objects that gives shape to the categories that people make . An example showed a number of objects that were developed to perform these classifications of races . By embedding the classifications in objects , Bowker and Star argued that the classification became invisible ( in the sense of taken for granted ) in the standards that were developed in the arrangements for upholding a certain classification . Following this argument , we have developed a research interest during the last couple of years that we have termed norm-critical design ( see also [ 15 ] ) . The object of our research is the values and norms in the interface ; the way that functions are making sense to the users and the way that e.g . navigation creates meaning . We have found that the way that the interface design presents itself to the user largely affects the way the user interpret the normative meaning of the activities that go on there . As in the examples in Bowker and Star , the implicit values embedded in the interface design is invisible in the sense that we do not think about how it structures our actions and interpretations of the online setting . Al We argue that interface design create normative understandings that goes beyond the more common analysis in the HCI field of ‘ usability ’ or ‘ aesthetics ’ or ‘ effectivity ’ . By viewing the construction of norms in interface design , we want to continue the corpus of examples that make it possible to critically examine the way that interface design provides a structural pattern that many of us come in contact with daily . By the term norm-critical we mean to investigate the norms and normative assumptions that a certain object generates . Norms refer to the ‘ normal ’ , the implicit expectations of what one should act , feel or experience in a certain situation . The focus of a norm-critical perspective is to make norms that affects and dominates our beliefs and values , more visible . To visualize and shed light on those norms also means to question the norms and to be able to challenge them . In a norm-critical perspective one makes the privileges visible and examine one ’ s own position ( see [ 8 ] ) . The positions and relations to power are something that differ and are changeable within different contexts , For example , discussing norm-critical design quality is both a part of the designer 's agenda ; the intentional norm-critical design of an artefact ; and also as user experience of use , form and relevant values . 2 Theoretical Points of Departure STS research Norms , values and/or meaning making actions are made up of humans and other actors acting in the world . As we see it , the technology is co-constructing norms and values , both in a social context in interaction , and as inhabitants of norms and values . We also view design as a carrier of norms . According to Berg and Lie ( 1995 ) “ artifacts do have gender and gender politics in the sense that they are designed and used in gendered contexts ” [ 5 ] . Technology and digital artefacts are developed and constructed in social and cultural contexts [ 4 ] . This , from a social constructivism perspective that has a focus on how social forces influences the invention of new technologies . Even though , when bringing societal and culture structures into the understanding of the design of technology and digital artefacts/spaces , the process becomes more then the design of the specific artefact/space ( see [ 16 ] , [ 17 ] ) . Technology creates rules and possibilities from the terms of production , which in turn leads to the impact of use , and the possibilities provided to , and created by , the users . This is of importance in relation to norm-critical design processes . Barad ’ s [ 1 ] concept of “ agential intra-actions ” , critize the dualism between human and for example technology . Human action is inseparable from the context of the culture and the technology . Agency is intertwined and something that is created in-between human actions and technological artifacts . The users are often active intentional agents in their inter- and intra-actions within different digital environments and/or arenas , and not at least in relation to the digital technology . Moser [ 13 ] use Haraway ’ s notion of interference to create a bridge between how differences are made , 42 interacted , and come to matter in people ’ s lives and how science , medicine , and technologies are involved and parts in such processes . Interference was used to create a metaphor for critical notions of academic work and it was argued that realities are not given , but rather created in material practices and locations . The practices are to be seen as reflexive , critical and enacted versions of the reality that interfere . “ They are “ in action ” , in the “ belly of the beast ” [ 13 ] . Moser claims that this perspective can show how realities and interpretations emerge and are effects of relations that go beyond the traditional interest of semiotic approaches . This way of exploring materials , practices , technology and artefacts also goes beyond the studies of traditional texts and discourses . The focus is rather how objects , interpretations and social orders are made , emerged and sustained in relation to their materialities and how these come to matter [ 13 ] . This perspective can be a starting point in relation to norm-critical perspectives of design and design processes . Critical perspectives in HCI Critical theory and critical perspectives is often used as term to include a number of terms and fields and has traditionally aimed to understand , explicate , evaluate and critique cultural phenomena [ 6 ] . In many design disciplines a critical frame of reference is present in the interplay between the creative practice and the critical perspectives . Critical approaches have accordingly to some extent been developed in HCI and design research and it has become more important in HCI to become more concerned with critical theory ( see [ 6 ] ) . Some of these critical perspectives are the Value Sensitive Design ( [ 10 ] ; [ 11 ] ; [ 14 ) , Interaction criticism framework ( that is suggested in e.g . [ 2 ] and [ 9 ] ) , research on Reflective and critical HCI ( see [ 6 ] ; [ 9 ] ) or Reflective Design ( see e.g . [ 18 ] ) and research on Aesthetics [ 2 ] . Other interesting critical perspectives on artifacts are perspectives and research by [ 20 ] and by [ 7 ] . Previous research has argued for an expert perspective that critically examines the qualities of the interaction design and the way the design is modelled to fit its context . The purpose of this activity is to contribute to a corpus and knowledge of what is good interaction design . [ 9 ] suggests that there are three programs or concerns for how digital artefacts can be critically examined . 3 . Case studies : online youth counseling The national Swedish web-based youth counselling , umo.se ( umo ) , propose is to make it easier for young people in the ages 13-25 to find relevant , updated and quality assured information about sex , health and relationships . Obviously , this movement from communication with a real person , either face-to-face at the healthcare centre or through telephone services , towards more generic self-diagnosing and information acquirement raises a large number of questions . Besides from different user experiences , there are a number of issues related to power and emancipation as well as the medical consequences . Design in the healthcare genre therefore , we argue , requires a specific rhetoric and/or approach . Responding to the users ’ expectations on trustworthiness and reliable information is guiding the umo design . It is not unexpected that the concept of norm-critical design is highly relevant and studied in 43 the context of healthcare information services , though these are one of the fields that have to deal with questions about equality , emancipation , diversity and empowerment . Umo.se work with this ambition in different ways during the work process of the content and the development of the site . Norms are questioned , discussed and debated through the whole working process with the site and throughout the content of the whole site . Regarding content umo.se use quality assurance processes that involves different examinations ; the external expert fact-reviewers , the umo.se editorial board , the medical director and an editorial board consisting of people representing youth clinics and experts on human rights and discrimination . At the umo editorial board , being critical towards norms means : ¢ Avoid reproducing norms and also question norms and standards . ¢ To show both people and groups of people that can be placed within and outside the norms . This inclusion is intended to be without focusing on problems or discrepancies . ¢ Address differences in conditions for different people or groups where they are relevant . ¢ Always has a human rights perspective . ¢ Actively promote equality through a respectful attitude towards the target group . ¢ To allow other types of sources and knowledge than the traditional scientific ones , such as personal experiences and everyday knowledge to be visible . ¢ Invite users to engage and submit comments and criticism on the content and the design of the site . On the umo site , the content is based on factual information that aims to be visible all through the site and the material . The texts are often short and with everyday language . The information is also visible through images , illustrations , movies and other visuals to include as many users as possible . Text , images and illustrations have a shared design and approach to attract users . The website has a lot of functions where the user can interact with the content , through games , questionnaires , slideshows , moving images , “ Ask Umo ” , etc . The design and layout of the images and illustrations are cartoon-like ; distinct and colourful . These features and ambitions aim to have an inclusive approach . The material should be easy to access and possible to use in several different ways . The website and the material that umo.se provide is also developed to be able to use for different users and in different ways , for example for young people , educators , youth clinics etc . Umo.se has defined five different areas that they especially aim to work with from a norm-critical perspective . The five different areas are : content , information structure and interaction design , external communication , co-operations and the working force . With information structure and interaction design umo aim for prioritizing of subjects , how the users are expected to search and find their way on the site etc . The external communication illustrates whom umo.se chooses to communicate with , in which way , where and how the information is visible . Also co-operations includes who umo.se choose to work with , who they hire for assignments , who ’ s knowledge and who ’ s perspective that is prioritized etc . The staff at umo.se consists of persons who have an awareness about issues like different groups ’ superior power and others lack of it , in order to be able to fulfil the above engagements . Umo.se also have an ambition to show transparency by encouraging users to help developing the site by submitting comments and criticisms about the contents of the site . Reflections on norm-critical design work In our analysis we have explored what design elements that contributes to the message in the design work at umo . We have also analyzed how the elements interplay to create the intended effect . Two important documents are the image policy and the text policy that is used . Quality in these two policies is highly focused on empowerment , equality and emancipation . Understanding what design quality means in this context is closely related to understanding what message the designers/editors want to convey . Drawing on the observations we made during the study at umo.se , we have made an initial organization of the different aspects of norm-critical elements in four categories : Technological Interaction , possibilities and navigation , interplay constraints Experience , values , norms Images and Written sounds , content , animations text Aesthetics Fashion , culture Figure 1 : Unpacking norm-critical design elements It is a rough division of elements but our main point here is that they all constitute and affect the norm-critical design . All four needs to be considered to unpack how normative meaning is embedded . The focus in the design process at umo is on the experience of the web site . The central intention is to design an experience that is value sensitive and norm-critical . In order to design the intended consistent message , umo uses a number of documents that states the requirements and restrictions in the design work . It is not only norm-critical aspects that are stated , there should also be a consistent “ umo-style ” ( colours , fonts , etc. ) . The two policy documents ( text and image policies ) are important . This way of organizing what constitutes the general message is probably inherited from other older media forms . But there are also interaction possibilities and navigation , as well as technological constraints that affect 45 the message . In this sense , texts and images should not be treated in isolation , because it is likely to weaken the intended norm-critical effect . 4 . Conclusions Critical perspectives are emerging in HCI research . Although digital artefacts constitute a fundamental part of the contemporary lifestyle it is seldom discussed how the use of such objects affect the way we understand the world . We propose a new concept , norm-critical design , in which the unit of analysis is the interaction design consisting of technology , interaction , images , sounds , text and how they together construct meaning . We argue that there is a need to unpack how digital design embeds norms and to examine how the relationship between norms and design can be critically examined . Based on our studies of the role of norms in design we argue that ¢ Digital design is not a neutral platform : digital design reformulates norms and power perspectives ; the way that interaction , navigation , text , images , etc . interplay is manifesting norms . ¢ The design/form/gestalt affect the message , shape the understanding and creates normative expectations of how to act and interpret the digital context . 5 . References 1 . Barad , Karen ( 2007 ) Meeting the Universe Halfway : Quantum Physics and the Entanglement of Matter and Meaning . Durham : Duke University Press . 2 . Bardzell , J. , & Bardzell , S. ( 2010 ) “ Interaction Criticism : Three Readings of an Interaction Design , and What they Get Us ” In Interactions , March+April 2010 3 . Bardzell , Shaowen ( 2010 ) “ Feminist HCI : Taking Stock and Outlining an Agenda for Design ” Paper presented in CHI 2010 : HCI For All , April 10-15 , 2010 , Atlanta , GA , USA 4 . Baym , Nancy K. ( 2010 ) Personal Connections in a Digital Age . Polity Press . 5 . Berg , Anne-Jorunn & Lie , Merete ( 1995 ) Feminism and Constructivism : Do Artifacts Have Gender ? Science , Technology , & Human Values , Vol . 20 , No . 3 , Special Issue : Feminist and Constructivist Perspectives on New Technology , ( Summer , 1995 ) , pp . 332-351 6 . Blythe , Mark , Bardzell , Jeffrey , Bardzell , Shaowen , Blackwell , Alan ( 2007 ) “ Critical Issues in Interaction Design ” BCS-HCI '08 Proceedings of the 22nd British HCI Group Annual Conference on People and Computers : Culture , Creativity , Interaction - Volume 2 7 . Bowker , G. , Star , S. L. ( 2000 ) ’ Sorting things out : Classification and Its Consequences ” , The MIT Press . 46 8 . Bromseth , Janne & Dar ) , Frida ( ed . ) ( 2010 ) Normkritisk pedagogik . Makt larande och strategier for f6randring . Uppsala : Centrum for genusvetenskap . 9 . Dourish , P. ( 2007 ) “ Seeing Like an Interface ” , Paper presented at OzCHI 2007 , Adelaide , Australia 10 . Friedman , B . ( 1996 ) Value-Sensitive Design In Interactions , Vol 3 Issue 6 11 . Le Dantec , C. A. , Poole , E.S . & Wyche , S. P. ( 2009 ) Values as Lived Experience : Evolving Value Sensitive Design in Support of Value Discovery . In the proceedings of CHI 2009 12 . Lundmark , Sofia & Normark , Maria ( work in progress ) “ Digital Arenas for Intra- Active Performances : On doing Gender Online ” 13.Moser , Ingunn ( 2006 ) * Sociotechnical Practices and Difference : On the Interferences Between Disability , Gender and Class ” In : Science , Technology & Human Values , Sep 2006 ; vol . 31 : pp . 537 - 564 14 . Nathan , L. P. , Friedman , B. , Klasnja , P. , Kane , S. K. , Miller , J. K. ( 2008 ) Envisioning Systemic Effects on Persons and Society Throughout Interactive System Design . In the proceedings of DIS 2008 , Cape Town , South Africa . 15.Normark , Maria & Lundmark , Sofia ( 2011 ; work-in-progress ) “ Experiences of Norm-Critical Design ” 16 . Satchell , Christine ( 2008 ) Cultural Theory and Design : Identifying Trends by Looking at the Action in the Periphery ” In : Interactions November + December 2008 17.Sefyrin , Johanna ( 2010 ) “ Entanglements of Participation , Gender , Power and Knowledge in IT Design ” Proceedings of the 11th Biennial Participatory Design Conference ACM New York , NY , USA ©2010 18 . Sengers , P. , Boehner , K. , David , S. , Kaye , J . ( 2005 ) ” Reflective Design ” Paper presented at the Critical Computing Conference , Aarhus , Denmark 19 . Stokoe , Elisabeth ( 2006 ) ” Analyzing gender categories in action : Feminism , etnomethodology and membership categorization analysis ” . In : Sociological Review , 54 ( 3 ) : 467-494 20.Suchman , Lucy ( 2007 ) Human-Machine Reconfigurations Plans and Situated Actions , 2nd Edition . Cambridge : University Press 47 Designing and Evaluating for Trust : A Perspective from the New Practitioners Aisling Ann O ’ Kane ' , Christian Detweiler * , Alina Pommeranz ? ! Royal Institute of Technology , Forum 105 , 164 40 Kista , Sweden aisling @ kth.se ? Delft Technical University , Mekelweg 4 , 2628 CD Delft , The Netherlands . { c.deweiler , a.pommeranz } @ tudelft.nl Abstract . Trust as a factor in the design of interactive technologies is a relatively new research subject , and this paper provides the perspective from new interaction designers and developers on their views and experience with the use of trust in the design and evaluation of technology . A survey was sent out and answered by participants in their early careers and education as interaction designers and developers about designing and evaluating trust in technology . The results show that overall , the new practitioners queried believed that designing for trust is important , but in their experience it is not accounted for adequately in practice . The survey also showed that qualitative methods were the most popular to identify trust issues in new technology , but perhaps the concept of trust as used for the design of interactive systems is still very new . 1 Introduction There is an emerging trend in Human Computer Interaction ( HCI ) and Human Factors Engineering ( HFE ) research to accept that new complex systems will never be perfect . In the HCI community , researchers such as Stewart and Williams [ 1 ] believe that the trend towards domestication and user-led creation of technologies originates from the unlikelihood that designers can entirely match user needs . In addition , new technologies are becoming more complex in the HFE domain , not allowing for comprehensive testing of all components particularly for finding interaction issues according to Parasuraman [ 2 ] . Although designers can strive for perfection and engineers try to design for complete reliability , “ there will always be a set of conditions under which the automation will reach an incorrect decision ” [ 2 , p. 293 ] . Trust in technology is important not only for system efficiency and user experience , but designing for trust comes with ethical concerns for designers as well . These are important considerations for the design of interactive systems , regardless of the type of system . According to Lee and See , trust has been linked to people ’ s reliance and adoption of technology and “ trust plays a critical role in people ’ s ability to accommodate the cognitive complexity and uncertainty that accompanies the move away from highly structured organizations and simple technology ” [ 3 , p. 52 ] . 48 As the study of trust in relation to technology is a new trend , it is of interest to see how new practitioners of interaction design view the importance of user trust in interactive technology and how they evaluate for trust issues with technology . This paper gives background on the research involving trust in technology , details the survey filled out by new practitioners , presents the results and analysis of the responses , and provides some discussion around trust in interactive technology design . 2 Background In the HFE domain , Lee and See 's [ 3 ] oft cited “ Trust in Automation : Designing for Appropriate Reliance ” presents substantial evidence pointing to the connection between trust and people ’ s reliance on technology . They also suggest the similarities between the factors that influence both human-human and human-automation relationships , and they define trust , a social psychological concept , as an attitude that an agent will help achieve a person 's goals , and that agent could be the automation . It is a very important concept when related to automation as it influences their adoption and reliance on it : “ people tend to rely on automation they trust and tend to reject automation they do not ” [ 3 , p. 51 ] . Corritore [ 4 ] argues that in order to be trusted , computers or technology do not need to be shown as moral agents capable of acting with reference to right and wrong , but rather being portrayed as social actors will suffice . People can enter into relationships with technology and respond to them according to rules that apply in trusting social relationships , as technology has a social presence . In the HCI domain , Experience-Oriented and Value Sensitive Design are emerging trends . To design for experience is important for the success of the design , as it needs to be useful in a person 's life and McCarthy and Wright [ 5 ] stress that feelings , cultures and values must be designed for . This view aligns with Value Sensitive Design , a framework where the resulting technology accounts for human values in a principled and comprehensive manner [ 7 ] . Friedman , Kahn , and Borning [ 6 ] in their VSD overview conclude trust “ refers to expectations that exist between people who can experience good will , extend good will toward others , feel vulnerable , and experience betrayal ” [ p. 17 ] . The methodology for exploring human values such as trust through VSD consists of conceptual , empirical , and technical investigations that are performed iteratively and integrated throughout the design process . Friedman , Kahn , and Borning caution the ethics involves in this type of design because “ unlike with people with whom we can disagree about values , we can not easily negotiate with the technology . Although inattention to moral values in any enterprise is disturbing , it is particularly so in the design of computer technology ” [ p. 21 ] . Beyond HCI and HFE , research on trust can be found in a variety of literature , spanning the fields of philosophy , sociology , psychology , management , marketing , ergonomics , industrial psychology and electronic commerce [ 4 ] . Looking at the variety of fields , it is no surprise that “ as a result of both the range of disciplinary lenses used to study trust and the inherent ambiguity of the trust construct , there is currently a confusing assortment of conceptual perspectives on trust ” [ 8 , p. 143 ] . In 49 summary , trust involves aspects of expectation , vulnerability , and risk regarding the likelihood of a favourable response , but this is not easily articulated . Trust is an attitude towards something and that experience is something that can be hard to describe , let alone design for . Although definitions of trust can vary significantly between disciplines , and between people in general , the emerging trends in HCI and HFE research show the importance of trust in technology and this research should influence the new generation of interaction designers and developers . Given these new trends in trust research from the HCI and HFE domains , it is of interest to see how new practitioners view the importance of trust in the design of technology and how they identify trust issues through different evaluation strategies . 2 Method A Google Docs form was piloted with 6 test users before the link to the survey was sent through Facebook to 57 personal contacts known to have experience in the HFE or HCI domain in Canada , Sweden , and the Netherlands . The message introduced the survey as a way to gain perspective on design practices around trust , and invited those who had experience as interaction designers or developers to fill it out and spread it to their respective interaction design networks . Although the use of personal contacts and introducing the survey as a means to investigate designing for trust introduced bias into the results as personal relationships and intrinsic interest in the topic of trust would effect response rate , the survey was merely a means of probing practices of new HCI and HFE practitioners so the results were not meant to be statistically significant . The aim of the survey was to compare new practitioners ’ perceived importance of trust versus their actual experience of accounting for trust in interaction design , and also to compare the popularity of different evaluation techniques for finding trust issues . The first two statements aim to shed light on if the participants have found trust issues to be important in their past work experience and if they believe that user trust is important . The third and forth statements aim to shed light on if trust issues have been raised in their design experience and if they believe that trust should be brought into the design process . The last three questions aim to shed light on which evaluation methodologies are the most popular for finding trust issues . These statements were piloted with 6 participants and the language was modified slightly before the survey was sent to the large sample . The first seven statements were based on participants ’ level of agreement on a seven point Likert scale which ranged from low agreement 1 ( not at all ’ ) to high agreement 7 ( ‘ very much ’ ) . The last item was an open ended question which welcomed general comments on the design and evaluation of trust . In addition , further statements on the connections between affective experience and trust were queried , but the above statements on designing and evaluating for trust are the focus of this paper . 50 4 Results and Analysis Of the 57 new practitioners contacted and not including the six test pilots of the survey , 20 participants ( 14 male ) responded . As listed in Table 1 below , the average age was just under 26.5 ( median = 26 , mode = 26 ) with respondents ranging from 24 to 32 and their self-identified nationalities showed 11 of the participants identified themselves as from Europe , 5 were from Asia , and 3 were from North America . With regards to education , 7 had achieved their Bachelor 's degree , 10 had received a Master ’ s degree , and 3 were at a Post-Graduate level . Regarding work experience , the average experience obtained was just over 3.2 years ( median = 3 , mode = 3 ) . Although they split on whether they considered themselves a technical designer ( 9 participants ) or an interaction designer ( 10 participants ) with one business analyst , their descriptions of a typical role they would play in a project showed that most had experience in various aspects of technology design . When asked about a typical design projects they were involved in , Human Factors Engineering and Human Computer Interaction domains were mentioned with roles ranging from interaction design research to nuclear safety consulting . Table 1 . Demographic information for the surveyed participants Gender | Age Nationality Education Experience PI | Male 27 | German Bachelor Interaction Design P2 | Female 25 | Kosovar Albanian Master Technical Design P3 | Male 24 | Pakistani Master Interaction Design P4 | Male 28 | Mexican Master Technical Design P5 | Female 24|US . Bachelor Interaction Design P6 | Male 26 | Greek Bachelor Technical Design P7 | Male 25 | Italian Master Technical Design P8 | Female 28 | Iranian Master Interaction Design P9 | Female 26 | Greek Master Technical Design P10 | Female 28 | Korean Bachelor Interaction Design Pil | Male 26 | Canadian Bachelor Technical Design P12 | Male 32 | Swedish Master Technical Design P13 | Male 25 | Bulgarian Master Technical Design P14 | Male 25 | Turkish Master Technical Design P15 | Male 26 | Greek Bachelor Interaction Design P16 | Male 25 | Belgian Master Interaction Design P17 | Female 28 | Nepalese Post-Grad Interaction Design P18 | Male 28 | Greek Post-Grad Interaction Design P19 | Male 26 | Canadian-Chinese Bachelor Business Analyst P20 | Male 27 | Spanish Post-Grad Interaction Design Although statistical analysis of a small sample size with a biased response rate will not be very accurate , Wilcoxon Signed-Rank Tests were conducted to show any statistical differences between the statements . This analysis showed significant statistical differences between S1 and S2 ( Z=-3.220 , P=0.001 ) , between S3 and S4 ( Z=-3.845 , P=0.000 ) , between S5 and S6 ( Z=-2.506 , P=0.012 ) , and between S6 and S7 ( Z=-2.209 , P=0.027 ) . 51 Table 2 . Statement agreement averages and standard deviations Statement Mean | Std Dev Sl . In my past work experience , user trust issues have influenced user | 4.85 1.496 acceptance of the design . 82 . I believe user trust in the system is a crucial part of its acceptance . 6.00 1.076 83 . In my past work experience , user trust is discussed and accounted forin | 3.90 1.373 the design process . S4 . Ideally , user trust in the system should be discussed and accounted for | 6.10 | 0.788 during the design process . S5 . In my past work experience , personally testing the system or having the | 4.55 1468 design team test the system has pinpointed issues with trust in the design . S6 . In my past work experience , having users test the system and | 5.55 1.638 conducting interviews , observations , and other qualitative measures have pinpointed issues with trust in the design . 87 . In my past work experience , having users test the system and collecting | 4.70 1.625 error rates , questionnaires , and other quantitative measures have pinpointed issues with trust in the design . The first four statements ’ averages point to the differences between the participants ’ opinions on the importance of trust in the design of interactive systems versus their past work experience as interaction designers and developers . Although these new practitioners believe user trust is a crucial part of interactive technology 's acceptance ( S2 ) , fewer have seen the result of this in practice ( S1 ) . Also , the participants believed that user trust ideally should be accounted for and discussed ( S4 ) , but found that in their past work experience it was not as highly regarded during the design process ( $ 3 ) . P12 works in software design and implementation and explains that “ 'Trust ' has never been explicitly addressed in any work I 've done before , neither by me or others ” . P7 explains his experience in web design as such : “ In my experience there has n't been as much attention on user 's trust as on user 's satisfaction [ ... ] More attention and stress on trust might and should be put in other areas , which for instance require a more complicated and [ thorough ] design process , or a closer user interaction , etc ” . There is a high positive correlation ( 0.683 ) between the participants who agreed with the two belief questions ( S2 and S4 ) about trust 's importance in user acceptance of technology and its importance in the design process for interactive technology . The statements about evaluation methods used in the participants ’ design experiences ( S5 , $ 6 , and $ 7 ) did not show strong results , but did point to qualitative methods as being the most popular to test trust issues . PS mentions that she tends to use qualitative methods , but “ Theoretically , I think experts can do a decent job of finding trust issues if they have a lot of experience in designing certain systems . Choice of users is also very influential , because some are more adept with technology than others . ( So a perceptive expert review could give more than a tech-savvy user. ) ” . Many participants chose the neutral level of agreement , indicating no agreement nor disagreement . This could be caused by the lack of attention on trust during the design process mentioned above , and therefore they did not have experience with using any evaluation methods for finding trust issues . 52 HS : 4.85 +1.496 __| O82 : 6+1.076 Os3 : 3.9 # 1.373_____ { } ____ . ESS : 4,55 1.468 —_ = — O86 : 5,55 +1.638 OS7 : 4.7 41.625 1 2 3 4 5 6 7 “ not at all '' `` very much ” Fig . 1 . Statement averages shown graphically with error bars representing standard deviation . The neutral level of agreement to the survey statements by participants may have also be caused by the ambiguity of the trust construct itself . In the design of this survey , no definitions of trust were made nor was there any reference to trust literature for participants that have not been exposed to this research . P12 made reference to this lack of direction in the survey : “ Before taking this [ survey ] , there should probably have been a definition of what 'trust ' and ‘ user trust ' etc is , my feeling for what it is does n't really feel like it fits in the questions above ” . P13 also suggested that the design of the survey should have included definitions of trust . 5 Discussion Despite the lack of experience in designing for trust , participants generally agreed that trust is an important concept in interaction design and development . Although many of the participants may not have thought about trust as related to the way users accept the technology they design , they have a general concept that it should be accounted for in the design process . These results perhaps do not point to HCI and HFE trust literature filtering down to the new practitioners , but could point to a general understanding of trust as a social issue that effects technology that has a social presence , as per Corritore [ 4 ] mentioned above . The participants could have been keeping the “ enduring human value of trust ” [ 7 , p. 40 ] in their minds during the design processes that they have been involved with without explicitly mentioning the term trust : essentially conducting value conscious design , without knowing or using the framework of Value Sensitive Design to describe their activities . 53 The lack of experience evaluating for trust is clear from the results of this survey . But even with the very neutral results of the evaluation statements , the participants still indicated that qualitative methods of user evaluation were the most popular for potentially identifying trust issues with the design . Perhaps because of the lack of experience with using the word trust explicitly during their experiences in design , they may have been evaluating for issues with user trust in their system without actually calling it such . Much like evaluation follows design in the interactive technology design process , perhaps evaluating for trust will follow a trend towards designing for trust . The word trust is something that is basically understood by anyone , but is very hard to define for everyone . Trust is a hard concept to define and definitions not only vary between disciplines , but also between people . This is apparent in the results of this survey about designing and evaluating for trust in the interaction design process through the neutral results as well as feedback about the survey . This perhaps points to trust not being brought up in these new practitioners ’ education or practical experience . This might be the result of the recent trust research in the HCI and HFE disciplines not reaching them yet in education or experience , or perhaps designing for trust has not been prioritized . 6 Conclusion The results of this survey show that new practitioners of interaction design and development believe that user trust is an important concept to discuss and include in the design process , but they have not seen this type of focus on user trust in their experience . The neutral answers to questions point to this lack of experience in designing and evaluating for trust , and therefore lack of focus on designing for trust in their education and professional experience . Their neutral answers also show the new practitioners were unsure of what was meant by “ trust ” or “ user trust ” , perhaps because they have never experienced these words being linked to design or technology , but rather human relationships . Although this survey shows that there is not a lot of familiarity with designing and evaluating for trust among the new practitioners , the results show the potential for a shift towards accounting for trust in future design processes of interactive systems . As technologies become more and more complex , the relationships between these technologies and their users will change . The complexities seen in autonomous and adaptive systems will push our relationships with these technologies closer to social human-human relationships , and just as human relationships are not perfect , technology will not be perfect . It is up to designers from all fields to account for user trust in an ethical manner , balancing designing to promote trust without engendering over trust in a system . Trust is an important concept when it comes to the adoption and reliance on technology , and even one breach of trust can highly influence user perception of that technology . It will become increasingly important to account for trust in the design process of interactive systems and this is seen in recent research in both the HCI and HFE domains . As this survey shows , the existing research on trust from both the HCI 54 and HFE fields trickling down to interaction design education and professional practice is too slow . Design for trust should be emphasized in interaction designers ’ education and work experience , and frameworks such as Value Sensitive Design and other methods that take trust into account should be further disseminated in both the HCI and HFE communities . References = . Stewart , J. , Williams R. : “ The Wrong Trousers ? Beyond the Design Fallacy : Social Learning and the User ” . In : User involvement in innovation processes . Strategies and limitations from a socio-technical perspective . Profil- Verlag , Munich ( 2005 ) . 2 . Parasuraman , R. , Sheridan , T.B. , Wickens , C.D . : A model for types and levels of human interaction with automation . In : IEEE Transactions on Systems , Man and Cybernetics , Part A : Systems and Humans , vol . 30 , no . 3 , pp . 286-297 ( 2000 ) . 3 . Lee , |.D. , See , K.A . : Trust in Automation : Designing for Appropriate Reliance . In : Human Factors : The Journal of the Human Factors and Ergonomics Society , vol . 46 , no . 1 , pp . 50 ( 2004 ) . 4 . Corritore , C.L. , Kracher , B. , Wiedenbeck , $ . : On-line trust : concepts , evolving themes , a model . In : International Journal of Human-Computer Studies , vol . 58 , no . 6 , pp . 737-758 ( 2003 ) . . McCarthy , J. , Wright , P. : Technology as Experience . The MIT Press , Cambridge , ( 2004 ) . 6 . Friedman , B. , Khan Jr , P.H. , Borning , A. : Value Sensitive Design and Information Systems . In : Human-Computer Interaction in Management Information Systems : Foundations , vol . 6 , pp . 348-372 ( 2006 ) . 7 . Friedman , B. , Khan Jr , P.H. , Howe , D.C. : Trust Online . In : Communications of the ACM , vol . 43 , no . 12 , pp . 34-40 ( 2000 ) . 8 . Zaheer , A .. McEvily , B. Perrone , V. : Does trust matter ? Exploring the effects of interorganizational and interpersonal trust on performance . In : Organization Science , vol . 9 , no . 2 , pp . 141-159 ( 1998 ) . wn 55 Experiencing mobility data Pedro Sanches ’ , Markus Bylund ' ISICS , Box 1263 , SE-164 29 Kista , Sweden { sanches , bylund } @ sics.se Abstract . Mobility data , collected during normal functioning of mobile networks , is to most phone users an abstract and invisible entity . In this position paper , we describe our method based on research through design , for involving users when designing with that intangible data . Our goal is to explore the design space of applications that can emerge if this data is made public and engage users in a process of grounded discovery of societal and ethical consequences . Keywords : Probe , research through design , mobility data , tracking 1 Introduction Location based services are increasingly common in today ’ s developed societies . Thousands of smartphone applications take advantage of the users ’ location data to recommend restaurants , forecast traffic congestions , or locate friends . Existing popular location based social networks , such as Gowalla , Foursquare and Facebook Places , use a “ check-in ” system , that allows users to tag places where they are at the moment , and share it with groups of friends . As more people get access to Internet through their phones , the amount of data collected in these handsets will likely increase rapidly in the near future . But even before access to Internet through cell phones , handsets already had to communicate with nearby cell towers to make the telephony service possible . At the moment , there is a wealth of mobility data safely stored behind the firewalls of each cell phone provider , for each customer . Every time the phone is switched on , the nearest cell tower is logged in the provider ’ s data center . Also , each phone is requested by the protocol to update their location in the network at a set time interval , or whenever it changes a pre-defined location area . Whenever a call is active , the network knows exactly which cell tower is to take responsibility for that call , in order to provide roaming — otherwise , it would not be possible to place a call while on the move . The data generated in the network is , in most cases , not being stored for anything else than for operational purposes . Recently , however , operators started to realize the potential of the data they have been storing . The Japanese Docomo has recently announced a project [ 3 ] where it would use aggregated mobility data from their cell phone customers in Tokyo for purposes of urban planning and earthquake 56 preparation . Also , companies like SkyHook [ 15 ] have started their own mobility mining projects , relying on their own sets of anonymized data , for research and marketing purposes . We are at the brink of a major shift in how communication mobility data is handled . The quality of the first systems making use of data of this kind will likely drive public acceptance of future systems and influence restrictions and legislations on how this data is to be used — see the recent case of Apple secretly storing a positioning log file in the device of each user and how will that likely influence laws dealing with positioning data [ 2 ] . At the moment , there is an open design space for systems of this kind and we , as designers of new technology , have the opportunity to map the ethical and societal consequences of using this data , engage users in ideation and co-creation of new systems and services and negotiate relationships between stakeholders . Privacy and more Location privacy has been appointed as one of the future main concerns for law and policy makers . Especially in the case of mobile network data , where the data already exists and is heavily regulated , there will be a need for new laws if this data is to be released for a purpose that was not originally intended for . There is a concern that disclosing location to strangers and third parties , especially if combined with diverse other sources of personal information , can pose a threat risk for citizens , consumers and society as a whole because of its implications for security , personal integrity and freedom . But privacy is far from a simple concept and there are several stances one can take . The surveillance model , present in Foucault ’ s work [ 17 ] , has been the most dominant discourse about privacy in the new media field . It is very useful in describing how power can be exerted over a subject under a constant state of observation . The observed subject internalizes the relentless surveillance by a hidden observer , ending up reducing herself as a political entity , with reduced free action . This model has produced many dystopian visions of future society . One of the most notable is Dobson and Fisher ’ s “ geoslavery ” concept [ 18 ] , which describes a sophisticated form of slavery where a master can track the whereabouts of a slave using current state-of- the-art positioning technology . As the surveillance model tends to assign a negative connotation to all data gathering activities , Agres has proposed another model , the capture model [ 23 ] . Unlike the surveillance model which assumes , at its extreme , a centralized all-knowing entity , the capture model contributes with a more dynamic view on the dialogue between development of new technology and its acceptance by society . It acknowledges that distributed computer systems still potentially have the capability of establishing a regime of total visibility over human activities but that does not need to be viewed as utopian or anti-utopian . The capture model is more in line with the recent trend of wearable sensors and the rise of self-monitoring tools [ 7 ] as well as tools for parental 57 monitoring over their children . As surveillance technology is developed , and as it is incorporated and accepted into our everyday lives , it slowly changes social norms and people adapt — cope or react - to those systems . Besides privacy of location data , one can have other ethical concerns on the use and application of network mobility data . Simply by having a crude idea of how a large group of individuals move - without necessarily invading personal privacy by getting to the identity of the individuals — one could potentially enable more effective exertion of crowd control , if the data was to be used for that purpose [ 18 ] . Also , since public infrastructure planning is one of the possible applications of this information — as in Docomo ’ s project - one must also consider how the system can introduce bias on that planning , by disregarding users who have chosen to opt out of the data collection , or simply were given no means to participate in it . Our goal is to contribute to the ongoing dialogue between social norms and introduction of new technology . In the case we describe in this paper , we want to discuss with mobile phone users about the possibilities and consequences of using network mobility data . However , we are left with a problem of engaging users . A generalized dystopic surveillance critique makes the current public debate about privacy , or the limits for what is right or wrong in respect to data , quite polarized . Typically it boils down to either “ if you have nothing to hide you have nothing to fear ” or “ the rapid development in information or communicating technology is creating an Orwellian society ” . We argue that the debate is in urgent need of more nuances in order to guide policy makers and designers of new technology . For that , we need methods and tools to engage users in novel ways . Our stance on surveillance technology and pervasive data collection is , rather than critical , exploratory . Our interest is to define ethical limits and opportunities for design of new systems or services that might use mobile network data in the near future . 2 Engaging users with the pervasive data collection landscape The first problem with engaging users with the mobile network data is that this data is already being collected invisibly in the existing infrastructure of mobile network providers . This invisibility of the infrastructure may cause problems with users understanding its complexity and appropriating it , as pointed by Chalmers [ 10 ] , which can in turn limit the responses and the engagement of the users when confronted with it . Added to this is the commonly observed mismatch between a high level of moral concern with privacy stated by users in polls , and the actual measures taken by users to ensure and protect their personal data — a phenomenon known as privacy paradox [ 19 ] . For these reasons , in order to obtain rich and grounded feedback from users , we have opted not to do any polls , questionnaires or scenarios and instead adopt a research through design approach , where the research will mainly be driven by design artifacts . 58 Zimmerman introduced research through design [ 20 ] as an approach that follows a process of design inquiry — i.e . designing artifacts - where the goal is production of knowledge , rather than obtaining commercially successful products . In his words , the goal is to : “ \\.make prototypes , products , and models to codify their understanding of a particular situation and to provide a concrete framing of the problem [ ... ] Design researchers can explore new materials and actively participate in intentionally constructing the future , in the form of disciplined imagination , instead of limiting their research to an analysis of the present and the past. ” [ 20 ] In the case presented here , our goal is to bring up the mobility data into the attention of the users , making them experience it , rather than conceptualizing it as an abstract entity stored away in a distant database . As such , we will build on our own previous work [ 9,16 ] where we have developed systems intended to provoke users into reflecting on the consequences of technology . We are inspired by the work of Paulos with sustainability [ 6 ] , where he and his team have designed critical artifacts that enable users to hold energy in their hands — such as a Light Jar , that stores solar light and releases it as a glowing light when the lid is open — in order to explore how making energy tangible , visible and limited would change would change users ’ attitudes towards it . Also inspiring is the work of Petra Sundstrom [ 5 ] with an exploration of the physical properties of intangible digital material — such as the Bluetooth protocol . Sundstrém ’ s method allows multi-disciplinary design teams to get acquainted with properties of a material by engaging playfully with artifacts designed to expose those properties . Likewise , the prototyping approach of Lim [ 8 ] puts do-it- yourself user friendly sensor kits in the homes of users and lets them explore the properties and potential of ubiquitous computing , allowing users to design their own systems at home by combining sensors . 3 Artifacts Our approach to research through design will make use of two kinds of artifacts : 1 ) a package of open-ended materials called Cultural Probe [ 21 ] and 2 ) our artifact for mobility data . Cultural Probes consists of packages of various objects such as disposable cameras , maps , postcards , diaries and scrapbooks . Users are asked to record specific events , feelings or interactions with their environment , anonymously . Included in the package are sometimes ambiguous instructions such as “ photograph the spiritual center of your home ” . The purpose is to get to know better the users ’ context and culture , rather than look for solutions for specific needs . Designers then interpret the probe returns and use those insights to create further design artifacts , in a manner of conversation with the users . For this application we are interested in getting to know how users experience their own travel habits . The way we will use the results is similar to the way the original creators intended , i.e . as inspiration for the design of the artifact for mobility data . 59 Our probe might then include instructions such as “ put an X on the most public place you usually frequent on a weekday ” . Our interpretation of the probe results will be crucial when designing the mobility data artifact . Mobility data artifact We have been previously exploring the properties of network and terminal positioning data , in an attempt to determine the technological constraints that this kind of data poses . Some of our work is publicly available [ 14 ] . There are many methods to estimate the location of the user within the network . The accuracy of the location information varies greatly based on which method is used to estimate the location of the user . It depends on the positioning method used , the layout of the network , and the surroundings of the subscriber that is being located . Depending on the combination of these factors the location information can have anywhere between 5m to 30km of uncertainty . As it will , most likely , not be possible to have access to real network data — as it is heavily regulated and operators do not easily release it — we envision our artifact to run on the mobile phone , logging nearby cell towers . The data will then have to be reduced in order to mimic the behavior of the network protocols and enriched with geographical coordinates of the cell towers . The simplest interface possible with the data would be a map shown in the mobile phone , with an approximate trace of the user 's path . However , in order to get rich feedback , we intend to integrate a critical edge to the artifact , much like the work of Paulos or our own , mentioned before . As such , the final artifact could take any shape such as a game , a social network , a personal assistant , etc . In order to get inspiration for the design we will use the returned packages from the Cultural Probes . We will distribute the resulting artifact — most likely an app for a smartphone —to a small group of users ( < 10 ) for a period of two weeks , where it will collect the data and possibly show it , in some form , in real-time . After that period of time we will conduct semi-structured interviews where we will follow a similar model to the ones used by Bowen [ 22 ] for his critical artifact methodology . Users will engage in a dialogue with the designers , with the artifact as a catalyst , and will be prompted to manifest their reactions to the artifact and to their own data . 4 Conclusion We expect the resulting knowledge from our process to be a rich qualitative account of user experiences on mobility — from the Cultural Probes — and on data collection through the mobile phone . Our hypothesis is that by following an artifact-driven research through design , using Zimmerman ’ s framework , we can tap into feelings and concerns from users that we wouldn ’ t be able to reach with conventional methods , such as polls . 60 References Hincapié , J.D. , Tabard , A. , Alt , F. , Computing , P. : Contextual-Analysis for Infrastructure Awareness Systems . FT.com / Technology - Apple and Android phones face tighter laws in Europe , http : //www . ft.com/cms/s/2/b7d304b6-8174-1 1 e0-9¢83- 00144feabdcO.htmli # axzz1 Mm U8R704 . How Docomo Plans To Use Mobile Data For City Planning & Earthquake Preparation | Penn Olson , http : //www.penn-olson.com/2011/06/04/docomo-japan-mobile- spatial/ ? utm source=feedburner & utm_medium=feed & utm_campaign=Feed % 3A+Penn Olson+ % 28Penn+Olson % 29 . Bennett , C.J . : In Defence of Privacy . Surveillance & Society . 8 , 486 ( 2011 ) . Sundstrém , P. , Taylor , A. , Grufberg , K. , Wirstrém , N. , Solsona Belenguer , J. , Lundén , M. : Inspirational bits : towards a shared understanding of the digital material . Proceedings of the 2011 annual conference on Human factors in computing systems . pp . 1561-1570 ( 2011 ) . Kuznetsov , S. , Paulos , E. : Participatory sensing in public spaces : activating urban surfaces with sensor probes . Proceedings of the 8th ACM Conference on Designing Interactive Systems . pp . 21-30 ( 2010 ) . Li , I , Dey , A. , Forlizzi , J. , Hé6k , K. , Medynskiy , Y. : Personal informatics and HCI : design , theory , and social implications . Proceedings of the 2011 annual conference extended abstracts on Human factors in computing systems . pp . 2417-2420 . ACM , Vancouver , BC , Canada ( 2011 ) . Lim , Y.-kyung , Nam , T.-jin , Oh , A. , Kim , K.-E. : Personal Informatics for Discovering Human-centered Lifecare System Opportunities . Personal Informatics Workshop . ACM , Atlanta , Georgia , USA . Bylund , M. , Hédék , K. , Pommeranz , A. : Pieces of identity . Proceedings of the 5th Nordic conference on Human-computer interaction : building bridges . pp . 427-430 ( 2008 ) . Chalmers , M. , Galani , A. : Seamful interweaving : heterogeneity in the theory and design of interactive systems . Proceedings of the Sth conference on Designing interactive systems : processes , practices , methods , and techniques . pp . 243-252 ( 2004 ) . Kim , M.-C. : Surveillance Technology , Privacy and Social Control . int sociol . 19 , 193- 213 ( 2004 ) . Chandrasekaran , S. , Cooper , O. , Deshpande , A. , Franklin , M.J. , Hellerstein , J.M. , Hong , W. , Krishnamurthy , S. , Madden , S.R. , Reiss , F. , Shah , M.A . : TelegraphCQ : continuous dataflow processing . Proceedings of the 2003 ACM SIGMOD intemational conference on Management of data . pp . 668-668 ( 2003 ) . 61 20 . 21 . 22 . 23 . 62 Halloran , J , Homecker , E. , Stringer , M. , Harris , E. , Fitzpatrick , G. : The value of values : Resourcing co-design of ubiquitous computing . NCDN . 5 , 245-273 ( 2009 ) . Svee , E.O. , Sanches , P. , Bylund , M. : Time geography rediscovered : a common language for location-oriented services . Proceedings of the 2nd International Workshop on Location and the Web . p. 11 ( 2009 ) Why “ Human Density Data ” Is a Big Deal - O ’ Reilly Media - O'Reilly Insights - Forbes , http : //blogs.forbes.com/oreillymedia/201 1/06/06/why-human-density-data-is-a- big-deal/ , Nordstrém , M. , Pyy , J. and Salo , L. . Qualitative analysis of Hot Potato . TKK / SICS / University of Helsinki , T-121.5900 ( 2007 ) Foucault , M. , Sheridan , A. : Discipline and punish : The birth of the prison . Penguin Books New York ( 1991 ) . Dobson , J.E. , Fisher , P.F . : Geoslavery . Technology and Society Magazine , IEEE . 22 , 47-52 ( 2003 ) . Norberg , P.A. , Horne , D.R. , Horne , D.A . : The Privacy Paradox : Personal Information Disclosure Intentions versus Behaviors . Journal of Consumer Affairs . 41 , 100-126 ( 2007 ) . Zimmerman , J. , Forlizzi , J. , Evenson , S. : Research through design as a method for interaction design research in HCI . Proceedings of the SIGCHI conference on Human factors in computing systems . pp . 493-502 . ACM , San Jose , California , USA ( 2007 ) . Gaver , B. , Dunne , T. , Pacenti , E. : Design : Cultural probes . interactions . 6 , 21-29 ( 1999 ) , Bowen , S. : A Critical Artefact Methodology : Using Provocative Conceptual Designs to Foster Human-centred Innovation , http : //www.simon- bowen.com/downloads/research/aCritical ArtefactMethodology . pdf , ( 2009 ) . Agre , P. , Surveillance and capture : Two models of privacy . The Information Society 10 , 2 , 101-127 ( 1994 ) Lockbox : Applying the Value of Privacy to Cloud Storage Luke Stark ! , Matt Tierney ” ! Media , Culture , and Communication , New York University * Computer Science , New York University luke . stark @ nyu.edu , tierney @ cs.nyu.edu Abstract . This paper examines one particular problem in cloud computing : how users can take advantage of the cloud to store data without compromising their autonomy and individual empowerment , giving up control of the appropriate flows of their personal data -- - in other words , how users can maintain privacy and security in the cloud without sacrificing data availability . Keywords : privacy , cloud computing , human-computer interaction ( HCI ) , Values-Sensitive Design , security , cryptography , trust , user empowerment 1 Introduction 1.1 . Values in Cloud Computing Context . Cloud computing is “ a model for enabling ubiquitous , convenient , on- demand network access ” to a shared collection of information systems such as “ networks , servers , storage , applications , and services ” [ 1 ] . One appealing feature of cloud computing is its possibilities for data storage ; data stored in the “ cloud ” of a networked server is , in theory , ubiquitously available where and when a user needs it . However , the market leader in cloud storage , file synching , sharing , and versioning — Dropbox—has come under increasing scrutiny for its weak privacy policies [ 2 ] . Moreover , as some tech commentators have noted , Dropbox ’ s uncomplicated reliance on Amazon ’ s Simple Storage Service makes the scope of Dropbox ’ s own Terms of Service , and its own security mechanisms , secondary to a more general problem : the vulnerability of user data stored in the cloud to privacy breaches , unauthorized or unanticipated access and circulation outside the control of the individual [ 3 ] . Application . Lockbox is a secure , built-from-scratch , cloud storage application that seeks to preserve certain values expressed in conventional cloud storage systems— namely , usability and data availability—while radically improving technical expression of the values of privacy and security for its users . As such , Lockbox is a privacy/security-aware alternative to popular systems like Dropbox . As Deborah Johnson observes , “ computer systems can not by themselves be moral agents , but they can be components of moral agency ” [ 4 ] . The initial impetuses behind the creation of Lockbox were the realizations that ( a ) from an empirical and technical standpoint , individual data storage in the “ cloud ” was not as secure as it might be , and ( b ) from a 63 conceptual standpoint Dropbox ’ s standing in the burgeoning field of cloud storage should be critically assessed from a values perspective . Competing Models . A number of consumer applications currently provide user storage in the “ cloud ” : these include SugarSync , Mozy and market leader Dropbox . While these applications do claim to encrypt user data , they do so only external to the applications themselves : the data is still vulnerable to inadvertent or deliberate access by employees of the companies involved , or to malicious actors hacking into the system . A number of consumer applications featuring enhanced security are also available , some of which are similar conceptually to Lockbox : these include Wuala , Tahoe-LAFS , Lockify , and SpiderOak . Arguably , these systems sacrifice the convenience of a single folder abstraction ( e.g. , Wuala ) or demand extraordinary expertise and confidence from end-users ( e.g. , installing a new file system ) . As such , the Lockbox team determined that a new application build specifically with privacy values in mind was an appropriate project . Conceptual Frames . This case study builds primarily on the framework of Value Sensitive Design ( VSD ) [ 5 ] [ 6 ] . As Flanagan , Howe and Nissenbaum observe , “ the study of human and social dimensions of technology is so demanding [ because ] the areas of knowledge and the methodologies it straddles are traditionally both far-flung and self-contained ” [ 7 ] . Given the challenges inherent in drawing together even as proximate a pair of disciplines as media criticism and computer science , Value Sensitive Design , “ a theoretically grounded approach to the design of technology that accounts for human values in a principled and comprehensive manner throughout the design process ” [ 8 ] , seems the most practical system at hand . While acknowledging similar schema for evaluating human values within technological systems , such as reflective design [ 9 ] , and incorporating some of these methods ’ key insights into our analysis , we believe VSD provides a robust and flexible framework within which to conduct our assessment of values designed into distributed systems . 1.2 Discovering Values in the Cloud User Empowerment . In preliminary discussions , the design team identified the concept of individual online autonomy—what David Clark and his co-authors term “ user empowerment ” —as an important value underpinning both the team ’ s general critique of Dropbox ’ s shortcomings , and its intuitions for improvements . According to Clark et al. , user empowerment is “ the preference that the user , rather than the service provider or the software provider , be able to pick what applications to run , what servers and services to use , and so on. ” Clark and his co-authors suggest that user empowerment is a basic principle of the Internet itself : it is “ the manifestation of the right to choose—to drive competition , and thus drive change ” [ 10 ] . In the distributed system context , we take “ user empowerment ” to mean accentuating the autonomy promoted by the cloud while diminishing the prospects for data to go astray beyond the user ’ s contextualized choices or permissions . 64 Availability . User empowerment or autonomy in cloud computing is defined by the cloud ’ s model of data availability . The user model for cloud storage presumes that the physical mobility of individuals ( across cities , borders , access terminals , or mobile devices ) matches data flows , and that people desire a virtual place to store data without requiring the end-user to update or duplicate files constantly , or worry about leaving a particular file on a particular piece of hardware ( e.g. , a USB flash drive ) ; in other words , a place accessible from anywhere with network access . In practical terms , Amazon Web Services ’ Simple Storage Service ( S3 ) provides this virtual location for both Dropbox and Lockbox . Tradeoffs . In light of the design team ’ s decision to highlight user autonomy as a key value in distributed systems , the team came to view autonomy as the correlation between the lived decisions and choices of a user and the synchronous availability of data within the cloud solely to that particular user . Data in the cloud is conveniently accessible from multiple points , matching a user ’ s mobility ; however , when a user is not accessing data , that user ’ s autonomy is preserved if the data is inert , inaccessible . The team therefore decided to turn to cryptography as a technical system through which the value of user empowerment could be actualized , paradoxically by binding the user—and arguable reducing autonomy —to his or her data through knowledge of an encryption key . Any digitally encoded data is evidently not materially “ inert ” — it can be moved or copied easily , including between different servers or terminals networked to the cloud . Cryptography permits data to persist in the cloud , but be separated from their legibility , and therefore their practical utility for users without the code : while the quantity of data is still discernible , its significance is , to most , only so much “ noise. ” Flows of information persist , but their contents are blocked from those without the decryption key . The Lockbox user views her data as cleartext , while unauthorized actors peering at data within the cloud storage server or network would perceive a user ’ s data as ciphertext . Thinking of “ user empowerment ” and “ availability ” together allowed the design team to consider what design tradeoffs were truly necessary in order to ensure the values of privacy and security could be built into a cloud storage system ; the decision to limit the legibility of data through encryption to the user “ in the know ” trades global availability of data for enhanced privacy for both any one user and that user ’ s data . 2 Designing Values in the Cloud : Lockbox Application Specifics . The Lockbox application operates as a background user program , synchronizing contents from user-specified directories to a cloud storage service . Data is encrypted in transit to and in storage on the cloud service provider's servers . Lockbox also enables users to share encrypted data with friends who use the Lockbox program , and makes secure file sharing private and always available . In conceptualizing and creating Lockbox , the design team was inspired to consider user empowerment in the cloud in several novel ways , particularly in regards to the role of 65 encryption in enhancing online autonomy . Lockbox ’ s encrypted storage is prototypical of a new approach to cloud storage : by setting the parameters for online data to be protected within a particular encrypted “ slice ” of the “ cloud ” controlled by a particular user , Lockbox begins to carve out autonomous spaces legible to particular individuals within servers protected by encryption , within which data is preserved until needed . Thus , it was also important to the design team that Lockbox be portable across platforms and operating systems in order to preserve a high degree of user choice . As such , Lockbox was written using the versatile Python programming language , licensed under a Sleepycat License ( Open Source Initiative ) , and designed so that its configuration by end users could be accomplished through a web browser ( a standard artifact and mostly homogeneous rendering engine across common contemporary desktop operating systems ) . In accord with the essence of the Sleepycat License , Lockbox also consists of bundle open source libraries for Amazon Web Service APIs , OpenSSL ( implements stream and block ciphers ) , and GNU Privacy Guard Gmplements OpenPGP protocol ) . Privacy . There is a voluminous literature available on the subject of online privacy , here defined as the “ appropriate flow of information ” [ 12 ] . A number of authors have suggested that informational or data privacy is a vital means to foster individual freedom in the face of institutions equipped with ever-more sophisticated systems for data harvesting , mining , retrieval and analysis [ 13 ] [ 14 ] [ 15 ] [ 16 ] [ 17 ] . Others have argued that technology has changed little in terms of the balance between a need to protect individual rights online versus the prerogatives of law enforcement and commerce [ 18 ] [ 19 ] . More nuanced empirical analysis has examined the ways in which everyday users of technology craft strategies for privacy in online situations which are less than amenable [ 20 ] . Though Lockbox ’ s mission is not identical to that of those espousing information privacy in general , we are evidently sympathetic to the criticisms espoused by the former view , namely that the promiscuity and recombinability of data requires close attention to empowering users to make “ appropriate ” choices themselves . As Brian Whitworth and Aldo de More suggest , “ Internet privacy concerns seem essentially a conflict between a social requirement ( privacy ) and current Internet system design ” ; this conflict represents a “ social-technical gap ... the degree software fails to meet social requirements ” [ 21 ] . Siani Pearson observes that , “ The privacy challenge for software engineers is to design cloud services in such a way as to decrease privacy risk , and to ensure legal compliance ” [ 22 ] . With Lockbox , the challenge with designing privacy affordances lacking in other cloud-based storage services that rely on a “ middleman ” hinges on balancing the convenience of the end user with a robust encryption regime enabling privacy . Along with its mobilization for industrial and military applications , cryptography has a long history of association with user empowerment movements online [ 23 ] . In existing cloud storage systems , one of the most common and practical methods for securely storing data is using a symmetric key encryption method known as the AES- 256 block cipher . Symmetric key cryptography is very similar to the everyday use of passwords to log into computers , email services , etc . ; to access a password-encrypted 66 document simply requires the correct password . However , this password , or “ key , ” must be shared between all parties who the owner wants to grant access to the data . The privacy practices of services like Dropbox raise concerns surrounding middleman companies that use symmetric key encryption , since the organization stores the password that is used to encrypt the stored data . The middleman can see the data and can release the cleartext data when pressured by an outside agency , at their employees ’ whim , or when their security services are compromised . * Lockbox uses a cryptographic system based on the primitives of symmetric key and public key cryptography . Public key cryptographic techniques are used to sign and encrypt data for two purposes : first , signing data ( with the private key ) guarantees that the recipient knows that sender of the data is who the sender claims to be ; second , encrypting data ( with the public key ) guarantees that only the corresponding private key owner can decrypt the data . ( Notably , the public key can not be used to decrypt the public key encrypted data . ) Lockbox uses a hybrid cryptosystem , a well-known combination of symmetric key and public key cryptography , to ensure privacy for user ’ s files . A randomly generated 32 character password is generated per file ; this password is used to AES-256 encrypt a file . The password is then encrypted with the public key of whomever the file owner wants to share the file with ; the public key- encrypted password files ( more than one , since there are multiple users to share the file with ) and the symmetric key encrypted file are then uploaded to the cloud service . The symmetric key encrypted file and the corresponding public key encrypted password file are made accessible to the user the file owner wants to share the original data with . Lockbox manages these operations in an opaque manner . A user is only required to drop files into her Lockbox directory , specify with whom she wants to share the file from the Lockbox address book ; the application manages the rest of the transaction . However , managing public keys remains a hard problem for security and privacy. > 4 The current practice for users who desire to combine the convenience of Dropbox with some type of encryption system involves an application called TrueCrypt , a free and open source disk encryption system . On a user ’ s file system , TrueCrypt creates block cipher-encrypted “ volumes , ” which are password-encrypted directories . Challenges arise for end-users , however , with respect to user experience details such as the order in which the TrueCrypt and Dropbox are started ( or stopped ) when a computer boots ( or shuts down ) . Moreover , the trouble with this method of sharing is that security hinges on sharing a password with another user ( recall the difficulty with symmetric key encryption techniques , in general ) . A single password that must be shared remains a dubious mechanism to protect secrets especially since the compromise of the password compromises the secrecy of the entire Dropbox volume undetectably . > For instance , the design team must solidify the design for how to appropriately handle access revocation . Do we retroactively apply the revocation to all previous versions of a file ? Other concerns include how do we want to store public keys and access control lists on the cloud . We may risk revealing information about users ( therefore compromising privacy ) with a bad design of key and ACL management . At the time of writing , the initial Lockbox prototype implemented a naive , proof-of-concept privacy , key management , and access control story . For every file and file update , a new password key is generated . Revocation is simple by changing permissions to the corresponding object in an S3 bucket as well as removing the revoked user ’ s keys from the list of keys with which to encrypt the files . The choice to implement a simple yet 67 Deploying a hybrid cryptosystem within the cloud allows Lockbox to operationalize a view of privacy based on contextual access and flow of data to a particular user : Lockbox therefore qualifies as a privacy-enhancing technology ( PET ) . Herbert Buckert has defined PETs as technologies that “ seek to eliminate the use of personal data altogether or ... give direct control over revelation of personal information to the person concerned ” [ 24 ] . Buckert ’ s taxonomy of PETs includes subject-oriented , object-oriented , transaction-oriented and system-oriented technical concepts ; Lockbox operates primarily as a subject-oriented PET , by aiming to “ eliminate or substantially reduce the capability to personally identify the acting subject ” through hybrid cryptography [ 25 ] . The design team is cognizant of Buckert ’ s critiques of PETs , particularly that the values underpinning the design of such technologies must be carefully though through . Security . Lockbox assures users that through its algorithm they are secure and free from harm in their data storage privacy . While security is not zero sum , the data that is secured sometimes is : the secure and encrypted nature of Lockbox ’ s service may prompt care and attention from lawmakers and regulators with an interest in tracking and classifying in the “ cloud. ” Moreover , Lockbox obviously does not protect side- channel or covert channel attacks , such as screen shots or password copying -- - threats which are predicated on a breakdown of trust offline . Cost . One final value the design team engaged with in the creation of Lockbox was of low cost , both financially and in terms of computer resources : given that the political economy of distributed systems ties the latter to the former for users , the design goal was to limit both . Using a service like Amazon $ 3 costs fractions of pennies to store and retrieve gigabytes of data . However , a user modifying an already-stored file on her laptop should not require her to upload the entire file again to the cloud ( this would be a costly , repetitive operation for most of the file ) . The process of applying delta encoding for incremental modifications is easy on cleartext files ; however , encrypted files make this process more difficult . Finding the right design to enable delta updates without revealing information about the files to the cloud will be important for future versions of Lockbox . To address the value of minimizing costs , the design team has begun implementing a more cost effective design that leverages the rsync algorithm in addition to Amazon Web Services ’ Simple Queue Service ( SQS ) and SimpleDB [ 26 ] . rsync is a well- known algorithm designed to quickly compute differences between files and quickly apply delta updates to files . SQS is designed to store messages as they travel between computers . SimpleDB is designed as a ( optionally , strongly consistent ) database optimized for efficient index and select queries ( non-relational queries ) . By combining the affordances of delta encoding ( to minimize bandwidth and storage costs ) , messaging ( to send notices easily between machines that share files ) , and inefficient design was made by the design team for the purpose of demonstrating a working proof-of-concept prototype . Nevertheless , the design team has debated the “ correct ” design of the key management and access control story ; we expand on this point in the “ Cost ” section . 68 strong consistency ( to ensure total ordering of updates ) , the design team will maintain the original vision of a correctly-implemented file sharing , syncing , and versioning while minimizing costs to end-users and trusted computation in the cloud . 3 Conclusion 3.1 Discovering Users As Lockbox has yet to go through alpha testing by users , more empirical research and feedback is needed to assess the degree to which the design team has been successful in programming for “ user empowerment , ” enabled by cryptographically ensured privacy . We are mindful of Sengers et al. ’ s six strategies for putting reflective design into practice , particularly that of using technical design to “ probe ” for un-assumed user needs and the exploration of previously overlooked concepts and metaphors brought forward by the user ’ [ 27 ] . Further empirical work is also necessary to systematically identify the design choices made by other secure cloud storage services : whether these applications have made similar or divergent design choices from those of the Lockbox team , and how design choices have affected expressed values in the use of the application . More broadly , interactions with prospective users continue to influence future design considerations of Lockbox . While the design team is aware that new technologies will inevitably breed new uses and new users , specific user constituencies have already been identified . In particular , discussions with technologists who work with human rights workers have yielded valuable insight into needs that Dropbox fails to meet . Human rights activists who must share large videos with individuals outside of a country of interest require bandwidth-shaping features to avoid detection by governments who censor network activity . Without bandwidth shaping to limit the amount of traffic uploaded or downloaded through a file sharing service , giant bursts of traffic could raise red flags for censoring governments . These interviews have prompted the design team to consider ways to extend Lockbox ’ s privacy-enhancing functions in future iterations of the product . At this point , further research and testing is a necessary compliment to the theoretical and technical work already accomplished . Ideally , the Lockbox project will not only stimulate further conceptual and theoretical work on the status of the individual and her privacy in the “ cloud , ” but also lead to a product useful to these groups whose design reflects attention to the values at play within it . References Mell , P. & Grance , T. : The NIST Definition of Cloud Computing ( Draft ) . National Institute of Standards and Technology Special Publication 800-145 ( Draft ) January 2011 ) Gain , B .. Why Dropbox ’ s Privacy Policy Is OK ( Just Proceed Carefully ) PCWorld , http : //www . peworld.com/printable/article/id,226080/printable . htm ] 69 22 . 23 . 24 . 25 . 26 . 27 . Matthews , L. “ Dropbox responds to privacy outrage. ” Geek.com , http : //www . geek . com/articles/news/dropbox-responds-to-privacy-outrage-20110421/ Johnson , D.G . : Computer Systems : Moral Entities but not Moral Agents . In : Ethics and Information Technology 8 , 195-204 ( 2006 ) Friedman , B . & Nissenbaum , H. : Bias in Computer Systems . In : ACM Transactions on Information Systems 14 ( 3 ) , 330-347 ( 1996 ) Friedman , B. , Kahn , P. and Borning , A. : Value Sensitive Design and Information Systems . In : Schneiderman , B. , Zhang , P. , & Galletta , D. ( eds ) Human-Computer Interaction in Management Information Systems : Foundations , pp . 348 -- 372 . M.E . Sharpe , New York ( 2006 ) Flanagan , M. , Howe , D. , & Nissenbaum , H. : Embodying Values in Technology : Theory and Practice . In : van den Hoven , J. , Weckert , J . ( eds ) Information Technology and Moral Philosophy , pp . 322—353 . Cambridge University Press , Cambridge ( 2008 ) , 324 Friedman , B. , Kahn , P. and Borning , A. : Value Sensitive Design and Information Systems . In : Schneiderman , B. , Zhang , P. , & Galletta , D. ( eds ) Human-Computer Interaction in Management Information Systems : Foundations , pp . 348—372 . M.E . Sharpe , New York ( 2006 ) , 350 Sengers , P. , Boehner , K. , David , S. & Kaye , J. : Reflective Design . In : Culturally Embedded Computing Group , pp . 49 -- 58 . Cornell Information Science , Ithaca ( 2005 ) Clark , D. D. , Wroclawski , J. , Sollins , K. R. , & Braden , R. : Tussle in Cyberspace : Defining Tomorrow 's Internet . IEEE/ACM Transactions on Networking 13 ( 3 ) , 462-475 ( 2005 ) , 473 Brewer , E. : Towards Robust Distributed Systems . Principles on Distributed Computing ( 2000 ) Nissenbaum , H. : Privacy in Context . Stanford University Press , Stanford ( 2010 ) , 127 Cohen , J. : Examined Lives : Informational Privacy and the Subject as Object . Stanford Law Review 52 , 1373 -- 1438 ( 2000 ) Kerr , I . & McGill , J : Emanations , Snoop Dogs and Reasonable Expectations of Privacy . Criminal Law Quarterly 52 ( 3 ) , 392 -- 432 ( 2007 ) Ohm , P. : The Fourth Amendment Right to Delete . Harvard Law Review 119 , 10 -- 18 , Gannett House , Cambridge ( 2005 ) Solove , D. : A Taxonomy of Privacy . University of Pennsylvania Law Review 154 ( 3 ) , 477 -- 564 ( 2006 ) Lyon , D. : Data , Discrimination , Dignity . In : Surveillance Studies : An Overview , pp . 179 -- 197 . Polity Press , Malden , MA ( 2007 ) Kerr , O. : Searches and Seizures in a Digital World . Harvard Law Review 119 , 531 -- 585 , Gannett House , Cambridge ( 2006 ) Posner , R. A. : An Economic Theory of Privacy . Regulation 2 ( 3 ) , 19 -- 26 ( 1978 ) boyd , danah : Making Sense of Privacy and Publicity . SXSW . Austin , Texas , March 13 ( 2010 ) Whitworth , B. and Moor , A. : Legitimate By Design : Towards Trusted Socio-Technical Systems . Behavior and Information Technology 22 ( 1 ) , 31-51 ( 2003 ) , 33 Pearson , S. : Taking Account of Privacy when Designing Cloud Computing Services . Proc . ICSE-Cloud09 , Vancouver , IEEE ( May 2009 ) Levy , S. : Crypto Rebels . In : Ludlow , P. ( ed ) High Noon on the Electronic Frontier , pp . 185 -- 205 . The MIT Press , Cambridge ( 1996 ) Burkert , H. : Privacy-Enhancing Technologies : Typology , Critique , Vision . In : Agre , P. & Rotenberg , M. ( eds ) Technology and Privacy : The New Landscape , pp . 125-142 . The MIT Press , Cambridge ( 1997 ) , 127 Burkert , H. : Privacy-Enhancing Technologies : Typology , Critique , Vision . In : Agre , P. & Rotenberg , M. ( eds ) Technology and Privacy : The New Landscape , pp . 125-142 . The MIT Press , Cambridge ( 1997 ) , 125 Tridgell , A . & Mackerras , P. : The rsync algorithm . The Australian National University ( 1996 ) Sengers , P. , Boehner , K. , David , S. & Kaye , J. : Reflective Design . In : Culturally Embedded Computing Group , pp . 49—58 . Cornell Information Science , Ithaca ( 2005 ) , 56-57 . 70 Elicitation of Values , Motivations and Emotions : The VBRE Method Sarah Thew ! , Alistair Sutcliffe ? ! Northwest e-Health , University of Manchester , UK ? Manchester Business School , University of Manchester , UK ( sarah.thew , alistair.sutcliffe ) @ manchester.ac.uk Abstract . Soft issues , such as emotions , motivations and values are often cited as problems in the RE process . A method is presented for analysing such issues . The method includes a taxonomy of users ’ values , motivations and emotions , with guidance for eliciting and analysing these issues during the RE process . Two method evaluation studies are described : a questionnaire evaluation of the website and method by novice and RE experts , and preliminary results from a series of three industry based case studies making use of the method during software development projects . The validation studies demonstrate the utility and acceptability of the method by industrial practitioners . Keywords : Requirements elicitation , values , motivations , emotions . 1 Introduction Soft issues , such as politics and people ’ s feelings are often cited as problems in the RE process , although there is little advice about how to deal with these issues . Few studies have directly considered stakeholders ’ emotions during the analysis phase , although there have been numerous studies which report the impact of negative user emotions after implementation e.g . [ 1 , 2 ] . Gowler [ 3 ] observed that systems must fit with stakeholders ’ values and beliefs to be successful . However , it is not easy to gain insight into personal values or emotions , since people rarely directly express such information . Experienced analysts may develop the ability to understand users ’ values , motivations and emotions ; however , this knowledge is tacit and rarely articulated . In this paper we attempt to make such knowledge explicit and propose a method for analysis of users ’ ‘ soft ’ issues in RE . Values are beliefs and attitudes held by people about other people , organisations or artefacts . Kluckhohn ’ s definition of values [ 4 ] : “ a conception explicit or implicit , distinctive or an individual or characteristic of a group , of the desirable which influences the selection from available modes , means and of action ” has been adopted by studies into values in the context of software development [ 5 , 6 ] . Values are complex concepts or knowledge schema , related to our beliefs and attitudes , which shape our response to events . Motivations are long-lasting , high-level behavioural drivers , the strength with which a motivation is held will influence the intensity and persistence of behaviour . An 71 understanding of motivation can be helpful in interpreting stakeholder behaviours during software design and development [ 7 ] . Emotions are reactive responses to events , objects and artefacts . Software developments have the potential to change working circumstances and therefore to have an emotional effect . Understanding values , motivations and emotions helps requirements engineers interpret stakeholder concerns and behaviours , the VBRE ( Value Based Requirements Elicitation ) method aims to facilitate this process . 2 . The VBRE Method Questionnaires are effective for surveying values , motivations or emotions within a population ; however , they restrict investigations to a pre-defined set of responses . Elaboration and exploration are desirable when considering subjective concepts , since one person ’ s understanding of a value such as ‘ equality ’ may well manifest itself with a meaning quite different from someone else ’ s . Furthermore , our research with practicing analysts indicated that they did not feel questionnaires were an appropriate or acceptable tool for exploring what might be sensitive or difficult subjects [ 8 ] . Hence the VBRE method aims to encourage a rich , qualitative understanding of the meaning of values , motivations and emotions within the context of individual projects and stakeholders . The method integrates into the analysts ’ usual elicitation activities , making use of the outputs of standard techniques such as interviews and workshops . The method can be used in two modes to suit novice or expert analysts and the time resources available . In novice mode ( summarised in figure 1 ) , preliminary analysis of the known project circumstances and the VBRE taxonomies leads to identification of key issues or ‘ hunches ’ , i.e . a sub-set of the users ’ values , motivations or emotions considered relevant to the project . Making these intuitions explicit encourages gathering evidence to support or challenge initial hunches . The analyst then begins their standard requirements elicitation work : interviews , workshops etc. , the elicitation advice provided by the VBRE website ( see below ) can be used to support this work , e.g . a list of questions that can be used to explore ‘ trust ’ . At regular intervals the analyst will review elicitation outputs for evidence of the expression of values , emotions or motivations . This involves reviewing interview/meeting notes for evidence of the expression of values , emotions or motivations . Novice analysts may wish to transcribe sections of text from audio recordings , if time resources are constrained an alternative is to simply listen to audio recordings and make notes . These reviews are inspected for frequently expressed value , motivation and emotions and possible causations thereof . The hunch list is modified following each cycle of reflection , and develops incrementally into a rich picture of the stakeholders ’ values , motivations and emotions . Finally the implications of the analysis for both the project process and the design are reviewed . These may be functional and non-functional requirements , but also recommendations for project procedures , functional allocation and work design . 72 Value , motivation Create hunch emotion list taxonomies v Interviews , _—————— , __ meetings , ———____ a observations —~ Functional Revised hunch requirements , non Review list , new funtional requirements , Interviews questions process implications NO Refined understanding 5 _A ————— > of values , motivations , RK emotions Figure 1 . The novice pathway through the VBRE method . In expert mode , the method knowledge is internalised so it can be used to formulate appropriate questions framed by the analyst ’ s understanding of the application domain . The method becomes part of the expert ’ s battery of techniques in scenario analysis , questioning using storyboard and prototype probes ; as well as informing review of interview notes , using Tables 1-3 as aide-memoires and prompts for wider thinking about values , motivations and emotions . 2.1 VBRE Taxonomies The taxonomy of values and their consequences for process guidance are illustrated in Table 1 . Eight upper-level value categories are proposed based on existing analyses of value theory [ 5 , 9 ] and our own investigations from card sort experiments and expert interviews . The process implications in column 4 vary from organising the team composition in response to aesthetic needs , specialisation of the RE process to include safety and risk analysis , to more general heuristics for project team management . Table 1 . Values : potential sources and implications for RE Value Related terms Potential sources Process concept implications Trust openness Relationships with other | less control , improved integrity individuals /groups . confidence responsibility , Privacy policies Collaboration | cooperation Relationships with others | improved cooperation friendship Awareness of others — shared awareness altruism office politics Morals/ Justice , fairness Behaviour towards openness and honesty in Ethics equality tolerance | others team Opinions of others ’ behaviours Creativity Onginality , Work processes , Creativity workshops , Innovation adventure problem solving brainstorming Aesthetics Beauty nature , art , | Self appearance Design as a_ priority , design reaction to images , storyboards shapes , art and design 73 Security safety Data management hazard / threat privacy , risk policies analysis Attitudes towards change Personal serious/playful Self image , personae Customisation analysis for characteristics | introvert/extrovert , | scenarios , psychological | personal RE . team conflict systematic/ questionnaires management opportunistic Beliefs & cultural , political , | Leisure interests , user Team composition , Attitudes religious topics background , reaction to incentives news events Motivations are important for understanding the behaviour of stakeholder groups as well as for individual-level requirements , some motivations may also be important as properties of organisations . Table 2 summarises the more important motivations for requirements analysis , synthesised from existing theories of motivation [ 10 ] [ 11 ] . Table 2 . Motivations and their implications Motivation Description Implications Power need to control others , Work organisation , responsibility , control authority , command Hierarchy Possession desire for material goods , resource control , monetary incentives , wealth marketing , Achievement | need to design , goal oriented , need to align users with construct , organise project aims Self-esteem need to feel satisfied with oneself link personal & project goals , praise personal achievement Peer-esteem need to feel valued by others team composition social feedback & rewards Self-efficacy | confidence in own capabilities | confidence building , training , skill matching Cunosity , desire to discover , extensible systems , self tutoring learning understand world Sociability desire to be part of a group collaboration in work organisation Altruism desire to help others cooperation in work organisation Emotions can give useful feedback about reactions to project plans and designs , especially since emotional responses are stronger than ordinary opinions and may therefore indicate significant problems leading to user dissatisfaction or system rejection . The principle emotions and their consequences are given in Table 3 . These emotions are based on the classification of emotions as responses ( positive or negative ) to events , people or artefacts by Ortony et al [ 12 ] Table 3 . Emotions and their potential causes Emotion Related Possible causes Remedial action feelings Fear fight , worry Design is threatening , Review/ameliorate threat negative consequences threats Pleasure joy , happiness Design is rewarding , None ; note for future positive reference 74 Anxiety Uncertainty Specification may be Explain specification , use worry confusing , scenarios , reassure users consequences not clear , little involvement Frustration annoyance , Irreconcilable conflict , Revisit stakeholder anger barriers , value-interest analysis clashes , values ignored Disgust revulsion , Design has clash with Radical design review horror values/culture Depression withdrawn , Lack of involvement in | Re-engage users , improve isolated , process , values ignored | communication & alone motivation 2.2 Initial Method Evaluation and Development of the VBRE Method Support Website A preliminary evaluation of the method was carried out by the first author , during two software projects . The method was trialled across several interviews and outputs reviewed with other project team members . The process of structured , guided reflection was considered valuable . However , it was also felt that some concepts in the taxonomy required additional explanation ; that further elicitation advice was useful , and that paper tables were difficult to work with . To make the taxonomies more accessible a website was developed ( http : //www.vbre.org.uk ) , structured around a table of values , motivations and emotions , with content drawn from the taxonomies ( figure 2 ) . LY Requirements Elicitation Exploring users ' values , motivations and emotions People Focused Requirements Investigation We tend to think of the design and development of software as technical , computer focussed work . However , all but the most minor developments have the potential to change users ' ways of working in both positive and negative ways . This website is intended to help requirements analysts reflect on the human impact of software developments ( insert ‘ click a term ’ CTA ) Absence of Conflict Accomplishment Achievement Altruism Ambitious An attractive environment Capable Challenge Contentedness Cooperation Courageous Curiosity Depression Disgust Equality Experience Fear Forgiving Freedom from anxiety Friendship Frustration Happiness Helpful Honest Imaginative Independent Intellectual Logical Obedient Open-minded Ordered Ownership Peer-Esteem Pleasure Polite Power Responsible Selfcontrol Self respect Sociability Social recognition Success Trust Figure 2 . Screenshot of the main values , motivations and emotions navigation table from the VBRE website . Each term has a page of detailed content , including example interview questions , scenarios to help the analyst consider how values , motivations or emotions might be important to their project , advice about its potential impact on the requirements process or software design . 75 3 . Method Validation Two approaches have been used to evaluate the VBRE method . Below we present a short summary of results from ( i ) a questionnaire to evaluate the website with RE students and professional analysts , and preliminary findings from ( ii ) an on-going series of case studies investigating use of the VBRE method and website by practising requirements analysts . 3.1 Questionnaire Evaluation of the website A questionnaire was used to gather feedback about the website . Respondents were asked to explore the website and then rate its utility and comprehensibility on a 7 point Likert scale . Respondents could also supply free text comments . The first group of respondents were final year undergraduate students ( n=12 , 9 male 3 female ) who had just completed a course in requirements engineering . The second group were professional requirements engineers recruited by a ‘ snowball ’ approach ( n=6 , 4 male , 2 female ) , by email with a short description of the purpose of the website , and links to the website and the questionnaire . Both the students and RE experts rated all aspects of the website positively , see table 4 , in particular both groups felt the scenarios and associated lists of related values , motivations and emotions were very useful . The experts were slightly more critical of comprehension of the concepts and design advice , which is not surprising given their more extensive experience ; however even these lower ratings were well above the mean . Table 4 . Students and expert ratings of the VBRE website based on a 7 point Likert scale . Students Experts Mean ( SD ) Mean ( SD ) Content Quality 5.5 ( 0.85 ) 6.33 ( 0.85 ) Comprehensibility — contents clear ? 6.45 ( 0.52 ) 5.66 ( 0.85 ) Comprehensibility - easy to understand ? 6.08 ( 1.03 ) 4.5 ( 1.76 ) Utility - scenarios 6.17 ( 0.63 ) 6.17 ( 0.98 ) Utility — design advice 5.75 ( 0.75 ) 4.83 ( 1.94 ) Utility - overall 6.33 ( 0.84 ) 6 ( 1.26 ) 3.2 Case Study Evaluation Whilst results from this initial questionnaire based study were encouraging , this approach was unable to tell us anything about the utility of the method in practice . We are running a series of case studies working with practising analysts who are using the VBRE method and website in their own projects . We are using the case studies to explore a number of questions : ¢ The impact ( if any ) of the method in the projects under study . ¢ Whether the method and website are used in the same way by novice and expert analysts ? 76 ¢ How the method is adapted for use in ‘ real-life ’ Three volunteers were recruited by advertising within local requirements and usability groups : Analyst 1 ( Al ) has a background in nursing and health informatics , but little formal requirements analysis training and has only worked as an analyst on one previous project . Analyst 2 ( A2 ) has a background in bioinformatics and has worked as a requirements analyst for 5 years on a series of large European projects around the sharing of scientific methods and results . She is testing the VBRE method within one of these projects , currently in a state of flux as new partners join the established project team . Analyst 3 ( A3 ) has a degree in Computer Science and has worked as a requirements analyst for over 10 years . He is a contractor working in a wide variety of industries , and is testing the VBRE method within a project to allow users from multiple health organisations to share sensitive patient information . We are using interviews and diary keeping to collect data about analyst experiences of working with the VBRE method . An initial introductory interview captured information about analysts ’ background , past project experiences and upcoming project work . This introductory meeting also included a tutorial describing the VBRE method and website . The analysts have kept an on-going diary of their experiences of using the method . We will shortly be carrying out final interviews during which we will review the content of the diary . All interviews and meetings have been audio- recorded and described , and we are in the process of thematic coding the content . Completed diaries will also be coded . 3.3 Preliminary Case Study Results and Discussion Our preliminary results have shown the three analysts making use of the method and website in ways which vary with their levels of experience and the demands of their projects . Thus far , Al has used the method and the website in a manner that closely mirrors the novice approach as laid out in figure 1 . He has frequently used the interview questions on the VBRE website , and has identified ownership , power and trust as particular issues within his project . A2 ‘ s users are spread across many European countries so rather than regular small individual meetings she holds larger workshops every 6 months . Her main use of the VBRE method has been in preparing for these workshops — in particular thinking about the motivations of new users joining these workshops , and the potential reactions of existing user group members to new team members . She perceives the usefulness of the method lies in encouraging her to make a point of taking the time to anticipate and reflect on soft issues within her projects . A3 ’ s use of the method has focussed on the website , in particular the list of values , motivations and emotions which he finds very useful when reflecting on the outcomes of interviews . He has identified a strong value clash between medical staff who are keen to share information and collaborate , and the IT team who are extremely anxious about information security and afraid that they will be held responsible for any breaches of patient confidentiality . TI 4 . Conclusions The VBRE method introduces new considerations into the RE process by drawing attention to individual stakeholders ’ values , motivations and emotions . The framework advances previous elicitation techniques around ‘ soft issues ’ by providing explicit taxonomies of values and motivations to guide discovery . The VBRE framework accommodates novice and expert practice , by describing different pathways for the method knowledge to be used directly as aide-memoires or learned and used directly . This flexibility was well received in the initial industrial trials , and early results from our case studies would also indicate that novice and expert analysts are making use of the method and website in different ways . Future work will focus on analysing the completed case studies , in particular identifying the impact of the VBRE method within the case study projects . REFERENCES [ 1 ] A. C. W. Finkelstein and J. Dowell , `` A Comedy of Errors : The London Ambulance Service Case Study , '' in 8th International Workshop on Software Specification and Design , Schloss Velen , Germany , 1996 . [ 2 ] K. Breitman , J. C. S. do Prado Leite , and A. Finkelstein , `` The World 's a stage : a survey on requirements engineering using a real-life case study. , ” Journal of the Brazilian Computer Society , vol . 6 , pp . 13-37 , 199 . [ 3 ] D. Gowler , `` Values , Contracts and Job Satisfaction , '' Personnel Review , vol . 3 , pp . 4-14 , 1974 . [ 4 ] C. Kluckhohn , `` Value and value-orientations in the theory of action , ” in Towards a General Theory of Action , T. Parsons and E. Shil , Eds . : Harvard University Press , 1951 . [ 5 ] E. Mumford , Values , Technology and Work : Martinus Nijhoff Publishers , 1981 . [ 6 ] Bjorn-Andersen , Hedberg , Mercer , E. Mumford , and Sole , The Impact of Systems Change in Organisations : Sijthoff & Noordhoff , 1979 . [ 7 ] R. J. Boland and W. F. Day , `` The experience of system design : A hermeneutic of organizational action , '' Scandinavian Journal of Management , vol . 5 , pp . 87-104 , 1989 . [ 8 ] S. Thew and A. Sutcliffe , `` Requirements Elicitation : Understanding Users' Values and Emotions , '' in NordiCHI 2008 Workshop on New Approaches to Requirements Elicitation , Lund , Sweden , 2008 . [ 9 ] N. Rescher , Introduction to Value Theory : Prentice-Hall Inc , 1969 . [ 10 ] A. H. Maslow , R. Frager , C. McReynolds , R. Cox , and J. Fadiman , Motivation and Personality . New York : Addison Wesley-Longman , 1987 . [ 11 ] A. Bandura , Social Cognitive Theory of Mass Communication : Lawrence Erlbaum Associates , 2001 . [ 12 ] A. Ortony , C. G , and C. A , The Cognitive Structure of Emotions . Cambridge University Press , 1990 . 78 What If More Speech Is No Longer the Solution ? First Amendment Theory Meets Fake News and the Filter Bubble Philip M. Napoli * II . II . IV . TABLE OF CONTENTS INTRODUCTION .0 ... ecececcecceeceeceeeeeeeeececeeceeceeeseeeeeeseseresneeteeesireseesnreenees 57 COUNTERSPEECH AND THE FIRST AMENDMENT : ASSUMPTIONS , APPLICATIONS , AND CRITIQUES ...... cccceccecseeeeeeeeeeceeeeeeecneeereeneeenteees 60 A . THE COUNTERSPEECH DOCTRINE IN PRACTICE ...... : : : ceeceeeees 62 B . CRITIQUES OF COUNTERSPEECH ....... : ccccccceeseeceeeeeseeeteeseeeeeeentens 66 How TECHNOLOGICAL CHANGES UNDERMINE THE COUNTERSPEECH DOCTRINE 0 ... cececcceececeececeeeeeeceeeeeeeeceeeecrecaeseeecaeeseeseresneseeseeatesseseresnaes 68 A . THE RELATIVE PROMINENCE OF TRUE VERSUS FALSE NEWS ... 68 B . DIMINISHED GATEKEEPING AND DISTRIBUTION BARRIERS ....... 71 C. INCREASED ABILITY TO TARGET THE MOST IMPRESSIONABLE .74 D THE DIMINISHED LIKELIHOOD OF BEING EXPOSED TO FACTUAL COUNTERSPEECH .. 0 ... cccccccececseeeeeeeseceeceeeceeeceesereceeseceesseenieeeeesntee 77 E. THE DIMINISHED ABILITY TO DISTINGUISH BETWEEN LEGITIMATE AND FALSE NEWS ....... : : : ccceccceceeceeeeeeeeeeeeeteeeeeentens 79 F. THE ENHANCED SPEED AT WHICH FALSE NEWS CAN TRAVEL.85 IMPLICATIONS ...... ceccceccecceececeeceeeeeececeeceeceeeseeeeeseeeereseeeeeseeneeseeeeneenees 87 James R. Shepley Professor of Public Policy , Sanford School of Public Policy , Duke University ; Andrew Carnegie Fellow . An earlier version of this paper was presented at the 45th Research Conference on Communications , Information , and Internet Policy . The author gratefully acknowledges the research assistance of Petra Ronald and Anne Napoli . This publication was made possible by a grant from the Carnegie Corporation of New York . The statements made and views expressed are solely the responsibility of the author . -55- A . THE FIRST AMENDMENT AND FALSITY .... 0ccceccecceeseeeeeeeeteenees 87 B . MARKET FAILURE IN THE MARKETPLACE OF IDEAS ........ : .0006 88 C. THE 2016 PRESIDENTIAL ELECTION AS MARKET FAILURE CASE STUDY ooeececccccecceeececneceeeeeceeeseecaeceeeeesceesereeeseeeeeesnesereeneseeets 93 D. THE FUTURE OF COUNTERSPEECH AND THE MARKETPLACE OF IDEAS 0c cecececccecceceeceeceeeeeeeeeeeeeeeeeceeeeeeeceeseeesesseesursnieeseestiesieeentees 97 CONCLUSION ... .ececccecceececeeceeeeeeeceeeceeceaeeceeceeeeaeeceeseeectesieesieesieeneents 103 - 56 - Issue 1 FAKE NEWS AND THE FILTER BUBBLE 57 I . INTRODUCTION The results and aftermath of the 2016 U.S. presidential election have brought increased attention to the dynamics of the contemporary news and information ecosystem and how these dynamics affect citizen knowledge and political decision-making . Specific points of focus have included the extent to which algorithmically-driven search and social media platforms are facilitating the construction of “ filter bubbles ” or “ echo chambers ” , ! the presence of political bias in content curation platforms , ’ the extent to which such platforms facilitate the widespread dissemination of false news stories , and inflammatory political advertisements placed by foreign governments . * These phenomena interact in ways that have raised significant concerns about the nature of the relationship between contemporary news and information channels , as well as the effective functioning of the democratic process.° 1 . See generally , Mostafa M. El-Bermawy , Your Filter Bubble Is Destroying Democracy , WIRED ( Nov. 18 , 2016 , 5:45 AM ) , [ https : //perma.cc/K87X-NJ59 ] , see also Matthew Ingram , Facebook and the News : Trends , Filter Bubbles and Algorithmic Bias , FORTUNE ( May 12 , 2016 ) , _ http : //fortune.com/2016/05/12/facebook-and-the-news/ [ https : //perma.cc/2KLF-EP6P ] . 2 . See , e.g , Olivia Solon & Sam Levin , How Google 's search algorithm spreads false information with a rightwing bias , THE GUARDIAN ( Dec. 16 , 2016 , 06:00 EST ) , https : //www.theguardian.com/technology/2016/dec/16/google-autocomplete-nghtwing-bias- algorithm-political-propaganda [ https : //perma.cc/COBT-2WP8 ] ; see also Daniel Trielli et al. , Googling Politics : How the Google Issue Guide on Candidates is Biased , SLATE ( June 7 , 2016 ) , http : //www.slate.com/articles/technology/future_tense/2016/06/how_the google issue guide _on_candidates is biased.html [ https : //perma.cc/N8DU-Y4HR ] , Nelson Granados , How Facebook Biases Your News Feed , ForBES ( June 30 , 2016 , 7:26 PM ) , https : //www . forbes.com/sites/nelsongranados/2016/06/30/how-facebook-biases-your-news- feed/ # 799f10621d51 [ https : //perma.cc/73LB-CYT4 ] ; Issie Lapowsky , Of Course Facebook Is Biased That 's How Tech Works Today , WIRED ( May I1 , 2016 , 7:00 AM ) https : //www . wired.com/2016/05/course-facebook-biased-thats-tech-works-today/ [ https : //perma.cc/5AKR-63KV ] . 3 . See generally , Jen Weedon et . al , FACEBOOK , INFORMATION OPERATIONS AND FACEBOOK 8 ( Version 1.0 , Apr . 27 , 2017 ) , https : //fonewsroomus . files . wordpress.com/2017/04/facebook-and-information-operations- vl.pdf [ https : //perma.cc/63QM-SH65 ] , ; ALICE MARWICK & REBECCA LEWIS , DATA & Soc ’ y , MEDIA MANIPULATION AND DISINFORMATION ONLINE 44 , https : //datasociety.net/pubs/oh/DataAndSocietyMediaManipulationAndDisinformationOnline .pdf [ https : //perma.cc/6M9 Y-FLCN ] . 4 . See , e.g , Mark Isaac & Scott Shane , Facebook ’ s Russia-Linked Ads Came in Many Disguises , NY . TIMES ( Oct. 2 , 2017 ) , https : //www.nytimes.com/2017/10/02/technology/facebook-russia-ads-.html [ https : //perma.cc/ZH2B-BY6E ] . 5 . See , e.g. , Clive Thompson , Social Networks Must Face Up to Their Political Impact , WIRED ( Jan , 5 , 2017 , 6:01 PM ) , https : //www.wired.com/2017/01/social-networks-must-face- political-impact/ [ https : //perma.cc/2WZ7-4GEJ ] , Alex Kantrowitz , How The 2016 Election Blew Up in ’ Facebook ’ s Face , BuzzFEED ( Nov. 21 , 2016 , 11:15 AM ) , https : //www.buzzfeed.com/alexkantrowitz/2016-election-blew-up-in-facebooks-face [ https : //perma.cc/9JKJ-5DCAJ , El-Bermawy , supra note 1 ; Nathaniel Persily , Can Democracy Survive the Internet , 28 J . DEMOCRACY 63 . 58 FEDERAL COMMUNICATIONS LAW JOURNAL Vol . 70 In 2013 , the World Economic Forum presciently highlighted “ massive digital misinformation ” as a leading global risk in its annual global risk assessment . © In 2016 , renowned fact-checking organization PolitiFact declared “ fake news ” its Lie of the Year. ’ Nonetheless , at least in the U.S. , issues of misinformation in the digital sphere have only very recently found their way onto the communications policy agenda . * This somewhat sluggish response can be explained , at least in part , by a First Amendment tradition that has valorized the notion of “ counterspeech. ” A central tenet of the First Amendment is that more speech is an effective remedy against the dissemination and consumption of false speech. * ? The counterspeech doctrine is a perspective that was first explicitly articulated by Justice Louis Brandeis in Whitney v. California . '° Since then , the effectiveness of counterspeech has become an integral component of most conceptualizations of an effectively functioning “ marketplace of ideas , ” in which direct government regulation of speech is minimized in favor of an open and competitive speech environment. '' ! This Article seeks to unpack the set of assumptions about the dynamics of the production , dissemination , and consumption of news that are embedded in the counterspeech doctrine . This Article then questions whether these 6 . See WORLD ECONOMIC FORUM , GLOBAL RISKS 2013 : EIGHTH EDITION 23 ( 2013 ) , http : //www3.weforum.org/docs/WEF GlobalRisks Report_2013.pdf [ https : //perma.cc/9GKG-UCW3 ] . 7 . See generally Angie Drobnic Holan , 2016 Lie of the Year : Fake News , POLITIFACT ( Dec. 13 , 2016 ) , http : / * www.politifact.com/truth-o-meter/article/2016/dec/13/2016-lie-year- fake-news/ [ https : //perma.cc/8X2N-SHJ9 ] . 8 . See , e.g. , Extremist Content and Russian Disinformation Online : Working with Tech to Find Solutions , Hearing Before the S. Comm . on the Judiciary , Subcomm . on Crime and Terrorism , 115 '' Cong . ( Oct. 31 , 2017 ) , https : //www judiciary.senate.gov/meetings/extremist- content-and-russian-disinformation-online-working-with-tech-to-find-solutions [ https : //perma.cc/42VE-5HSD ] ; Social Media Influence in the 2016 United States Elections , Hearing Before the 8S . Select Comm on Intelligence ( Nov. 1 , 2017 ) , https : //www intelligence.senate.gov/hearings/open-hearing-social-media-influence-2016-us- elections [ https : //perma.cc/K65 Y-KAQ4 ] , Russia Investigative Task Force Open Hearing with Social Media Companies , Hearing before the H. Permanent Select Comm . on Intelligence ( Nov. 1 , 2017 ) , _ https : //intelligence house .gov/calendar/eventsingle.aspx ? EventI D=814 [ https : //perma.cc/8DYT-QRJU ] . 9 . See Robert D. Richards & Clay Calvert , Counterspeech 2000 : A New Look at the Old Remedy for `` Bad '' Speech , 2000 B.Y.U.L . Rev . 553 , 553-554 ( 2000 ) ( “ Rather than censor allegedly harmful speech and thereby risk violating the First Amendment ’ s protection of expression , or file a lawsuit that threatens to punish speech perceived as harmful , the preferred remedy is to add more speech to the metaphorical marketplace of ideas ’ ) . 10 . Whitney v. California , 274 U.S. 357 , 377 ( 1927 ) ( Brandeis , J. , concurring ) . 11 . See Abrams v. United States , 250 U.S. 616 , 630 ( 1919 ) ( Holmes , J. , dissenting ) . ( “ [ T ] he ultimate good desired is better reached by free trade in ideas — that the best test of truth is the power of the thought to get itself accepted in the competition of the market , and that truth is the only ground upon which their wishes safely can be carried out . That , at any rate , is the theory of our Constitution. ” ) ; see also Alvin I. Goldman & James C. Cox , Speech , Truth , and the Free Market for Ideas , 2 LEGAL THEORY 1 , 3 ( 1996 ) ; Ronald Coase , The Market for Goods and the Market for Ideas , 63 AM . ECON . REV . 384 , 384 ( 1974 ) ( “ [ I ] n the market for goods , government regulation is desirable whereas , in the market for ideas , government regulation is undesirable and should be strictly limited. ” ) . Issue 1 FAKE NEWS AND THE FILTER BUBBLE 59 assumptions remain viable in the face of the evolving structure and operation of the contemporary media ecosystem : and if not , what this means for contemporary media law and policy . Specifically , this Article argues that conditions , such as the structural and economic changes that have affected the news media , increased fragmentation and personalization , and increasingly algorithmically-dictated content dissemination and consumption , affect the production and flow of news in ways that may make it more difficult than it has been in the past to assume that legitimate news will systematically win out over false news . Thus , just as it has been asked whether the assumptions underlying the Second Amendment right to bear arms ( written in the era of muskets and flintlocks ) are transferrable to today ’ s technological environment of high-powered , automatic assault weapons , ' ? it may be time to ask whether this fundamental aspect of First Amendment theory , crafted in an era when news circulated primarily via interpersonal contact and print media , and in which electronic media were just beginning to develop , is effectively transferrable to today ’ s radically different media environment . In addressing this issue , Part I will review the counterspeech doctrine , its underlying assumptions , the ways that it has been put into practice in legal and policy decision-making , and the critiques that have been leveled against it . As Part 1 will illustrate , the focal points of these critiques have been the psychological and behavioral barriers to counterspeech , as well as the resistance of certain types of speech to the effectiveness of counterspeech . Missing from the counterspeech dialogue , however , has been a substantive consideration of whether the evolution of the media ecosystem has progressed in ways that might affect the validity of the doctrine . Part II then will provide an overview of the profound technological changes that have affected the media ecosystem and media users over the past two decades . While most of these changes are widely recognized , this section will argue that each of these developments bears directly on the integrity of the counterspeech doctrine . Specifically , this part will illustrate that technological changes have : 1 ) affected the relative prominence of the production of true versus false news ; 2 ) diminished the gatekeeping barriers that have traditionally curtailed the production and dissemination of false news ; 3 ) increased the ability of those producing false news to target those most likely to be receptive to/affected by the false news ; 4 ) diminished news consumers ’ likelihood of being exposed to accurate news that counteracts false news ; 5 ) diminished news consumers ’ ability to distinguish between true and false news ; and 6 ) enhanced the speed at which false news can travel . 12 . See , e.g. , Christopher Ingraham , What ‘ Arms ’ Looked Like When the 2nd Amendment Was Written , WASH. Post ( June 13 , 2016 ) , https : //www . washingtonpost.com/news/wonk/wp/2016/06/13/the-men-who-wrote-the-2nd- amendment-would-never-recognize-an-ar-15/ ? utm_term=.86da76908f41 [ https : //perma.cc/KA8E-WV53 ] ( “ Of course , semiautomatic firearms technology did n't exist in any meaningful sense in the era of the founding fathers . They had something much different in mind when they drafted the Second Amendment . The typical firearms of the day were muskets and flintlock pistols . They could hold a single round at a time , and a skilled shooter could hope to get off three or possibly four rounds in a minute of firing . By all accounts they were not particularly accurate either. ” ) . 60 FEDERAL COMMUNICATIONS LAW JOURNAL Vol . 70 Each of these six conditions contributes to undermining the extent to which counterspeech can effectively operate as a fundamental assumption of First Amendment theory . Finally , Part II will consider the broader political , legal , and policy implications of this argument . In particular , this part will consider what the diminished efficacy of counterspeech might mean for the understanding of the marketplace of ideas metaphor and the potential for failure in the marketplace of ideas . The results of the 2016 presidential election will be used to examine possible causes and indicators of such market failure . This part will conclude with a consideration of the legal and policy implications of a media ecosystem in which the counterspeech doctrine has been undermined due to technological change . II . COUNTERSPEECH AND THE FIRST AMENDMENT : ASSUMPTIONS , APPLICATIONS , AND CRITIQUES The counterspeech doctrine was first formally articulated by Justice Louis Brandeis in Whitney v . California. ? According to Brandeis , “ [ i ] f there be time to expose through discussion the falsehood and fallacies , to avert the evil by the processes of education , the remedy to be applied is more speech , not enforced silence. ” ” '' 4 This perspective is in many ways a natural outgrowth of the well-known “ marketplace of ideas metaphor ” , ! > which has served as a fundamental principle in communications law and policy , '® but has been subject to substantial critique in its own right . ' 7 As Justice Holmes ’ famous articulation of the marketplace of ideas metaphor asserts , “ the ultimate good desired is better reached by free trade in ideas — that the best test of truth is the power of the thought to get itself accepted in the competition of the market. ” ! ®§ Under this formulation , the ideas marketplace is inherently capable of distinguishing between truth and falsity and can be counted on to accept and act upon true information and reject false information . This process is , in turn , fundamental to the well-functioning democracy that , according to many interpretations , the First Amendment is intended to protect. ! ? Today , Holmes ’ 13 . See 274 U.S. 357 , 377 ( 1927 ) ( Brandeis , J. , concurring ) . 14 . Id 15 . See Daniel E. Ho & Frederick Schauer , Testing the Marketplace of Ideas , 90 N.Y.U . L. REV . 1160 , 1167 ( 2015 ) ( observing that Brandeis ’ opinion in Whitney v. California represents a “ ‘ canonical formulation ’ of the marketplace of ideas metaphor ’ ) . 16 . See generally PHILIP M. NAPOLI , FOUNDATIONS OF COMMUNICATIONS Po.Licy ( 2001 ) . 17 . See , e.g , Darren Bush , “ The Marketplace of Ideas. ” Is Judge Posner Chasing Don Quixote ’ s Windmills ’ , 32 Ariz. ST. L.J . 1107 , 1146 ( 2000 ) ( arguing that , in realms such as speech , “ the market metaphor becomes increasingly less applicable or useful ” ) , Ho & Schauer , supra note 15 ; Stanley Ingber , The Marketplace of Ideas : A Legitimizing Myth , 1984 DUKE L.J . 1 ( 1984 ) . 18 . Abrams v. United States , 250 U.S. 616 , 630 ( 1919 ) ( Holmes , J. , dissenting ) . 19 . See generally ALEXANDER MEIKLEJOHN , POLITICAL FREEDOM : THE CONSTITUTIONAL POWERS OF THE PEOPLE ( 1960 ) , See also CASS SUNSTEIN , DEMOCRACY AND THE PROBLEM OF FREE SPEECH ( 1995 ) . Issue 1 FAKE NEWS AND THE FILTER BUBBLE 61 statement is echoed within more contemporary notions of the “ wisdom of crowds ” ? or “ the wealth of networks. ” ” ! Counterspeech is an outgrowth of this marketplace of ideas framework . Given the metaphor ’ s assumption that the marketplace is capable of effectively distinguishing between truth and falsity , * * then a speech environment that facilitates as much speech as possible is a potentially effective way of assuring that truth prevails over falsity , and that the good ideas prevail over the bad ones . “ More speech ” ( 1.e. , counterspeech ) thus becomes an effective and First Amendment-compliant approach to assuring that individuals have the information they need to be informed and effective participants in the democratic process . There are a number of fundamental assumptions that underlie this perspective . First , there is the assumption that individuals are capable of discerning between true and false information. ” * The logic here is that , just as participants in the traditional product market are capable of distinguishing between high and low value products , participants in the idea market are similarly capable of distinguishing between true and false news and information . A second , related , assumption is that participants in the idea marketplace place greater value on true news and information than they do on false information. ” * This assumption strikes at the core of what it is the marketplace actually values . A third assumption 1s that , as late U.S. Supreme Court Justice Antonin Scalia has stated , “ [ g ] iven the premises of democracy , there is no such thing as too much speech. ” * * A fourth assumption that underlies the counterspeech doctrine is that a sufficient number of those exposed to false information also will be exposed to the countervailing true information . * ° Of course , if the previous assumptions hold true , then this exposure to true and accurate information will have its desired effect in terms 20 . See generally JAMES SUROWIECKI , THE WISDOM OF CROWDS XII ( 2004 ) ( arguing that “ under the nght circumstances , groups are remarkably intelligent , and are often smarter than the smartest people in them ’ ) . 21 . YocHAl BENKLER , THE WEALTH OF NETWORKS : How SocIAL PRODUCTION TRANSFORMS MARKETS AND FREEDOM 4 ( 2006 ) ( illustrating “ the nse of effective , large-scale cooperative efforts — peer production of information , knowledge , and culture ” ) . 22 . See Abrams v. United States , 250 U.S. 616 , 630 ( 1919 ) ( Holmes , J. , dissenting ) ( “ [ T ] he best test of truth is the power of the thought to get itself accepted in the competition of the market ” ) . 23 . See , eg. , Lyrissa Barnett Lidsky , Nobody 's Fools : The Rational Audience as First Amendment Ideal , 2010 U. ILL. L. REv . 799 , 801 ( discussing the “ rational audience ” assumption in First Amendment jurisprudence : “ The first of these assumptions is that audiences are capable of rationally assessing the truth , quality , and credibility of core speech ’ ) . 24 . See Goldman & Cox , supra note 11 , at 18 “ Thus , if consumers have no very strong preference for truth as compared with other goods or dimensions of goods , then there is no reason to expect that the bundle of intellectual goods provided and `` traded '' in a competitive market will have maximum truth content . If people valued falsehood , then perfect competition would provide falsehood in a Pareto-optimal way. ” ) . 25 . See McConnell v. FEC , 540 US . 93 , 258-59 ( 2003 ) ( Scalia , J. , concurring in part and dissenting in part ) . 26 . See , e.g. , Vincent Blasi , Reading Holmes through the Lens of Schauer : The Abrams Dissent , 72 NOTRE DAME L. REV . 1343 , 1357 ( 1997 ) , see also Richards and Calvert , supra note 9 , at 554-55 . 62 FEDERAL COMMUNICATIONS LAW JOURNAL Vol . 70 of contributing to an informed citizenry . Each of these are contentious assumptions in their own right. * ? However , as will be discussed below , economic and technological changes in the media ecosystem have led to conditions that further challenge many of these assumptions . A . The Counterspeech Doctrine in Practice Applications of the counterspeech doctrine have been wide ranging in media law and policy , as well as in industry practice . * * Below , are a few applications that have particular relevance to the focus on the structure and operation of the contemporary media ecosystem and its relationship to a well- functioning democracy . The well-known ( some might say notorious ) Fairness Doctrine is a useful case study of a rare instance in which the counterspeech doctrine has been utilized to justify government regulation. * ? The Fairness Doctrine required broadcast licensees to devote news coverage to controversial issues of public importance . * In providing such coverage , broadcasters were further required to devote time to competing perspectives on an issue. * ! So , for instance , if a news broadcast ran a story on new research asserting a link between cigarette smoking and cancer , the tobacco industry was entitled to demand that time be devoted to the perspective that the causal link between cigarette smoking and cancer had yet to be determined . And , importantly , this competing perspective needed to be broadcast during a day/time when a comparable number of viewers who viewed the initial broadcast could be reached . To the extent that the Fairness Doctrine essentially compelled additional , most likely contradictory , speech , it embodies the counterspeech doctrine and its commitment to “ more speech. ” The irony is that the Fairness Doctrine was eliminated in the late 1980s under the logic that the requirement to provide counterspeech “ chilled ” broadcaster coverage of controversial issues overall , ” essentially resulting in less speech rather than more speech . 27 . See generally DARREN BUSH , supra note 17 ; Ho & SCHAUER , supra note 15 , STANLEY INGBER , supra note 17 . 28 . See RICHARDS AND CALVERT , supra note 9 , at 553-585 . 29 . For a more detailed discussion of the Faimess Doctrine and its relationship to counterspeech , see Adam Welle , Campaign Counterspeech : A New Strategy to Control Sham Issue Advocacy in the Wake of FEC v. Wisconsin Right to Life , 2008 Wis. L. REV . 795 , 823- 825 . ( 2008 ) . 30 . KATHLEEN ANNE RUANE , FAIRNESS DOCTRINE : HISTORY AND CONSTITUTIONAL IssUES 2 ( 2011 ) ( noting that the Fairness Doctrine “ affirmatively established the duty of broadcast licensees to cover controversial issues of public importance in a fair and balanced manner ” ) ; See generally Report on Editorializing by Broadcast Licensees , 13 F.C.C . 1246 ( 1949 ) . 31 . RUANE , supra note 30 , at 2 ( “ Broadcasters .. . had the affirmative duty to determine what the appropriate opposing viewpoints were on these controversial issues , and who was best suited to present them. ” ) . 32 . See RUANE , supra note 31 at 6 ( “ The Commission examined the effect of its enforcement of the Fairness Doctrine upon broadcasters and came to the conclusion that the doctrine chilled speech substantially ’ ) . Issue 1 FAKE NEWS AND THE FILTER BUBBLE 63 In the case of the Fairness Doctrine , counterspeech was used to justify speech regulation . More often , it has been used to reject speech regulation . For instance , in the realm of political campaign advertising there has been a history of efforts to impose restrictions on the dissemination of false information . * * A useful example involves efforts in the state of Washington to impose a regulation that allowed a state agency to determine the veracity of campaign statements , and to fine campaigns found to disseminate false statements . * 4 These regulations were overturned by the Washington State Supreme Court for a host of reasons , * ° including a rejection of the State ’ s contention that protecting the integrity of elections represented a sufficiently compelling government interest . 3° According to the court , prohibiting “ arguably false , but nondefamatory , statements about political candidates to save our elections conflicts with fundamental principles of the First Amendment. ” ? ’ Moreover , the court explicitly argued that counterspeech represented the more appropriate mechanism for coping with falsity in political campaign communications . * * According to the court , “ [ oJur constitutional election system already contains the solution to the problem that RCW 42.17.530 ( 1 ) ( a ) is meant to address. ” * ? Quoting Brown v. Hartlage , the court noted that “ “ [ iJn a political campaign , a candidate 's factual blunder is unlikely to escape the notice of , and correction by , the erring candidate's political opponent . * ° The preferred First Amendment remedy of ‘ more speech , not enforced silence , ’ thus has special force. ’ ” * ! Thus , the court concluded , “ [ i ] n other words , the best remedy for false or unpleasant speech is more speech , not less speech. ” What is particularly important about both of these examples is the extent to which they reflect how the First Amendment will facilitate the dissemination of false news and information . However , the importance of the circulation of diverse ideas and viewpoints is so important that such falsity must be tolerated . This tolerance is accompanied by the confidence that a robust speech environment will allow truthful and accurate news and information to triumph over falsity . This position is well-reflected in the Supreme Court ’ s statement in Gertz v. Robert Welch , Inc. , that the First 33 . See Rickert v. State Pub . Disclosure Comm ’ n , 168 P.3d 826 , 827 n. 2-3 ( Wash. 2007 ) . 34 . Id 35 . Reasons included the court ’ s rejection of the notion that “ the State possesses an independent nght to determine truth and falsity in political debate , ” id at 827 , as well as the fact that the statute did not require proof of the defamatory nature of the speech , id at 828-829 . 36 . Jd . at 830-831 . 37 . Id at 831 . 38 . Jd . at 832 . 39 . Id 40 . Brown v. Hartlage , 456 U.S. 45 , 61 ( 1982 ) ( quoting Whitney v. California , 274 U.S. 357 , 377 ( 1927 ) ( Brandeis , J. , concurring ) . 41 . See Rickert 168 P.3d at 855 . 42 . Id at 855-56 . 64 FEDERAL COMMUNICATIONS LAW JOURNAL Vol . 70 Amendment requires protecting “ some falsehood in order to protect speech that matters. ” Compared to less-protected categories of speech , such as commercial speech , the First Amendment protections for political false speech — and thus the reliance upon counterspeech — are at their most pronounced . * * News organizations represent the most explicitly protected category of speakers ( as reflected in the “ of the press ” clause ) . * * For news organizations , since New York Times Co. v. Sullivan , ” legal liability for falsity has been largely limited to intentional and malicious falsities directed at individuals or organizations that are damaging to the individual ’ s or organization ’ s reputation . * ’ This focus is a reflection of the Supreme Court ’ s position that “ false statements of fact [ can ] cause damage to an individual ’ s reputation that can not easily be repaired by counterspeech , however persuasive or effective. ” * ® No such liabilities exist for the production and dissemination of journalistic falsities for the remaining political issues and concerns around which falsities could be generated , whether it be older examples , such as AIDS conspiracy theories or Holocaust denial , ” or more recent examples , such as the nature of the scientific evidence surrounding climate change , given the broad protections given to the press and its role in maintaining “ uninhibited , robust , and wide open ” political discussion . Sunilarly , the journalistic presentation of falsities about individuals or organizations that are beneficial rather than harmful are fully protected . So while a news outlet accusing a political figure of running a child sex ring out of a Washington , DC , pizza parlor could be vulnerable to a libel lawsuit , a news outlet that knowingly reports inflated figures for a candidate ’ s net worth or charitable donations ( thereby enhancing the candidate ’ s status with voters ) is in the clear , even if it is subsequently proven that this information was published with knowledge of its falsity , since in no way was the candidate ’ s stature or reputation damaged by the false information . The bottom line is that “ any test of truth ” when applying the First Amendment to the work of journalists has been rejected. * ! According to the Supreme Court in New York Times Co. v. Sullivan , “ [ ijnjury to official reputation error affords no more warrant for repressing speech that would 43 . See 418 US . 323 , 340-41 ( 1973 ) . 44 , See Frederick Schauer , Facts and the First Amendment , 57 UCLA L. REV . 897 , 912- 914 ( 2009-2010 ) . 45 . See Potter Stewart , “ Or of the Press ” , 26 HASTINGS L.J . 631 ( 1974-1975 ) . 46 . See 376 US . 254 ( 1964 ) . 47 . See generally ANTHONY LEWIS , MAKE No LAw : THE SULLIVAN CASE AND THE FIRST AMENDMENT ( 1991 ) . 48 . See Hustler Magazine , Inc. v. Falwell , 485 U.S. 46 , 52 ( 1988 ) . 49 . See Schauer , supra note 46 at 897 . For a discussion of the First Amendment protections for Holocaust deniers , see generally Jonathan D. Varatt , Deception and the First Amendment : A Central , Complex , and Somewhat Curious Relationship , 33 UCLA L. REv . 1107 , n. 27-29 and accompanying text . 50 . SeeN.Y . Times Co. v. Sullivan , 376 US . 254 , 270 ( 1964 ) . 51 . Jd at271 . Issue 1 FAKE NEWS AND THE FILTER BUBBLE 65 otherwise be free than does factual error .. ” ° ? From this standpoint , we can assume that the prevailing First Amendment position on fake news is the production , dissemination , and consumption of more news . Finally , it is important to note that counterspeech has become tightly integrated into the operation of the social media platforms and content aggregators that have become the eye of the storm for escalating concerns about the impact of false news on democratic decision-making . Facebook , for example , has commissioned a series of studies that highlights the prominence of counterspeech within the context of a variety of controversial issues across different countries . * ’ In addition , in 2016 , the company launched the Online Civil Courage Initiative , which states its mission as to “ [ t ] o promote the civil courage displayed by organizations and grassroots activists carrying out valuable counterspeech work online. ” “ 4 Facebook ’ s commitment to counterspeech is reflected in its description of the Online Civil Courage Initiative : “ We believe that engagement is more powerful than censorship in reforming prejudiced and bigoted opinions and voices , and are committed to amplifying campaigns which encourage positive dialogue and debate. ” In this statement , Facebook seems to suggest that the platform will work to enhance ( i.e . “ amplifying ” ) counterspeech to address prejudiced and bigoted opinions and voices . Along similar lies , Twitter has organized online convenings to facilitate discussions about strategies for producing and disseminating counterspeech through social media . * ° Google , in its 2017 testimony before the Senate Subcommittee on Crime and Terrorism about its initiatives to combat extremist content and disinformation on its platforms , highlighted that 52 . Id at 272 . 53 . See JAMIE BARTLETT & ALEX KRASODOMSKI-JONES , DEMOS , COUNTER-SPEECH ON FACEBOOK ( 2016 ) , https : / ( www.demos.co.uk/wp-content/uploads/2016/09/Counter-speech- on-facebook-report.pdf [ https : //perma.cc/YPW5-WPHN ] , JAMIE BARTLETT & ALEX KRASODOMSKI-JONES , DEMOS , COUNTER-SPEECH EXAMINING CONTENT THAT CHALLENGES EXTREMISM ONLINE ( 2015 ) , https : //www.demos.co.uk/wp-content/uploads/2015/10/Counter- speech . pdf [ https : //perma.cc/B YM6-MVW/7 ] . It is worth noting that while these studies seek to document the prevalence of counterspeech on Facebook , they do not seek to determine its effectiveness . 54 . See ONLINE CIVIL COURAGE INITIATIVE , FACEBOOK , https : //www.facebook.com/pg/OnlineCivilCourage/about/ [ https : //perma.cc/SW32-SF6X ] ( ast visited June 9 , 2017 ) . 55 . Id . 56 . See , e.g. , @ TweeSurfing , Counter Speech On Social Media : The New Age Activism , TWITTER , ( Dec. 2 , 2016 ) , https : //perma.ce/TYE7-XK9L . See also Colin Crowell , Our Approach to Bots and Misinformation , TWITTER BLoG ( June 14 , 2017 ) , https : //perma.cc/68UA-DSES ( “ Twitter ’ s open and real-time nature is a powerful antidote to the spreading of all types of false information . This is important because we can not distinguish whether every single Tweet from every person is truthful or not . We , as a company , should not be the arbiter of truth . Journalists , experts and engaged citizens Tweet side-by-side correcting and challenging public discourse in seconds . These vital interactions happen on Twitter every day ... . ” [ emphasis in original ] ) . 66 FEDERAL COMMUNICATIONS LAW JOURNAL Vol . 70 it is “ creating new programs to promote counterspeech on [ its ] platforms. ’ * ” These programs include efforts to redirect consumers of extremist propaganda toward content that counters those narratives , as well as efforts to encourage YouTube content creators to speak out against hate speech , xenophobia , and extremism. ” ® B . Critiques of Counterspeech To some extent , critiques that have been directed at counterspeech overlap with those directed at the overarching marketplace of ideas metaphor within which the counterspeech doctrine is embedded . This is particularly the case for those critiques that emphasize fundamental human characteristics and tendencies that could lead to the embracing of false news and information over true news and information . In light of the concerns that have arisen in the wake of the 2016 U.S. presidential election about the potential influence of fake news , ’ there appears to be a renewed interest in the vast literatures across fields , such as communication , cognitive psychology , and behavioral economics , that highlight fundamental human tendencies that can lead to the acceptance of false information over accurate information. ” This literature illustrates how established behavioral patterns , such as selective exposure , confirmation bias , heuristics for coping with information overload , and directionally motivated reasoning explain how false news can be favored over legitimate news. * ! 57 . See Extremist Content and Russian Disinformation Online : Working with Tech to Find Solutions : Hearing Before the Subcomm . on Crime and Terrorism of the S. Comm . the Judiciary , 115 '' Cong . ( 2017 ) ( Statement of Richard Salgado , Director , Law Enforcement and Information Security , Google ) . 58 . Id . 59 . See Weedon et al. , supra note 3 . 60 . See , e.g. , CASS SUNSTEIN , # REPUBLIC 71-97 ( 2017 ) , Elizabeth Kolbert , Why Facts Don ’ t Change Our Minds , THE NEW YORKER ( FEB. 27 , 2017 ) , https : //perma.cc/M354-3U YN , Parmy Olson , Why Your Brain May Be Wired to Believe Fake News , FORBES ( FEB. 1 , 2017 , 5:35PM ) , https : //perma.cc/UN3J-DFAC . It is beyond the scope of this paper to review these bodies of literature . For helpful reviews , see Derek E. Bambauer , Shopping Badly : Cognitive Biases , Communications , and the Fallacy of the Marketplace of Ideas , 77 U. COL. L. REV . 649 ( 2006 ) , Goldman & Cox , supra note 11 ; Ho & Schauer , supra note 15 . 61 . See , eg . R. Kelly Garrett & Natalie Jomini Stroud , Partisan Paths to Exposure Diversity . Differences in Pro- and Counterattitudinal News Consumption , 64 J. COMM . 680 , 693-94 ( 2014 ) , Michael A. Beam , Automating the News : How Personalized News Recommender System Design Choices Impact News Reception , 41 COMM . RES . 1019 , 1020-36 ( 2014 ) , D.J . Flynn , Brendan Nyhan & Jason Reifler , The Nature and Origins of Misperceptions : Understanding False and Unsupported Beliefs About Politics , 38 ADVANCES POL . PSYCHOL . 127,128-32 ( 2017 ) . For a more detailed discussion of the range of cognitive biases that can come into play see Bambauer , supra note 60 at 673-96 . See also Alessandro Bessi et . al. , Homophily and Polarization in the Age of Misinformation , 225 Eur . PHys . J . SPECIAL Topics 2047 ( 2016 ) ( discussing research showing a correlation between polarized social networks and participation in the consumption and spread of false news and information ) . Issue 1 FAKE NEWS AND THE FILTER BUBBLE 67 These are long-standing behavioral and psychological patterns. ” As Frederick Schauer has noted , “ [ t ] hat people believe things that are false comes as no surprise . That a large number of people believe things that are false despite being told the truth is also hardly a revelation. ” * The bottom line is that the notion of the “ rational audience , ” capable of processing speech from diverse sources , and capable of effectively and rationally assessing the truth , quality , and credibility , is much more an ideal-type in First Amendment theory than an empirical reality . * * What may be different today , however is the extent to which the U.S. media system is capable of counteracting these fundamental human tendencies . Instead , it may be exacerbating them. ” Other critiques have explored specific speech contexts , where it has been argued that the counterspeech doctrine is particularly ineffective . It has frequently been noted that the efficacy of counterspeech can depend upon a wide range of circumstances related to the character of the speech at issue . Hate speech , for mstance , has been singled out as being particularly resistant to the effects of counterspeech.® Hate speech may have a silencing effect on would-be speakers , inhibiting their ability to engage in counterspeech or it may impose unfair or dangerous burdens on those who engage in counterspeech.® Further , marginalized groups that often are the targets of hate speech may lack the access and resources to effectively reach all of those exposed to the initial speech . The counterspeech doctrine is a pillar of First Amendment theory that rests on an intellectual foundation that 1s somewhat shaky , at best . The critiques of counterspeech have focused on either the aspects of human psychology that work against counterspeech being consumed and/or having its intended effects , or on those types of speech that the mechanisms of counterspeech are less likely to affect. ” Largely absent from these critiques of the counterspeech doctrine are detailed considerations of how technological and structural changes in the media and information environment may impact the extent to which we can 62 . See , e.g. , Schauer , supra note 44 , at 899 . 63 . See Schauer , supra note 44 , at 898 . 64 . See generally Lidsky , supra note 23 . 65 . See infra notes 76-180 and accompanying text . 66 . See , e.g. , Blasi , supra note 26 , at 1357 , see also Richards and Calvert , supra note 9 , 67 . See Richard Delgado & David Yun , “ The Speech We Hate ” : First Amendment Totalism , the ACLU , and the Principle of Dialogic Politics , 27 ARIZ. ST.L.J . 1281 , 1292 ( 1995 ) . 68 . See , e.g. , OWEN M. FIss , THE IRONY OF FREE SPEECH 25-6 ( 1996 ) . 69 . See Mari J. Matsuda , Public Response to Racist Speech : Considering the Victim ’ s Story , in MARIJ . MATSUDA ET AL , WORDS THAT WOUND : CRITICAL RACE THEORY , ASSAULTIVE SPEECH , AND THE FIRST AMENDMENT 17 , 48 ( 1993 ) ( arguing that minority groups have “ diminished access to private remedies such as effective counterspeech ’ ” ) . 70 . See Schauer , supra note 46 , at 912-914 , see generally Man J. Matsuda , Public Response to Racist Speech : Considering the Victim ’ s Story , in WORDS THAT WOUND : CRITICAL RACE THEORY , ASSAULTIVE SPEECH , AND THE FIRST AMENDMENT 17 , 48 ( 1993 ) . 68 FEDERAL COMMUNICATIONS LAW JOURNAL Vol . 70 expect factual speech to overcome false speech.7 ! How might these technological changes affect the integrity of the counterspeech doctrine ? This question is the focus of the next section , which argues that the media ecosystem has evolved in ways that undermine the likelihood ( however slim it already may have been ) ” that true and high-quality news and information will overcome false and low-quality news information . In this regard , the arguments presented here can be layered upon the established critiques discussed above , thereby further calling into question the validity of the notion of more speech serving as an effective antidote to false speech . II . How TECHNOLOGICAL CHANGES UNDERMINE THE COUNTERSPEECH DOCTRINE The goal of this section is to consider the range of changes affecting the contemporary media ecosystem through the lens of counterspeech , with a particular focus on contemporary concerns about the prominence of fake news and the operation of filter bubbles . That is , how do these changes potentially affect the production , distribution , and consumption of legitimate versus false news and information ? A . The Relative Prominence of True Versus False News ” In considering the changes that have affected the media ecosystem over the past two decades , it makes sense to begin with the changing dynamics of news production . The technological and economic changes that have transformed the media ecosystems have had a number of intersecting effects that have , on the one hand , undermined the production of legitimate news , while at the same time enhanced the production of false news . 71 . For instance , see Schauer ’ s supra note 46 at 899 , wherein Schauer recognizes t the apparent “ increasing and unfortunate acceptance of factual falsity in public communication ” , but doesn ’ t explore how the evolution of the media sector might be contributing to this increase . 72 . See supra , notes 62-72 and accompanying text . 73 . It should be noted that this analysis starts from the premise that it 1s possible to make valid distinctions between “ legitimate ” and “ fake ” news . Certainly , as with all dimensions of speech classification ( e.g. , commercial vs. non-commercial speech , libelous vs. non-libelous speech ) , there will be areas of ambiguity and disagreement , but such ambiguity and disagreement does not invalidate the viability , legitimacy or importance of maintaining the distinction . See James Weinstein , Speech Characterization and the Limits of First Amendment Formalism : Lessons from Nike v. Kasky , 54 CASE WESTERN RESERVE L. REV . 1091 , 1093 ( 2004 ) ( “ In a typical free speech case , ... use of verbal formulae or case matching to determine the category in which to place the speech in question works well enough . There is often precedent so factually similar that it really is controlling ; or even in the absence of such truly controlling precedent , categorizing the speech in question one way rather than the other so clearly promotes the values underlying free speech doctrine that a judge can intuitively make the nght choice ” ) . Not surprisingly , efforts to clarify the concept of fake news or to develop more precise terminology , are ongoing ; see , e.g. , Claire Wardle & Hossein Derakhshan , INFORMATION DISORDER 4 ( 2017 ) ( developing the concept of “ information pollution ” as an alternative to “ fake news ’ ) . Issue 1 FAKE NEWS AND THE FILTER BUBBLE 69 In terms of the production of legitimate news , the ongoing economic crisis in journalism has been well documented. ” Key consequences of this crisis include : declines in the number of newspapers across the country , in the size of television newsrooms , and in the number of professional journalism positions. ” * The rise of various online news outlets , and the new opportunities technological change fostered for “ citizen journalism , ” have been interpreted by some as adequate countervailing forces in the wake of declines in traditional journalism ; however , the reality is that these developments have not been able to fully replace the declines in news workers or news reporting that have resulted from the declines affecting traditional media. ’ The troubling paradox here is that increases in the number of media outlets and channels have led to decreases in the production of genuime journalism . While it is difficult to reconcile this position with the apparent abundance of online news , it is more understandable if we consider a seldom discussed , and insufficiently researched , phenomenon in the realm of digital journalism : what is perhaps best described as parasitic journalism. ” ’ Parasitic journalism refers to news stories that have as their origins and foundation reporting produced by another media outlet. ” If one examines news stories produced by digital media outlets through this analytic lens , the proportion of the online news reporting that merits classification as original journalism declines dramatically . Indeed , this kind of parasitic journalism ( or “ vampire web pages , ” as they are sometimes called ) has emerged as a thriving business model , due in large part to the extent to which social media platforms facilitate 74 . See , eg . Leonard Downie , Jr. , & Michael Schudson , The Reconstruction of American Journalism , COLUM . J. REV . 1 ( Nov/Dec . 2009 ) , http : //archives.cjr.org/reconstruction/the_reconstruction_of_american.php [ https : //perma.cc/83MQJ-GQB8 ] ( “ As almost everyone knows , the economic foundation of the nation ’ s newspapers , long supported by advertising , is collapsing , and newspapers themselves , which have been the country ’ s chief source of independent reporting , are shrinking—literally . Fewer journalists are reporting less news in fewer pages , and the hegemony that near-monopoly metropolitan newspapers enjoyed during the last third of the twentieth century , even as their primary audience eroded , is ending . Commercial television news , which was long the chief rival of printed newspapers , has also been losing its audience , its advertising revenue , and its reporting resources ” ) , , C.W . Anderson et al. , Post-Industrial Journalism : Adapting to the Present 2 ( Colum . J . School / Tow Ctr . for Digital Journalism Rep. ) http : //towcenter.org/wp- content/uploads/2012/11/TOWCenter-Post_Industrial_ Journalism.pdf [ https : //perma.cc/U V9D-HPS8 ] . ( “ The effect of the current changes in the news ecosystem has already been a reduction in the quality of news in the United States ” ) . 75 . See BUR . LAB . STAT. , NEWSPAPER PUBLISHERS LOSE OVER HALF THEIR EMPLOYMENT FROM JANUARY 2001 TO SEPTEMBER 2016 ( Apr . 3 , 2017 ) , https : //www.bls.gov/opub/ted/2017/mobile/newspaper-publishers-lose-over-hal f-their- employment-from-january-200 | -to-september-2016.htm , https : //perma.cce/A4VT-22NH . 76 . See PEw RES . CTR , STATE OF THE NEWS MEDIA 2016 ( June , 2016 ) , http : //www.journalism.org/2016/06/15/state-of-the-news-media-2016/ , , [ https : //perma.cc/2_LAM-E72U ] . 77 . See generally The Future of Newspapers , THE INDEP . ( Nov. 13 , 2006 ) , http : //www.independent.co.uk/news/media/the-future-of-newspapers-5331270.html [ https : //perma.cc/8C WU-LK WM ] . 78 . Id . ( “ Although there 's an enormous amount of online news-related material , if you analyse it , very , very little is actually new fact , new information - it 's almost all parasitic journalism carried out either by broadcasters or newspapers. ” ) . 70 FEDERAL COMMUNICATIONS LAW JOURNAL Vol . 70 the ability to identify popular news stories , and then recycle and recirculate nearly identical versions of those stories that demonstrably drain the audience ( and thus , revenue ) away from the outlets that produced the original story. ” Ultimately , the apparent multitude of online news outlets masks a journalistic ecosystem in which original reporting is recycled and circulated by scores of under-resourced news outlets incapable in engaging in original reporting . * ° In many ways , this may be the true online echo chamber — the process by which the same reporting reverberates through outlet after outlet , often reconfigured and re-summarized in ways that sometimes seek to disguise the story ’ s true origins and that provide opportunities for original commentary — but not original reporting . The end result is that the bulk of the news produced continues to originate from a relatively small number of media outlets , each of whose economic capacity to produce news is in a continued state of decline. * ! The bottom line is that original reporting is costly to produce and , given the degrading economics of journalism , this production is in decline . Fake news , on the other hand , is far less costly to produce . * * Fabricated news stories do not require the same rigorous research , verification processes , or tramed professionals to produce . This is why fake news has a fairly extensive history — one that certainly predates the Internet and social media * ’ — with changes in communications technologies consistently affecting the dynamics of how fake news is produced , disseminated , and consumed . * * Today , fake news can be easily and effectively produced ( and monetized ) by a “ Macedonian ” teenager in his bedroom . * From this standpoint , the evolution of the media ecosystem has done nothing to make the production of false news and 79 . See Steven Rosenfeld & Ivy Olesen , Vampire Webpages Suck Content from Legitimate Progressive News Sites , ALTERNET ( Mar . 6 , 2017 ) , http : //www.alternet.org/media/vampire-webpages-suck-content-legitimate-progressive-news- sites [ https : //perma.cc/Y6BX-WF3N ] . 80 . Even producers of fake news engage in rampant cannibalization of other fake news producers . See Craig Silverman & Lawrence Alexander , How Teens in The Balkans Are Duping Trump Supporters with Fake News , BUZZFEED.COM ( Nov. 3 , 2016 ) , https : //www.buzzfeed.com/craigsilverman/how-macedonia-became-a-global-hub-for-pro- trump-misinfo ? utm_term=.jgOP8e208 # mcSdvo9bv [ https : //perma.cc/YCH9-8NN4 ] ( “ Most of the posts on these sites are aggregated , or completely plagiarized , from fringe and right-wing sites in the US ” ) . 81 . See supra notes 76-82 and accompanying text . 82 . See generally , Jamie Condliffe , Fake News is Unbelievably Cheap to Produce , MIT TEcH . R. ( June 14 , 2017 ) , https : //www.technologyreview.com/s/608105/fake-news-is- unbelievably-cheap/ . 83 . See , e.g. , David Uberti , The Real History of Fake News , COLUM . J. REV . ( Dec. , 15 , 2016 ) , http : /www.cjr.org/special_report/fake_news_history.php _ [ https : //perma.cc/K5FH- Z9C8 ] . 84 . See Jacob Soll , The Long and Brutal History of Fake News , POLITICO ( Dec. 18 , 2016 ) , http : //www . politico.com/magazine/story/2016/12/fake-news-history-long-violent-2 14535 [ https : //perma.cc/ZRR6-ZY35 | ( discussing impact of the printing press on production , dissemination , and consumption of fake news ) . 85 . See Samantha Subramanian , /nside the Macedonian Fake-News Complex , WIRED ( Feb. 15 , 2017 ) , https : //www.wired.com/2017/02/veles-macedonia-fake-news/ [ https : //perma.cc/AG3C-7D6Z ] ; Silverman & Alexander , supra note 80 . Issue 1 FAKE NEWS AND THE FILTER BUBBLE 71 information more economically challenging in the way that it has for legitimate news . On the contrary , the economics of false news have been enhanced as a result of the changes in systems of news distribution . * ° Thus , from the standpoint of the counterspeech doctrine , the relative production of legitimate news and information compared to false news and information is in the midst of perhaps an unprecedented decline . B . Diminished Gatekeeping and Distribution Barriers The shift in the relative prominence of legitimate versus false news is a function of the fact that the gatekeeping barriers that have traditionally curtailed the dissemination of false news relative to legitimate news have been dramatically reduced . The notion of gatekeeping barriers refers to the decision-making mechanisms controlling the type of news to which consumers have access .. ° ’ The mass media era was defined by gatekeeping bottlenecks , in which freedom of the press was “ guaranteed only to those that own one. ” * ® Effective distribution was confined to outlets , such as broadcast stations , cable networks/systems , newspapers , and magazines , all of which were relatively scarce for technological and economic reasons , and thus operated as news and information bottlenecks that wielded substantial gatekeeping power. * ? The Internet has provided the opportunity to circumvent these bottlenecks . As a consequence , the economic incentives for producing legitimate journalism have been undermined , even as , the opportunities to distribute news have increased , and the costs of distribution have decreased. ” Conversely , given the low costs associated with producing fake news , the diminished gatekeeping barriers and minimal distribution costs have enhanced the economic incentives for producing fake news. * ! The size of the potential market is , simply , larger. ? ? Even the gatekeeping to advertising dollars has been transformed in ways that enhance the opportunities for fake news outlets . Today , the allocation of online advertising dollars is increasingly handled by algorithmically-driven ad placement networks , given the overwhelming 86 . See infra notes 92-102 and accompanying text . 87 . See generally Pamela Shoemaker and Timothy Vos , GATEKEEPING THEORY ( 2009 ) . 88 . See AJ . Liebling , The Wayward Press : Do You Belong in Journalism ? NEw YORKER , ( May 14 , 1960 ) , at 109 . 89 . See Jonathan Taplin , The IP TV Revolution , in THE NETWORK SOCIETY 241 ( 2005 ) ( describing the “ critical transition from a media world of analog scarcity to ... digital abundance where any maker of content ( films , music , video games ) could have access to the world ’ s audience through a server based on demand media environment ” ) . 90 . See supra notes 78-83 and accompanying text . 91 . See Abby Ohlheiser , This is How Internet 's Fake News Writers Make Money , WASH. POST ( Nov. 18 , 2016 ) , https : //www.washingtonpost.com/news/the- intersect/wp/2016/11/18/this-is-how-the-internets-fake-news-writers-make- money/ ? utm_term=.7c4ee4d7e8d6 [ https : //perma.cc/V5S9-LBJS ] . 92 . Id 72 FEDERAL COMMUNICATIONS LAW JOURNAL Vol . 70 number of ad placement options. ” Often , online advertisers do not even know exactly where their advertisements are being placed. ” This is in stark contrast to the mass media era , when information about when and where advertisements were being placed was common knowledge. ” The end result is that , on the basis of the criteria embedded in the ad-placement algorithms , fake news sites have been on more or less equal footing with other online content providers . Even recent , initial efforts to ban known fake news outlets from major ad networks ( a response to the post-2106 fake news revelations ) appear to have — at least initially — proven not entirely effective . * Previously , the distribution and monetization of fake news would be prevented to some extent via the limited number of gatekeepers . * ’ Given their limited number , these gatekeepers had both the incentive and the opportunity to curb the dissemination of fake news . The incentive came from the fact that , in a far less fragmented media environment , neutral and objective ( and thus less likely to be false ) reporting represented an effective approach to attracting and retaining the largest possible audience . * * The opportunity came in the form of the substantial economic resources these outlets had to research and verify stories — resources that were a function of the economic health of these 93 . See Robert Thomson , News Corp. CEO on Fake News , ‘ Digital Duopoly ’ and What Role Advertising Plays in All of Jt , MEDIASHIFT ( Apr . 3 , 2017 ) , http : //mediashift.org/2017/04/news-corp-ceo-fake-news-digital-duopoly-role-advertising- plays/ [ https : //perma.cc/P382-B8VV ] . 94 . David laconangelo , Why Didn ’ t These Companies Know They Were Advertising on Breitbart ? CHRISTIAN SCIENCE MoNITOR ( 2016 , Nov. 30 ) , https : //www.csmonitor.com/Business/2016/1130/Why-didn-t-these-companies-know-they- were-advertising-on-Breitbart ( “ The fact that many of the companies apparently didn ’ t know that their ads were appearing [ on Breitbart ] seems to highlight how new ad technologies have loosened companies ’ grip over their brand ’ s associations ’ ) . 95 . Jd ( noting that it has become “ a lot easier for buyers to lose a degree of control over where their ads run ” ) . 96 . See Craig Silverman et al. , In Spite of the Crackdown , Fake News Publishers Are Sall Earning Money from Major Ad Networks , BUuZzFEED ( Apr . 4 , 2017 ) , https : //www.buzzfeed.com/craigsilverman/fake-news-real-ads [ https : //perma.cc/62GN- L72N ] . 97 . See AJ . Liebling , The Wayward Press ) Do You Belong in Journalism ? NEW YORKER , May 14 , 1960 , at 105 . 98 . See , e.g. , JAMES T. HAMILTON , ALL THE NEWS THAT ’ S FIT To SELL : How THE MARKET TRANSFORMS INFORMATION INTO NEWS 38 ( 2004 ) ( “ The evidence in this chapter demonstrates that independent news coverage grew as scale economies became more important ” ) , see also GERALD J. BALDASTY , THE COMMERCIALIZATION OF NEWS IN THE NINETEENTH CENTURY 28 ( 1992 ) . It should be noted that some researchers have questioned whether the development of the norm of objectivity is tied to the commercialization of the press . See , e.g. , Michael Schudson , The Objectivity Norm in American Journalism , 2 JOURNALISM 149 , 160 ( 2001 ) ( ‘ The notion that the move from partisanship to objectivity was economically motivated is widely believed but nowhere justified. ” ) . Issue 1 FAKE NEWS AND THE FILTER BUBBLE 73 outlets prior to the damaging effects of an increasingly fragmented media environment. ” This scenario of diminished bottlenecks and gatekeepers represents a tremendous opportunity for the production and dissemination of fake news . As has been well-illustrated in the months since the 2016 U.S. presidential election , many of those engaged in the production and distribution of fake news did so purely because of the tremendous economic opportunity it presented , not out of any ideological motivations . '°° Economic incentives to provide false news have always existed , given the appealing economics of false news production discussed above. ! ° ! The key point here is that the diminished barriers to entry ( and thus diminished institutional gatekeeping ) afforded by the Internet enhanced these incentives . These economic incentives have been further enhanced over the past few years by social media distribution. ’ Social media provides a means to more effectively capitalize on the diminished gatekeeping barriers facilitated by the Internet by providing previously unprecedented paths to low-cost distribution and large aggregations of audiences . Research indicates that social media referrals are a more crucial component of story distribution for hyper-partisan and fake news sites than they are for legitimate news sites. ‘ Another recent study found that , in the days before the 2016 election , many Twitter users received a higher volume of misinformation and conspiratorial content than professionally produced news . ! ™ 99 . See , eg. , Leonard Downie , Jr. , & Michael Schudson , The Reconstruction of American Journalism , COLUM . J. REV . 1 ( Nov/Dec . 2009 ) , http : //archives.cjr.org/reconstruction/the_reconstruction_of_american.php [ https : //perma.cc/KD6D-DBLM ] ( “ Commercial television news , which was long the chief rival of printed newspapers , has also been losing its audience , its advertising revenue , and its reporting resources. ” ) . 100 . See , e.g. , Subramanian , supra note 85 ( “ These Macedonians on Facebook didn ’ t care if Trump won or lost the White House . They only wanted pocket money to pay for things—a car , watches , better cell phones , more drinks at the bar. ” ) . As Adam Mosseri , Facebook ’ s Vice President of News , has stated , “ We ’ ve found that a lot of fake news is financially motivated. ” Adam Mossen , News Feed FYI : Addressing Hoaxes and Fake News , FACEBOOK ( Dec. 15 , 2016 ) , _ https : //newsroom.fb.com/news/2016/12/news-feed-fyi-addressing-hoaxes-and-fake- news/ [ https : //perma.cc/GT4S-X4QH ] ; Silverman & Alexander , supra note 82 ( “ Their reasons for launching these sites are purely financial , according to the Macedonians with whom BuzzFeed News spoke ” ) . 101 . See supra notes 84-88 and accompanying text . 102 . See generally Timothy B. Lee , Facebook 's Fake News Problem , Explained , Vox ( Nov. 16 , 2016 ) , http : //www.vox.com/new-money/2016/11/16/13637310/facebook-fake- news-explained [ https : //perma.cc/JV55-2MZP ] 103 . See Alexios Mantzarlis , Facebook Referrals are Crucial for Traffic to Hyperpartisan and Fake News Sites , POYNTER ( Nov. 28 , 2016 ) , https : //www.poynter.org/2016/facebook- referral s-are-crucial-for-traffic-to-hyperpartisan-and-fake-news-sites/440132/ [ https : //perma.cc/KT3K-YBAP ] . 104 . See Philip N. Howard et al. , Social Media , News and Political Information During the U.S. Election : Was Polarizing Content Concentrated in Swing States ? COMPROP DaTa MEMO ( Sept. 27 , 2017 ) , http : //comprop.oii.ox.ac.uk/wp- content/uploads/sites/89/2017/09/Polanizing-Content-and-Swing-S tates . pdf [ https : //perma.cc/53VP-PBY2 ] , at 1 ( finding that “ nationally , Twitter users got more misinformation , polarizing and conspiratorial content than professionally produced news ” ) . 74 FEDERAL COMMUNICATIONS LAW JOURNAL Vol . 70 It is important to emphasize that these social media platforms , like their mass media predecessors , also represent bottlenecks with substantial gatekeeping capacity . ! ° > The reality however , has been that , likely due to a combination of factors ( scale , technological limitations , economic incentives , organizational philosophy , ignorance ) , this gatekeeping authority has not been rigorously deployed to combat the dissemination of fake news . It is important to recognize that underlying this argument is the assumption that , regardless of the motivation , sources of news and information with more partisan orientations produce more false news than journalistic sources that adhere to more traditional notions of neutrality and objectivity . While perhaps controversial , this assumption is grounded in compelling empirical evidence. ! In sum , within the counterspeech doctrine ’ s valorization of “ more speech , ” the point here is that , in today ’ s news ecosystem , more of this “ more speech ” is likely to be false speech . C. Increased Ability to Target the Most Impressionable Within the context of the distribution of news , it is also important to take into consideration the ways in which the distribution of false news can now be more effectively targeted at those individuals most likely to be affected by the misinformation . Nicholas Negroponte ’ s famous speculation about the inevitability ( and desirability ) of The Daily Me provides a useful starting point for the rise of personalization in digital media . ' ’ Personalization is a data driven phenomenon , facilitated by the information backchannels that are inherent in interactive media . '° * As Negroponte predicted , interactive media have allowed people to craft their own individual news diets . Negroponte ’ s somewhat utopian perspective has since been tempered by concerns about the 105 . See Emily Bell , Facebook is Eating the World , Cou . J. REV . ( Mar . 7 , 2016 ) ( “ The largest of the platform and social media companies , Google , Apple , Facebook , Amazon , and even second order companies such as Twitter , Snapchat and emerging messaging app companies , have become extremely powerful in terms of controlling who publishes what to whom .... There isa far greater concentration of power in this respect than there ever has been in the past ” ) . 106 . See , e.g. , Kate Starbird , Examining the Alternative Media Ecosystem Through the Production of Alternative Narratives of Mass Shooting Events on Twitter ( 2017 ) ( unpublished manuscript ) , http : //faculty . washington.edu/kstarbi/Alt_Narratives ICWSM17- CameraReady.pdf [ https : //perma.cc/HS9M-8VF7 ] . The author notes that , “ [ n ] ot surprisingly , we found the conversation around alternative narratives of mass shooting events to be largely fueled by content on alternative ( as opposed to mainstream ) media. ” Jd at 9 . 107 . See NICHOLAS NEGROPONTE , BEING DIGITAL 153 ( 1996 ) . 108 . See generally , Mary Collins , Personalized Media : It ’ s All About the Data , TVNEWSCHECK ( 2017 , Sept. 8 ) , http : // ( www.tvnewscheck.com/article/107097/personalized- media-its-all-about-the-data . Issue 1 FAKE NEWS AND THE FILTER BUBBLE 75 political and cultural detriments of residing in such filter bubbles . ! Nonetheless , personalization continues to work its way through the news ecosystem , with even the New York Times recently launching an initiative to bring more data-driven personalization to the process of presenting stories to online news consumers. ! ! ° The key point here is that interactivity provides a stream of audience data that facilitates audience targeting and personalization to an unprecedented extent . Within the context of counterspeech , this means that those with an economic and/or political mterest in the dissemination of false news are now far better equipped than in the past to deliver their content to those they most desire to reach . Targeting exclusively right- or left-leaning news consumers ( or other , more specific political traits ) with false news or information has never been easier , as observable social media activity provides a host of reliable indicators of an individual ’ s political orientation. ' ! ! In these ways , the magnitude of the “ evil ” ( to use Brandeis ’ term ) ! ” that false speech can achieve is amplified . In the wake of the 2016 election , it was reported that Donald Trump ’ s campaign employed a consulting firm , Cambridge Analytica , which drew upon massive amounts of social media data to construct detailed psychological , demographic , and geographic profiles of individual voters . These data were then utilized by the Trump campaign to deliver micro- targeted political messages through social media platforms such as 109 . See , e.g. , Eli Pariser , THE FILTER BUBBLE : WHAT THE INTERNET IS HIDING FROM You ( 2011 ) ; SUNSTEIN , supra note 62 at 2 ( “ In the 1990s , the idea of a Daily Me seemed more than a little absurd . But it ’ s looking astoundingly good . If anything , Negroponte understated what was coming , what has now arrived , and what is on the horizon . Is that a promise or a threat ? I think it ’ s both — and that the threatening part is what needs to be emphasized , not least because so many people see it as pure promise ” ) ; Jon Keegan , Blue Feed Red Feed : See Liberal Facebook and Conservative Facebook , Side by Side , WALL ST. J . ( May 18 , 2016 ) , http : //graphics.ws ] .com/blue-feed-red-feed/ [ https : //perma.cc/8SPX-SBGA ] . For empirical evidence of filter bubbles , see Tien T. Nguyen et . al. , Exploring the Filter Bubble : The Effect of Using Recommender Systems on Content Diversity , in WWW ='14 IN PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WoRLD WIDE WEB 677 ( Apr . 2014 ) , http : //dl.acm.org/citation.cfm ? doid=2566486.2568012 [ https : //perma.cc/TH9X-KW9F ] , Alessandro Bessi et al. , Users Polarization on Facebook and YouTube , PLOS ONE ( Aug. 23 , 2016 ) , https : //doi.org/10.1371/journal.pone.0159641 [ https : //perma.cc/NASD-SG4P ] , Walter Quattrociocchi et al. , Echo Chambers on Facebook ( 2016 , June 13 ) ( unpublished manuscript ) , https : //papers.ssrn.com/sol3/papers.cfm ? abstract_1d=2795110 [ https : //perma.cc/PA95- WDGD ] . 110 . See Ricardo Bilton , All the News That ’ s Fit for You : The New York Times is Experimenting with Personalization to Find New Ways to Expose Readers to Stories , NIEMAN LAB ( Sept.28 , 2017 ) , http : / * www.niemanlab.org/2017/09/all-the-news-thats-fit-for-you-the- new-york-times-is-experimenting-with-personalization-to-find-new-ways-to-expose-readers- to-stories/ [ https : //perma.cc/QJ8T-XZ8P ] . 111 . See Elanor Colleoni et al. , Echo Chamber or Public Sphere ? Predicting Political Orientation and Measuring Political Homophily in Twitter Using Big Data , 64 J. oF COMMUNICATION 317 , 321 ( 2014 ) ( “ By classifying all the content posted according to its political orientation we are able to identify the general political onentation of the users and measure levels of political homophily in their network ” ) . 112 . See Whitney v. California , 274 U.S. 357 , 377 ( 1927 ) ( Brandeis , J. , concurring ) . 76 FEDERAL COMMUNICATIONS LAW JOURNAL Vol . 70 Facebook. ! ' Hundreds of Russian-operated Facebook accounts also have been found to have been engaging in such election-related micro-targeted advertising . '' 4 Congressional investigators are currently evaluating the content of these ads , so there is no clear sense yet of the extent to which false news or claims were delivered in these messages. ! ! ° However , the point here is that the technological capacity to target citizens with tailored messages or false news stories based on their characteristics appears to have taken yet another substantial leap forward , beyond what was possible through previous communications channels. ! ! ® From a false news perspective , according to a U.S. Senate investigation , the Russians working to spread fake news stories specifically targeted voters in swing states such as Wisconsin , Michigan , and Pennsylvania , ' ! ” with this geographic targeting facilitated by social media data . Further , according to the testimony of cybersecurity expert Clint Watts , some of these fake news outlets explicitly targeted Donald Trump , tweeting fake news stories directly to his Twitter account during time periods when he was known to be online , under the presumption that he has shown himself to be particularly susceptible 113 . See Issie Lapowsky , What Did Cambridge Analytica Really do for the Trump Campaign ? WIRED ( Oct. 26 , 2017 ) , https : /Awww.wired.com/story/what-did-cambridge- analytica-really-do-for-trumps-campaign/ [ https : //perma.cc/72E7-8WLL ] . For methodological details , see generally Joshua Green & Sasha Issenberg , /nside the Trump Bunker , with Days to Go , BLOOMBERG BUSINESSWEEK , _ https : //www.bloomberg.com/news/articles/2016-10- 27/inside-the-trump-bunker-with- 12-days-to-go [ https : //perma.cc/79L3-MVJV ] . 114 . See Alex Stamos , An Update on Information Operations on Facebook , FACEBOOK ( Sept/ 6 , 2017 ) , _ https : //newsroom.fb.com/news/2017/09/information-operations-update/ [ https : //perma.cc/ASRY-Z7F 5 ] . 115 . See Craig Timberg et al. , Facebook to Turn Over Thousands of Russian Ads to Congress , Reversing Decision , WASH. POST ( Sept. 21 , 2017 ) , https : //www . washingtonpost.com/business/technology/facebook-to-turn-over-thousands-of- russian-ads-to-congress-reversing-decision/2017/09/21/9790b242-9f00-1 1e7-9083- fbfddf6804c2_story.html ? utm_term=.0d6c72e30048 [ https : //perma.cc/RJSA-TM6H ] . 116 . See Zeynep Tufekci , Engineering the Public : Big Data , Surveillance , and Computational Politics , 19 FIRST MONDAY , http : //firstmonday.org/article/view/490 1/4097 [ https : //perma.ce/3_LWW-AWMC ] ( “ While computational politics in its current form includes novel applications , the historical trends discussed in this paper predate the spread of the Internet . In fact , there was already a significant effort underway to use big data for purposes of marketing , and the progression of using marketing techniques for politics — and “ selling of the President ” — clearly reflects longer-term trends . However , computational politics introduces significant qualitative differences to that long march of historical trends . Unlike previous data collection efforts ( for example , collating magazine subscriptions or car type purchases ) which required complicated , roundabout inferences about their meaning ( does a magazine subscription truly signal a voter preference ? ) and allowed only broad profiling in the aggregate , this data provides significantly more individualized profiling and modeling , much greater data depth , and can be collected in an invisible , latent manner and delivered individually [ . ] ’ ” ) . 117 . See Rachel Roberts , Russia Hired 1,000 People to Create Anti-Clinton Fake News in Key U.S. States During Election , Trump-Russia Hearings Leader Reveals , THE INDEP . ( Mar . 30 , 2017 ) ( According to Senator Mark Warner , “ [ i ] t ’ s been reported to me , and we ’ ve got to find this out , whether they were able to affect specific areas in Wisconsin , Michigan , Pennsylvania [ . ] ” ) . For further evidence of the targeting of fake news to swing state social media users , see Howard et al. , supra note 104 . Issue 1 FAKE NEWS AND THE FILTER BUBBLE 77 to fake news. ! ! 8 This is an extreme example of today ’ s highly personalized media environment enhancing the opportunities for purveyors of fake news to reach those both most likely and most important to be affected by the misinformation . One could certainly argue that these dynamics provide comparable opportunities for true and accurate news to target those news consumers most in need of being reached , or most vulnerable to fake news . The problem with this logic becomes clearer when factoring in the ways in which this process of personalization undermines the likelihood of exposure to counterspeech that directly addresses the false speech that has been consumed. ! ! ° D. The Diminished Likelihood of Being Exposed to Factual Counterspeech As Vincent Blasi has emphasized , one of the key conditions impacting the effectiveness of counterspeech is the extent to which “ the counter- message comes to the attention of all the persons who were swayed by the original idea. ” ' ? ° The dynamics of the contemporary media environment to some extent serve to explicitly prevent this type of exposure to counterspeech from taking place . This is the essence of the filter bubble phenomenon , in which the intertwining of individual and algorithmic content personalization ’ ? ! on social media and other news aggregation platforms works to deflect news sources and content that do not correspond to the user ’ s established content preferences and political orientation. ’ Certainly , this 118 . See MEDIA MATTERS FOR AMERICA , CNN . Fake News Trolls Pushing Conspiracy Theories “ Tweet Right at President Trump ” Hoping that “ He Cites it Publicly ( Mar . 30 , 2017 ) https : //www . mediamatters.org/video/2017/03/30/cnn-fake-news-trolls-pushing-conspiracy- theories-tweet-right-president-trump-hoping-he-cites-it/2 15878 [ https : //perma.cc/35GH- 43VN | ( “ WOLF BLITZER ( HOST ) : Do these fake news trolls sometimes actually target President Trump himself ? BRIAN TODD : According to the cybersecurity expert Clint Watts who you had on earlier , Wolf , they do , in fact , do that . Watts testified today that some outlets pushing fake or misleading stories will tweet nght at President Trump during high volume periods when they know he 's online . They 're pushing conspiracy theories hoping that he clicks on one and cites one publicly. ” ) . 119 . See infra notes 122-136 and accompanying text . 120 . See Blasi , supra note 26 , at 1357 . 121 . See Eytan Bakshy et al. , Exposure to Ideologically Diverse News and Opinion on Facebook , 348 SCIENCE 1130 , 1130 ( June 5 , 2015 ) ( “ The media that individuals consume on Facebook depends not only on what their friends share but also on how the News Feed ranking algorithm sorts these articles and what individuals choose to read. ” ) , Philip M. Napoli , Social Media and the Public Interest : Governance of News Platforms in the Realm of Individual and Algorithmic Gatekeepers , 39 TELECOM . PoL ’ y 751 ( Oct. 2015 ) . 122 . See Sunstein , supra note 60 , Seth R. Flaxman et al. , Ideological Segregation and the Effects of Social Media on News Consumption , at 1 ( May 2014 ) ( unpublished manuscript ) , https : //bfi uchicago.edw/sites/default/files/research/flaxman_goel_rao_onlinenews.pdf ( finding that “ recent technological changes do increase ideological segregation ’ ) . For critiques of the filter bubble logic and some contrary empirical findings , see Mark S. Nadel , Customized News Service and Extremist Enclaves in Republic.com , 54 STANFORD L. REV . 831 ( 2002 ) , Jacob L. Nelson , Js Fake News a Fake Problem ? COLUMBIA J. REV . ( January 31 , 2017 ) , https : //www.cjr.org/analysis/fake-news-facebook-audience-drudge-breitbart-study.php . 78 FEDERAL COMMUNICATIONS LAW JOURNAL Vol . 70 process of deflection works both ways . That is , one ’ s filter bubble might deflect fake news that contradicts previously-consumed legitimate news . Or , it might deflect legitimate news that contradicts previously-consumed false news . But here again is where the extent to which the filter bubbles have a partisan orientation comes into play . Given the empirical connection between partisanship and falsity , ' ? to the extent one ’ s filter bubble has a partisan orientation , the likelihood of fake news making it through the filter bubble increases . 4 At the same time , the likelihood of legitimate news that counteracts that fake news decreases. ! * * The current state of play is perhaps best termed the “ Spiral of Partisanship. ” ! ° In this scenario , the increased media fragmentation and personalization that began in the 1980s with the development of cable television ; then accelerated through the 90s and 2000s with the rise of the Internet and social media , simultaneously facilitates the mutually dependent phenomena of the rise of more partisan news outlets and the selective exposure to more partisan news . These are mutually dependent phenomena in that partisan news outlets require an audience to justify their existence and more partisan news consumption requires the availability of more partisan news outlets . And so , as the media environment grows more fragmented , its ability to both sow and satisfy increasing partisanship is amplified . ! ” ’ It is likely no coincidence that the upswing in self-reported partisanship begins in the 1980s , at the same time that media fragmentation begins in earnest , primarily through 123 . See Starbird , supra note 106 . 124 . See , e.g , Delia Mocanu et al. , Collective Attention in the Age of ( Mis ) information , 51 Comp . IN Hum . BEHAV . 1198 , 1202 ( 2015 ) ( finding that “ users with strong preferences for alternative information sources .. . are more susceptible to false information ” ) , Alessandro Bessi et al. , Science vs Conspiracy . Collective Narratives in the Age of Misinformation , PLOS ONE at | ( finding that “ polarized communities emerge around distinct types of contents and usual consumers of conspiracy news result to be more focused and self-contained on their specific contents ” ) . 125 . See Quattrociocchi et al. , supra note 109 . 126 . This term is used in reference to the well-known Spiral of Silence , which has posited that individuals who perceive their opinion to be in the minority will choose not to express that opinion , thus feeding into a downward spiral that systematically silences more and more of those holding that minority opinion , thereby creating a false impression of a widely-shared majority opinion . See ELIZABETH NOELLE NEUMAN , THE SPIRAL OF SILENCE : PUBLIC OPINION — OUR SOCIAL SKIN ( 1994 ) . 127 . See JONATHAN M. LADD , WHY AMERICANS HATE THE MEDIA AND How IT MATTERS ( 2011 ) Gllustrating how increased media fragmentation has interacted with demand for more partisan news to amplify partisanship and distrust of institutional news media ) . Issue 1 FAKE NEWS AND THE FILTER BUBBLE 79 the rise of cable television. ! * * And , as data tell us , consumers of partisan news are both more likely to consume false news ! ’ and possibly are inherently more resistant to counterspeech that corrects that false news. ! * ° Therefore , the net effect is one in which the dynamics of the contemporary media ecosystem tilt the balance toward the consumption/impact of fake news to an extent that was not the case in the pre-filter bubble era . This dynamic is particularly damaging to traditional articulations and applications of the counterspeech doctrine . Traditional approaches to counterspeech have essentially operated under a broadcast-era model of media distribution . Consider the Fairness Doctrine , which operated under the assumption that counterspeech presented on the same platform and at the same time of day as the original speech would be effective. '' ! Such an assumption seems at best quaint , and at worst utterly anachronistic , when applied to today ’ s media environment of intertwined individual and algorithmic content filtering , ! * * in which filter bubbles have been constructed in ways that often are fundamentally oriented toward deflecting counterspeech . From this standpoint , it seems reasonable to suggest that the ability of counterspeech to reach exactly those it needs to reach has been diminished as a result of the technological changes that have affected the media ecosystem . E. The Diminished Ability to Distinguish Between Legitimate and False News Technological changes are undermining news consumers ’ abilities to distinguish between legitimate and false news . In illustrating this point , it is important to begin with the unique challenges associated with evaluating news . To do so , it is useful to begin with how consumers evaluate the quality of the products that they consume . Economists generally recognize three 128 . See Amanda Taub , The Real Story About Fake News is Partisanship , N.Y .TIMES ( Jan. 11 , 2017 ) , https : /Awww.nytimes.com/2017/01/11/upshot/the-real-story-about-fake-news- is-partisanship.html [ https : //perma.cc/DQ34-XERP ] ( “ [ S ] tarting in the 1980s , Americans began to report increasingly negative opinions of their opposing party. ” ) . For a more detailed discussion of the relationship between fragmentation and political polarization , see RICARDO GANDOUR , A NEW INFORMATION ENVIRONMENT : How DIGITAL FRAGMENTATION IS CHANGING THE WAy WE PRODUCE AND CONSUME NEws ( 2016 ) , https : //knightcenter.utexas.edu/books/NewInfoEnvironmentEnglishLink . pdf [ https : //perma.cce/8KZA-WG7A ] . 129 . See Delia Mocanu et al. , supra note 124 . 130 . See R. Kelly Garrett et al . Driving a Wedge Between Evidence and Beliefs : How Online Ideological News Exposure Promotes Political Misperceptions , 21 J . OF COMPUTER- MEDIATED Com . 331 , 344 ( 2016 ) ( “ In the month leading up to the election , a quarter of Americans said they used biased news sites several times or more . Reliance on these websites appears to produce a distorted understanding of evidence , potentially promoting inaccurate beliefs even when evidence is understood correctly . It is sobering to recognize that online news may contribute to misperceptions even when consumers encounter a range of outlets and have been exposed to more accurate political information ” ) . 131 . See Ruane , supra note 30 . 132 . See Napoli , supra note 121 . 80 FEDERAL COMMUNICATIONS LAW JOURNAL Vol . 70 categories of goods : 1 ) search/inspection goods , for which quality can be readily determined through examination ; 2 ) experience goods , for which quality can be determined only after usage for a period of time ; and 3 ) credence goods , which must be consumed on faith , as quality is difficult to ascertain. ! News can sometimes fall into the second category ( say , for example , when the local newscast reports rain for tomorrow , but it ends up snowing instead ) . ' * 4 But more often , news is likely to fall into the third category , with news being consumed , and potentially being put to use in decision-making , in ways that do not always result in the kind of observable feedback that allows for a subsequent evaluation of the veracity or quality of that reporting . '°5 When it comes to the evaluation of any kind of product , the notion of “ bounded rationality ” comes into play . ! °° And news consumers typically are extremely rational , lacking the necessary information to make fully informed determinations as to the quality of the product they are consuming . This 1s a reflection of the fact that “ by definition , news is what the public does not know. ” ! * ’ For these reasons , the consumption of false news is to some extent a function of receiving inadequate information ( interacting with the various cognitive biases discussed above ) , ! * * and the resulting inability of consumers to distinguish between true and false information , and thus consuming fake news under the misperception that it is truthful . The challenge of accurately distinguishing between true and false news is further exacerbated by the dramatic increase in available news and information sources online , which places a greater cognitive burden on news consumers in terms of distinguishing between legitimate and false news sources and stories. ! ? 133 . See John H. McManus , What Kind of Commodity is News ? 19 COMMC ’ N RESEARCH 787 , 794 ( 1992 ) . 134 . In this situation , news is not unlike a “ lemon ” purchased from an automobile seller . The poor quality of the information ( or car ) is not revealed until well after the purchase is finalized . See George A. Akerlof , The Market for “ Lemons ” : Quality Uncertainty and the Market Mechanism , 84 Q.J . oF Econ . 488 , 490-91 ( 1970 ) ( discussing “ asymmetrical information ” ) . 135 . Seeld 136 . For an overview and advocacy of the concept of bounded rationality , see generally John Conlisk , Why Bounded Rationality ? , 34 J. oF ECon . LIT . 669 ( 1996 ) . For a discussion of the concept ’ s relationship to the marketplace of ideas metaphor , see generally Joseph Blocher , Institutions in the Marketplace of Ideas , 57 DUKE L.J . 821 ( 2008 ) . 137 . See McManus , supra note 133 , at 793 . 138 . See Garrett & Stroud , supra note 61 . 139 . See , e.g. , Olivia Solon , Only 20 % of US . Adults Have Information Overload . but Those Who do Feel the Burden , THE GUARDIAN ( Dec. 7 , 2016 ) , https : //www.theguardian.com/technology/2016/dec/07/information-overload-pew-study- digital-divide . [ https : //perma.cc/647C-C5QP ] , Xiaoyan Qiu et al. , Lack of Quality Discrimination in Online Information Markets ( January 2017 ) ( unpublished manuscript ) ( on file with ResearchGate ) , https : //www.researchgate net/publication/312194354 Lack of quality discrimination in on line_information_markets [ https : //perma.cc/E3R6-UFWV ] . Issue 1 FAKE NEWS AND THE FILTER BUBBLE 81 Of particular importance is the extent to which the traditional mechanisms for combating this sort of uninformed consumption have been undermined by technological change . For instance , the reputations of news outlets long have served as a way for consumers to distinguish between truth and falsity. “ ° Reputations have often been identified as an important factor to facilitate efficient markets for experience and credence goods . ! The reputation of the New York Times for being truthful and accurate has generally been better than that of the National Enquirer . This important heuristic , however , is being undermined as news consumption migrates to news aggregators and social media platforms . This is most compellingly demonstrated by research showing how seldom news consumers know the actual source of the news they are consuming . For example , recent research by the Pew Research Center indicates that individuals who consume news via social media are capable of identifying the originating source of the story consumed only about half the time. ' * ? Further , this traditional outlet reputation-based mechanism for evaluating the likely truthfulness of a news story is being replaced by a new heuristic — the trustworthiness of the individual who shared the story on social media. ' “ ? Thus , an article shared by a trusted member of an individual ’ s social network , but written by a source unknown to that individual , will be evaluated as more trustworthy — and thus be more likely to be consumed and shared — than an article produced by a reputable news source but shared by someone viewed as less trustworthy. ’ This halo effect extends to news brands as a whole , with individuals more likely to follow and recommend news outlets that were referred to them by trusted members of their social network . ! 4 Given that the filter bubble dynamic discussed above is a function of the ideological homogeneity that characterizes many individuals ’ social 140 . See Miriam J. Metzger et al. , Social and Heuristic Approaches to Credibility Evaluation Online , 60 J. COMM . 413 , 426 ( 2010 ) ( “ One of the most prevalent heuristics used for evaluating credibility that was mentioned by focus group participants was relying on site or source reputation. ” ) . 141 . See Steffen Huck et al. , Pricing and Trust 1 ( Feb. 2008 ) ( unpublished manuscript ) ( on file with Paris School of Economics ) ( noting that “ [ w ] henever contracts for the exchange of a good are incomplete and sellers have leeway to shade its quality about which the consumer finds out only if it is too late ... A key role in markets for such goods is assumed by trust ” ) , https : //www.parisschoolofeconomics.eu/IMG/pdf/Huck2 . pdf [ https : //perma.cc/RS7B- EWVX ] . 142 . See Amy Mitchell et al .. How Americans Encounter , Recall and Act Upon Digital News , PEw RES . CTR . ( Feb. 9 , 2017 ) , http : /www.journalism.org/2017/02/09/how-americans- encounter-recall-and-act-upon-digital-news/ . [ https : //perma.cc/L6JG-VQQA ] . 143 . See generally , THE MEDIA INSIGHT PROJECT , “ WHO SHARED IT ? ” : How AMERICANS DECIDE WHAT NEWS To TRUST ON SOCIAL MEDIA ( 2017 ) , http : //mediainsight.org/PDFs/Trust®20Social % 20Media % 20Experiments % 202017/Medialns ight Social % 20Media % 20Final.pdf [ https : //perma.cc/ED2R-YHEK ] . 144 . Id at4-9 . 145 . Jd at 10 ( “ Those who trusted the sharer but saw the unknown outlet were more likely than those who did not trust the sharer and saw the reputable outlet to share the article , follow the sharer , sign up for news alerts from the source , and recommend the source to friends. ” ) . 82 FEDERAL COMMUNICATIONS LAW JOURNAL Vol . 70 networks , ' * ° the situation once again presents itself in which the likelihood of exposure to counterspeech is being undermined by the social media context in which news consumption is increasingly taking place . These dynamics help to explain recent findings indicating that trust in mainstream news outlets is much lower than the levels of trust that news consumers place in the news outlets catering to their ideological orientation. ” The distribution of trust in news organizations is essentially being reallocated in ways that favor the consumption and acceptance of fake news over legitimate news , which works against the effectiveness of counterspeech . Ultimately , if news consumers are increasingly unable to accurately gauge whether a news source ’ s reporting is likely to be true or false , then more speech ( 1.e .. , counterspeech ) does nothing to assure that truth prevails and that democratic decision-making is well-informed . ! “ * Moreover , news consumers need to consider the issue of intentional misrepresentation of news sources . Political propaganda has always been a part of political campaigns . ‘ 4 ? Under the logic of counterspeech , false propaganda should be effectively counteracted by true and accurate news and information . However , a key means of enhancing the effectiveness of false propaganda involves disguising the source . °° Propaganda disguised as 146 . See Itai Himelboim et al. , Birds of a Feather Tweet Together : Integrating Network and Content Analyses to Examine Cross-Ideology Exposure on Twitter , 18 J. COMPUTER- MEDIATED Como . 40 , 40 ( Jan. 2013 ) ( finding that “ Twitter users are unlikely to be exposed to cross-ideological content from the cluster of users they followed as these were usually politically homogeneous ” ) , Andrei Boutyline & Robb Willer , The Social Structure of Political Echo Chambers : Variation in Ideological Homophily in Online Networks , 38 POL . PSYCHOL . 551 , 566-567 ( 2017 ) ( finding that more ideologically extreme individuals have more homophilous social networks , which should “ result in networks that embed their members in denser webs of like-minded associations , which could then insulate individuals from the demotivating effects of dissenting views , and may enable political behaviors to spread faster than they would through sparser networks ” ) . 147 . See Amy Mitchel et . al. , Political Polarization & Media Habits , PEw RES . CTR . ( Oct. 21 , 2014 ) ( showing “ little overlap in the news sources [ liberals and conservatives ] turn to and trust ” ) , http : //www jourmalism.org/2014/10/21/political-polarization-media-habits/ . [ https : //perma.cc/MR4D-DUHL ] ; “ My ” Media Versus “ The ” Media : Trust In News Media Depends on Which News Media You Mean 1 , MEDIA INSIGHT PROJECT ( May 2017 ) , http : //www . mediainsight.org/PDFs/Meaning % 200f % 20Media/APNORC_ Trust_The Media_ Topline final.pdf . https : //perma.cc/N6FQ-5M5E . ( finding that “ on many fronts , Americans are skeptical of ‘ the news media ’ in the abstract but generally trust the news they themselves rely on ” ) . 148 . See Goldman & Cox , supra note 11 , at 23 . 149 . For a comprehensive overview of the history of propaganda and its use in political campaigns , see generally Garth S. Jowett & Victoria J. O ’ Donnell , Propaganda & Persuasion ( 6 '' ed . ) ( 2014 ) . 150 . See Jessie Daniels , Cloaked Websites : Propaganda , Cyber-Racism and Epistemology in the Digital Era . 11 NEW MEDIA & SOCIETY 658 , 660 ( 2009 ) ( “ The emergence of websites such as Weltner ’ s Katrina Families and American Civil Rights Review illustrates a central feature of propaganda and cyber-racism in the digital era : the use of difficult-to-detect authorship and hidden agendas intended to accomplish political goals. ” ) . Issue 1 FAKE NEWS AND THE FILTER BUBBLE 83 legitimate news has proven to be particularly effective. ! * ! What is different now is the extent to which propaganda can be effectively disguised as legitimate news. ! * * This is a function of the diminished barriers to entry and institutional gatekeeping , which operate in concert with the enhanced distribution capacity of social media . The degree to which propaganda operations can masquerade as news outlets is much greater in an environment in which legitimate and illegitimate news outlets can all exist side-by-side on social media platforms. ' ? This is well-illustrated by the report that as many as 1,000 Russians were actively engaged in the production and distribution of fake news through social media during the 2016 election . An analysis of Russia ’ s online propaganda efforts emphasized Russia ’ s utilization of a multiplicity of online sources that are often disguised as news outlets. ! * In a 2012 television interview on the influence of money on political campaigning , the late , conservative Supreme Court Justice ( and established counterspeech enthusiast ) Antonin Scalia was asked how Thomas Jefferson would likely have viewed the contemporary political communication environment. ! * ° Scalia ’ s reply was , “ I think Thomas Jefferson would have said ‘ the more speech the better. ” That ’ s what the First Amendment 1s all about. ” ! * ’ He followed that statement , however , with this important caveat : “ so long as the people know where the speech is coming from. ” * * Thus , even from a traditionalist First Amendment perspective , the counterspeech doctrine is not absolute , and 1s especially vulnerable when the true source of news or information is disguised . 151 . Ja at 662 ( “ Organizations and individuals who deploy the strategies of ‘ black ’ and ‘ grey ’ propaganda online via cloaked websites can be more effective precisely because they conceal their intention and authorship. ” ) . 152 . Research indicates that social media users find it particularly difficult to accurately distinguish news posts from other types of social media posts . See Emily K. Vraga et al. , Blurred Lines : Defining Social , News , and Political Posts on Facebook , 13 LINFo . & TECH.POL . 272 , 272 ( 2016 ) ( “ [ U ] sers and researchers often agree on defining social and political content , but are more likely to disagree on categorizing news content. ” ) . 153 . Technological changes are likely to further enhance the ability to disguise fake news as legitimate news . See Nick Bilton , Fake News is About to Get Even Scarier than You Ever Dreamed , VANITY FAIR ( Jan. 26 , 2017 ) , http : /Awww.vanityfair.com/news/2017/01/fake-news- technology . [ https : //perma.cc/93U3-4MY9 ] ( “ At corporations and universities across the country , incipient technologies appear likely to soon obliterate the line between real and fake . Or , in the simplest of terms , advancements in audio and video technology are becoming so sophisticated that they will be able to replicate real news—real TV broadcasts , for instance , or radio interviews—in unprecedented , and truly indecipherable , ways ” ) . 154 . See Roberts , supra note 117 . 155 . See Christopher Paul & Miriam Matthews , The Russian “ Firehouse of Falsehood ” Propaganda Model . RAND COoRP . : PERSP . ( 2016 ) , http : //www.rand.org/content/dam/rand/pubs/perspectives/PE100/PE198/RAND PE198.pdf , https : //perma.cc/U3N8-5LXV ( “ [ T ] here are dozens of proxy news sites presenting Russian propaganda , but with their affiliation with Russia disguised or downplayed. ” ) . 156 . See Piers Morgan Tonight ( air date : Jul . 18 , 2012 at 21:00 ET ) , CNN , http : //www.cnn.com/TRANSCRIPTS/1602/13/cenr.12.html , [ https : //perma.ce/5C42-7MUX ] . 157 . Id . 158 . Jd ( emphasis added ) . 84 FEDERAL COMMUNICATIONS LAW JOURNAL Vol . 70 It is important to note that even mainstream news outlets have , on many occasions , shown themselves to be unable to distinguish between legitimate news and fake news , and thus have contributed to the dissemination of fake news. ! ° ? Parasitic journalism is an increasingly prominent dimension of the news ecosystem , with news outlets facing diminished resources to produce their own reporting or to rigorously verify the reporting of other news outlets. ’ These patterns increase the likelihood that legitimate news outlets will facilitate the dissemination of fake news and thereby legitimize it for some news consumers . Thus , it is not surprising that recent research has illustrated that the false news stories emanating from “ hyper-partisan ” nght-wing news sites were able to influence the agenda of the mainstream news media. ' * ! From a counterspeech perspective , this means that even the key providers of the legitimate news that is intended ( according to the counterspeech doctrine ) to overcome false news are not only operating at a diminished capacity to counteract false news , but are sometimes even complicit in its perpetuation . And then , of course , there is the question of how well new distributors of news ( 1.e. , social media platforms ) are capable of distinguishing between true and false news , and whether they take action on the basis of such distinctions . Certainly , in the wake of the election these platforms have ratcheted up their efforts to identify and curtail the spread of fake news 159 . For a discussion of the challenges to the journalistic process of verifying news and information disseminated online , see Alfred Hermida , Tweets and Truth : Journalism as a Discipline of Collaborative Verification , 6 JOURNALISM PRAC . 659 ( 2012 ) . 160 . See The Future of Newspapers , supra note 79 . 161 . See Yochai Benkler etal. , Study . Breitbart-Led Right-Wing Media Ecosystem Altered Broader Media Agenda , CoLUM . JOURNALISM . REV . ( Mar . 3 , 2017 ) , http : //www.cjr.org/analysis/breitbart-media-trump-harvard-study.php , _ttps : //perma.cc/B4K8- ULQA ( “ Our own study of over 1.25 million stories published online between April 1 , 2015 and Election Day shows that a right-wing media network anchored around Breitbart developed as a distinct and insulated media system , using social media as a backbone to transmit a hyper- partisan perspective to the world . This pro-Trump media sphere appears to have not only successfully set the agenda for the conservative media sphere , but also strongly influenced the broader media agenda , in particular coverage of Hillary Clinton. ” ) . Issue 1 FAKE NEWS AND THE FILTER BUBBLE 85 stories . ! © Whether these efforts have thus far been successful has been called into question . ! ® The bottom line , however , is that when previous iterations of content distributors ( cable systems , broadcast networks , book distributors , etc . ) are compared to today ’ s social media platforms , social media platforms know far less about the sources and content they are distributing ( given the massive scale at which they operate ) than any previous generation of content distributor. ‘ In this regard , their relatively limited ability to distinguish between fake and legitimate news stories/sources — their bounded rationality — has been transferred to the news consumer . F. The Enhanced Speed at Which False News Can Travel Finally , it is important to consider how changes in media technology have altered the speed at which fake news can travel . The issue of speed is particularly important given that Brandeis ’ original articulation of the counterspeech doctrine notes that counterspeech represents the appropriate remedy to false speech only “ If there be time . . . ” ! ° > This is a very important qualification to take into consideration within the context of today ’ s media ecosystem , in which news can “ go viral. ” ! It has been well documented how advances in media technologies have compressed the “ news cycle ” and facilitated ever greater immediacy in the 162 . See Josh Constine , Facebook Shows Related Articles and Fact-Checkers Before You Open Links , TECHCRUNCH ( Apr . 25 , 2017 ) , https : //techcrunch.com/2017/04/25/facebook- shows-related-articles-and-fact-checkers-before-you-open-links/ . https : //perma.ce/P243- XPQE ; Fergus Bell , Here ’ s a List of Initiatives that Hope to Fix Trust in Journalism and Tackle Fake News , MEDIUM ( Apr . 25 , 2017 ) , https : //medium.com/ @ ferg/heres-a-list-of-initiatives- that-hope-to-fix-trust-in-journalism-and-tackle-fake-news-30689feb402 . https : //perma.cc/W72T-KQG6E ; See also Testimony of Sean J. Edgett , Acting General Counsel , Twitter , Inc. , S. Comm . on the Judiciary , Subcomm . on Cnme and Terrorism ( October 31 , 2017 ) , https : //www._judiciary.senate.gov/imo/media/doc/10-31- 17 % 20Edgett™20Testimony.pdf . [ https : //perma.cc/YN59-VF5Z ] ; Testimony of Richard Salgado , Senior Counsel , Law Enforcement and Information Security , Google , S. Comm . on the Judiciary , Subcomm . on Cnme and Terrorism ( October 31 , 2017 ) , https : //www judiciary .senate.gov/imo/media/doc/10-31-17 % 20Salgado % 20Testimony . pdf . [ https : //perma.cc/SGAS-T6FJ ] ; Testimony of Colin Stretch , General Counsel , Facebook , S. Comm . on the Judiciary , Subcomm . on Cnme and Terrorism ( October 31 , 2017 ) , https : //www _judiciary.senate.gov/imo/media/doc/10-31-17 % 20Stretch * s20Testimony . pdf . [ https : //perma.cc/472D-H32W ] . 163 . See , e.g , Sam Levin , Facebook Promised to Tackle Fake News . But the Evidence Shows it ’ s not Working , THE GUARDIAN ( May 16 , 2017 , 5:00 EDT ) , https : //www.theguardian.com/technology/2017/may/16/facebook-fake-news-tools-not- working [ https : //perma.cc/TQP6-R7KD ] . 164 . Indeed , one could convincingly argue that the goal of these platforms is to host as many speakers , and as much speech , as possible , with relatively little consideration given to the nature of the speakers/speech — particularly in comparison to previous generations of content distributors . 165 . 274US . 357 , 377 ( 1927 ) ( Brandeis , J. , concurring ) . 166 . For a useful case study of viral news , see Sapna Maheshwan , How Fake News Goes Viral : A Case Study , N. Y . TIMES ( Nov. 20 , 2016 ) , https : //www.nytimes.com/2016/11/20/business/media/how-fake-news-spreads.html ? r=1 . [ https : //perma.cc/G53 Y-DZ9X ] . 86 FEDERAL COMMUNICATIONS LAW JOURNAL Vol . 70 delivery of news . '° ’ The latest development in this process is the role that social media can play in accelerating the distribution of a news story. ’ An emerging literature on “ digital wildfires ” documents the speed at which false news can travel and seeks to explain the factors that can affect its diffusion. ’ The speed of diffusion can be enhanced by technological advances such as bots ( certainly something Brandeis didn ’ t have to consider ) that can operate on a scale and pace that human false news disseminators can not ! ” distribute fake news in their efforts to influence the 2016 election . ! 7 ! Presumably , legitimate news has the same capacity to travel at equal speeds to false news today , just as it did in Brandeis ” time . However , while the underlying technological capacity is the same , the troubling reality is that the rapid dissemination capacity of social media appears more likely to be brought to bear for false news stories than for true news stories . Recent data indicate that false news stories are more likely to be shared — and are thus 167 . See generally HOWARD ROSENBERG & CHARLES S. FELDMAN , No TIME TO THINK : THE MENACE OF MEDIA SPEED AND THE 24-HOUR NEWS CYCLE ( 2008 ) . 168 . This process dates back to the development of radio , and progresses through the rise of 24-hour news networks and the dissemination of news online . Jd . 169 . For a review , see Helena Webb et al. , Digital Wildfires : Propagation , Verification , Regulation , and Responsible Innovation . 34 ACM TRANSACTIONS ON INFo . Sys . | ( Apr . 2016 ) . 170 . See Alessandro Bessi & Emilio Ferrara , Social Bots Distort the 2016 US . Presidential Election Online Discussion , FIRST MONDAY ( Nov. 7 , 2016 ) , http : //journals.uic.edu/ojs/index . php/fm/article/view/7090 , [ https : //perma.cc/258N-D44N ] ( ‘ Our findings suggest that the presence of social media bots can indeed negatively affect democratic political discussion rather than improving it , which in turn can potentially alter public opinion and endanger the integrity of the Presidential election. ” ) , Samuel C. Woolley & Douglas R. Guilbeault , Computational Propaganda in the United States of America : Manufacturing Consensus Online , Computational Propaganda Research Project Working Paper No . 2017.5 , Oxford Internet Institute 3 ( 2017 ) , http : //comprop.oil.ox.ac.uk/wp- content/uploads/sites/89/2017/06/Comprop-USA pdf , [ https : //perma.cc/K2WM- RXYC ] ( finding that bots are used to create “ the illusion of significant online popularity in order to build real political support , ” and “ democratiz [ e ] propaganda through enabling nearly anyone to amplify online interactions for partisan ends ’ ) . 171 . See Gabe O ’ Connor & Avie Schneider , How Russian Twitter Bots Pumped Out Fake News During The 2016 Election , NPR ( Apr . 3 , 2017 ) , http : //www . npr.org/sections/alltechconsidered/2017/04/03/522503844/how-russian-twitter- bots-pumped-out-fake-news-during-the-2016-election [ https : //perma.cc/BR5U-KA4G ] ( “ When he testified before the Senate Intelligence Committee last week , former FBI agent Clint Watts described how Russians used armies of Twitter bots to spread fake news using accounts that seem to be Midwestern swing-voter Republicans ” ) . Issue 1 FAKE NEWS AND THE FILTER BUBBLE 87 likely to spread faster ( and farther ) — than legitimate news stories. ' ” ? The explanation for this disparity once again takes us back to the role of partisanship — in this case the role that partisanship plays in increasing the likelihood of sharing a partisan news story , ' ” in combination with the increased likelihood that a partisan news story is a false news story . ! “ The key implication here , once again , 1s that social media disproportionately favor fake news over legitimate news . In the end , given that news has never been able to travel faster and farther than it can today , it seems reasonable to conclude that the likelihood of there “ be [ ing ] time ” to rely upon counterspeech to counteract false news is less today than in Brandeis ’ era , and perhaps less today than has ever been the case before , particularly given the other technologically-imposed challenges that truthful counterspeech faces in counteracting false speech . The end result , then , is a compounding set of conditions that contributes to a digital media ecosystem that encourages and facilitates the production , dissemination , and consumption of false news in ways that the traditional media ecosystem did not . IV . IMPLICATIONS This section considers the broader legal , policy , and political implications of the arguments developed above , all of which point to a media environment in which the efficacy of counterspeech is being systematically undermined . A . The First Amendment and Falsity As a starting point , it is worth considering how the arguments developed here connect with other analyses of if and how First Amendment jurisprudence has addressed the issue of false news and information . As Schauer points out , the troubling irony is that First Amendment theory has 172 . Craig Silverman , This Analysis Shows How Viral Fake Election News Stories Outperformed Real News On Facebook , BuzzFEED ( Nov. 16 , 2016 ) , https : //www.buzzfeed.com/craigsilverman/viral-fake-election-news-outperformed-real-news- on-facebook ? utm_term=.cq7v VRjOK # .tgekXRJOE ( “ During these critical months of the campaign , 20 top-performing false election stones from hoax sites and hyperpartisan blogs generated 8,711,000 shares , reactions , and comments on Facebook . Within the same time period , the 20 best-performing election stories from 19 major news websites generated a total of 7,367,000 shares , reactions , and comments on Facebook ” ) , Craig Silverman , Lies , Damn Lies , and Viral Content 45 ( Tow Ctr . for Digital Journalism Tow/Knight Rep. ) http : //towcenter.org/wp-content/uploads/2015/02/LiesDamnLies_Silverman_TowCenter.pdf ( observing that “ Misinformation is often more viral and spreads with greater frequency than corrective information ” ) . 173 . Jisun An , Daniele Quercia , & Jon Crowcroft , Partisan Sharing : Facebook Evidence and Societal Consequences , PROCEEDINGS OF THE SECOND ACM CONFERENCE ON ONLINE SOcIAL NETWORKS 13 , 17 ( Oct. 2014 ) ( showing that “ partisan skew ” in the sharing of news stories on social media “ holds not only for high-activity users but also for low-activity ones ’ ) . 174 . See Starbird , supra note 108 . 88 FEDERAL COMMUNICATIONS LAW JOURNAL Vol . 70 seldom grappled with the issue of truth versus falsity ; or , in today ’ s vernacular , facts versus “ alternative facts. ” ' 7 Schauer proceeds to convincingly demonstrate that , “ nearly all of the components that have made up our free speech tradition . . . in the cases and in the literature , and in the political events that inspired free speech controversies , have had very little to say about the relationship between freedom of speech and questions of demonstrable fact . Implicit in much of that tradition may have been the belief that the power of the marketplace of ideas to select truth was as applicable to factual as to religious , ideological , political , and social truth , but rarely is the topic mentioned. ” ! ’ ° Continuing in this vein , Schauer distressingly notes , “ although factual truth is important , surprisingly little of the free speech tradition is addressed directly to the question of the relationship between a regime of freedom of speech and the goal of increasing public knowledge of facts or decreasing public belief in false factual propositions. ” ! ” ” As a result , the First Amendment has essentially facilitated the type of speech that , ironically , undermines the very democratic process that the First Amendment is intended to serve and strengthen . Historically , different categories of speech have received different levels of First Amendment protection based upon its relevance and value to the democratic process . ! ” For instance , commercial speech receives less First Amendment protection ( and more rigorous restrictions against falsity ) than political speech , which represents the pinnacle of speech protection given its centrality to the democratic process . ! ” The irony here is that fake news is a type of speech that is most directly and irrefutably damaging to the integrity of the democratic process , yet because it resides within the large and undifferentiated protective bubble of political speech ( where journalism generally resides ) , it receives ( as long as it is not libelous ) the highest level of First Amendment protection . B . Market Failure in the Marketplace of Ideas It is also worth considering the troubling state of counterspeech in relation to the marketplace of ideas metaphor from which it arose , and whether the increasing inefficacy of counterspeech may cause failure in the marketplace of ideas . From a strictly economic perspective on the marketplace of ideas , false speech can be thought of as a negative externality 175 . For a transcript of the Meet the Press broadcast in which the term was famously introduced , see Rebecca Sinderbrand , How Kellyanne Conway Ushered in the Era of “ Alternative Facts , ” WASHINGTON Post ( Jan. 22 , 2017 ) , https : //www . washingtonpost.com/news/the-fix/wp/2017/01/22/how-kellyanne-conway- ushered-in-the-era-of-alternative-facts/ ? utm_term=.b633a394a39f . [ https : //perma.cc/MMC2- 23J6 ] . 176 . See Schauer , supra note 46 at 907 . 177 . Id . at 902 . 178 . See generally T.M . Scanlon , Jr. , Freedom of Expression and Categories of Expression , 40 U. PITT . L. REV . 519 ( 1979 ) . 179 . See , e.g. , Alex Kozinski & Stuart Banner , Who ’ s Afraid of Commercial Speech ? , 76 Va. L. REV . 627 ( May 1990 ) . Issue 1 FAKE NEWS AND THE FILTER BUBBLE 89 of free speech , ' * ° but a negative externality of increasing magnitude , given counterspeech ’ s increasing inadequacy as an antidote . In economics , negative externalities are accepted indicators of market failure. ' * ! When considering the implications of the diminished potency of counterspeech for the effective functioning of the marketplace of ideas , the presence of such negative externalities raises the question : should the public be concemed about the possibility of market failure in the marketplace of ideas ? And if so , how does market failure in the marketplace of ideas look ? The prospect and nature of market failure in the marketplace of ideas has received relatively little discussion , particularly within the context of news and journalism. ! * * Economist Ronald Coase , in his landmark comparative analysis of regulatory perspectives toward the market for goods and the market for ideas , noted the “ results actually achieved by this particular political system suggest that there is a good deal of ‘ market failure ’ ” in the marketplace of ideas , though he deemed the topic “ a large subject on which I will avoid comment. ” ! ® In addressing these questions , an important starting point is to consider some key causes and indicators of market failure . At the general level , a market failure occurs when the allocation of goods and services are inefficient . ' * * Markets for public goods , such as journalism , have proven to be uniquely prone to market failure. ! * * Public goods have a tendency to be under-produced relative to their full value , given the ease with which they can be shared or consumed without payment . ' * * Journalism also produces value 180 . See Richard A. Tybout , Pricing Pollution and Other Negative Externalities , 3 BELL J. Econ . & Men . Sci . 252 ( Spring 1972 ) . Therefore , as Schauer notes in a statement from 2009 that sounds particularly contemporary , “ [ W ] e are left with the conclusion that the seemingly increased pervasiveness of falsity in public discussion is a phenomenon that may possibly be a consequence of a strong free speech culture , but is certainly not a phenomenon that a free speech regime is likely to be able to remedy. ” Schauer , supra note 46 at 911-912 . 181 . See , e.g , Francis M. Bator , The Anatomy of Market Failure , 72 QUARTERLY J. Econ . 351 , 3633-371 ( 1958 ) . 182 . For exceptions , see Tamara Piety , Market Failure in the Marketplace of Ideas : Commercial Speech and the Problem that Won ’ t Go Away . 41 LOYOLAL.A . L. REV . 181 ( 2007 ) ( focusing on market failures in the marketplace of ideas within the specific context of commercial speech ) , Gregory Brazeal , How Much Does a Belief Cost ? Revisiting the Marketplace of Ideas . 21 8 . CAL . INTERDISC . L.J . 46 ( 2011 ) . For a more general overview of forms of market failure that may affect the marketplace of ideas , see Bush , supra note 17 , nn . 47-90 and accompanying text , see also C. Edwin Baker , Scope of the First Amendment Freedom of Speech , 25 UCLA L. REV . 964 ( 1978 ) nn 61-83 and accompanying text . 183 . See Ronald H. Coase , The Market for Goods and the Market for Ideas , 64 AM . ECON . REV . 384 , 385 ( 1974 ) . 184 . Kenneth A. Shepsle and Barry R. Weingast , Political Solutions to Market Problems , 78 Am . POL . Scl . REV . 417 ( 1984 ) ( “ According to the market failure orthodoxy , inefficiency in the marketplace provides a prima facie case for public intervention ” ) . 185 . See Victor Pickard , The Great Evasion : Confronting Market Failure in American Media Policy , 31 CRITICAL STUDIES STUD . IN MEDIA CoMM.153 , 154 ( 2014 ) ( “ Because public goods are non-rivalrous ( one person ’ s consumption does not detract from another ’ s ) and non- excludable ( difficult to monetize and to exclude from free nders ) , they differ from other commodities , like cars or clothes , within a capitalistic economy ’ ) . 186 . See Hamilton , supra note 100 at 8 ( “ A person can consume a public good without paying for it , since it may be difficult or impossible to exclude any person from consumption ” ) . 90 FEDERAL COMMUNICATIONS LAW JOURNAL Vol . 70 for society as a whole ( positive externalities ) that often is not captured in the economic transactions between news organizations and news consumers , and/or between news organizations and advertisers . ' * ” All of this leads to market inefficiency in the form of the underproduction of journalism , ' * a situation only exacerbated by the more challenging economic environment discussed above. ! * From an economic theory perspective , an informed citizenry and an effectively functioning democratic process are positive externalities . From a democratic theory perspective , however , these characteristics are not peripheral ; they are fundamental . Thus , an effectively functioning marketplace of ideas needs to be assessed according to different standards . According to Piety , market failures in the marketplace of ideas can be exemplified by characteristics such as : “ ( 1 ) the proliferation and acceptance of false ideas , ( 2 ) the suppression of truthful information , ( 3 ) the failure to produce truthful information , and ... ( 4 ) limitations on choice , and the channeling of the exercise of preferences within those limitations. ” ! °° Each of these characteristics connects fairly clearly to the conditions described above. ' ? ! For example , items one and two reflect the apparent increasing prominence and influence potential of fake news and the role of filter bubbles in inhibiting exposure to legitimate news . ' ? Item three reflects the diminishing journalistic capacity of legitimate news organizations . Item four concerns the operation of algorithmic filter bubbles , and how they tend to constrict news and information consumption within a narrower range of options determined by demonstrated preferences . Some might argue that the increasing production , dissemination , and consumption of fake news is a reflection of the ways in which technological changes have allowed the market to more efficiently identify and meet consumer demand for falsity ( the marketplace of ideas essentially becoming more efficient in serving consumer demand for fake news ) , rather than a reflection of consumers ’ diminished ability to accurately distinguish between legitimate and false news. ! * } In considering this possibility , the notion that 187 . Jd at 13 ( “ ... since individuals do not calculate the full benefit to society of their learning about politics , they will express less than optimal levels of interest in public affairs coverage and generate less than desirable demands for news about government ’ ) . 188 . See Pickard , supra note 195 at 155 ( “ The inadequacy of commercial support for democracy-sustaining infrastructures suggests what should be obvious by now : the systematic underproduction of vital communications like journalistic media ” ) . 189 . See Downie & Schudson , supra note 76 . 190 . See Piety , supra note 191 at 189-190 . 191 . See supra notes 75-180 and accompanying text . 192 . See Piety , supra note 191 at 189-190 . 193 . See Goldman & Cox , supra note 11 at 18 ( “ The whole idea of economic efficiency is that the system should be responsive to consumers ' tastes or preferences ( subject to the limits of technology ) , not that it should produce certain goods in comparatively large quantities no matter what people want . Thus , if consumers have no very strong preference for truth as compared with other goods or dimensions of goods , then there is no reason to expect that the bundle of intellectual goods provided and `` traded '' in a competitive market will have maximum truth content . If people valued falsehood , then perfect competition would provide falsehood in a Pareto-optimal way ” ) . Issue 1 FAKE NEWS AND THE FILTER BUBBLE 91 consumer demand for fake news is now being better met is cynical in that it reflects a grim view of the citizenry , in terms of a conscious desire to be misinformed . Even the bulk of the literature discussed above delineating the various cognitive biases that can lead to the consumption and acceptance of false news and information does not suggest that individuals are consciously and intentionally seeking false information , but rather that their cognitive biases lead them to mistakenly embrace false news and information as true . ! ™ The notion that individuals desire true and accurate information but are not always capable of making the distinction , reflects a less cynical view of the citizenry and a reasonable sense of how an idea marketplace actually functions , given the recognized prominence of “ bounded rationality ” ! in limiting marketplace efficiency . Further , this perspective represents the more optimistic ( and perhaps naive ) normative principle that an effectively functioning marketplace of ideas facilitates informed democratic decision- making — something that is presumably incompatible with decisions based upon false information . As Lidsky argues , “ The ideal of democratic self-governance . . . makes no sense unless one assumes that citizens will generally make rational choices to govern the fate of the nation . If the majority of citizens make policy choices based on lies , half-truths , or propaganda , sovereignty lies not with the people but with the purveyors of disinformation . If this 1s the case , democracy is both impossible and undesirable . '° Reflecting this position , this analysis operates ( perhaps naively and optimistically — but First Amendment theory is nothing if not somewhat naive and optimistic ) from the perspective that consumers generally prefer legitimate to false news . From this perspective , the unintentional consumption of fake news is a reflection of the bounded rationality of the news consumer , which can be seen as a function of inadequate information for making determinations as to the accuracy and reliability of available news sources . Inadequate information is a recognized source of market failure. ’ According to Brazeal , “ [ i ] mperfect information is arguably the most significant and pervasive source of market failure in the marketplace of ideas. ” ! ° * A market can not operate efficiently if 194 . See , e.g. , Olson , supra note 62 . ( “ Humans have an evolutionary tendency towards gullibility and wanting to believe what people are telling them ” ) . 194 . See supra notes 62-63 and accompanying text . 195 . See Conlisk , supra note 140 . 196 . Lidsky , supra note 23 at 839 . 197 . For a review see Deborah Haas-Wilson , Arrow and the Information Market Failure in Health Care : The Changing Content and Sources of Health Care Information , 26 J . HEALTH PoL . Pol ’ y & L. 1031 , 1034-1037 ( 2001 ) . 198 . See Brazeal , supra note 191 at 32 . 92 FEDERAL COMMUNICATIONS LAW JOURNAL Vol . 70 consumers lack the information necessary to make well-informed decisions about the relative value of the products and services available to them. ! * ” Another widely acknowledged source of market failure — both in the economic marketplace and in the marketplace of ideas — is imperfect competition . * ” From an ideas marketplace standpoint , a lack of competition fails to provide the “ diverse and antagonistic ” sources upon which the marketplace of ideas premise is founded. * ” ! More relevant to this analysis , however , is the fact that any biases inherent in the monopolist producers or distributors of news and information can undermine the extent to which the news consumers that rely upon them are properly informed . * ” A suddenly more vocal concern in the wake of the 2016 election has been the extent to which platforms , such as Facebook and Google play such an increasingly powerful bottleneck role in the dissemination and consumption of news and information. * '' ? Such concerns have tended to focus on these platforms ’ dominant position in the online advertising marketplace , 7 % or their increasingly dominant position in the emerging data marketplace . * ” However , these platforms ’ growing bottleneck position in the dissemination of news and information has begun to receive more attention — and explicitly in relationship to the fake news problem that is the focus here . As Sally Hubbard convincingly argues , “ fake news is [ fundamentally ] an antitrust problem ” , given the powerful intermediary position of Facebook , and the extent to which the algorithms that underlie the platform can point news 199 . Id . at 31-32 . 200 . Id . 201 . See Associated Press v. United States , 326 U.S. 1 , 20 ( 1945 ) , ( noting that the First Amendment “ rests on the assumption that the widest possible dissemination of information from diverse and antagonistic sources is essential to the welfare of the public ” ) . 202 . See Brazeal , supranote 191 at 31 ( “ Imperfect competition in the marketplace of ideas also occurs when the promotion of ideas is subsidized unequally ” ) . 203 . See , e.g. , Brad Auerbach , Are Amazon , Facebook and Google Monopolies ? Are They Undermining Democracy ? Taplin is Persuasive , FORBES ( May 26 , 2017 ) , https : //www . forbes.com/sites/bradauerbach/2017/05/26/taplin/ # 4f7d67d2G6daa , [ https : //perma.cc/YHW4-XVYS ] ; On the Media , The Fight for Antitrust ( Sept.ember 22 , 2017 ) , https : //www.wnyc.org/story/fight-antitrust/ , [ https : //perma.cc/6THS-KR3F ] . 204 . See BitClave , The Facebook-Google Online Ads Duopoly is Bad for Business , MEDIUM ( July 8 , 2017 ) , https : //medium.com/ @ BitClave/the-facebook-google-online-ads- duopoly-is-bad-for-business-fa2 b3 88de8fd [ https : //perma.cc/E2VZ-B3 VK ] . 205 . See Nick Srnicek , We Need to Nationalise Google , Facebook , and Amazon . Here ’ s Why , THE GUARDIAN ( Aug. 30 , 2017 ) , https : //www.theguardian.com/commentisfree/20 1 7/aug/30/nationalise-google-facebook- amazon-data-monopoly-platform-public-interest , [ https : //perma.cc/HG3K-S8KN ] . https : //www.theguardian.com/commentisfree/2017/aug/30/nationalise-google-facebook- amazon-data-monopoly-platform-public-interest , [ https : //perma.cc/HG3K-S8KN ] . Issue 1 FAKE NEWS AND THE FILTER BUBBLE 93 consumers toward fake news and away from legitimate news organizations.2 ” ° The extent to which so many news consumers are relying upon these same algorithms ( and whatever flaws or biases are baked into them ) provides the baseline from which the damage to the marketplace of ideas emerges . C. The 2016 Presidential Election as Market Failure Case Study In light of these market failure concerns , a looming question is whether the results of the 2016 presidential election represent a case study of market failure in the marketplace of ideas . Perhaps this is a way to make sense of an election outcome that baffled and blind-sided many journalists , political analysts , and voters * * ’ — and that took place within a media ecosystem that has changed significantly in the years since the 2012 presidential election . Certainly , there are other equally ( and perhaps even more ) plausible explanations for this outcome ( discussed below ) . The question being posed here is whether market failure in the marketplace of ideas , as a byproduct of the increased inefficacy of counterspeech , represents another potentially plausible explanation . In considering the increasing challenges discussed above that not only news consumers , but news producers and ( perhaps most importantly ) distributors face in discerning between real and fake news , there is an “ information asymmetry ” — a classic cause of market failure — between the creators and the distributors and consumers of news . This is a problem potentially compounded by the “ imperfect competition ” scenario described above . And in considering the consumption of fake news as a negative externality , then there is a potential indicator of market failure . However , to truly accept the consumption of fake news as a negative externality , one must consider its negative consequences . Given that the idea marketplace is intended to facilitate well-informed decision-making , if there is evidence of poorly-informed decision-making , then that could potentially be seen as evidence of market failure . Well-informed voting decisions have been defined by many political analysts in terms of the extent that citizens vote in ways that reflect their best 206 . See Sally Hubbard , Why Fake News is an Antitrust Problem , FORBES ( Jan. 10 , 2017 ) , https : //www.forbes.com/sites/washingtonbytes/2017/01/10/why-fake-news-is-an-antitrust- problem/ # 4c557dc730f1 , [ https : //perma.cc/P8GP-TFGM ] ( “ When viewed through an antitrust lens , news publishers are Facebook ’ s competitors . They compete for users ’ time spent online , user data and advertising dollars . .. . Indeed , competitive biases baked into Facebook ’ s design deserve a healthy portion of the responsibility for the nse of fake news . By pulling technological levers that keep users on its platform , thereby lessening clicks to news publishers ’ sites , Facebook has sped the decline of legitimate news and provided a breeding ground for the fake variety ’ ) . 207 . See , e.g. , Susan Davis and Scott Detrow , A Year Later , the Shock of Trump ’ s Win Has n't Totally Worm Off in Either Party , NPR ( 2017 , Nov. 9 ) , https : //www.npr.org/2017/11/09/562307566/a-year-later-the-shock-of-trumps-win-hasn-t- totally-worn-off-in-either-party , Shane Goldmacher and Ben Schreckinger , Trump Pulls Off Biggest Upset in US . History , POLITICO ( 2016 , Nov. 11 ) , https : //www . politico.com/story/2016/11/election-results-2016-clinton-trump-23 1070 , 94 FEDERAL COMMUNICATIONS LAW JOURNAL Vol . 70 interests . * °° Economic approaches , in particular , have emphasized the role of self-interest , 1.e. , that voters will vote for those candidates whose policy positions are likely to benefit them the most . ? ” And , it should be emphasized that this notion of self-interest has been conceptualized not purely in terms of narrow , short-term economic self-interest , but more broadly as well , to accommodate family and social network affinities. ? ! ° There are a variety of competing theoretical perspectives that seek to explain the dynamics of voting behavior . Other theoretical perspectives emphasize the “ expressive ” dimension of voting , ? ! ! or the inherent irrationality of voting that is a function of the negligible likelihood of rational voting behavior having a meaningful impact. ? '' ? The market failure argument being put forth here in reference to the 2016 election does not reflect these theoretical perspectives , but is rather an extension of the self-interested voter hypothesis described above , which , it should be noted , has received strong empirical support in recent research . ? ° There have similarly been a variety of competing perspectives offered to explain the results of the 2016 presidential election . Some of these explanations have emphasized the likelihood that voters were motivated 208 . For an overview of this perspective , see generally Gordon Tullock , On Voting : A Public Choice Approach ( 1998 ) . 209 . See Bryan Caplan , The Myth of the Rational Voter 18 ( 2007 ) ( “ [ M ] ost economists . . . compare voters to consumers who shrewdly ‘ vote their pocketbooks ” ) . 210 . See Jason Weeden & Robert Kurzban , The Hidden Agenda of the Political Mind : How Self-Interest Shapes Our Opinions and Why We Won ’ t Admit It 39-40 ( 2014 ) ( Arguing that “ it ’ s probably best to jettison the term ‘ self-interest ’ altogether ... [ and ] refer to ‘ inclusive interests. ’ Something is in a person ’ s ‘ inclusive interests ’ when it advances their or their family members ’ everyday , typical goals , ” as well as those of “ their fnends , allies , and social networks ” ) . 211 . See Geoffrey Brennan and Loren Lomasky , Democracy & Decision : The Pure Theory of Electoral Preference ( 1993 ) 15-16 ( contending that because “ electoral outcome is detached from electoral ‘ choice ’ for each voter , ” voting becomes a form of “ expressive behavior [ that reflects ] various kinds of ethical and ideological principles that are suppressed in the market setting . Politics , therefore , gives much freer range to ethical considerations than do markets ” ) . 212 . See Caplan , supra note 225 at 3 ( arguing that “ Voter irrationality is precisely what economic theory implies once we adopt introspectively plausible assumptions about human motivation ’ ) . 213 . See Weeden & Kurzban , supra note 226 at 203 ( “ The key debate in these discussions .. 1s how much interests matter in driving political opinions . In chapter 2 we responded to claims that self-interest hardly matters : When we run simple tests of these simple claims , quite often the simple claims are simply untrue ” ) . Issue 1 FAKE NEWS AND THE FILTER BUBBLE 95 primarily by informed self-interest. ? ! 4 Others have emphasized factors , such as frustration with the entirety of the political system ( i.e. , a desire to “ blow up the status quo ” in protest ) , ? ! ° or prejudices , such as racism ? ! * and sexism. ? ! 7 An additional possibility is that the 2016 election represented a case of market failure in the marketplace of ideas . Under this scenario , some segment of self-interested voters was sufficiently ill-informed ( 1e. , “ boundedly rational ” ) due to the changing conditions in the media ecosystem described above that they failed to vote in a way that reflected their best interests , an outcome that is associated with market failure . This market failure outcome is premised upon the substantial body of analysis that has been produced in the wake of the election that has repeatedly demonstrated that many categories of voters who voted for Donald Trump are actually those most 214 . See Robert Kurzban & Jason Weeden , No , Trump Voters Were Not Irrational , WASHINGTON PosT ( Nov. 9 , 2016 ) , _ https : // ( www.washingtonpost.com/news/in- theory/wp/2016/11/09/no-trump-voters-were-not-irrational/ ? utm_term=.45ad6fae23c6 , [ https : //perma.cc/QU7H-4A3U ] ( arguing that white , blue collar voters voted for Trump not “ because they ’ re irrational , but because they are self-interested — something generally true of voters on both sides ” ) , see also David Goodhart , White Self-Interest is not the Same Thing as Racism , AMERICAN RENAISSANCE ( Mar . 2 , 2017 ) , https : //www.amren.com/news/2017/03/white-self-interest-not-thing-racism/ , [ https : //perma.cc/JB4A-JM33 ] ; Ned Barnett , Duke Professor Dispels Myth About Trump and Working Class Voters , THE NEWS-OBSERVER ( Jun . 10 , 2017 ) , http : //www.newsobserver.com/opinion/opn-columns-blogs/ned- barnett/article 155509549 html [ https : //perma.cc/U87C-AKMP ] . 215 . See Daniel Henninger , The Trump Question , WALL STREET JOURNAL ( Jan. 18 , 2017 ) , https : //www . wsj.com/articles/the-trump-question-1484784436 ( “ It is said that the Trump electorate wanted to blow up the status quo ” ) . 216 . See generally Sean McElwee & Jason McDaniel , Economic Anxiety Didn ’ t Make People Vote Trump , Racism = Did THE NATION ( May 8 , 2017 ) , https : //www.thenation.com/article/economic-anxiety-didnt-make-people-vote-trump-racism- did ’ , [ https : //perma.cc/2K AH-97U4 ] ( “ Our analysis shows Trump accelerated a realignment in the electorate around racism , across several different measures of racial animus—and that it helped him win . By contrast , we found little evidence to suggest individual economic distress benefited Trump ” ) . 217 . See Carl Bialik , How Unconscious Sexism Could Help Explain Trump ’ s Win , FIVETHIRTYEIGHT ( January 21 , 2017 ) , https : //fivethirtyeight.com/features/how-unconscious- sexism-could-help-explain-trumps-win/ , [ https : //perma.cc/ ) WM6E-DCLM ] ( “ an important obstacle to the first woman president remains : the hidden , internalized bias many people hold against career advancement by women . And perhaps surprisingly , there is evidence that women hold more of this bias , on average , than men do ” ) . 96 FEDERAL COMMUNICATIONS LAW JOURNAL Vol . 70 likely to be harmed by his policies.7 ! * These analyses have concluded , for instance , that elderly and rural voters ( two demographics who were strong Trump supporters ) face the greatest economic harms from Trump policy initiatives such as the repeal of the Affordable Care Act , the abandoning of the Trans-Pacific Partnership , and dramatic cuts to Medicaid and agriculture subsidies. * ” ? Such patterns may reflect that the role of partisan affiliation in contemporary voting decisions has become largely disconnected from the associated policy positions of the candidates , * ° which is evidence of the Spiral of Partisanship phenomenon discussed above. ” ” ! If we accept the conclusions of these analyses ( for arguments sake ) that there was an unusual degree of voter failure to engage in self-interested voting behaviors , then this could reflect the possibility that a segment of voters lacked adequate information to accurately determine the voting decision that best reflected their self-interest . From the standpoint of a politically-oriented analysis of the operation of the marketplace of ideas , such indicators of voters failing to vote in their best interests , possibly due to false or inadequate information ( through the spread of fake news , which was facilitated by the 218 . See , e.g. , Martha C. White , Trump Voters Stand to Suffer Most from Obamacare Repeal and Trade War . NBC NEws ( Feb. 6 , 2017 ) http : //www.nbenews.com/business/business-news/trump-voters-stand-suffer-most- obamacare-repeal-trade-war-n717491 [ https : //perma.cc/HWU7-PP8N ] ; Paul Krugman , Coal Country Is a_ State of Mind NEw York TIMES , ( Mar . 31 , 2017 ) https : //www.nytimes.com/2017/03/31/opinion/coal-country-is-a-state-of-mind html , [ https : //perma.cc/9AGM-ZLBY ] ; Andrew Restuccia et al. , Trump Releases Budget Hitting His Own Voters Hardest , POLITICO ( May 22 , 2017 ) , http : //www . politico.com/story/2017/05/22/trump-budget-cut-social-programs-23 8696 , [ https : //perma.cc/8JW9-AHRU ] , ; Amanda Taub , Why Americans Vote “ Against Their Interest ’ : Partisanship . NEW YORK TIMES ( Apr . 12 , 2017 ) , https : //www.nytimes.com/2017/04/12/upshot/why-americans-vote-against-their-interest- partisanship.html ? 1-0 , [ https : //perma.cc/3 VEG-7GRS ] ; Catherine Rampell , Why the White Working Class Votes Against Itself , WASHINGTON PosT ( December 22 , 2016 ) https : //www . washingtonpost.com/opinions/why-the-white-working-class-votes-against- itself/2016/12/22/3aa65c04-c88b-1 1e6-8bee- 54e800ef2a63_ story . html ? utm_term=.99d233ea82fb , [ https : //perma.cc/EW5N-NX22 ] , Neil H. Buchanan , Why Did So Many Americans Vote to Be Poorer ? NEWSWEEK ( January 15 , 2017 ) , http : //www.newsweek.com/neil-buchanan-why-did-so-many-americans-vote-be-poorer- 542453 , [ https : //perma.cc/E9V7-C5LN ] ; Neil Macdonald , 7rump ’ s Poor and Rural Supporters Line Up to Take their Economic Beating CBC News ( April 5 , 2017 ) , http : //www.cbe.ca/news/opinion/americans-voting-for-cuts-1.4055389 , [ https : //perma.cc/TGP8-A58M ] . 219 . See White , supra note 234 ( “ Donald Trump ’ s most ardent supporters are likely to be hit the hardest if he makes good on his promise to dismantle the Affordable Care Act and embark on trade wars with China and Mexico ” ) ; Restuccia et al. , supra note 218 ( “ Donald Trump , whose populist message and promises to help American workers propelled him to the White House , issued a budget proposal on Tuesday that instead takes aim at the social safety net on which many of his supporters rely ” ) . 220 . See Taub , supra note 234 ( “ Why do people vote against their economic interests ? The answer , experts say , is partisanship . Party affiliation has become an all-encompassing identity that outweighs the details of specific policies ’ ) . 221 . See supra notes 128-131 and accompanying text . Issue 1 FAKE NEWS AND THE FILTER BUBBLE 97 economic and technological conditions outlined above ) , could be seen as evidence of market failure. ” Whether or not one accepts this explanation as the cause of the 2016 election results , it still seems worth considering the ramifications of the market failure in the marketplace of ideas concerns being raised here . Accepting this possibility highlights the danger inherent in the institutionalized confidence in truth to overcome falsity that is endemic of First Amendment theory . It may very well be that the media ecosystem has evolved in such a manner that the gap between normative theory and empirical reality is no longer just a gap , but something much greater and more dangerous . D. The Future of Counterspeech and the Marketplace of Ideas Even if this market failure argument remains unconvincing , it seems necessary that , going forward , First Amendment jurisprudence and the operational decision-making of social media platforms , recognize the more limited efficacy of counterspeech within the context of the operation social media platforms . It seems appropriate that , within the context of news on social media , the counterspeech doctrine should receive the same kind of more circumspect and limited application that has been advocated for in speech contexts , such as hate speech ? ” and adopted by the courts in contexts such as libel . * * * The Supreme Court ’ s recognition that “ false statements of fact ” are particularly resistant to counterspeech * * * needs to extend beyond the context of individual reputation that provided the basis for that decision . In sum , the analytical frameworks of policymakers and the courts , and the governance approaches taken by social media platforms , need to take into account that the dissemination and consumption of news in the increasingly social-mediated online environment ( what we might term the algorithmic marketplace of ideas ) merits inclusion amongst those speech contexts in which reliance on counterspeech is increasingly ineffectual and potentially damaging to democracy . In the end , perhaps this discussion illustrates a larger problem , which is the extent to which the application of First Amendment theory has tended to conflate the marketplace of ideas with what should perhaps be termed the marketplace of facts , particularly in relation to the role and function of journalism . The “ ideas ” terminology contains an inherent embrace of subjectivity , analysis , and opinion that reflects some , but not all , of the functionality of journalism in a democracy . A fundamental dimension of journalism is to provide factual information to facilitate informed decision- 222 . In this scenario , the decision by some voters to vote for Donald Trump is essentially the marketplace equivalent of purchasing a lemon , see Akerlof , supra note 138 . 223 . See Delgado and Yun , supra note 69 . 224 . See , e.g. , Hustler Magazine , Inc. v. Falwell , 485 U.S. 46 ( 1988 ) . 225 . Id . at 52 . 98 FEDERAL COMMUNICATIONS LAW JOURNAL Vol . 70 making . * * ° To the extent that this functionality is folded into the broader marketplace of ideas metaphor , the result is something of a mischaracterization of this aspect of journalism ’ s function. ? ? ” 7 One could argue that the very notion of facts competing for acceptance in the marketplace in the same way as ideas fundamentally undermines the very meaning of the term “ fact ” as something “ that is indisputably the case. ” In any case , the end result is that mtentional disinformation under the guise of journalism receives a degree of First Amendment protection that is not afforded to other categories of false speech ; this despite the Supreme Court ’ s explicit statement that “ there is no constitutional value in false statements of fact. ” ° From this standpoint , it is encouraging that , in the wake of the 2016 election , there has been a dramatic increase in efforts by the news aggregators and social media platforms that played central roles in the dissemination of fake news to alter their policies and procedures in ways intended to combat the spread of fake news . Thus , platforms , such as Google and Facebook , have dropped fake news sites from their ad networks . * * ° Facebook and Google have created initiatives to integrate fact-checking and content labeling from third parties into their presentation of news stories to users. * * ! There have been more concerted efforts to shut down disguised social media accounts operating as fronts for disinformation efforts . * * * Initiatives such as these address the growing need for “ tools of truth recognition ” that operate “ independent of the market in order for the market to be optimal. ” * * 3 Such efforts can be seen as working to reduce the “ transaction costs ” ? * 4 associated with evaluating the reliability of news sources , and thereby addressing the information asymmetry that is the fundamental cause of the postulated market failure in the marketplace of 226 . See Irene Costera Meijer , The Public Quality of Popular Journalism : Developing a Normative Framework , 2 JOURNALISM STUD.189 , 189 ( 2001 ) ( “ Informing citizens in a way that enables them to act as citizens has traditionally been the responsibility of the press ” ) , Mark Cooper , The Future of Journalism : Addressing Pervasive Market Failure with Public Policy , WILL THE LAST REPORTER PLEASE TURN OUT THE LIGHTS , 320 , 322 ( 2011 ) ( “ The core concept of the monitorial role involves the journalist serving as a neutral watchdog , rather than a partisan participant , holding social , economic , and political actors to account by presenting facts rather than advocating positions and offering opinions ” ) . 227 . Fora discussion of the Supreme Court ’ s failure to develop adequate mechanisms for distinguishing fact from opinion as it relates to journalistic output , see Robert Neal Webner , The Fact-Opinion Distinction in First Amendment Libel Law : The Need for a Bright-Line Rule . 72 Geo . L. J . 1817 ( 1984 ) . 228 . See Google Dictionary ( https : //www.google.com/ # q=fact & spf=14973654 12638 ) . 229 . See Gertz v. Robert Welch , Inc. , 418 U.S. 323 , 339-40 ( 1973 ) . 230 . See Silverman , supra , note 98 . 231 . See Bell , supra note 167 . 232 . See Stretch , supra note 167 at 4 ( “ we incorporated what we learned from the 2016 election in our detections systems , and as a result of these improvements , we disabled more than 30,000 accounts in advance of the French election ” ) . 233 . See Goldman and Cox , supra notel1 at 23 . 234 . For a discussion of transaction costs in the marketplace of ideas , see Blocher , supra note 140 at 852-60 . Issue 1 FAKE NEWS AND THE FILTER BUBBLE 99 ideas . Going forward , these and other initiatives need to be evaluated in terms of the extent to which they address one or more of the six changes outlined above that have affected the marketplace of ideas in ways that have increased the ability of false news to undermine legitimate news . Of course , such efforts by news aggregators and social media platforms raise the specter of further empowering already-powerful digital media bottlenecks , such as Facebook , Twitter , Google , and YouTube . The irony in this scenario is the extent to which it reflects a transition back towards the limited number of powerful gatekeepers that characterized the pre- fragmentation mass media era , but in a technological context in which many of the barriers to entry characteristic of the mass media era are no longer present . The mass media era was accompanied by critiques about concentration of ownership and the accompanying systemic homogeneity of viewpoints . * * ° These critiques gave rise to concerns about the production and influence of propaganda that are similar to the concerns that underlie the current fake news scenario . * * ° Given the extent to which different technological contexts seem to be leading to surprisingly similar institutional structures , it is tempting to conclude that a media ecosystem comprised of a fairly limited number of powerful gatekeepers is an inevitability , borne of larger mstitutional and economic forces , as well as nate audience behavior tendencies. ” 2 ’ Fortunately , from a journalistic standpoint , it is also the case that the mass media era of few , powerful gatekeepers cultivated a stronger “ public service ethos ” than has been present since technological change facilitated increased fragmentation and competition , and an associated need for news organizations to prioritize audience and revenue maximization over public service . * * * Of course , within some media sectors ( e.g. , broadcasting ) , this public service ethos could be attributed , at least n part , to a government- imposed public interest regulatory framework . * * In any case , one of the most distressing aspects of contemporary social media gatekeepers is the extent to 235 . See , eg. , Edward S. Herman & Noam Chomsky , Manufacturing Consent : The Political Economy of the Mass Media ( 1988 ) . 236 . Idat 1-36 ( developing a “ propaganda model ” of the mass media ) . 237 . For an historical description of evolutionary patterns in the media and telecommunications sectors that support this argument , see Tim Wu , The Master Switch : The Rise and Fall of Information Empires ( 2010 ) at 6 ( illustrating that each communications technology became “ a highly centralized and integrated new industry ” and that “ Without exception , the brave new technologies of the twentieth century .. . eventually evolved into privately controlled industrial behemoths , the ‘ old media ’ giants of the twenty-first , through which the flow and nature of content would be strictly controlled . . . History also shows that whatever has been closed too long is ripe for ingenuity ’ s assault : in time a closed industry can be opened anew , giving way to all sorts of technical possibilities and expressive uses for the medium before he effort to close the system likewise begins again ” ) . 238 . Foran account of the increased emphasis on audience and revenue maximization that took hold in journalism in the 1980s and 1990s , see John H. McManus , Market-Driven Journalism : Let the Citizen Beware ? ( 1994 ) . 239 . See Napoli , supra note 123 at 753 ( “ . . . articulations of public interest principles inherent in the professional practice of journalism parallel , to some extent articulations of the public interest that are found in the realms of media regulation and policy. ” ) . 100 FEDERAL COMMUNICATIONS LAW JOURNAL Vol . 70 which they have originated and evolved from a technology sector milieu in which the journalistic norms and/or regulatory framework associated with the public interest and social responsibility have been largely foreign to them . * ” ° Moving forward , then , perhaps the most essential development is that these new gatekeepers evolve in such a way as to absorb and implement a more robust public service ethos that is reflective of the institutional responsibilities associated with serving as an essential gatekeeper to the news and information necessary for an effectively functioning democracy . In the aftermath of the 2016 election , and the associated critiques of social media platforms and their role in disseminating fake news , it is certainly evident that things are moving in this direction.4 ! Efforts by search engines and social media platforms , such as Facebook and Google , to work with established and reputable fact-checking organizations to identify and label fake news stories , and to figure out ways at which such fact-checking and verification can operate the scale necessary for social media seem particularly promising. ? ” ? However , it seems important that such collaborations go beyond mere content labeling , and that the editorial discretion ascribed to these platforms under Section 230 of the Telecommunications Act of 19967 '' be put to use to filter out false news in the same way that this discretion has long been used to filter out other types of harmful speech such as hate speech and pornography . Indeed , the demonstrated commitment to counterspeech that has been 240 . See , e.g. , Philip M. Napoli & Robyn Caplan , Platform or Publisher ? 44 INTERMEDIA 26 , 27 ( 2017 ) ( “ One challenge in this regard , however , is a fundamentally different set of institutional perceptions that are being cultivated around social media platforms. ” ) , Emily Bell , We Can ’ t Let Tech Giants , Like Facebook and Twitter , Control Our News Values , THE GUARDIAN ( Aug. 31 , 2014 ) , https : //www.theguardian.com/media/media- blog/2014/aug/31/tech-giants-facebook-twitter-algorithm-editorial-values , [ https : //perma.cc/T8BQ-SL66 ] ( “ Platforms that want public trust should be employing many more journalists than they presently do and using their knowledge to imbue automated process with values ... . Accountability is not part of Silicon Valley ’ s culture . But surely as news moves beyond paper and publisher , it must become so. ” ) . 241 . See , e.g , Fidji Simo , Introducing the Facebook Journalism Project ( Jan. 11 , 2017 ) , https : //media.fb.com/2017/01/11/facebook-journalism-project/ , [ https : //perma.cc/V59V- S5CLA ] ; Mark Zuckerberg , Building Global Community ( Feb. 17 , 2017 ) , https : //www.facebook.com/notes/mark-zuckerberg/building-global- community/10154544292806634/ , [ https : //perma.cc/PMA9-S72D ] ( Among the questions Zuckerberg raises for Facebook is “ How do we help people build an informed community that exposes us to new ideas and builds common understanding in a world where every person has a voice ? ” ) . 242 . See Samuel Gibbs , Google to Display Fact-Checking Labels to Show if News is True or False , THE GUARDIAN : TECH ( Apr . 7 , 2017 , 11:37 AM ) , https : //www.theguardian.com/technology/2017/apr/07/goo0gle-to-display-fact-checking- labels-to-show-if-news-is-true-or-false , [ https : //perma.cc/M4RV-DH25 ] ; Eile Hunt , ‘ Disputed by multiple fact-checkers ’ : Facebook Rolls Out New Alert to Combat Fake News , THE GUARDIAN : TECH ( Mar . 21 , 2017 , 8:37 PM ) , https : //www.theguardian.com/technology/2017/mar/22/facebook-fact-checking-tool-fake- news , [ https : //perma.cc/34GB-5GS5H ] . ; Samuel Gibbs , Google to Display Fact-Checking Labels to Show if News is True or False , THE GUARDIAN ( Apr . 7 , 2017 ) , https : //www.theguardian.com/technology/2017/apr/07/google-to-display-fact-checking- labels-to-show-if-news-is-true-or-false . 243 . 47U SC . § 230 . Issue 1 FAKE NEWS AND THE FILTER BUBBLE 101 articulated by social media platforms such as Facebook , YouTube , and Twitter “ needs to be tempered and surpassed by a greater commitment and editorial responsibility toward truth and accuracy that is reflective of our most reputable journalistic institutions. “ It is unclear at this point , however , whether the efforts put forth by social media platforms reflect a politically savvy ( and perhaps temporary ) response to the current moment of increased scrutiny , or whether these efforts represent the starting point for much-needed and more substantial institutional change . If it 1s the former , then with the key question is if or how government intervention might be an appropriate response . Other countries have already begun heading down this path . Germany , for instance , recently adopted a law that requires social media platforms to remove stories identified as fake news ( along with other content types , such as hate speech and child pornography ) , or face government-imposed fines of up to 50 million Euros . * “ ° Such approaches , of course , raise the contentious question of who should be in the position of making judgments as to what constitutes fake news . In the U.S. , given the indiscriminate and politicized ways in which the fake news label is being applied by governmental actors , ” the prospect of establishing an objective , reliable , and widely-trusted arbiter of fake news within a government agency seems more dangerous now than perhaps at any time in recent U.S. history . It is perhaps worth remembering that , within fairly narrow technological contexts ( e.g. , broadcasting ) , a precedent for regulatory intervention in response to false news reporting has been established . 244 . See , e.g. , Bartlett & Krasodomski-Jones supra note 55 , at 5 , TweeSurfing supra note 58 , ONLINE CIVIL COURAGE INITIATIVE , supra note 56 . 245 . See , e.g. , Robyn Caplan , Like it or Not , Facebook is Now a Media Company , NEW YorK TIMES ( May 17 , 2016 ) , https : /www.nytimes.com/roomfordebate/2016/05/17/1s- facebook-saving-journalism-or-ruining-it/like-it-or-not-facebook-is-now-a-media-company , [ https : //perma.cce/ZY Y9-VDLK ] , Seth Fiegerman , Dear Facebook , You 're a Media Company Now . Start Acting Like One , MASHABLE : BUSINESS ( May 15 , 2016 ) , http : //mashable.com/2016/05/15/facebook-media-company/ # zOF0ooxw0aqo [ https : //perma.cc/25PB-Y366 ; Seth Fiegerman , Dear Facebook , You ’ re a Media Company Now . Start Acting Like One , MASHABLE : BUSINESS ( May 15 , 2016 ) , [ https : //perma.cc/25PB- Y366 ] . 246 . See Staff , Germany Approves Plan to Fine Social Media Firms Up to 50 Million Euros , THE GUARDIAN ( June 30 , 2017 ) , https : //www.theguardian.com/media/2017/jun/30/germany-approves-plans-to-fine-social- media-firms-up-to-50m . [ https : //perma.cc/_L6EW-TKF9 ] . 247 . See Lloyd Grove , How Will the Media Fight the Right ’ s Weaponization of “ Fake News , ” THE DAILY BEAST , ( Jan. 11 , 2017 ) , http : /Awww.thedailybeast.com/how-will-the- media-fight-the-n ghts-weaponization-of-fake-news/ [ https : //perma.cc/HBY6-QFR7 ] ( “ . . . the term ‘ fake news ’ —the enduring catchphrase of the 2016 presidential campaign , initially used to describe made-up tales and internet hoaxes that tended to benefit Trump and damage Hillary Clinton—is fast becoming the nascent Trump administration ’ s rightwing-populist bludgeon to delegitimize the purveyors of real news ” [ emphasis in original ] . ) , ; see also Wardle & Derakhshan , supra note 75 at 5 ( “ the term has also begun to be appropriated by politicians around the world to describe news organizations whose coverage they find disagreeable . In this way , it ’ s becoming a mechanism by which the powerful can clamp down upon , restrict , undermine and circumvent the free press ’ ) . 102 FEDERAL COMMUNICATIONS LAW JOURNAL Vol . 70 Specifically , current FCC regulations prohibit broadcast licensees from knowingly broadcasting false information conceming a crime or catastrophe , if the licensee also knows beforehand that “ broadcasting the information will cause substantial ‘ public harm. ’ ” ? 4 * This public harm must begin immediately and cause direct and actual damage to the property , health , or safety of the general public , or divert law enforcement or public health and safety authorities from their duties. ” In addition , since the late 1960s , the Federal Communications Commission ( “ FCC ” ) also has maintained a more general policy that it will “ imvestigate a station for news distortion if 1t receives documented evidence of such rigging or slanting , such as testimony or other documentation , from individuals with direct personal knowledge that a licensee or its management engaged in the intentional falsification of the news. ’ ? °° According to the FCC , “ of particular concern would be evidence of the direction to employees from station management to falsify the news . However , absent such a compelling showing , the Commission will not intervene. ” * ! News distortion investigations have been rare ( especially since the deregulatory trend that began in the 1980s ) , and seldom have led to any significant repercussions for broadcast licensees. ? Of course , the nature of the regulatory rationales that have traditionally applied to broadcasting ( spectrum scarcity , pervasiveness ) generally do not apply to a technological context such as social media . 7 ? However , discussions about possible regulatory interventions into the social media 248 . See Federal Communications Commission , Broadcasting False Information ( November 3 , 2015 ) , _ http : //transition.fcc.gov/cgb/consumerfacts/falsebroadcast.pdf. , [ https : //perma.cc/4PJU-GVLS ] . 249 . Id . 250 . See Federal Communications Commission , The Public and Broadcasting ( July , 2008 ) , https : //www.fec . gov/media/radio/public-and-broadcasting # DISTORT , [ https : //perma.cc/FZX9-QFWV ] . 251 . Id . 252 . See Chad Raphael , The FCC ’ s Broadcast News Distortion Rules : Regulation by Drooping Eyelid , 6 CoMM . L. & PoLicy 485 ( 2001 ) ( Arguing that the FCC ’ s news distortion regulations are more symbolic than genuine ) . See also William B. Ray , FCC : The Ups and Down of Radio-TV Regulation at 31 ( 1990 ) ( “ On the whole , the commission has done less to carry out its stated policies regarding news broadcasting than in any other field ” ) . 253 . For a detailed discussion of established rationales for U.S. media regulation , the distinction between regulatory rationales and motivations , and the significance of this distinction for possible regulatory responses to issues related to social media , see Philip M. Napoli , Bridging the Disconnect Between Digital Media and the Public Interest , Paper Presented at the XVIII Nordic Political Science Congress , Odense , Denmark ( August , 2017 ) . Issue 1 FAKE NEWS AND THE FILTER BUBBLE 103 space have gained some momentum of late , ” the role of social media in the 2016 elections having recently taken place . Given these indicators of potential shifts m the political environment , it is important to recognize that concerns about fake news have an established , if not modest and somewhat forgotten , foothold in the U.S. media regulatory framework . Ultimately , though , it is important to acknowledge that the current political environment lends strength to the First Amendment tradition that has placed the judgment of truth and falsity in the realm of political speech completely outside the bounds of government authority , ? °° and points us back to what might — at least for the time being — be considered the lesser of two evils — the need for today ’ s dominant digital gatekeepers to more aggressively impose editorial authority in ways that reflect well-established norms of journalistic service in the public interest. ? * ” with congressional hearings on 235 V. CONCLUSION The goal here has been to consider how the evolution of the news ecosystem has undermined legitimate news ’ ability to overcome fake news . This argument builds upon a body of critique of the counterspeech doctrine that is grounded in the persistent psychological and cognitive tendencies in news consumption that also undermine the efficacy of counterspeech . * ° * From this standpoint , it may be that the news ecosystem , as previously constructed , has helped to protect citizens , to some extent , from some of their innate flaws and biases as news consumers . 254 . See , e.g. , Lincoln Caplan , Should Facebook and Twitter be Regulated Under the First Amendment ? WIRED ( November 11 , 2017 ) , https : //www.wired.com/story/should-facebook- and-twitter-be-regulated-under-the-first-amendment/ , [ https : //perma.cc/83HM4-P4HB ] ; , John Herrmann , What If Platforms Like Facebook are Too Big to Regulate ? N.Y. TIMES ( October 4 , 2017 ) , https : //www.nytimes.com/2017/10/04/magazine/what-if- platforms-like-facebook-are- too-big-to-regulate html , [ https : //perma.cc/RD3R-NNY7 ] ; Sally Hubbard , Why Fake News is an Antitrust Problem , Vox ( September 23 , 2017 ) , https : //www.vox.com/technology/2017/9/22/16330008/facebook-google-amazon-monopoly- antitrust-regulation , [ https : //perma.cc/EGSW-2K5G ] . 255 . See Extremist Content and Russian Disinformation Online : Working with Tech to Find Solutions , Hearing Before the S. Comm . on the Judiciary , Subcomm . on Crime and Terrorism , 115 '' Cong . ( Oct. 31 , 2017 ) , https : //www judiciary.senate.gov/meetings/extremist- content-and-russian-disinformation-online-working-with-tech-to-find-solutions [ https : //perma.cc/42VE-5HSD ] ; Social Media Influence in the 2016 United States Elections , Hearing Before the 8S . Select Comm on Intelligence ( Nov. 1 , 2017 ) , https : //www intelligence.senate.gov/hearings/open-hearing-social-media-influence-2016-us- elections [ https : //perma.cc/K65 Y-KAQ4 ] , Russia Investigative Task Force Open Hearing with Social Media Companies , Hearing before the H. Permanent Select Comm . on Intelligence ( Nov. 1 , 2017 ) , _ https : //intelligence house .gov/calendar/eventsingle.aspx ? EventI D=814 [ https : //perma.cc/8DYT-QRJU ] . 256 . See Thomas v. Collins , 323 U.S. 516 , 545 ( 1945 ) ( Jackson , J. , concurring ) ( “ every person must be his own watchman for truth , because our forefathers did not trust any government to separate the true from the false for us ” ) . 257 . For a discussion of journalistic norms of public service and their applicability to social media platforms , see Napoli , supra note 123 . 258 . See Bambauer , supra note 62 . 104 FEDERAL COMMUNICATIONS LAW JOURNAL Vol . 70 And it may be that the contemporary news ecosystem has been doing the exact opposite . The end result may be a state of market failure in the marketplace of ideas . Consequently , this Article has suggested social media platforms , content aggregators , policymakers , and the courts temper their commitment to counterspeech . This Article has also suggested that these platforms adopt a greater institutional commitment to a public interest- grounded approach to content filtering , in keeping with the editorial responsibilities that have characterized previous generations of news organizations . In the end , counterspeech can no longer function as a viable assumption when considering the current dynamics of the social media-based flow of news and information . ResearchGate See discussions , stats , and author profiles for this publication at : https : //www.researchgate.net/pu blication/36287 6047 From mass to automated media Revisiting the ‘ filter bubble' Chapter - August 2022 DOI : 10.4324/9780429288654 CITATION READS 1 29 2 authors , including : 5 Mark Andrejevic Monash University ( Australia ) 78 PUBLICATIONS 3,849 CITATIONS SEE PROFILE All content following this page was uploaded by Mark Andrejevic on 23 August 2022 . The user has requested enhancement of the downloaded file . Chapter 2 From mass to automated media Revisiting the ‘ filter bubble ’ Mark Andrejevic and Zala Volcic In the face of social media ’ s problems with fake news and political polarisation , the ready response has been to propose economic , technical , and educational fixes . Reacting to US concerns about Russian disinformation campaigns , for example , Facebook executive Rob Goldman tweeted : ‘ There are easy ways to fight this . [ ... ] Finland , Sweden and Holland have all taught digital literacy and critical thinking about misinformation to great effect. ” ! A recent report by the Data & Society Research Institute considered a range of possible solutions , including fortified fact- checking and verification services and incentives for de-emphasising fake content and closing down the accounts of those who circulate it. ? `` The hope embedded in such responses is that the overarching commercial model we have developed for circulating , news and information online can be salvaged for the purposes of informed commu- nication and democratic deliberation . Some combination of self-regulation by plat- form giants , public pressure to reconfigure economic incentives , anti-trust measures , and increased media literacy on the part of users has been advanced as a strategy for curbing the flood of politically polarised misinformation online . This chapter argues that the concerns raised by commercial social media are significant and structural , which means the commercial model we have developed is not salvageable solely through education and self-regulation . Rather we need to critically examine the broader connections between media infrastructures and social policies that erode the resources for mutual recognition and collective deliberation . The question is not just what kind of information people receive online , but the conditions under which they receive it , and the disposition these foster . Diverse content and perspectives are necessary but not sufficient for democratic deliberation . Meaningful deliberative processes rely equally upon the formation of a ‘ discourse ethics ’ , which , ‘ by requiring that perspective-taking be 1 Sheera Frenkel , ‘ Fact-Checking a Facebook Executive ’ s Comments on Russian Inter- ference ’ The New York Times ( 19 February 2018 ) www.nytimes.com/2018/02/19/ technology /facebook-executive-russia-tweets-fact-check.html , accessed 30 August 2019 . 2 Robyn Caplan , Lauren Hanson and Joan Donovan , Dead Reckoning : Navigating Content Moderation After Fake News ’ ( Data & Society Report , 21 February 2018 ) https : //datasociety.net/output/dead-reckoning , accessed 30 August 2019 . 18 Mark Andrejevie and Zala Volcic general and reciprocal , builds the moment of empathy into the procedure of coming to a reasoned agreement ’ . * The critique of online ‘ filter bubbles ’ can have the misleading effect of diverting attention away from the context and material conditions of news reception and the broader societal conditions within which these are embedded , including the ongoing regulatory assault on ‘ social bonds and obligations , social conscience , and social welfare ’ . > The shift in the news environment associated with the platform economy coincides with a political assault on the conditions that enable citizens to take into consideration the needs , perspectives , and values of others , including those whom they do not know and may never meet , but who nevertheless form part of their shared communities . I . ‘ Everyone ’ s got their goons ’ Many of the proposed solutions to the pathologies of commercial media platforms assume a shared understanding of the problem and the civic will to solve it . It is possible to discern quite different subject positions from those that share civic good will - indeed , ones that are cultivated by and thrive on the logics of polar- isation . Consider , for example , the conservative businessman interviewed by the New York Times who views right-wing conspiracy theories as a form of entertain- ment : ‘ I just like the satisfaction [ ... ] It ’ s like a hockey game . Everyone ’ s got their goons . Their goons are pushing our guys around , and it ’ s great to see our goons push back. ” ® The subject position here is one that seeks out fake news as a form of politicised entertainment because it confirms one ’ s prejudices and preconceptions . There is another subject position that is worth taking into consideration : that which questions the efficacy of fact-checking itself . Consider the example of Florine Goldfarb , one of the ‘ unwitting ’ Americans who promoted events orchestrated by Russian Internet trolls during the 2016 presidential campaign. ” When confronted with the fact that she had posted information generated by a Russian propaganda organisation on her pro-Trump Facebook page , her response was dismissive : ‘ I don ’ t believe that . That ’ s bulls—. ” ® Such responses highlight the impasse of media 3 Jiirgen Habermas , Moral Consciousness and Communicative Action ( MIT Press 1990 ) 11 . 4 Eli Pariser , The Filter Bubble : How the New Personalized Web is Changing What We Read and How We Think ( Penguin 2011 ) . 5 Jo Littler , ‘ Where the files are : Wendy Brown Talks to Jo Littler ’ ( 2018 ) 68 Sound- ings 14 , 14 . 6 Sabrina Tavernise , ‘ As Fake News Spreads Lies , More Readers Shrug at the Truth ’ The New York Times ( 6 December 2016 ) www.nytimes.com/2016/12/06/us/fake-new s-partisan-republican-democrat.html , accessed 30 August 2019 . 7 Scott Shane , ‘ How Unwitting Americans Encountered Russian Operatives Online ’ The New York Times ( 18 February 2018 ) www.nytimes.com/2018/02/18 /us/poli tics /russian -operatives-facebook-twitter.html , accessed 30 August 2019 . 8 Bryan Logan , ‘ CNN interview with a Trump supporter goes sideways after she learns she unknowingly touted pro-Trump events coordinated by Russian trolls ’ Business Insider ( 21 February 2018 ) www.businessinsider.com/cnn-interviews-woman-unkno wingly-manipulated-by-russian-trolls-2018-2 , accessed 30 August 2019 . From mass to automated media 19 education : it runs the danger of simply pushing the problem of fact-checking back a level . The philosopher Slavoj Zizek has described this vertiginous infinite recess of credibility as the retreat of ‘ symbolic efficiency ’ , suggesting that in the con- temporary information environment , ‘ what is increasingly undermined is precisely the symbolic trust which persists against all skeptical data ’ . ? Il . The role of a ‘ civic disposition ’ The issues raised by political polarisation thus reach beyond the circulation of content to the ways in which information is experienced , and the concrete prac- tices that materialise this experience . Keeping this claim in mind , this chapter argues for a reconsideration of arguments about media customisation , suggesting that the critiques they raise are relevant but that the mechanism they posit needs to be revisited . Specifically , it argues that while the notion of a “ filter bubble ” ! ® has captured much of the research attention in the field , additional emphasis needs to be placed on the conditions available for the formation of a ‘ civic disposition ’ in the platform economy. ' ! The central concern from the perspective of fostering democratic deliberation is not ( only ) whether people are exposed to a narrower range of news and information online ( a claim that seems increasingly implausible in the contemporary media environment ) , but whether social media undermine the civic purchase of diverse information streams . In other words , it may be that , in a context of media surfeit , people find themselves both exposed to a broader range of information and less inclined to take into consideration the larger com- munity of which they are part and the perspectives of those unknown others who comprise it . The point here is not simply that confirmation bias ’ ? might con- tribute to how people navigate a flood of information , but that a combination of platform logics and communicative practices with broader social policies under- mines the background conditions for democratic deliberation . The problem of the ‘ filter bubble ’ ? may really be one of the declining efficacy of the conditions that make deliberation meaningful . If , as Benedict Anderson argued , ’ * the rise of print capitalism resulted in media technologies and artefacts that helped people form a sense of imagined community at the national level , the shift toward platform media in the era of ‘ statist neo-liberalism ’ ’ * undoes this achievement . Growing resistance to countervailing facts and opinions may not be due to echo chamber- ing , but rather to the degradation of people ’ s ability to see themselves as part of an 9 — Slavoj Likek , The Ticklish Subject : The Absent Centre of Political Ontology ( Verso 1999 ) 332 . 10 Pariser ( n 4 ) . 11 Richard Pratte , The Civic Imperative : Examining the Need for Civic Education ( Tea- chers College Press 1988 ) . 12 Pariser ( n 4 ) . 13 Benedict Anderson , Imagined Communities : Reflections on the Origin and Spread of Nationalism ( Verso 1983 ) . 14 Littler ( n 5 ) . 20 Mark Andrejevie and Zala Volcic imagined community in which the concerns and interests of others , both indivi- dually and collectively , matter to one ’ s own thriving and thus to one ’ s deliberative decision-making processes . This is a large claim that reaches beyond the limits of a book chapter , so the goal of this piece is to establish the importance of revisiting the filter bubble argument by moving beyond its focus on the range of available content and perspectives . The chapter discerns in pioneering work on the filter bubble the resources for considering the overarching question of the formation of a civic disposition and the conditions that threaten it . The two most influential writers positing a connection between online news and political fragmentation , Eli Pariser ! °and Cass Sunstein , ’ © both develop arguments that have a dual focus : the range of content to which users are exposed and the resulting shift in civic dispositions . However , it tends to be the content side of the argument that gets the most attention in recent research , perhaps because of the keywords with which their work is associated : ‘ The Daily Me ’ ( Sunstein , borrowing from Negro- ponte ) and the ‘ Filter Bubble ’ ( Pariser ’ s term ) both refer to the automated tailoring of content to particular users . As Sunstein puts it in his first book on the topic [ T ] here are serious dangers in a system in which individuals bypass general interest intermediaries [ mass circulation newspapers and electronic mass media | and restrict themselves to opinions and topics of their own choosing [ ... ] A situation of this kind is likely to produce far worse than mere fragmentation . ' ” Pariser uses Sunstein ’ s book as a jumping-off point for his own exploration of online filtering , coming to much the same conclusion : “ Together , these engines create a unique universe of information for each of us —- what P ’ ve come to call a filter bubble — which fundamentally alters the way we encounter ideas and infor- mation ’ . ’ ® He notes the inevitability of filtering in an increasingly saturated infor- mation environment , while also critiquing its tendency toward individualisation : ‘ Left to their own devices , personalization filters serve up a kind of invisible autopropaganda , indoctrinating us with our own ideas. ’ ’ ” The concerns here have to do with a shifting information environment in which the broadening of avail- able information coincides with increasing information nichification . Il . Finding filter bubbles One result of this argument , which has regained attention in the wake of recent events , has been a spate of research seeking to empirically verify the existence of ‘ filter bubbles ’ - customised information environments that reflect a narrowing of perspectives despite the proliferation of online content . However , the empirical 15 Pariser ( n 4 ) . 16 Cass Sunstein , Repudlic.com ( Princeton University Press 2001 ) . 17 Ibid 16 . 18 Pariser ( n 4 ) 12 . 19 Ibid 13 . From mass to automated media 21 evidence in this regard remains contested . Fletcher and Nielsen draw on the Reuters Institute Digital News Report to argue that , ‘ [ c ] ontrary to conventional wisdom , our analysis shows that social media use is clearly associated with inci- dental exposure to additional sources of news that people otherwise wouldn ’ t use — and with more politically diverse news diets ’ . * ° Similarly , Flaxman and col- leagues found that the use of social media and search engines is ‘ associated with an increase in an individual ’ s exposure to material from his or her less preferred side of the political spectrum ’ . ? ’ Alternatively , a review essay by Borgesius and collea- gues concludes that , ‘ at present , there is no empirical evidence that warrants any strong worries about filter bubbles ’ . ? ? In the era of high-volume social media sharing , it seems increasingly plausible that those who spend more time online are likely to encounter diverse perspec- tives — even if these are simply shared in the form of critique or indignation . Wired magazine reported , for example , that those who most strenuously critiqued con- spiracy theories about school shootings in the United States contributed to their prominence on social networking platforms since ‘ people outraged by the con- spiracy helped to promote it — in some cases far more than the promoters of the story ’ . ? The communicative economy of outrage and sensationalism that char- acterises so much of the online information helps circulate a broad range of per- spectives — if only to allow people to critique and deride those with whom they disagree . The focus on content that characterises the recent reception of the filter bubble argument gives rise to the assumption that exposure to a broader range of per- spectives could ameliorate the problem of fragmentation and polarisation . How- ever , even if the evidence regarding the extent of ‘ autopropaganda ’ remains in dispute , the evidence of increasing polarisation is less controversial . A large-scale survey by the Pew Research Center found that , by a number of measures , the level of political polarisation in the United States has increased dramatically in the pre- vious two decades . * * According to these findings , the number of Americans who 20 Richard Fletcher and Rasmus K. Nielsen , ‘ Using social media appears to diversify your news diet , not narrow it ? NiemanLab ( 21 June 2017 ) www.niemanlab.org/2017/ 06 /using-social-media-appears-to-diversify-your-news-diet-not-narrow-it/comm ent-page-1 , accessed 30 August 2019 . 21 Seth Flaxman , Sharad Goel and Justin M Rao , ‘ Filter Bubbles , Echo Chambers , and Online New Consumption ’ ( 2016 ) 18 ( S1 ) Public Opinion Quarterly , 298 , 303 . 22 Frederik J Zuiderveen Borgesius et al. , ‘ Should we worry about filter bubbles ? ’ ( 2016 ) 5 ( 1 ) Internet Policy Review DOI : 10.14763/2016.1.401 . 23 Molly McKew , ‘ How liberals amped up a Parkland shooting conspiracy theory ’ WIRED ( 27 February 2018 ) www.wired.com/story /how-liberals-amped-up-a-parkla nd-shooting-conspiracy-theory , accessed 30 August 2019 . 24 Pew Research Center , Political Polarization in the American Public : How Increasing Ideological Uniformity and Partisan Antipathy Affect Politics , Compromise and Epery- day Life ( Pew Research Center , 12 June 2014 ) http : //assets.pewresearch.org/wp -content/uploads /sites/5 /2014/06/6-12-2014-Political-Polarization-Release pdf , accessed 30 August 2019 . 22 Mark Andrejevie and Zala Volcic expressed consistently conservative or consistently liberal views doubled - that is , people seemed to be more ‘ dug into ’ a partisan political perspective . At the same time , Pew researchers reported : Partisan animosity has increased substantially . [ ... ] In each party , the share with a highly negative view of the opposing party has more than doubled since 1994 . Most of these intense partisans believe the opposing party ’ s poli- cies ‘ are so misguided that they threaten the nation ’ s well-being ’ . ? ° Although levels of polarisation vary internationally , the Reuters Institute has dis- covered growing perceptions of media bias and increasing political polarisation in the countries it surveyed : ‘ People cluster to media organisations that fit their belief , and dismiss other outlets . The internet , once thought to open the world up to all the information possible and bring people together , has instead drawn people into their own corners. ’ * ° A variety of other factors come into play in dis- cussions of political polarisation , including media deregulation and levels of eco- nomic inequality ; however , the media remain an important realm in which these tensions are played out. ” IV . Beyond content Further consideration of the filter bubble arguments provides resources for con- sidering the ways in which increased exposure to diverse content might coincide with increasing political polarisation . Attempts to verify the existence of filter bubbles shift attention away from ancillary concerns raised by both Pariser and Sunstein about shifting civic dispositions , because the latter are viewed simply as a consequence of the former . However , their work provides some openings for considering the possibility that content alone is not the issue . Indeed , there are openings in their arguments for approaching the question of how even greater exposure to a range of perspectives might coincide with increasing , political polar- isation . Both authors supplement their concerns about customisation with criti- cism of the impact that media have on the disposition of users . For Sunstein , the operative distinction is between what he describes as ‘ consumer sovereignty ’ and ‘ political sovereignty ’ .2 * The former prioritises individual tastes and defines free- dom as their expression within the constraints set by the price system ( and avail- able resources ) . From the perspective of consumer sovereignty , consuming the news is indistinguishable from shopping for clothes or cars . Political sovereignty , 25 Ibid . 26 Nic Newman et al. , Reuters Institute Digital News Report 2017 ( Reuters Institute for the Study of Journalism , 2017 ) 30 https : //reutersinstitute.politics.ox.ac.uk/sites/ default/files /Digital % 20News % 20 Report % 202017 % 20web_0.pdf , accessed 30 August 2019 . 27 Ibid . 28 Sunstein ( n 16 ) 86 . From mass to automated media 23 by contrast , ‘ does not take individual tastes as fixed or given . It prizes democratic selfgovernment , understood as a requirement of “ government by discussion , ” accompanied by reason-giving in the public domain ’ . ? ? In other words , political sovereignty requires the practices of recognition that make it possible to form preferences in discussion with others , taking into consideration their perspectives and claims . It relies on the recognition that the conditions for the formation of individual tastes rely on underlying forms of sociality and community that enable a perceived commonality of interests . Similarly , Pariser argues that filter bubbles collapse citizenship into consumerist individualism : ‘ The filter bubble [ ... ] creates the impression that our narrow self interest is all that exists . And while this is great for getting people to shop online , it ’ s not great for getting people to make better decisions together. ” * ° Beyond his concern with a potential narrowing of the range of content , Pariser is targeting the ways in which automated curation helps erode the social foundation upon which meaningful deliberation relies : ‘ Personalization has given us something very different : a public sphere sorted and manipulated by algorithms , fragmented by design , and hostile to dialogue. ’ * ! At the same time , Pariser ’ s concern over the fate of the public and the social suggests the possibility that recalibrating algorithms for serendipity and breadth may not , on its own , address the pathologies of fragmentation . As he puts it , the problem must also be countered by ‘ a more humanistic and nuanced sense of iden- tity , and an active promotion of public issues and cultivation of citizenship ’ . * ? Tellingly , in this regard , both Pariser and Sunstein invoke the importance of what we might describe as a ‘ civic disposition ’ that recognises the claims and concerns of others as playing an important role in one ’ s own political calculus . Such a disposition is difficult to achieve without the community resources that allow for the imagined possibility of a shared , public interest . As Pratte puts it , ‘ [ c ] ivic virtue is not a matter of mere behavior ; it is a matter of forming a civic dis- position , a willingness to act in behalf of the public good while being attentive to and considerate of the feelings , needs , and attitudes of others ’ . * ? For Habermas , such a disposition is the result of concrete social practice and conscious forms of social cultivation . As McCarthy puts it , practical discourse features ‘ moral agents trying to put themselves in each other ’ s shoes [ ... ] And this must be done pub- licly ; arguments played out in the individual consciousness or in the theoretician ’ s mind are no substitute for real discourse. ’ * * Viewed as a concrete social practice , the formation of such a disposition relies upon materialised practices that foster 29 Ibid 45 . 30 Pariser ( n 4 ) 90 . 31 Ibid 91 . 32 Ibid 127 . 33 Pratte ( n 11 ) 308 . 34 Thomas McCarthy , Introduction , in Jiirgen Habermas , Moral Consciousness and Communication Action ( Shierry Weber Nicholsen and Christian Lenhardt tr , MIT Press 1990 ) 12 . 24 Mark Andrejevie and Zala Volcic turn taking , the ability to place oneself in the position of others , and a sense of a community in common with them . Pariser and Sunstein closely associate customisation of content with the frag- mentation of a shared media sphere and thus with the erosion of conditions for the formation of a civic disposition , which is displaced by abstract conceptions of primary individualism and the concrete practices of consumerism . Their own arguments suggest that the core problem is not just a question of information , but also one of a civic disposition toward that information , in which case we might consider what factors beyond content are implicated in the erosion of such dis- positions online ( and off ) . It may be the fact of customisation itself and the con- crete technologies and practices with which it is associated , rather than the alleged narrowing , of content , that plays the more decisive role —- accompanied as it is with broader shifts in the social , cultural , and political environment . It is nice to imagine that diverse ideas and perspectives , on their own , would bring into being an openness to considering competing claims and putting one ’ s own preconceptions to the test , but history has disproven this over and over . The development of a civic disposition is an historical achievement that requires the development of societal and institutional resources and practices . It is an achieve- ment that can be undone if the reservoir of public commitment and social prac- tices that impel people toward good faith engagement and public deliberation are reconfigured . The philosopher J.M . Bernstein highlights the underlying issues in his discussion of Jiirgen Habermas ’ s version of communicative reason — a core attribute of deliberation in the public sphere : ‘ The ground for orienting ourselves toward establishing validity claims through intersubjective recognition is inter- subjective recognition. ’ * > Much as we might like them to do so , arguments do not command recognition on their own . The deeper question at work in critiques of media fragmentation , then , is the extent to which the rise of customised com- mercial platforms does more than simply reproduce niche world views ( a contested claim ) by helping to reconfigure the practices and dispositions that serve as the underlying conditions for meaningful public deliberation . One crucial task for addressing contemporary concerns about the relationship of platform media to democracy is to identify some starting points for moving the discussion beyond an overly narrow focus on content customisation . The remainder of this chapter considers , in turn , the shift from mass to automated media and the dismantling of imagined community and sociality associated with statist neoliberalism . V. From mass to automated media The 20th-century era of mass circulation media represents , for Sunstein , a sig- nificant if relatively brief historical period that played an important democratic role at the national level . The mainstream mass media — what he describes as ‘ general 35 J M Berstein , Recovering Ethical Life : Jiirgen Habermas and the Future of Critical Theory ( Routledge 1995 ) 180 . From mass to automated media 25 interest intermediaries ’ * ® — provide a mediated sociality that serves as the social glue that enables shared deliberation . As he puts it , ‘ [ p ] eople who rely on such intermediaries have a range of chance encounters , involving shared experience with diverse others and exposure to material that they did not specifically choose ’ . ? ” The emphasis in this formulation , as in much of Sunstein ’ s writing on the topic , is , unsurprisingly , on content : a common set of stories contributes to the formation of shared world views that provide common ground for delibera- tion . Sunstein compares these media to public spaces in which people encounter perspectives and viewpoints that differ from their own but that are nevertheless contained within a shared set of reference points . * * The advantage of mass media is that they can extend this sense of a shared informational space beyond the limits of physical space : ‘ [ I ] ntermediaries of this sort have large advantages over streets and parks precisely because they tend to be national , even international . Typically they expose people to questions and problems in other areas , even other coun- tries. ” Sunstein is moving beyond content in this formulation : he is articulating the role that the mass media play in forming a sense of what Benedict Anderson has described as an ‘ imagined community ’ . * ° Anderson draws on the example of one of the first mass production technologies , the commercial printing press , to explore the relationship between the rise of the concept of the nation state and of the mass audience for newspapers and novels . The novel , he argues , ushers in the notion of ‘ a sociological organism moving calendrically through homogeneous , empty time ” ? — a notion that parallels ‘ the idea of the nation ’ as a container that holds together people who will never know each other but who nonetheless are conceptually assembled into a shared sense of community . As he puts it : An American will never meet , or even know the names of more than a handful of his 240,000,000-odd fellow Americans [ Anderson was writing 80 million people ago ] . He has no idea of what they are up to at any one time . But he has complete confidence in their steady , anonymous , simultaneous activity. ” He describes the daily newspaper - Sunstein ’ s general interest intermediary — as the basis of a rhythmic ritual of reading that reinforces a sense of community : The significance of this mass ceremony — Hegel observed that newspapers serve modern man as a substitute for morning prayers — is paradoxical . It is performed in silent privacy , in the lair of the skull . Yet each communicant is 36 Sunstein ( n 16 ) 3 . 37 Ibid 11 . 38 Ibid 12 . 39 Cass Sunstein , “ The Daily We : Is the Internet really a blessing for democracy ’ ( 2001 ) 26 Boston Review 3 , 6 . 40 Benedict Anderson , Imagined Communities ( 2nd edn , Verso Books 2006 ) . 41 Ibid 26 . 42 Ibid . 26 Mark Andrejevie and Zala Volcic well aware that the ceremony he performs is being replicated simultaneously by thousands ( or millions ) of others of whose existence he is confident , yet of whose identity he has not the slightest notion . * * This awareness is a true achievement insofar as it calls into being the sense of a shared , common , existence with unknown , remote , but imagined others . Dwelling on the power of this achievement , we might consider the practical and material components that underwrite a sense of simultaneity as community . The news comes according to a rhythm — morning edition , late edition , evening edition - that synchronises reading patterns across space . Readers know the stories they are reading are simultaneously being consumed by unknown others in their regional or national sphere . The papers themselves circulate as discrete sharable items whether in the home or on the commuter train , where a discarded paper might be retrieved and re-read by many , marking an informational bond between readers . Mass media homogenise and unify the informational community — a process that has both its benefits and its pathologies ( the latter of which provided the impetus for undermining the former ) . Like mass transport , mass media assemble people into groups and provide them with a collective sense of movement through time . Anderson ’ s formulation is suggestive because it highlights the role that media infrastructures , artefacts , and practices play in providing the imagined community that contributes to the formation of a civic disposition . As Bernstein suggests , recognising the claims of unknown others requires that some sense of a shared community interest must already be in place . * * Anderson provides us with some ways of thinking about the role played by media practices and technologies in building this sense of community ( which is not to say that the media are the sole contributor , but surely they have an important role to play ) . The mass reproduc- tion enabled by the printing press standardised a national language and provided those who spoke it with shared informational resources . Mass circulation news- papers helped to build a shared sense of mediated experiences and rituals at the regional and eventually the national level . People watched the same shows at the same times ( more or less ) ; they read stories about the same issues , and the mass market gave rise to conventions of objectivity that set the boundaries for what counted as mainstream perspectives . The subsequent critique of the ‘ mainstream ’ media was enabled by the fact that there was a palpable mainstream , largely built around the consensus of political and media elites and those who depended on these for information and access . * * The limitations of mass media meant that there was an ‘ outside ’ to the media environment — people were not immersed in the endless flow of customised information and entertainment that characterises 43 Ibid 35 . 44 Bernstein ( n 35 ) . 45 See e.g . Robert W. McChesney , The Political Economy of Media : Enduring Issues , Emerging Dilemmas ( NYU Press 2008 ) ; Edward S. Herman and Noam Chomsky , Manufacturing Consent : The Political Economy of the Mass Media ( Random House 2010 ) . From mass to automated media 27 always-on media . There is no need to romanticise the era of the general interest intermediary ( from its inception riven by commercial pressures — at least in the US - and constrained by power and convention ) , to trace the role it might play in the formation of an imagined community that could gesture toward something like a shared public interest . The rise of the commercial model for information provision online offers some telling contrasts to the era of the general interest intermediary —- beyond the dif- ferences in content identified by Sunstein and Pariser . The notion of homogenous time gives way to mass customisation and the rhythm of media consumption becomes disaggregated and reconfigured . The evening newscast is replaced , for many , by the constant flow of customised information . We dig into our own worlds not simply by drawing on customised content , but by reconfiguring our spatial and temporal relationships to information , to the world around us , and to each other . The TV room in the dorm gives way to roommates watching separate Netflix shows in adjoining rooms on their personal devices . Local newspapers dry up and blow away , leaving a vacuum to be filled by local Facebook groups created by , among , others , civilian militias and right-wing hate groups . The rhythm of reading and viewing is accelerated while the time to absorb and contemplate is displaced by the relentless flow of updates and information tidbits . The space ‘ outside ’ of media consumption shrinks as people take their devices into the public parks and streets , largely oblivious of the strangers around them , focused on their own personal window on the world unfolding before them . Of course , there are exceptions and alternatives , but the tendency is clear , and the implications for our sense of imagined community deserves a central place in any approach to the relationship between digital media and political fragmentation . The reluctance of influential platforms such as Facebook and Twitter to view them- selves as publishers , and thus responsible for the content they circulate , furthers the shift away from a notion of public — and the goal of serving it — toward that of marketing to disaggregated consumers . The imperatives of the automated information economy are shaped by the data-driven advertising models that rely primarily on ‘ stickiness ’ ( the time spent on a site ) and engagement ( user content production and information sharing ) to maximise both exposure to ads and data collection about users . * © One of the leading contemporary critics of the social effects of the device-based plat- form economy is lapsed cyber-celebrant Sherry Turkle . For Turkle , social media are fundamentally anti-social technologies insofar as they displace communion onto digital ( and , we might add , commercial ) networks . Her book Alone Together laments the def- icit of sociality wreaked by hyper-connectivity : * ” the rise in playground accidents that coincides with parents and nannies focusing on phones rather than children , the college 46 Paul Lewis , “ Fiction is outperforming reality ” : how YouTube ’ s algorithm distorts truth ’ , The Guardian ( 2 February 2018 ) www.theguardian.com/technology/2018/ feb/02 /how-youtubes-algorithm-distorts-truth , accessed 30 August 2019 . 47 Sherry Turkle , Alone Together : Why We Expect More from Technology and Less from Each Other ( 3rd edn , Basic Books 2017 ) . 28 Mark Andrejevic and Zala Volcic suitemates texting one another from room to room rather than talking , the loss of the ‘ raw , human part ’ of being with one another . * ® Turkle found that for her respondents , managing sprawling social media networks can be so time- consuming that people look for the most efficient ways to communicate : texting rather than talking by phone ( which comes to be seen as too intrusive and an outdated form of ‘ mono-tasking ’ ) , shorthand signs of support and affirmation ( likes , retweets , posts ) , asynchronous modes of inter- acting with friends and families , and so on . As Turkle puts it : [ T ] oday our machine dream is to be never alone but always in control . This can ’ t happen when one is face-to-face with a person . But it can be accom- plished with a robot , or by slipping through the portals of a digital life . * ” One related recent development is the accelerating tendency to offload sociality onto increasingly automated platforms . A platform called Molly , for example , profiles users in order to craft automated answers to questions from other . As one press account put it : Eventually [ ... ] it will provide answers that are not already in its system using , machine learning . By using all the information the app can gather about you ( upon creating a profile , you have the option to add social accounts from which Molly can learn ) , it will be able to predict an answer to a question relevant to you . Molly would confirm its formulated answer with you — to affirm yes , that ’ s what you would say — and whoever asked the query will be sent an answer . 50 Instead of communicating directly with an interlocutor , users interact with the bot that becomes their always-on networked presence . As the demands of constant 48 Catherine de Lang , ‘ Sherry Turkle : “ We ’ re losing the raw , human part of being with each other ” ’ The Guardian ( 5 May 2013 ) www.theguardian.com/science/2013/may/05/ra tional-heroes-sherry-turkle-mit , accessed 30 August 2019 . Some recent empirical research ( Jeffrey A Hall , Michael W Kearney and Chong Xing , “ Two tests of social dis- placement through social media use ’ ( 2018 ) 22 Information , Communication & Society 1396 ) has pressed against the ‘ social displacement via social media ’ hypothesis , finding no support for the assumption that ‘ social media decreases interactions with close friends and family ’ ( 12 ) . Although the authors cite Turkle ’ s work as an example of the social dis- placement hypothesis , her findings focus not on the frequency of contact but on the rhythm and character of social interaction . Parents and children may , for example , have face-to-face contact even while their attention and focus is directed toward their devices . From the perspective of Sunstein ’ s concerns , the question is not whether interactions with close friends and family are displaced , but whether public encounters are diminished through the privatisation of public space associated with mobile , networked devices . See more in Jeffrey A Hall et al. , ibid . 49 Turkle ( n 47 ) 157 . 50 Molly McKew , ‘ Our Bots , Ourselves ’ The Ringer ( 7 March 2018 ) www.theringer . com /tech/2018/3/7 /17089364/molly-machine-learning-social-platform-bots , accessed 30 August 2019 . From mass to automated media 29 connectivity pile up , automation becomes the ready response . Google is develop- ing an Al-based automatic reply system for text messages that will allow users to eyeball its suggested response and send it off with a single tap . As the developers describe it , the system would incorporate context awareness derived from other social media apps and platforms : ‘ The system can apparently work out what people are saying to you and suggest one-tap answers , but Google says it will go further , taking your location , your calendar and other bits of information into account. ” * ! Through the dialectical reversal enacted by automation , the acceleration of soci- ality culminates in its elimination via automation : the convergence of hyper-inter- activity with solipsism . VI . Neoliberal sociality Media practices do not exist in a vacuum and the tendencies described by Turkle , Sunstein , and Pariser parallel broader claims about the resources for sociality under conditions of what Wendy Brown has described as ‘ statist neoliberalism ’ .° ? The triumph of ‘ consumer sovereignty ’ , combined with technologies and practices that foster increasingly individualistic forms of media consumption and solipsistic social interaction described by Turkle , align themselves with the regulatory assault on notions of a public interest and policies that support social security and collective benefits . Brown argues that the political climate in the Trump era promotes a regulatory approach that literally takes apart social bonds and social welfare — not simply by promoting a libertarian notion of freedom and dismantling the welfare state , but also by reducing , legitimate political claims only to those advanced by and for families and individuals , not social groups generated by social powers.° ? The list of policy changes and proposals that fit this description continues to grow : the attempts to undermine the Affordable Care Act in the US , to dismantle environmental regulation , to de-fund public service media and publicly funded research , to cut low-cost health care for poor children and cross-subsidies for broadband access , are just a few . What the programmes and policies under attack have in common is that they reflect a commitment to forms of mutual recognition and the sense of common , shared public interest . This commitment reflects and reproduces a crucial compo- nent of democratic culture , according to Brown : ‘ The saturation of the state , political culture , and the social with market rationality effectively strips 51 Hal 90210 , ‘ Tired of texting ? Google tests robot to chat with friends for you ’ The Guardian ( 14 February 2018 ) www.theguardian.com/technology/2018/feb/14/ google-tests-robot-chat-reply-friends , accessed 30 August 2019 . 52 Littler ( n 5 ) . 53 Ibid 14 . 30 Mark Andrejevie and Zala Volcic commitments to political democracy from governance concerns and political cul- ture.° * Cayley Sorochan , in her related discussion of the fate of participation in the neoliberal era , observes : It is not simply that the political sphere has minimized its purview or become corrupted by capitalist interests , it is that the possibility of understanding the political as a distinct dimension of human life with its own logic and set of values is disappearing or made unintelligible by the ubiquity of economistic thinking . * > At issue in such accounts is the diminished or disappearing space for forms of political interaction that are irreducible to the economic - and thus of subject positions distinct from the individual preferences and structured competition pri- vileged by the market . This wide-ranging reconfiguration of the societal landscape emerges from and reproduces a suppression of the underlying forms of trust and recognition that enable the functioning of social and political life . The subject position that celebrates tax cuts paid for by the dismantling of health care for the poor refuses any conception of a common interest that foregrounds social interdependence . The emphasis on indivi- dual self-interest suppresses and misrecognises the underlying social bonds that make the market society it relies on able to function in the first place . The threat of this form of extreme misrecognition — the taxpayer screaming over the use of public money for public services that benefit others — is that we become less conscious of the underlying forms of trust that make possible even the most basic of activities in con- temporary society , from vouchsafing our children to the public schools to crossing the street when the light turns red ( it is certainly a symptom of contemporary social pathologies that both of these realms of trust have become highly publicised vectors of attack and vulnerability ) . In myriad ongoing ways , we rely on forms of trust and recognition that are all too easily ignored , overlooked , and disavowed in favour of an abstract notion of individuality that would be impossible to sustain without both these forms of sociality and their disavowal . The assault on public institutions ranging from public education to public parks and libraries to public health care provide evi- dence of the social amnesia upon which the forms of neoliberal governance described by Brown thrives . As the philosopher J.M . Bernstein puts it : “ The American version of these practices has , from the earliest days of the republic , made individuality auto- chthonous while suppressing to the point of disappearance the manifold ways that individuality is beholden to a complex and uniquely modern form of life. ” °° 54 Wendy Brown , ‘ American Nightmare : Neoliberalism , Neoconservatism , and De- Democratization ’ ( 2006 ) 34 ( 6 ) Political Theory 690 , 695 . 55 Cayley Sorochan , The Participatory Complex : Participation as Ideolagy in the Neo- liberal Eva ( PhD thesis , McGill University 2017 ) 36 . 56 J M Bernstein , ‘ The Very Angry Tea Party ’ The New York Times ( 13 June 2010 ) http s : //opinionator.blogs.nytimes.com/2010/06/13/the-very-angry-tea-party , accessed 30 August 2019 . From mass to automated media 31 Against this background , it comes as no surprise that the frustration of the current political moment has to do with people ’ s inability to reach across political and ideological divides to agree upon underlying facts , evidence , and reality . The shift toward automated , customised media works in both form and content to reinforce a conception of consumerist individualism that disavows the background practices , institutions , and social relations that serve as its own conditions of pos- sibility . Thus , the questions we should be asking of social media and the platform economy have to do not just with the diversity of content they provide , but also with the ways in which it structures and reinforces this version of solipsism . These influences are not limited to the messages we receive , but to the ways in which we encounter them . If the underlying resources for meaningful deliberation — the ground that makes it possible for people to hear the concerns and arguments of others — are eroded , it is not clear that technical or educational fixes , as important as they might be , are sufficient . Instead , it becomes important to reconfigure the practices , platforms , and policies that reinforce an understanding of news and information as indivi- dualised , custom-tailored commodities , dismantling the sense of publicness , com- monality of interest , and mutual recognition that underwrite democratic deliberation . The stakes are high because of the role deliberation plays in demo- cratic self-governance — that is , in providing an alternative to the role of violence in resolving disagreements . As Simone Chambers put it in her work on deliberative democracy , political deliberation is predicated , in part , on ‘ the intuition that talk- ing is better than fighting ’ . > ” If the resources available for talking dissipate , we run the danger of finding ourselves in a post-deliberative , post-diplomatic realm in which the play of force and violence is unleashed . VII . The glut chamber The insight resulting from such arguments is that diversity of media content and perspectives is an outmoded proxy for meaningful deliberation . Neither Sunstein > ® nor Pariser® ’ celebrates diversity simply for diversity ’ s sake : they both see the breadth of media exposure as a necessary precondition for functional public deliberation . That is , even if those who lament the rise of online echo chambers are empirically wrong about the breadth of perspectives to which people are exposed , this does not mean we no longer have to worry about the state of con- temporary political deliberation . It seems increasingly possible that the most important change is not in the breadth of content , but in its efficacy . This is the paradox of the contemporary information environment : that , under certain 57 Simone Chambers , Reasonable Democracy : firgen Habermas and the Politics of Dis- course ( Cornell University Press 1996 ) 2 . 58 Cass Sunstein , # Republic : Divided Democracy in the Age of Social Media ( Princeton University Press 2017 ) ; Cass Sunstein , Repudblic.com 2.0 ( Princeton University Press 2007 ) ; Sunstein ( n 16 ) . 59 Pariser ( n 4 ) . 32 Mark Andrejevie and Zala Volcic circumstances , a breath-taking expansion of the information environment might exacerbate ( rather than overcome ) political polarisation . Such an observation is perhaps less surprising than it might at first seem : when there are myriad conflicting accounts and perspectives , people experience greater latitude in choosing among them . In a world of proliferating media outlets , wherein even the most extreme perspectives can readily find themselves reinforced by a range of media sources and resources ( as well as by a ready core of like-minded supporters ) , it is easier to feel that one has not only the right but the obligation to choose one ’ s own facts . In an environment of media surfeit , one is cast adrift on a sea of narratives and counter- narratives , equipped only with the pole star of pre-existing preconceptions and pre- judices . In the digital information environment , every account can be undermined and contested , every representation deconstructed , every proof counterfeited , every theory transformed into a conspiracy and vice versa . But perhaps glut , on its own , is not enough to explain this vertiginous dis- mantling of symbolic efficiency . Isn ’ t the whole point of evidence and reasoned argument that it can cut through the clutter of falsehood , superstition , and wrong opinion ? The reality of public debate on a national scale is that it draws heavily on media representations and thus relies on some level of fundamental trust in the systems of expertise , accountability , and responsibility meant to serve as guarantors of these representations . Functional debate also relies on what might be described as good faith engagement in processes of reasoned , consistent argumentation and the ability to step outside of one ’ s own perspective to consider that of others — that is , some degree of generalisability . The commercial platform model poses profound challenges to both of these underlying preconditions , which suggests the importance of a fundamental rethinking and reconfiguration of this model . All of which is not to say that these challenges are unique to social media , which in many ways extend the logics of hyper-commercialisation and nichification that char- acterised the development of the mass media in the late 20th century . The truth of the ‘ democratising ’ ? promise of social media , then , is that it reconfigures the citizen as both consumer ( and thus as an individualised target ) and brand ( tasked with self-marketing and self-broadcasting ) .° ! Simultaneously , it displaces practices of human sociality with automated sorting systems running on commercial platforms . Offloading our interactions onto bots allows us to suppress the recognition of our interdependence , our reliance on others . Hyper-con- nectivity , on this account , defaults to a form of hermetic solipsism that looks increasingly familiar in the era of the decline of symbolic efficiency.® ? The new challenge for democratic deliberation becomes not that of providing evidence and countervailing narratives and viewpoints , but of securing recognition for the 60 Mark Andrejevic , Infoglut : How Too Much Information Is Changing the Way We Think and Know ( Routledge 2013 ) . 61 Alison Hearn , ‘ “ “ Meat , Mask , Burden ” : Probing the contours of the branded “ self ” ’ ( 2008 ) 8 ( 2 ) Journal of Consumer Culture 197 . 62 Zizek ( n 9 ) . From mass to automated media 33 underlying forms of interdependence that make it possible to take on the per- spective and position of others — and to invite them to do the same for us . In the automated , mass customised media environment , perhaps the real chal- lenge to democratic deliberation is not the narrowing of content and perspectives available on social media platforms , but the combination of their indefinite pro- liferation with the erosion of the social preconditions for adjudicating between them . If , in the filter bubble , people are deafened to the views of others by the constant reinforcement of their preconceptions and prejudices , in a context of “ nfoglut ’ , ® ? the cacophony is equally deafening . The pressing question becomes how to cultivate the resources that would calm this cacophony by facilitating the shared adjudication of mutually exclusive arguments and perspectives . If recog- nising , the validity claims of others depends in turn on underlying forms of inter- subjective recognition that are eroded by the rise of automated sociality ( and the assault on practices and institutions that provide a sense of shared political and social commitment ) , we can not expect the claims of whatever passes as reasoned deliberation to retain purchase on their own . We need to imagine alternatives to offloading , sociality onto commercial automated networks that render hyper-com- municativity ineffective for actual deliberation ( listening , perspective taking , and recognition of mutuality and shared interdependency ) . Failing to do so would be to concede that talking no longer provides a viable alternative to fighting , rele- gating information to the ongoing process of weaponisation that is colonising contemporary social relations . 63 Andrejevic ( n 60 ) . A “ Filter Bubble ” for Relationships ? Interpersonal Closeness and Surprise About Missed Posts on Facebook Emilee Rader and Rebecca Gray Department of Media and Information Michigan State University { emilee , grayreb } @ msu.edu ABSTRACT Our study investigates the discovery of posts on Facebook that were missed in one ’ s News Feed , a possible individual- level effect of content filtering algorithms on Facebook , as a way of exploring potential outcomes of feedback loops be- tween user and system behavior . We examine the relation- ships between the strength of Facebook Friendships , use of explicit News Feed curation mechanisms , and the outcomes of noticing missed posts from Friends , and associated feel- ings of surprise . We find that the closeness of a relation- ship does not impact the likelihood of noticing missed posts from Friends , but that closeness does impact the degree to which individuals are surprised about missed posts . Finally , we discuss reasons to believe that missed posts associated with higher levels of surprise for close friends might be an individual-level symptom of a systematic pattern of unex- pected behavior by Facebook ’ s News Feed algorithm , and what this means for feedback loops and algorithmic curation in socio-technical systems . INTRODUCTION We have all experienced a feeling of information overload . This phenomenon did not originate with the Internet and social media ; people complained of it when print books first made their appearance , and when the telegraph was in- vented [ 19 ] . People turn to online media for the same things they used to find offline in pamphlets , telegrams , and newspa- pers : for information about what is going on in the world and in the lives of people they care about ; for entertainment ; for help with information-based tasks like finding a restaurant or figuring out when they should go to a doctor ; and to discover , learn and do many other things . People are becoming increasingly dependent on online socio- technical systems that collect , organize and display large quantities of information . These systems are implementing algorithmic curation : filtering the content displayed to users via automated algorithms that determine what should be dis- Working paper , last updated July 21 , 2014. played and what should be hidden . In his recent book , Eli Pariser refers to this phenomenon as the “ filter bubble ” [ 30 ] . His construct represents the effects of online information per- sonalization over time—primarily the bad things that might happen when algorithms make it easier for users to access content that is in some way similar to the content they have already read or experienced [ 24 ] . Researchers have imagined this becoming a problem in a number of ways , from a lack of diversity of opinion in politi- cal discussions online [ 1 , 18 ] ( which we know results in more extreme viewpoints [ 19 ] ) , to the emergence of a new kind of digital divide between those who are well versed in “ algorith- mic literacy ” ! and those who are not , to a self-reinforcing spi- tal of groupthink responsible for poor decision-making [ 8 ] . These negative consequences are all presumably the result of feedback loops : situations where the output of some process becomes an input to that same process . This happens in social media because information consumers are also producers— both explicitly via choices to post , comment or “ Like ” , and also implicitly via their behavioral traces recorded in system logs . What users learn about the system when they act as con- sumers can affect the choices they make as producers . For example , if I notice that particular Facebook posts created by a couple of Friends have received a lot of positive attention in the form of comments and “ Likes ” , I might ( consciously or unconsciously ) start creating posts with similar character- istics [ 40 ] . Algorithmic curation acts as a constraint on users ’ choices about what to pay attention to . Outsourcing curation to help users mitigate information overload and stay on top of things is not a new phenomenon , either . The first dictionaries were invented not to make sure everybody spelled words correctly and had a good vocabulary—it was actually to keep a list of all the words that people were using in all the different senses ( and spellings ) they appeared , so that people could un- derstand and communicate with each other better [ 19 ] . The Yellow Pages , bestseller lists , even ancient dictionaries can be thought of as curation of a sort , in that someone took charge of organizing and maintaining a collection of a particular type of information , for the consumption of others . A series of Facebook blog posts starting in 2013 describes ongoing changes to the News Feed to make it so that users are only shown the posts from their Friends that they should ‘ http : //www.thelateageofprint.org/201 1/10/17/algorithmic- literacies find most interesting , rather than thousands of new posts that could be displayed each time a user visits Facebook [ 4 ] . In effect , like the curators of the first dictionaries , Facebook has assumed the responsibility of determining which content users should see . These constraints are personalized for each user based on characteristics of the producers , consumers , and the content itself . As the users and content change over time , these constraints change along with them . We wondered whether algorithmic curation on Facebook might have effects that can be detected at the individual level . If so , this could be evidence of a feedback loop that could bias users ’ interactions on Facebook in directions they would not necessarily pursue if they had a more obvious choice . Face- book presents a unique opportunity to study this , because people know who many of their Friends are and have a list of them they can use to navigate their Friends ’ content . This directory—the Friend List—means it is theoretically possible to ask users to go looking for possible individual-level effects of algorithmic curation , and to answer questions about these effects . In this project , we asked respondents of our online sur- vey to visit the Timelines of a subset of their Facebook Friends—both those they selected as close friends and some that were randomly selected from their Friend Lists—and tell us whether they found any posts there that they did not re- member seeing in their News Feeds . We wondered whether the prevalence of missed posts would vary according to re- spondents ’ perceived closeness of their relationship with each Friend , and whether that would have any bearing on whether or not they were surprised at having missed posts from partic- ular people . Finally , we asked respondents to speculate about possible explanations for why they did not see post ( s ) from particular Friends in their News Feeds . We found that individuals are very likely to have missed posts from Friends in their News Feeds , regardless of how close they are with their Friends . Very active users who report accu- rate memories of the recency of Friends ’ latest posts still en- counter posts they have missed when visiting Friends ’ Time- lines . Feelings of surprise about missed posts , however , are generally reserved for missed posts from close Friends , in- dicating a kind of expectation violation . We relate these ex- periences of surprise to the reasons for which users believe they missed particular posts from Friends , and discuss the implication that surprising missed posts may be a symptom of a feedback loop resulting from algorithmic curation in the News Feed . RELATED WORK In a socio-technical system like Facebook , the information contributed through the normal course of users ’ actions is both input and output of the system . This means that the News Feed algorithm is a part of a feedback loop that shapes the diversity of information users have access to—and who they communicate with—on Facebook . Systems that use algorithmic curation to filter content to be consumed by users are conceptually and technically similar to recommender systems , with one important difference . In a recommender system viewing the recommendation is just the first step toward consumption . The user must then take some action ( e.g. , watch the movie , listen to the artist , buy the product , etc. ) . In social media curation , there is no rec- ommendation . The system displays some items and does not display others . To extrapolate this to Netflix , it would be as if the user sat down to watch a movie and instead of choosing one , had to go down the queue watching the recommended movies in order without seeing what else might be available . Algorithmic curation removes the ability to explicitly choose , and replaces it with inferences based on a user model that is developed from behavioral traces accumulated as people use the system over time . It is difficult to objectively measure effectiveness of and satis- faction with the system ’ s “ recommendations ” , because users aren ’ t explicitly making choices , and it is challenging to col- lect data about what content has actually been consumed ( read ) . Another complication is that even in the filtered stream , there will be some content items that users just aren ’ t interested in , and there is still just too much information for users to read all of it . At a behavioral level , we can often identify influences and effects of algorithmic curation only indirectly . One possible approach is to try to identify points of unexpected or surprising behavior within the system ; these often occur in conjunction with aspects of the system ’ s struc- ture that we do not yet understand [ 28 ] . In the related work below , we review literature about user at- tention in social media , preferences in recommender systems , and relationship maintenance on Facebook to provide context for our focus on using unseen posts as a potential indicator of unexpected system behavior . Attention and Posts Not Seen One of the main reasons for using algorithmic curation in a social media system is to help users cope with information overload . We know that there is too much information flying by in systems like Facebook and Twitter for users to possi- bly attend to it all , even if they wanted to . For example , we know that Twitter users seem to produce no more than about 40 tweets per day [ 20 ] , and that on average one ’ s friends are more active than they are . The larger one ’ s network , the more information is coming in , and this leads to a situation where the people one is following produce more content than users are willing to consume [ 25 ] . While people with larger networks tend to be more active users , this does not necessarily mean that they treat all in- coming content equally . Users tend to start at the top of the stream and work their way down , but as the volume of the feed goes up , the probability of retweeting a particular post [ 26 ] decreases . In addition , even when a Twitter user is “ over- loaded ” ( meaning they can not keep up with the stream ) , they prioritize tweets from a subset of sources for retweeting [ 20 ] . Studies like the above use behavioral trace data to infer atten- tion based on network connections , post and stream metadata , and also use re-sharing content as a proxy for attention . How- ever , this does not take into consideration the posts that users read and then do not interact with any further . Counts and Fisher [ 11 ] conducted an eye tracking study of users reading tweets from their own feed , and then measured memorabil- ity of the tweets . Participants remembered 69 % of the posts they had seen during the study , and tweets they had attended to for longer were more memorable for them . Also , partici- pants paid less attention to tweets from frequent tweeters , and remembered these tweets less . Taken together , these findings indicate that users are rate- limited in terms of their consumption of social media content , and that they do not divide their limited attention evenly . In- stead , they prefer content from some users over others , and become more discriminating and potentially biased toward particular information producers as the volume of the incom- ing stream increases . Feedback Loops in Algorithmic Curation Recommender systems depend on some way of measuring user preferences . More accurate data about preferences sup- ports making better recommendations . However , in situations of algorithmic curation , behavioral traces and network or tie strength data are often used as a proxy for preferences . This approach has merit : Sharma et al . [ 36 ] demonstrated that in terms of preferences for movies and music on Facebook and hashtag use on Twitter , users are more similar to their own networks than to random users . Recommender system designers must assume a relationship between past preferences and future preferences , because the past information is all the system has to go on when trying to figure out what people might want to see in the future . The assumption here is that preferences in the past are identical to future preferences ; that ’ s the easiest shortcut , and various in- vestigations have shown that preferences to tend to be stable over time ( i.e. , if I liked “ Star Wars ” the first time I rated it , I ’ m likely to give it a similar rating if I rated it again ) [ 13 ] . However , this assumption does not necessarily hold in social media systems where the timeframe for consumption of in- formation , or one ’ s awareness of how many other people have seen or posted it , changes the meaning or importance of the information itself . We know that ratings in recommender systems are vulnerable to bias and manipulation , having consequences for the abil- ity of the system to make effective recommendations [ 32 ] . Several research projects have found that seeing other users ’ ratings for an item influences subsequent ratings [ 2 , 10 ] . In addition , preferences and behavior in a socio-technical sys- tem are not independent , meaning that users influence both each other and the composition of the corpus of information in the system . If I give “ Star Wars ” a high rating , the assump- tion is that ’ s because I actually liked it , not because I want you to know that I liked it , or for some other social reason . It becomes very hard to interpret and make satisfactory rec- ommendations based on information that does not represent true preferences . However , this is often the case in social me- dia where communication takes place . For example , a recent paper by Cheng et al . [ 9 ] reports that negative feedback in response to comments and votes on news stories leads to a subsequent drop in post quality by the users who received the feedback , and also encourages more frequent posting activity and negative evaluations of others . Preferences can also be a result of the interaction between the recommendation and some other information the system is not privy to , which means it is difficult to make accurate predictions about what users want to see . In an investigation of social recommendations , Sharma et al . [ 35 ] found effec- tiveness of recommendations was based both on the nature of the user ’ s relationship with the endorser of the content ( e.g. , “ X and Y recommend this ” ) , but also other prior information or past experience . As these points illustrate , the circumstances under which al- gorithmic curation operates make it very difficult to make both effective and satisfactory recommendations : where users are both producers and consumers of information leading to a feedback loop that is vulnerable to artificial manipulation , and where the value and benefit gained from information is short-lived and influenced by the social context . Relationships on Facebook Keeping in touch with close social ties is one of the main rea- sons for using Facebook , and many have reported that using it has “ revived ‘ dormant ’ relationships ” [ 31 ] . Research on predictors of SNS use has found that individuals derive great enjoyment from learning about close friends ’ and acquain- tances ’ lives , with heavier users displaying more curiosity about how individuals from their pasts are faring , and how they may have changed [ 42 ] . A variety of affordances are associated with lower barriers to maintaining relationships in these contexts , such as the ability to perform actions such as “ Liking ” others ’ posted content , commenting , sending mes- sages , and posting direct messages to others ’ profile pages [ 7 , 16 , 41 ] . These actions can be used as a proxy for measuring “ social attention ” on Facebook , or how an individual chooses to focus their attention across their network . Our online and offline social networks are composed of re- lationships of varying strengths . Research on the variation of active ? network size revealed that across varying sizes of social networks , the distribution of closeness across ties is relatively similar [ 33 ] ; most individuals have a normal distri- bution of emotionally close relationships in their offline ac- tive social networks , with very few ties of very high or very low emotional closeness . Past research of online social net- works has suggested that the low barriers to adding Friends and maintaining relationships on many SNSs is associated with higher numbers of weak ties in individuals ’ online social networks [ 38 , 43 ] ; in past studies of Facebook Friend net- works , users have reported that they consider approximately 25-37 % of their Facebook Friends to be “ actual ” friends [ 15 , 16 ] . Backstrom et al . [ 5 ] found what they called “ churn ” across two time periods among Facebook users ’ most com- mon communication partners , meaning the distribution of at- tention among these ties was not the same from one time pe- riod to the next . “ Active ” relationships met three conditions : ( 1 ) they had contact information ; ( 2 ) they had been in contact within past year ; ( 3 ) they desire the relationship to continue [ 33 ] Relationships of different strengths in one ’ s online social net- work are related to varying kinds of benefits beyond the sat- isfaction of maintaining social relationships . Weak ties on Facebook , for example , have been empirically linked to per- ceived access to diverse information and resources within one ’ s network ( or bridging social capital ) [ 6 , 14 ] and receiv- ing useful responses to broadcasted questions to one ’ s net- work [ 21 ] . Strong ties , on the other hand , have also been asso- ciated with benefits such as aid with finding new employment after losing a job [ 6 ] , providing satisfying responses [ 21 ] and overall knowledge contributions [ 29 ] in response to broad- casted questions on Facebook . Both kinds of ties add value to the use of SNSs for users with varying needs and goals . Use of SNSs can also impact the strength of the relation- ships maintained in these contexts . Recent longitudinal re- search by Burke and Kraut [ 7 ] revealed that communicating with others on Facebook is related to increases in reported re- lational closeness , even when controlling for other kinds of non-Facebook communication , such as face-to-face interac- tion , phone calls , and email . All kinds of one-on-one com- munication led to increases in tie strength , with larger im- pacts of written communication ( e.g. , composed messages , direct posts , and comments ) over other kinds of signals ( e.g. , “ Likes ” ) [ 7 ] . Other recent research has also found that recent and more frequent communication on Facebook , as well as the use of more kinds of Facebook communication modes , predicts “ relational escalation , ” or an increase in tie strength [ 37 ] . METHOD In a typical recommender system , users are not aware of the bounds of the set of possible items that might be suggested to them . In information retrieval terms , there ’ s no way for users to assess the recall capabilities of the system because they don ’ t know what ’ s out there to choose from . However , Face- book users are typically Facebook Friends with individuals they already know offline [ 39 ] and may have a general sense of what and who should be represented in their News Feeds . Situations of incomplete system recall are much more likely to be noticed when the possibilities are all at least somewhat familiar . The content of each user ’ s News Feed is determined by an algorithm designed to show what the system believes is the most relevant to each user , based on behavioral traces such as , “ the number of comments , who posted the story , and what type of post it is ( ex : photo , video , status update ) ” [ 17 ] . By exposing users to Friends ’ content that was potentially not displayed in their News Feeds , we can investigate ques- tions such as , how likely are users to miss posts from indi- vidual Facebook Friends ? What role does closeness play— are users more likely to have noticed a missed post from a closer Friend ? How surprising is it to users to find out they have missed posts ? What explanations do they associate with missed posts from particular Friends ? We conducted an on- line survey to present respondents with a situation where they might notice one of the effects of implicit curation : visiting a Facebook Friend ’ s Timeline and noticing a post that they did not remember seeing in their News Feeds . To achieve this , we used the Qualtrics survey platform , and wrote custom JavaScript to integrate our survey with the Facebook API . After consenting to the study , respondents were prompted to log in to Facebook ( if they were not logged in already ) . The JavaScript Facebook app running on our server connected to the respondent ’ s Facebook pro- file and collected basic information , which it transferred into the Qualtrics survey : the names , profile photos and profile links of the respondent ’ s Facebook Friends . The survey then displayed a popup window with a list of all of the respon- dent ’ s Facebook Friends , and asked the respondent to select a handful of people they feel closest to * . After selecting close Friends , the popup window appeared again , this time popu- lated with 20 people randomly selected from the respondent ’ s Friend list , not including the close Friends they already se- lected . In both cases , they were instructed not to select Friends under the age of 18 , anyone they would feel uncomfortable answer- ing questions about , and any “ Friends ” that were not actually people ( e.g . pets , organizations , etc. ) . The app retained the same number of randomly selected Friends as close friends for inclusion in the survey , so both types would be evenly represented . The names and profile photos of the selected Friends , as well as links to the Friends ’ Timelines , were in- corporated into questions in the survey and then discarded when each respondent completed the survey . The survey included questions at two levels : some questions were about respondents , like their Facebook activity and de- mographics . The survey also included questions at the Friend level , like the respondent ’ s self-report of the closeness of their relationship with each Friend incorporated into the survey via the Facebook app . In the first section of the survey , respondents answered sep- arate questions about their memory for each Friend ’ s recent activity on Facebook , and how close they felt to each Friend . Then , they were asked to visit each Friend ’ s Facebook Time- line via a profile link collected by the Facebook app and em- bedded in the survey , and answer questions about Friends ’ actual posting behaviors . After visiting each Friend ’ s time- line , respondents were asked questions that make up the two main dependent variables in this study : - When you were scrolling through X ’ s Timeline , did you notice posts he or she created that you don ’ t remember seeing in your News Feed ? [ No , Yes ] - “ I feel surprised that I did not see X ’ s post ( s ) in my News Feed ” [ Strongly Disagree - Strongly Agree ] The next section of the survey included questions about re- spondents ’ own Facebook activity , and their beliefs and in- ferences about how the News Feed selects content to display . The final section asked questions about respondent demo- graphics . The text of survey questions and descriptive statis- tics are available in the Appendix . PARTICIPANTS 3The instructions were based on the survey in Burke and Kraut [ 7 ] . Respondents in the Qualtrics survey selected 4 close and 4 random Friends ; MTurk respondents selected 5 of each . Qualtrics MTurk Total N A475 464 Internet Literacy M=2.5 M=3.5 ( 0.92 ) ( 0.83 ) Men 177 274 Women 298 190 s About once/wk 6 8 = A few times/wk 30 32 ‘ E About once/day 50 63 f & Several times/day 389 361 « > Never 13 10 & Less than once/wk 125 170 3 About once/wk 61 89 8 A few times/wk 109 98 & About once/day 16 54 Several times/day 91 43 3 21-100 friends 173 114 -£ 101-300 friends 150 208 a 301-500 friends 85 83 = 501+ friends 67 59 Qualtrics = MTurk Friends in Survey 8 10 18-25 105 157 » 26-34 113 191 = 35-50 115 103 51-65 113 12 66-75 29 1 Some HS 22 9 & HS grad 130 63 = Vocational 35 31 = Some college 160 170 § College grad 94 161 Post-grad 34 30 Caucasian/White 412 372 African American 27 41 £ Native American 11 7 = Asian 23 40 & Pacific Islander 3 3 Hispanic/Latino 27 24 Other 7 1 Table 1 . A comparison of demographics between the two samples . We collected a first round of data using a panel recruited and maintained by Qualtrics , and a second round with Ama- zon Mechanical Turk ( MTurk ) workers . Respondents in both samples were not eligible to participate if they were younger than 18 , had 20 or fewer Facebook Friends , or visited Face- book less than once per week . The Qualtrics sample included an age quota : 30 % of respondents had to be older than 50 . For the MTurk sample , there was no age quota , but only workers from the USA who had a 90 % or higher approval rating af- ter completing at least 500 tasks were eligible . Five hundred thirty respondents from the Qualtrics sample finished the sur- vey , as did 505 MTurk respondents . We excluded cases from our analysis for several reasons . First , we excluded respondents who answered any of the “ at- tention check ” questions incorrectly , and incomplete cases on the variables we used for the analyses in this paper . We also excluded respondents from both samples who said they had “ Good ” or “ Full ” familiarity with a fake word that was part of the Internet Literacy index variable * . Finally , we excluded a small number of cases where MTurk respondents had sub- mitted nonsensical responses to the open-ended question , as well as several cases with different MTurk worker [ Ds that had virtually identical open-ended responses . We encountered an issue with the way the Qualtrics survey platform ’ s client-side JavaScript works—or rather does not work—in Internet Explorer , which resulted in some otherwise eligible respondents being unable to complete the survey cor- rectly . The Qualtrics survey platform heavily uses client-side JavaScript that works fine in most modern web browsers , but an interaction between Qualtrics ’ code and our Facebook app caused the Friend chooser to not operate correctly for some * The questions that comprise the Internet Literacy variable are based on the Web Use Skills survey reported in Hargittai and Hsieh [ 22 ] ) . It consists of the average of respondents ’ assessments of their famil- iarity with a list of Internet-related terms ( /=3.00 ; SD=0.99 , Cron- bach ’ s a=0.87 ) . The list of terms is available in the Appendix . respondents who tried to complete the survey using IE . This resulted in questions in the survey not populating correctly with Friend names , profile photos and profile links . We were able to detect when this happened , and exclude just those cases . The final size of the Qualtrics panel sample was 475 respon- dents , and for Mechanical Turk , 464 . The sample from the Qualtrics panel was more women ( 298 ) than men ( 177 ) , while the MTurk sample was more men ( 274 ) than women ( 190 ) . Qualtrics respondents had a lower mean Internet Literacy score ( M=2.54 , SD=0.92 ) than MTurk respondents ( M=3.48 , SD=0.83 ) . MTurk respondents were younger overall than Qualtrics respondents ( MTurk median = “ 26-34 ” , Qualtrics median = “ 35-50 ” ) . The education distribution was very sim- ilar across both samples . We combined these two samples into one dataset , which al- lowed us to analyze a sample of heavy Facebook users in the US that is much more valid than the typical convenience sample . We purposefully sampled for heavier users because we felt that we were already asking questions about some- thing respondents were not expected to have seen ( i.e . missed posts ) , and we wanted to have a best-case opportunity to en- counter respondents who had that experience . In addition , according to a report by the Pew Research Cen- ter ’ s Internet & American Life Project , the majority of Amer- ican Facebook users utilize the site at least once a day ( 63 % ) with at least 40 % checking the site several times per day [ 12 ] . Also , an analysis of Nielsen data from a nationally repre- sentative US household audience panel collected in March 2011 that involved measured computer usage ( not self-report ) found that Facebook users are more likely than non-users to be female , young ( 13-17 years old ) , white , and to have at least a high school diploma [ 44 ] . We feel that our sample is a reasonable approximation of these characteristics , with the caveat that users younger than 18 were ineligible for our survey . MEASURES In this section we describe the measures we used in the sur- vey , and our expectations for the analyses we conducted . Likelihood of Noticing a Missed Post The dependent variable notice.missing is a Friend-level vari- able , meaning that respondents answered the same question once for each Friend : “ When you were scrolling through X ’ s Timeline , did you notice posts he or she created that you don ’ t remember seeing in your News Feed ? [ No , Yes ] . ” Missed posts present an interesting opportunity to explore respon- dents ’ beliefs about how the News Feed chooses what to dis- play , and is also an inflection point that could indicate either a totally expected or a totally unexpected outcome for respon- dents . Ninety-three percent of respondents from the MTurk sample ( 433 of 464 ) noticed at least one missed post , as did 74 % ( 353 of 475 ) of respondents from the Qualtrics sample . Likelihood of SURPRISE at Noticing a Missed Post For each Friend respondents were asked questions about in our survey , if the respondent indicated that they saw on the Friend ’ s Timeline a post they had missed , we asked the re- spondent to indicate how surprised they were about this . Sur- prise is an indicator of an expectation violation . With this question , we wanted to elicit a reaction from each respon- dent that would indicate whether for this particular relation- ship , the system behavior met their expectations . The ques- tion was , “ I am surprised that I did not see X ’ s post ( s ) in my News Feed ” . Qualtrics respondents answered on a 1-7 Likert scale , strongly disagree to strongly agree . The same question in the MTurk survey used a 5-point scale ; therefore , we cen- tered both variables around their respective neutral values and scaled them so that they range from -1 to 1 , before combin- ing the samples into one dataset . We then collapsed these values into a categorical variable with three levels : Not Sur- prised ( values less than 0 ) , Neutral ( values equal to 0 ) , and Surprised ( values greater than 0 ) . Two hundred sixty-eight MTurk respondents ( 58 % ) experienced surprise at a missed post on at least one Friend ’ s Timeline , as did 216 Qualtrics respondents ( 45 % ) . Relationship Closeness Previous research has identified effects of Facebook commu- nication on the strength of users ’ relationships : the more peo- ple communicate with each other on Facebook , the closer they become , even controlling for other forms of interper- sonal communication online and offline [ 7 ] . We measured closeness using the “ Inclusion of Other in the Self Scale ” [ 3 ] , which is a 7 point scale that uses images of circles that do not overlap on the low end ( coded as 1 ) and move closer to each other until they almost completely overlap on the high end ( coded as 7 ) . The mean closeness for the “ close ” Friends respondents had specified via the Facebook app at the begin- ning of the survey was 4.38 ( SD=1.97 ) , and for the “ randomly selected ” Friends was 2.19 ( SD=1.60 ) . We explicitly sampled close Friends , instead of randomly se- lecting all the Friends asked about in the survey , because Facebook users have many more weak ties as Friends than strong ties . We expected closeness would be related both whether respondents noticed a missed post , and how sur- prised they were about it , and wanted to have sufficient varia- tion in the closeness variable to see these effects . We thought that whether respondents noticed a missed post would have an inverse relationship with closeness : respondents should be more likely to notice missed post from more distant Friends , because these are the posts that respondents would be least likely to spend their limited attention on . Conversely , we hy- pothesized that it would be more surprising for a respondent to find a post she had missed on a close Friend ’ s Timeline than a distant acquaintance ’ s . Manual Curation Behaviors We asked respondents to report whether they had ever done ( No , Yes ) a list of behaviors that can potentially influence whether or not particular posts appear in the News Feed . The actions included the following , and were presented in random order to each participant : Use sorting options for your News Feed ( e.g. , Top Stories , Most Recent , other Friend lists , etc . ) [ 507 Yes ] - Add someone to your Close Friends list [ 414 Yes ] Click “ Hide all ” to remove all stories from a person , page or group [ 460 Yes ] Click “ I don ’ t want to see this ” to hide a post [ 648 Yes ] “ Like ” a page [ 900 Yes ] - Turn OFF notifications for a page [ 500 Yes ] - Turn ON notifications for a Friend ’ s activity [ 319 Yes ] Unfollow a person [ 569 Yes ] UnFriend or block a person [ 792 Yes ] - “ Unlike ” a page [ 662 Yes ] The variable curation.behaviors is the count of the above ac- tions for which each respondent answered Yes . It ranges from 0 to 10 , with a median of 6 . Thirteen people from the Qualtrics sample had never done any of these behaviors . We expected that respondents who do a greater variety of man- ual curation behaviors would be more likely to experience missed posts . Respondents who are more active in curating their own feeds would likely be only seeing a subset of posts , determined by their own explicit curation actions . We also ex- pected that respondents who engage in more different manual curation behaviors—who take a more active role in deciding what posts they do and do not want to see—would be less surprised to find missed posts . Memory Compared with Reality We thought the accuracy of respondents ’ recollections about how recently their Facebook Friends had created posts might also be important for whether or not they noticed or were surprised by missed posts . If a respondent ’ s memory is in- accurate , we might expect that her judgment about whether posts from a Friend appeared in her News Feed would be less reliable than if she had remembered her Friend ’ s posting be- havior accurately . Also , we feel that this can be interpreted as a proxy for the amount of attention the respondent pays to a particular Friend ’ s posts , so we expected that respondents who had a fairly accurate recollection of when their Friends last posted would be more surprised to find missed posts . In the survey , we asked respondents to first estimate how re- cently they thought each Friend had last created a post , before looking at that Friend ’ s Timeline . Respondents then went to that Friend ’ s Timeline to see how recently he or she had ac- tually created a post . We coded the difference between these two responses as a categorical variable with three levels : the most recent post was either “ Older than the respondent re- membered ” , “ About what the respondent remembered ” , or “ Newer than the respondent remembered ” . The majority of respondents reported having accurate memory for when each Friend ’ s most recent post took place ( MTurk : 59 % , Qualltrics : 63 % ) . Demographics and Facebook Activity Three variables describe respondents ’ level of activity on Facebook in terms of how often they visit , post , and how many Facebook Friends they have . Visit frequency was mea- sured with the question , “ How often do you usually VISIT Facebook ? ” Respondents were also asked , “ How often do you usually POST to Facebook ? ” These categorical control variables were all included as numeric predictors in the re- gression models described below . Three additional variables are demographic controls : internet literacy , age , and gender . The Facebook activity and age variables were all centered at the median for both analyses , and the internet literacy variable was centered at the mean . This changes the interpretation of the intercepts in the regressions from “ all variables held at zero ” to “ all variables held at their median/mean ” . Finally , each regression model includes a categorical term indicating which sample each data point came from , MTurk or Qualtrics . Table 1 presents the values for each of these variables , for both samples . RESULTS We used regression analysis to investigate the relationship between the measures described above and two dependent variables : whether or not a respondent noticed a missed post when visiting the Timeline of a Facebook Friend , and if the missed post surprised them . The predictors in both models are identical , and allow us to answer questions about how important closeness with the Friend is for the occurrence of missed posts and surprise , controlling for subject-level dif- ferences like level of Facebook activity , demographics , and which sample they were a part of . Closeness Did Not Matter for Missed Posts We used binary logistic regression to identify influences on the likelihood of a respondent noticing a post that he ( or she ) had not seen in the News Feed , when visiting the Timelines of specific Friends . The dataset consists of multiple responses from each respondent , one per Friend selected at the begin- ning of the survey . We chose not to use a multilevel model , and instead pooled across respondents so that we could use measured variables to control for individual differences such as age , gender , Facebook activity , etc . The regression results are presented in Table 2 . The Intercept in this model ( -1.29 , SE=0.07 ) represents the log odds of noticing missed posts by men from the MTurk sample who remembered their Friend ’ s last post being more recent than it actually was , and who are at the median on manual curation behaviors , Facebook visit and post frequency and age , and of average internet literacy . When the Intercept is exponentiated and transformed into a probability , we find that there is a 22 % chance these respondents would say YES , they missed posts from a particular Friend . Contrary to our expectations , closeness had no distinguish- able effect on the likelihood of experiencing a missed post ( OR=1.002 ) and was not statistically significant ( 95 % CI [ 0.98 , 1.03 ] ) . This means that whether or not a respondent noticed a missed post was not meaningfully related to how close the respondent is to each Friend . Also , the number of different manual curation behaviors respondents used to con- trol what they see in their News Feeds had only a very small positive and statistically significant effect on the dependent variable ( OR=1.03 ) . This means that for every additional manual curation behavior type that respondents reported us- ing , the odds of noticing a missed post increase by a factor of 1.03 ( 95 % CT [ 1.00,1.05 ] ) . The two largest effects were Facebook visit frequency ( OR=0.85 ) and memory accuracy ( OR Older|Accurate=1.09 ; OR Older|Newer=2.25 ) . This means that respondents who visit Facebook more often are LESS likely to notice missed posts on their Friends ’ Timelines , and if a Friend ’ s most re- cent post is newer than the respondent remembered they are MORE likely to notice a missed post on the Friend ’ s Time- line . Both of these results make intuitive sense : a person who visits Facebook many times during the day is likely to be ex- posed to a greater variety of posts than someone who , say , only visits Facebook on the weekends . Also , a recent post that is newer than the respondent remembered is either an in- dication of a post the respondent didn ’ t attend to or wasn ’ t shown . The practical significance of these effects is easier to under- stand as the percent likelihood of particular outcomes occur- ring . If auser visits Facebook about once per week , and views a Friend ’ s Timeline whose last post is older than she remem- bered , these results say there is a 31 % chance that she will notice a post that she had not seen in her News Feed ( see the predicted probabilities generated from the regression model , in Figure 1 ) . However , if she visits Facebook several times per day , and she accurately remembers when her Friend last posted , there ’ s a 23 % chance she will notice a post she hadn ’ t seen in your News Feed . The magnitude of this effect sur- prised us—this means that even for frequent Facebook users and the Friends whose posts they attend to , there was still a 1 in 5 chance that visiting that Friend ’ s Timeline will reveal a missed post . Greater Closeness is Associated with More Surprise We used an ordered multinomial logistic regression to esti- mate the likelihood of a respondent experiencing surprise at a missed post , with a dataset that included only the Friends notice.missing surprise No = 6105 No = 912 Yes = 2335 Neutral = 461 Yes = 962 Model Term Coef . SE OR Coef . SE OR Variable Info Intercept No-Yes -1.286 * * * ( 0.072 ) 0.276 -0.490 * * * ( 0.121 ) 0.613 No-Neutral Intercept 0.382 * * ( 0.121 ) 1.465 Neutral-Yes Intercept closeness ( F ) 0.002 ( 0.012 ) 1.002 0.189 * * ( 0.021 ) 1.208 Median = 3 , Range = 1-7 memory : accurate ( F ) 0.095 ( 0.071 ) 1.099 -0.304 * « ( 0.119 ) 0.738 n ( all ) =5097 , n ( missed ) =1244 memory : newer post ( F ) 0.813 * * * ( 0.080 ) 2.254 -0.129 ( 0.130 ) 0.879 n ( all ) =1889 , n ( missed ) =747 curation behaviors 0.025 * ( 0.011 ) 1.025 0.021 ( 0.018 ) 1.021 Median = 6 , Range = 1-10 FB visit frequency -0.166 * * * ( 0.040 ) 0.847 0.208 ( 0.064 ) = 1.232 Median = “ Several times per day ” FB post frequency 0.049 « * ( 0.019 ) 1.050 0.070 * ( 0.031 ) 1.073 Median = “ A few times per week ” # of Facebook Friends 0.040 ( 0.026 ) 1.040 -0.011 ( 0.042 ) 0.989 Median = “ 101-300 Friends ” internet literacy 0.190 * * * ( 0.030 ) 1.209 -0.148 * ( 0.048 ) 0.863 Mean = 3.14 , SD = 0.99 age 0.002 ( 0.025 ) 1.002 0.034 ( 0.041 ) 1.035 Median = “ 26-34 ” gender : woman 0.000 ( 0.053 ) 1.000 -0.097 ( 0.085 ) 0.907 men = 451 , women = 488 sample : Qualtrics -0.077 ( 0.061 ) 0.926 0.611 * * ( 0.099 ) 1.842 Qualtrics = 475 , MTurk = 464 AIC 9710.70 4712.43 Pseudo-F ? 0.027 0.047 Dataset All Missed Posts Total N 8440 friends 2335 friends Signif . codes : 0 “ * * * ’ 0.001 * * * 0.01 * * 0.05 ° ” 0.1 ° ” 1 Table 2 . Regression results for notice.missing and surprise . The intercept coefficients represent the log odds of a male MTurk respondent moving up one category ( e.g. , from No to Yes ) in the dependent variable , when a Friend with whom he reports median closeness had last posted longer ago than he remembered . All other variables are centered at the median , except for internet literacy , which is centered at the mean . OR = Odds Ratio . ( F ) = friend level variable . Pseudo-R ? is McFadden ’ s . | | Longer ago than memory T T T T About once per week Afew times per week About once per day Several times per day Facebook Visit Frequency Accurate memory More recent than memory ° Predicted Probability ° 2 1 0.04 Figure 1 . Predicted probability of noticing a missed post when visiting a Friend ’ s timeline , by Facebook visit frequency and accuracy of respon- dents ’ memories for when the Friend ’ s most recent post was created . for whom each respondent had noticed a missed post . This model has the same set of predictors as the previous one . The Facebook activity and demographics variables are likewise centered at the median , except for internet literacy which is centered at the mean . There are three potential outcomes for the dependent variable in this regression : “ Not Surprised ( No ) ” , “ Neutral ” , and “ Sur- prised ( Yes ) ” . The conceptual equivalent of the intercept in a binary logistic regression is to calculate the predicted proba- bilities of this model holding all other variables at the refer- ence categories ( Man , MTurk , “ Longer ago than memory ” ) , and 0 for the centered Facebook activity and demographic variables . We find that under those conditions , there is a 38 % chance that a respondent will report “ Not Surprised ” , a 21 % chance that they would report “ Neutral ” , and a 40 % chance that they would be surprised at noticing a missed post from a Friend of closeness 3 ( the median level of closeness ) . As expected , closeness had a fairly large , positive , statisti- cally significant relationship ( 0.189 , SE=0.021 ) with the like- lihood of feeling surprised at a missed post . For every one point increase in closeness , the odds of moving up one cate- gory ( No to Neutral , or Neutral to Yes ) increase by a factor of 1.21 . Respondents who reported feeling closer to a particular Facebook Friend were indeed more surprised to find missed posts . Surprisingly , the number of different manual curation behaviors respondents engaged in had only a small positive effect that was not statistically significant ( 0.021 , SE=0.018 ) . We had expected that using more different ways to curate one ’ s News Feed would result in less surprise , because re- spondents would be more engaged and invested in making surprise * No= Neutral # Yes Longer ago than memory - = T a a ca x - ma a ” w Accurate memory More recent than memory 5 Predicted Probability a 6 ° i } # 6 2 4 6 2 Closeness ( 1=lowest , 7=highest ) Figure 2 . Predicted probability of a Qualtrics respondent being sur- prised about a missed post , by closeness and accuracy of the respon- dent ’ s memories for when the Friend ’ s most recent post was created . sure some posts appear and others do not . The likelihood of experiencing surprise about a missed post was less for those respondents who had accurate memory for when their Friend ’ s last post took place ( -0.304 , SE=0.119 ) , and also for respondents whose Friend ’ s last post was newer than he or she remembered ( compared with the Intercept , which represents Friends for whom the most recent post was older than the respondent remembered ) . This was contrary to our predictions . Believing that one ’ s friend posted longer ago than they actually did is an indication that the respondent is not attending closely to the respondent ’ s posts , which we had thought would be acknowledged by respondents register- ing less surprise . However , it seems that more attention was associated with less surprise at missed posts . The predicted probabilities in Figure 2 illustrate this pattern . This graph shows the predicted probability for a man from the Qualtrics sample feeling surprise at a missed post , for each level of memory accuracy and closeness , and all other variables held at the mean or median . At the low end of close- ness , the likelihood of surprise is 53 % for a respondent with accurate memory for when the Friend ’ s most recent post took place . For the median level of closeness ( 3 ) , that increases to 62 % , and for Friends of closeness 7 , the probability of sur- prise at a missed post jumps to 78 % . Said another way , our results indicate that if a user visits four close friends ’ time- lines and finds posts he did not see in his News Feed , for three of those friends this will come as a surprise . Agreement with Explanations for Missed Posts In the MTurk survey , respondents rated their agreement with a series of possible explanations for why they thought they missed these posts . The reasons came from a bottom-up anal- ysis of a subset of responses to an open-ended question in the Qualtrics survey asking “ Do you ever feel like you are miss- ing posts from Friends in your News Feed ? If so , why do you think this happens ? If not , why not ? ” These reasons we iden- tified included ( 1=Strongly Disagree , 5=Strongly Agree ) : - I don ’ t spend a lot of time going through my News Feed ( dont.spend.time , M=2.31 , SD=1.12 ) - I don ’ t scroll down to see older posts in my News Feed ( dont.scroll.down , M=2.46 , SD=1.21 ) - I don ’ t always read every post when I browse my News Feed ( dont.read.every.post , M=3.06 , SD=1.26 ) - I ’ ve previously used the News Feed settings to hide posts from X ( hid.Friends.posts , M=1.70 , SD=1.05 ) - There are so many posts from X that I don ’ t always see every one ( too.many.posts , M=2.55 , SD=1.29 ) - Facebook doesn ’ t show me posts like this in the News Feed ( dont.see.posts.like.this , M=2.50 , SD=1.10 ) - Ido not interact ( comment , like , share ) with X ’ s posts very often ( dont.interact.w.posts , M=3.29 , SD=1.32 ) - Facebook must think I don ’ t want to see X ’ s posts ( fb.not.interesting , M @ =3.06 , SD=1.22 ) X is not popular enough on Facebook for me to see all of his or her posts ( Friend.not.popular , M=2.27 , SD=1.06 ) Facebook thinks X and I are not good Friends ( fb.not.close , M=2.97 , SD=1.23 ) - I didn ’ t see it because I wasn ’ t tagged in it ( not-tagged , M=2.60 , SD=1.17 ) - The post is too new for me to have seen it yet ( post.too.new , M=2.05 , SD=1.15 ) Figure 3 plots the mean agreement with each explanation against the level of surprise reported by respondents for each Friend , with a different line representing each level of closeness . The highest mean agreement overall was for dont.interact.w.posts , “ I do not interact ( comment , like , share ) with X ’ s posts very often ” . Means for Friends of close- ness 1 or 2 ( the low end of the closeness scale ) are clearly higher than all other levels of closeness . “ Facebook thinks X and I are not good Friends ” ( fb.not.close ) showed a similar pattern . This difference makes sense , because both of these explanations draw on different ways to represent closeness of the respondent ’ s relationship with his or her Friend . There was a slight upward trend for Friends of closeness 4- 7 ( the high end of the closeness scale ) on fb.not.close , in- dicating that if they missed a post from a close Friend and were surprised about it , they agreed more with the explana- tion that the News Feed did not show the post because the system had inferred they are not good Friends . This seems to be an acknowledgement from respondents that the News Feed algorithm is working to shape their experiences on Facebook based on relationship closeness . Likewise , slight agreement with the explanation “ Facebook must think I don ’ t want to see X ’ s posts ” ( fb.nor . interesting ) represents an understanding on the part of the respondent that Facebook is choosing to show some posts and not others . A very slight downward trend for dont.interact.w.posts , “ I do not interact ( comment , like , share ) with X ’ s posts very often ’ , indicates that for some levels of closeness respondents who were more surprised about missed posts thought their level of interaction with posts from that person was not a good ex- planation for why the posts didn ’ t appear in the News Feed . This could indicate that one ’ s interaction history with a par- ticular Friend is not a good proxy for the closeness construct we measured in the survey . Respondents commonly agreed with the explanation , “ I don ’ t always read every post when I browse my News Feed ” ( dont.read.every.post ) at lower levels of surprise , whereas closeness —1 -- 2— ' 3 . 4 5 -- 6—7 fb.not.close dont.interact.w.posts . fb.not.interesting friend.not.popular Lot= Sn '' o vo = aatTETESS it || 47 chy te oa oy gw Zn|| . —~ 7 / ~ ¢ dont.see.posts.like.this|| dont.read.every.post hid . friends.posts dont.scroll.down te ! 5 y 7 , || pares , aml = dont.spend.time x 4 eee valle oo . post.too.new o N Ps , “ 7 Ny too.many.posts . Mean Agreement with Explanation » / 3 ) AS he ea ! a5 een , | pA PRG , | ERS | . ae : 247 es ealecA ba Bem lf / 7 410 05 00 05 1010 05 00 05 1010 05 00 05 1010 05 00 05 10 Level of Surprise : < O = Not Surprised , O=Neutral , > O = Surprised Figure 3 . Means for respondent agreement with the “ Reasons why you might have missed post ( s ) ” questions . The scale ranged from “ Strongly Disagree ” ( 1 ) to “ Strongly Agree ” ( 5 ) . The x-axis shows level of surprise at having missed a post from each Friend , and each line represents a different level of reported closeness with each Friend ( 1=low , 7=high ) . when surprise was high they disagreed with this explanation . This indicates that missed posts due to inattention seemed more plausible to respondents when they were not surprised , than when they were . It seems like it would be easy for re- spondents to just assume they must have skipped over a post they feel like they didn ’ t really want to see anyway ; however , for posts they felt like they wanted to see but did not , this ex- planation would not be sensible . This pattern is evidence for the idea that the feeling of surprise at a missed post might be an indicator of an unexpected system behavior . Finally , agreement was universally low for “ I ’ ve previ- ously used the News Feed settings to hide posts from X ” ( hid.Friends.posts ) , indicating that most of the time respon- dents believed it was NOT their own action that caused the particular post not to appear . Agreement was also low across all levels of closeness for “ The post is too new for me to have seen it yet ” ( post.too.new ) , which was a check we used to make sure respondents weren ’ t answering these questions in response to posts that had been created while they were com- pleting the survey . Limitations Our survey asked respondents only a Yes or No question about whether there was a post on their Friend ’ s Timeline that they didn ’ t remember seeing in their News Feeds . We didn ’ t ask respondents to count how many posts they missed , nor for any data about the posts themselves , because we were sensitive to the privacy of the Friends of our respondents . So , we can ’ t make any claims about characteristics of posts that are more or less likely to be attended to by users or filtered by the News Feed algorithm , or how many posts users missed . Also , we can ’ t say whether the missed posts actually did not display in the News Feed . A respondent might have read 10 a post and forgotten about it , or skipped some posts while scrolling , or not scrolled down far enough to see them . How- ever , it is also possible that they were not displayed at all . We can not disambiguate these potential explanations for why respondents perceived that posts were missed . DISCUSSION Up to now , we have been careful to refer to posts as “ missed ” rather than “ missing ” , to avoid judgments about agency or cause when reporting our results . Posts could have been missed by respondents because they did not attend to or re- member them , or because they were never displayed in the News Feed . However , we feel that because closeness had no bearing on whether respondents missed posts , but had a strong relationship with the likelihood of experiencing sur- prise at encountering one of these posts , we can reasonably conceptualize these two kinds of situations differently from each other . Missed vs. missing is an interesting distinction that the surprise dependent variable allows us to make . Some missed posts were not surprising for respondents ; these are the ones that Facebook says in their blog users probably don ’ t want to see anyway . These are the situations where , if in fact these posts were hidden , the News Feed algorithm is working as expected [ 4 ] . We conceptualize the posts respondents were surprised they didn ’ t remember seeing in their News Feeds as “ missing ” rather than missed , because that feeling is a clue that an ex- pectation violation has occurred . We know that understand- ing the behavior of systems is very hard for human beings , because people tend to use heuristics to interpret cause and effect that assume only one thing happens at a time and ev- erything they know about happens in order [ 28 ] . Surprising outcomes tend to signal that people don ’ t understand the in- fluences on a system ’ s behavior . We opened this paper wondering about whether algorithmic curation on Facebook might have effects that can be detected at the individual level . Assume for a moment that a feedback loop exists here , and that users are missing at least a few posts from close friends that they feel like they should have seen . Overall , at the system level , this is likely not a problem . Users are still contributing content , and their Friends are still seeing posts . But what about individual-level outcomes ? Assuming that respondents were being honest when they answered the survey questions and that they did indeed miss posts and feel more surprise about missed posts from closer friends , we be- lieve missing posts might signal a system-level pattern in the News Feed that has undesirable individual-level outcomes . We know that people use Facebook for maintaining relation- ships , for reconnecting and keeping up with those they care about . However , there are reasons why it might make sense that a curation algorithm might not prioritize posts from peo- ple users feel closest to . Although individuals are capable of growing closer by way of communicating on Facebook , there is also research to suggest that close ties are not only communicating on Facebook . In a study of distance learn- ers , Haythornthwaite [ 23 ] found that stronger ties between pairs were associated with the use of more different media to communicate whereas weaker ties were associated with the use of fewer communication media . This work was later ex- tended to friend relationships by Ledbetter [ 27 ] who found that increased use of different kinds of online and offline com- munication media helped to predict levels of interdependence between friends . The communication of stronger ties across myriad channels bears potentially significant implications for personalization algorithms that rely on behavioral traces and interactions to prioritize relevant content to users . Users may be communi- cating more with certain Friends in other channels , rendering the appearance of their relational strength with these friends to be similar to weak ties on Facebook for whom Facebook may be their only mode of communication . The News Feed ’ s algorithm may not have enough information about users ’ be- haviors outside of the platform to accurately predict who is deemed more important to see represented in the News Feed than others . Communication on Facebook is both output from and input to the News Feed algorithm . Burke and Kraut [ 7 ] provided very strong evidence that communication on Facebook , as opposed to other channels , impacts the strength of users ’ relationships . If a part of the News Feed algorithm uses a behavioral proxy for closeness in determining which posts to display , this could have significant consequences for real relationships . We be- lieve the closeness result might be a symptom of a feedback loop—a filter bubble for relationships—that has the potential to affect who people are close to . In essence : if I don ’ t see your posts , I won ’ t be reminded to communicate with you on Facebook . If I don ’ t communicate with you on Facebook , the News Feed will think we aren ’ t close friends . If the News Feed thinks we are not close friends , it won ’ t show me your posts . The behavioral traces , which are all Facebook has to go on when inferring the strength of friendships , go away . “ Missing ” posts become “ missed ” . But because filtering is invisible , on a post-by-post basis it is hard for users to be aware that this is happening . One strategy for overcoming the filter bubble ( also es- poused by Pariser in his information diet metaphor [ 30 ] ) is to include some “ preference-inconsistent ” information , to reduce confirmation bias . In the News Feed , that might look like occasionally bringing back posts from people users—or the algorithm—have previously hidden . However , Schwind et al . [ 34 ] found that when given the choice , par- ticipants preferred choosing preference-consistent arguments over preference-inconsistent ones to read more about . To gen- eralize this to the News Feed , it seems like the preference- inconsistent posts would be the ones the users would be most likely to skip over or choose to hide . Also , this tweak would have system-level effects too , just different ones ! We are not trying to argue that the News Feed is broken and that it should show users everything their friends post . Rec- ommender systems and algorithmic curation are a necessary and beneficial part of the infrastructure of a socio-technical system . But , at the same time , because filtering is invisible , users don ’ t know the extent to which their choices are con- strained so they can ’ t help the system self-correct . Cosley et al . [ 10 ] and others have found that users of recommender systems have some sensitivity for deliberately incorrect or manipulated ratings . Without some reason to go looking for missed posts , what is there for users to suspect ? This is a difficult tension for designers of socio-technical systems to navigate . Our advice based on this work is that designers of socio- technical systems should develop conceptual and functional requirements both at the individual and system level , and that involve interactions among all the parts of the system : human , technology , and information . Then , do periodic testing to find out whether both levels of outcomes fall within expectations . This testing must be repeated , because it is only possible to see these patterns as they develop over time . The Facebook News Feed is an instructive case study , but algorithms make decisions that constrain user behavior in a wide variety of socio-technical systems , from search engines to self-driving cars . As researchers , we must develop new socio-technical systems theory and methods that will help practitioners de- velop tools and metrics to accomplish this task . ACKNOWLEDGMENTS We thank Rick Wash and Scott Rucinski for javascript inte- gration of the Facebook API with the Qualtrics survey ; and the MSU BITLab research group for feedback on the survey questions and helpful conversations . This material is based upon work supported by the National Science Foundation un- der Grant No . IIS-1217212 . REFERENCES 1 . Adamic , L. A. , and Glance , N. The Political Blogosphere and the 2004 U.S. Election : Divided They Blog . In Proceedings of the 3rd international workshop on Link discovery , ACM ( 2005 ) , 36-43 . 2 . Adomavicius , G. , Bockstedt , J. C. , Curley , S. P. , and Zhang , J . Do Recommender Systems Manipulate Consumer Preferences ? A Study of Anchoring Effects . Information Systems Research 24 , 4 ( Dec. 2013 ) , 956-975 . 3 . Aron , A. , Aron , E. N. , and Smollan , D. Inclusion of Other in the Self Scale and the Structure of Interpersonal Closeness . Journal of personality and social ... 63 , 4 ( 1992 ) , 596-612 . 4 . Backstrom , L. News Feed FYI : A Window Into News Feed . https : //www.facebook.com/business/news/News-Feed-FY I-A-Window- Into-News-Feed , Aug. 2013 . 5 . Backstrom , L. , Bakshy , E. , Kleinberg , J. , Lento , T. M. , and Rosenn , I . Center of Attention : How Facebook Users Allocate Attention Across Friends . JCWSM 201 ] ( 2011 ) , 34-41 . 6 . Burke , M. , and Kraut , R. Using Facebook after Losing a Job : Differential Benefits of Strong and Weak Ties . In CSCW 7/3 : Proceedings of the 2013 conference on Computer supported cooperative work ( June 2013 ) , 1419-1430 . 7 . Burke , M. , and Kraut , R. Growing Closer on Facebook : Changes in Tie Strength Through Social Network Site Use . In CHI ’ 14 ( Jan. 2014 ) , 1-10 . 8 . Cass R. Sunstein . Infotopia : How Many Minds Produce Knowledge . Oxford University Press , 2006 . 9 . Cheng , J. , Danescu-Niculescu-Mizil , C. , and Leskovec , J . How Community Feedback Shapes User Behavior . In JCWSM ( 2014 ) , 1-10 . 10 . Cosley , D. , Lam , S. K. , Albert , . , Konstan , J . A. , and Riedl , J . Is seeing believing ? : how recommender system interfaces affect users ’ opinions . In CHI ’ 03 ( Ft. Lauderdale , Florida , USA , 2003 ) , 585-592 . 11 . Counts , S. , and Fisher , K. Taking It All In ? Visual Attention in Microblog Consumption . In JCWSM 20/1 ( Apr . 2011 ) , 1-8 . 20 . 21 . 22 . 23 . 24 . 25 . 26 . 27 . 28. . Duggan , M. , and Smith , A . Social Media Update 2013 . Tech . rep. , Pew Research Center , Dec. 2013. . Ekstrand , M. D. , Reidl , J. T. , and Konstan , J . A. Collaborative Filtering Recommender Systems . Foundations and Trends in Human-Computer Interaction 4 , 2 ( 2010 ) , 81-173. . Ellison , N. B. , Lampe , C. , Steinfield , C. , and Vitak , J . With a little help from my Friends : Social network sites and social capital . In A networked self : Identity , community and culture on social network sites , Z. Papacharissi , Ed . Routledge , New York , NY , June 2010 , 124-125. . Ellison , N. B. , Steinfield , C. , and Lampe , C. Connection strategies : Social capital implications of Facebook-enabled communication practices . New Media & Society 13 , 6 ( June 2011 ) , 873-892. . Ellison , N. B. , Vitak , J. , Gray , R. , and Lampe , C. Cultivating Social Resources on Social Network Sites : Facebook Relationship Maintenance Behaviors and Their Role in Social Capital Processes . Journal of Computer-Mediated Communication ( 2014 ) , n/a-n/a . . Facebook . How News Feed Works : Facebook Help Center . https : //www.facebook.com/help/327131014036297/ , 2014. . Gilbert , E. , Bergstrom , T. , and Karahalios , K. Blogs Are Echo Chambers : Blogs Are Echo Chambers . In HICSS 2009 ( 2009 ) . . Gleick , J . The Information : a History , a Theory , a Flood . Pantheon , 2011 . Gomez-Rodriguez , M. , Gummadi , K. P. , and Scholkopf , B. Quantifying Information Overload in Social Media and its Impact on Social Contagions . In JCWSM ( 2014 ) , 1-10 . Gray , R. , Ellison , N. B. , Lampe , C. , and Vitak , J . Who wants to know ? Question-asking and answering practices among Facebook users . In Proceedings of the 2013 Conference on computer supported cooperative work and social computing ( June 2013 ) , 1213-1224 . Hargittai , E. , and Hsieh , Y. P. Succinct Survey Measures of Web-Use Skills . Social Science Computer Review 30 , 1 ( 2011 ) , 95-107 . Haythornthwaite , C. Social networks and Internet connectivity effects . Information , Communication & Society 8 , 2 ( June 2005 ) , 125-147 . Hill , W. C. , Hollan , J. D. , Wroblewski , D. , and McCandless , T. Edit wear and read wear . In Proceedings of the SIGCHI conference on Human factors in computing systems - CHI ’ 92 , ACM Press ( New York , New York , USA , 1992 ) , 3-9 . Hodas , N. O. , Kooti , F. , and Lerman , K. Friendship Paradox Redux : Your Friends Are More Interesting Than You . In JCWSM 7/3 ( Apr . 2013 ) , 1-9 . Hodas , N. O. , and Lerman , K. How Visibility and Divided Attention Constrain Social Contagion . In Socia/Com 2012 , IEEE ( 2012 ) , 249-257 . Ledbetter , A. M. Patterns of media use and multiplexity : Associations with sex , geographic distance and friendship interdependence . New Media & Society 11 , 7 ( June 2009 ) , 1187-1208 . Meadows , D. H. Thinking in Systems : A Primer . Chelsea Green Publishing , 2008 . 12 29 . 30 . 31 . 32 . 33 . 34 . 35 . 36 . 37 . 38 . 39 . 40 . Al , 42 . 43 . 44 , Panovich , K. , Miller , R. C. , and Kraut , R. Tie strength in question & answer on social network sites . In Proceedings of the ACM 2012 conference on Computer Supported Cooperative Work - CSCW 12 ( June 2012 ) , 1057-1066 . Pariser , E. The Filter Bubble : What the Internet is Hiding from you . Penguin Press HC , The , 2011 . PewResearch Internet Project . Social Networking Fact Sheet . http : //www.pewinternet.org/fact-sheets/social-networking-fact-sheet/ , 2013 . Resnick , P. , and Sami , R. The Influence Limiter : Provably Manipulation-Resistant Recommender Systems . In RecSys ’ 07 ( 2007 ) , 25-32 . Roberts , S. G. B. , Dunbar , R. L M. , Pollet , T. V. , and Kuppens , T. Exploring variation in active network size : Constraints and ego characteristics . Social Networks 31 , 2 ( May 2009 ) , 138-146 . Schwind , C. , Buder , J. u. r. , and Hesse , F. W. I Will Do It , but I Don ’ t Like It : User Reactions to Preference-Inconsistent Recommendations . In CHI 2011 ( 2011 ) , 349-352 . Sharma , A. , and Cosley , D. Do Social Explanations Work ? Studying and Modeling the Effects of Social Explanations in Recommender Systems . In WWW 7/3 ( 2013 ) , 1133-1143 . Sharma , A. , Gemici , M. , and Cosley , D. Friends , Strangers , and the Value of Ego Networks for Recommendation . In JCWSM 713 ( 2013 ) , 721-724 . Sosik , V. S. , and Bazarova , N. N. Relational maintenance on social network sites : How Facebook communication predicts relational escalation . Computers in Human Behavior 35 ( June 2014 ) , 124-131 . Steinfield , C. , Ellison , N. B. , and Lampe , C. Social capital , self-esteem , and use of online social network sites . Journal of Applied Developmental Psychology 29 ( June 2008 ) , 434-445 . Subrahmanyam , K. , Reich , S. M. , Waechter , N. , and Espinoza , G. Online and offline social networks . Journal of Applied Developmental Psychology 29 , 6 ( Nov. 2008 ) , 420-433 . Sukumaran , A. , Vezich , S. , McHugh , M. , and Nass , C. Normative influences on thoughtful online participation . In Proceedings of the 2011 annual conference on Human factors in computing systems , ACM ( 2011 ) , 3401-3410 . Tong , S. T. , and Walther , J . B. Relational Maintenance and CMC . Computer-mediated communication in personal relationships ( June 2011 ) , 98-118 . Tufekci , Z. GROOMING , GOSSIP , FACEBOOK AND MYSPACE . Information , Communication & Society 11 , 4 ( June 2008 ) , 544-564 . Vitak , J. , and Ellison , N. B . ’ There ’ s a network out there you might as well tap ” . New Media & Society 15 , 2 ( June 2013 ) , 243-259 . Wells , T. , and Link , M. Facebook User Research Using a Probability-Based Sample and Behavioral Data . Journal of Computer Mediated Communication ( Jan. 2014 ) , n/a—n/a . APPENDIX Sample Information Qualtrics Sample N =475 respondents , 3800 Friends Date collected : 2014-04-02 — 2014-04-07 MTurk Sample N = 464 respondents , 4640 Friends Date collected : 2014-04-16 — 2014-04-21 Instructions LOG_IN_TO_FACEBOOK First , verify that you are logged in to Face- book , and allow access to your Friend list . If you are already logged in to Facebook , your name should appear in BOLD text below . If not , please click the `` Log In ” button and enter your username and password in the window that appears . Then , click `` Okay ” to allow the survey to use a Facebook app to access your Friend list . At the end of this survey , you will be provided instructions for removing the application . Even if you do not remove it , it will not do anything once you have completed the survey . Please note : if you do not approve the application , you are not eligible to complete the survey . You are currently logged in to Facebook as < RESPONDENT > . [ Click here ] to change the account you are using . -OR- You are not currently logged into Facebook . [ Facebook Log In button ] SELECT_CLOSE_FRIENDS Next , select 5 close friends . Who are the people you feel closest to ? This might include people you dis- cuss important matters with , really enjoy socializing with , or anyone else you feel especially close to . Select exactly 5 people . Please do not select any friends who are under the age of 18 , or any names that do NOT represent actual friends ( businesses , pets , etc. ) . [ Click here ] to select close friends . SELECT_RANDOM_FRIENDS Now , review friends selected by the sur- vey . Next , we will show you some of your Facebook friends , that you did not already select . These friends have been randomly selected by the survey . Please click to deselect any friends who you do NOT want to answer ques- tions about . Also , please deselect friends who are under the age of 18 , and any names that do NOT represent actual friends ( businesses , pets , etc. ) . [ Click here ] to review randomly chosen friends . 13 Survey Questions and Descriptives CLOSENESS How close do you feel to X ? Close Random QUALTRICS M=4.54 , SD=2.14 M=2.28 , SD=1.76 MTURK M=4.25 , SD=1.81 M=2.11 , SD=1.44 LAST_POST_ESTIMATE ( Friend-level ) How recently would you esti- mate was the last time X posted on Facebook , without looking at his or her Timeline ? QUALTRICS Within the past day 1131 Within the past week but not within the past day 1046 Within the past month but not within the past week 620 More than a month ago 482 Not at all 203 I don ’ t know 318 MTURK Today < Date > 672 Yesterday < Date > 995 Within the past week ( < Day > , < Date > ) , but not yes- 1448 terday or today More than a week ago , but within the past month ( since 673 < Day > , < Date > ) More than a month ago 552 I don ’ t know 300 WHEN-POSTED_ACTUAL ( Friend-level ) How recently did X create a post ? Please note : this does not include instances when * other * friends posted on X ’ s Timeline ; only when X him or herself posted or instances in which X changed their profile or cover photo . QUALTRICS Today 891 Yesterday 632 Within the past week but not as recently as yesterday 963 Not at all within the past week 1314 MTURK Today < Date > 905 Yesterday < Date > 828 Within the past week ( < Day > , < Date > ) , but not yes- 1272 terday or today More than a week ago , but within the past month ( since 718 < Day > , < Date > ) More than a month ago 846 I don ’ t know 71 NOTICE.MISSING ( Friend-level ) When you were scrolling through X ’ s Timeline , did you notice posts he or she created that you don ’ t remember seeing in your News Feed ? QUALTRICS Yes 965 No 2835 MTURK Yes 1370 No 3270 SURPRISED ( Friend-level ) HOW_OFTEN-VISIT_FB How often do you usually VISIT Facebook ? QUALTRICS : How much do you agree with the statement , “ I feel surprised that I did not see X ’ s post ( s ) in my News Feed ” ? about ones per day times per day 00 Strongly agree ( 1 ) 125 A few times per week 240 Agree ( 2 ) 142 About once per week 48 Somewhat agree ( 3 ) 230 Neither agree nor disagree ( 4 ) 207 Somewhat disagree ( 5 ) 96 MTURK Several times per day 3610 Disagree ( 6 ) 116 About once per day 630 Strongly disagree ( 7 ) 49 A few times per week 320 NA ’ s 2835 About once per week 80 MTURK : Please indicate your level of agreement from “ Strongly disagree ” to “ Strongly agree ” : I am surprised that I did not see X ’ s post ( s ) in my News Feed . POST_FREQUENCY How often do you usually POST to Facebook ? ( status updates , links , photos , videos , or other content ) Strongly agree ( 5 ) 112 - Agree ( 4 ) 353 Several times per day 1158 Neither agree nor disagree ( 3 ) 254 About once per day 1148 Disagree ( 2 ) 430 A few times per week 1852 Strongly disagree ( 1 ) 92 ] About once per week 1378 NA ’ s 3270 Less than once per week 2700 Never 204 REASONS_MISSED_POSTS ( MTurk only ) Below are the possible rea- sons why you might have missed post ( s ) on Facebook from X . Please indicate your level of agreement from “ Strongly disagree ” to “ Strongly agree ” . EVER_DONE_CURATION_BEHAVIORS Have you ever done any of the following actions ? Check all that apply . vo Es s a vo “ < 3 g g > 2 z 2 2 g a ] bb @ 5 3 = > gs ze s & g Ss & 4 Z a & Unfriend or block a person 7166 = =1274 7 7 Unfollow a person 5230 3210 Idon ’ t spend a lot of time going through 9358 533 224 208 47 “ Unlike ” a page 6042 2398 my News Feed . Turn OFF notifications for a page 4566 3874 I don ’ t scroll down to see older posts in 343 482 « 185 294 66 Click “ I don ’ t want to see this ” to hide a post 5890 2550 my News Feed Click “ Hide all ” to remove all stories froma 4208 4232 I don ’ t always read every post whenI 209 285 227 507 142 person , page or group , browse my News Feed Turn ON notifications for a Friend ’ s activity 2882 5558 I ’ ve previously used the News Feed set- 813 333 94 86 44 Add someone to your Close Friends list 3708 4732 tings to hide posts from X “ Like ” a page 8110 330 There are so many posts from X thatI 345 428 209 271 117 Use sorting options for your News Feed ( e.g. , 4560 3880 don ’ t always see every one . Top Stories , Most Recent , other friend Facebook doesn ’ t show me posts like 271 487 317 246 49 lists , etc . ) this in the News Feed None of the above 104 8336 Ido not interact ( comment , like , share ) 169 280 179 471 271 with X ’ s posts very often Facebook must think Idon ’ t wanttosee 189 282 298 463 138 X ’ s posts X is not popular enough on Facebook 356 534 269 179 32 for me to see all of his or her posts Facebook thinks X and I are not good §=213 289 « 331 = 402— 135 friends Ididn ’ t see it because I wasn ’ t taggedin 295 378 334 309 54 it The post is too new forme tohave seen 542 491 115 170 52 it yet 14 INTERNET_LITERACY How familiar are you with the following ETHNICITY What is your ethnicity ? Internet-related terms ? Please rate your familiarity with each term below from None ( no understanding ) to Full ( full understanding ) : What is your ethnicity ? ( Check all that apply . ) Cau- 784 casian/White African American 68 QUALTRICS Native American 18 Asian 63 v v uv 3 + 5 8 E 3 3 Pacific Islander 6 42 4 4 oO & Hispanic/Latino 51 Wiki 113 62 77 113° 110 Other 8 Netiquette 281 51 53 45 45 Phishing 138 67 89 85 96 Bookmark 49 32 77 117 200 EDUCATION What is the last grade or class you completed in school ? Cache 105 85 « 98 98 89 SSL 288 80 57 31 19 None , or grades 1-8 0 AJAX 401 37 24 6 7 Some high school 31 Filtibly 413 , 34-28 0 0 High school graduate or GED certificate 193 Technical , trade , or vocational school AFTER high 66 school Some college , no 4-year degree 330 MTURK Four-year college degree 255 2 8 zs 3 = Post-graduate training or professional school after col- 64 ° =a oO 9° 3 lege Zz 4 “ A Oo a 8 Wiki 8 8 47 139° 262 Netiquett 127 50 63 101 123 Phishing ° 23 38 91 132 . 180 INCOME Last year , how much was your household income , before taxes ? Bookmark 11 5 20 97 331 Less than $ 10,000 85 Cache 21 39 86 157 161 $ 10,000 to less than $ 20,000 124 SSL 99 107 107 78 73 $ 20,000 to less than $ 30,000 141 AJAX 281 94 47 21 21 Filtibl 303 46 25 0 0 $ 30,000 to less than $ 40,000 135 ey $ 40,000 to less than $ 50,000 108 $ 50,000 to less than $ 75,000 184 $ 75,000 to less than $ 100,000 91 $ 100,000 or more 70 GENDER What is your gender ? Man 451 Woman 488 15\n",
            "Total number of tokens: 385888\n",
            "Length of token dictionary: 24268\n",
            "    Token     TF\n",
            "62    the  20492\n",
            "65     of  14408\n",
            "3     and  10958\n",
            "8      to   9505\n",
            "95     in   6717\n",
            "53      a   6368\n",
            "153  that   4852\n",
            "52     is   4454\n",
            "61    for   3508\n",
            "22     on   3316\n",
            "128    as   2776\n",
            "25    The   2768\n",
            "233  with   2411\n",
            "75    are   2269\n",
            "171    we   1930\n",
            "----------------------stemming--------------------\n",
            "Total number of tokens after stemming words: 385078\n",
            "Length of token dictionary after  stemming: 13656\n",
            "    Token     TF\n",
            "25    the  23390\n",
            "61     of  14486\n",
            "3     and  11159\n",
            "8      to   9768\n",
            "90     in   8102\n",
            "52      a   7146\n",
            "138  that   4924\n",
            "51     is   4546\n",
            "58    for   3968\n",
            "22     on   3449\n",
            "118    as   3127\n",
            "123  user   3031\n",
            "151    we   2669\n",
            "36    thi   2613\n",
            "199  with   2473\n",
            "----------------------------stop words removal-------------------------\n",
            "Total number of tokens after removing stop words: 228760\n",
            "Length of token dictionary after removing stop words: 23910\n",
            "            Token    TF\n",
            "163   information  1834\n",
            "153         users  1709\n",
            "101        social  1419\n",
            "367         media  1368\n",
            "111          user  1185\n",
            "135        filter  1092\n",
            "2342       search  1039\n",
            "229        bubble   872\n",
            "354          news   803\n",
            "358     political   741\n",
            "129       content   738\n",
            "1073         data   738\n",
            "359          also   728\n",
            "126       results   714\n",
            "13             et   697\n",
            "----------------------------case_folding-------------------------\n",
            "Total number of tokens after stemming: 385078\n",
            "Length of token dictionary after stemming: 19668\n",
            "    Token     TF\n",
            "25    the  23390\n",
            "61     of  14486\n",
            "3     and  11158\n",
            "8      to   9768\n",
            "91     in   8102\n",
            "52      a   7146\n",
            "143  that   4924\n",
            "51     is   4546\n",
            "58    for   3968\n",
            "22     on   3447\n",
            "121    as   3127\n",
            "160    we   2669\n",
            "36   this   2613\n",
            "214  with   2473\n",
            "71    are   2294\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "898BrQ-3NOMO",
        "outputId": "21371503-0022-4df7-8944-b908e092f248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ]
}